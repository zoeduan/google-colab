{
  "title": "Position Engineering: Boosting Large Language Models through Positional Information Manipulation",
  "authors": [
    "Zhiyuan He",
    "Huiqiang Jiang",
    "Zilong Wang",
    "Yuqing Yang",
    "Luna Qiu",
    "Lili Qiu"
  ],
  "abstract": "\n The performance of large language models (LLMs) is significantly influenced by the quality of the prompts provided. In response, researchers have developed enormous prompt engineering strategies aimed at modifying the prompt text to enhance task performance. In this paper, we introduce a novel technique termed position engineering, which offers a more efficient way to guide large language models. Unlike prompt engineering, which requires substantial effort to modify the text provided to LLMs, position engineering merely involves altering the positional information in the prompt without modifying the text itself. We have evaluated position engineering in two widely-used LLM scenarios: retrieval-augmented generation (RAG) and in-context learning (ICL). Our findings show that position engineering substantially improves upon the baseline in both cases. Position engineering thus represents a promising new strategy for exploiting the capabilities of large language models. \n",
  "references": [
    {
      "id": null,
      "title": "Position Engineering: Boosting Large Language Models through Positional Information Manipulation",
      "authors": [
        "Zhiyuan He",
        "Huiqiang Jiang",
        "Zilong Wang",
        "Yuqing Yang",
        "Luna Qiu",
        "Lili Qiu"
      ],
      "year": "2024",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Semantic parsing on Freebase from question-answer pairs",
      "authors": [
        "Jonathan Berant",
        "Andrew Chou",
        "Roy Frostig",
        "Percy Liang"
      ],
      "year": "2013",
      "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Language models are few-shot learners",
      "authors": [
        "B Tom",
        "Benjamin Brown",
        "Nick Mann",
        "Melanie Ryder",
        "Jared Subbiah",
        "Prafulla Kaplan",
        "Arvind Dhariwal",
        "Pranav Neelakantan",
        "Girish Shyam",
        "Amanda Sastry",
        "Sandhini Askell",
        "Ariel Agarwal",
        "Gretchen Herbert-Voss",
        "Tom Krueger",
        "Rewon Henighan",
        "Aditya Child",
        "Daniel M Ramesh",
        "Jeffrey Ziegler",
        "Clemens Wu",
        "Christopher Winter",
        "Mark Hesse",
        "Eric Chen",
        "Mateusz Sigler",
        "Scott Litwin",
        "Benjamin Gray",
        "Jack Chess",
        "Christopher Clark",
        "Sam Berner",
        "Alec Mccandlish",
        "Ilya Radford",
        "Dario Sutskever",
        "Amodei"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "Cesare Campagnano, Yoelle Maarek, Nicola Tonellotto, and Fabrizio Silvestri. 2024. The power of noise: Redefining retrieval for rag systems",
      "authors": [
        "Florin Cuconasu",
        "Giovanni Trappolini",
        "Federico Siciliano",
        "Simone Filice"
      ],
      "year": "",
      "venue": "Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '24",
      "doi": "10.1145/3626772.3657834"
    },
    {
      "id": "b3",
      "title": "Transformer-XL: Attentive language models beyond a fixed-length context",
      "authors": [
        "Zihang Dai",
        "Zhilin Yang",
        "Yiming Yang",
        "Jaime Carbonell",
        "Quoc Le",
        "Ruslan Salakhutdinov"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P19-1285"
    },
    {
      "id": "b4",
      "title": "Longrope: Extending llm context window beyond 2 million tokens",
      "authors": [
        "Yiran Ding",
        "Li Lyna Zhang",
        "Chengruidong Zhang",
        "Yuanyuan Xu",
        "Ning Shang",
        "Jiahang Xu",
        "Fan Yang",
        "Mao Yang"
      ],
      "year": "2024",
      "venue": "Longrope: Extending llm context window beyond 2 million tokens",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "Mathematical capabilities of chatgpt",
      "authors": [
        "Simon Frieder",
        "Luca Pinchetti",
        "Ryan-Rhys Griffiths",
        "Tommaso Salvatori",
        "Thomas Lukasiewicz",
        "Philipp Petersen",
        "Julius Berner"
      ],
      "year": "2024",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "Retrieval augmented language model pre-training",
      "authors": [
        "Kelvin Guu",
        "Kenton Lee",
        "Zora Tung",
        "Panupong Pasupat",
        "Ming-Wei Chang"
      ],
      "year": "2020",
      "venue": "Proceedings of the 37th International Conference on Machine Learning, ICML 2020",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "Toward semantics-based answer pinpointing",
      "authors": [
        "Eduard Hovy",
        "Laurie Gerber",
        "Ulf Hermjakob",
        "Chin-Yew Lin",
        "Deepak Ravichandran"
      ],
      "year": "2001",
      "venue": "Proceedings of the First International Conference on Human Language Technology Research",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Unsupervised dense information retrieval with contrastive learning",
      "authors": [
        "Gautier Izacard",
        "Mathilde Caron",
        "Lucas Hosseini",
        "Sebastian Riedel",
        "Piotr Bojanowski",
        "Armand Joulin",
        "Edouard Grave"
      ],
      "year": "2021",
      "venue": "Unsupervised dense information retrieval with contrastive learning",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "",
      "authors": [
        "Alexandre Albert Q Jiang",
        "Arthur Sablayrolles",
        "Chris Mensch",
        "Devendra Bamford",
        "Diego Singh Chaplot",
        "Florian De Las Casas",
        "Gianna Bressand",
        "Guillaume Lengyel",
        "Lucile Lample",
        "Saulnier"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension",
      "authors": [
        "Mandar Joshi",
        "Eunsol Choi",
        "Daniel Weld",
        "Luke Zettlemoyer"
      ],
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P17-1147"
    },
    {
      "id": "b11",
      "title": "Large language models struggle to learn long-tail knowledge",
      "authors": [
        "Nikhil Kandpal",
        "Haikang Deng",
        "Adam Roberts",
        "Eric Wallace",
        "Colin Raffel"
      ],
      "year": "2023",
      "venue": "International Conference on Machine Learning",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Dense passage retrieval for opendomain question answering",
      "authors": [
        "Vladimir Karpukhin",
        "Barlas Oguz",
        "Sewon Min",
        "Patrick Lewis",
        "Ledell Wu",
        "Sergey Edunov",
        "Danqi Chen",
        "Wen-Tau Yih"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.18653/v1/2020.emnlp-main.550"
    },
    {
      "id": "b13",
      "title": "Large language models are zero-shot reasoners",
      "authors": [
        "Takeshi Kojima",
        "Shane Shixiang",
        "Machel Gu",
        "Yutaka Reid",
        "Yusuke Matsuo",
        "Iwasawa"
      ],
      "year": "2022",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "A 176bparameter open-access multilingual language model",
      "authors": [
        "Le Teven",
        "Angela Scao",
        "Christopher Fan",
        "Ellie Akiki",
        "Suzana Pavlick",
        "Daniel Ilić",
        "Roman Hesslow",
        "Alexandra Castagné",
        "François Sasha Luccioni",
        "Matthias Yvon",
        "Gallé"
      ],
      "year": "2023",
      "venue": "A 176bparameter open-access multilingual language model",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "Latent retrieval for weakly supervised open domain question answering",
      "authors": [
        "Kenton Lee",
        "Ming-Wei Chang",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P19-1612"
    },
    {
      "id": "b16",
      "title": "Retrieval-augmented generation for knowledge-intensive NLP tasks",
      "authors": [
        "S H Patrick",
        "Ethan Lewis",
        "Aleksandra Perez",
        "Fabio Piktus",
        "Vladimir Petroni",
        "Naman Karpukhin",
        "Heinrich Goyal",
        "Mike Küttler",
        "Wen-Tau Lewis",
        "Tim Yih",
        "Sebastian Rocktäschel",
        "Douwe Riedel",
        "Kiela"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Learning question classifiers",
      "authors": [
        "Xin Li",
        "Dan Roth"
      ],
      "year": "2002",
      "venue": "COLING 2002: The 19th International Conference on Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Lost in the middle: How language models use long contexts",
      "authors": [
        "Kevin Nelson F Liu",
        "John Lin",
        "Ashwin Hewitt",
        "Michele Paranjape",
        "Fabio Bevilacqua",
        "Percy Petroni",
        "Liang"
      ],
      "year": "2024",
      "venue": "Transactions of the Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "Eureka: Human-level reward design via coding large language models",
      "authors": [
        "Jason Yecheng",
        "William Ma",
        "Guanzhi Liang",
        "De-An Wang",
        "Osbert Huang",
        "Dinesh Bastani",
        "Yuke Jayaraman",
        "Linxi Zhu",
        "Anima Fan",
        "Anandkumar"
      ],
      "year": "2023",
      "venue": "Eureka: Human-level reward design via coding large language models",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "When not to trust language models: Investigating effectiveness of parametric and non-parametric memories",
      "authors": [
        "Alex Mallen",
        "Akari Asai",
        "Victor Zhong",
        "Rajarshi Das",
        "Daniel Khashabi",
        "Hannaneh Hajishirzi"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2023.acl-long.546"
    },
    {
      "id": "b21",
      "title": "Crosslingual generalization through multitask finetuning",
      "authors": [
        "Niklas Muennighoff",
        "Thomas Wang",
        "Lintang Sutawika",
        "Adam Roberts",
        "Stella Biderman",
        "Teven Le Scao",
        "M Saiful Bari",
        "Sheng Shen",
        "Zheng Xin Yong",
        "Hailey Schoelkopf",
        "Xiangru Tang"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2023.acl-long.891"
    },
    {
      "id": "b22",
      "title": "YaRN: Efficient context window extension of large language models",
      "authors": [
        "Bowen Peng",
        "Jeffrey Quesnelle",
        "Honglu Fan",
        "Enrico Shippole"
      ],
      "year": "2024",
      "venue": "The Twelfth International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "Train short, test long: Attention with linear biases enables input length extrapolation",
      "authors": [
        "Ofir Press",
        "Noah A Smith",
        "Mike Lewis"
      ],
      "year": "2022",
      "venue": "The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "Mathematical discoveries from program search with large language models",
      "authors": [
        "Alexander Barekatain",
        "Matej Novikov",
        "M Pawan Balog",
        "Emilien Kumar",
        "Francisco Jr Dupont",
        "Jordan S Ruiz",
        "Pengming Ellenberg",
        "Omar Wang",
        "Fawzi"
      ],
      "year": "2024",
      "venue": "Nature",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "Simple entity-centric questions challenge dense retrievers",
      "authors": [
        "Christopher Sciavolino",
        "Zexuan Zhong",
        "Jinhyuk Lee",
        "Danqi Chen"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2021.emnlp-main.496"
    },
    {
      "id": "b26",
      "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
      "authors": [
        "Richard Socher",
        "Alex Perelygin",
        "Jean Wu",
        "Jason Chuang",
        "Christopher D Manning",
        "Andrew Ng",
        "Christopher Potts"
      ],
      "year": "2013",
      "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Gaussian process optimization in the bandit setting: No regret and experimental design",
      "authors": [
        "Niranjan Srinivas",
        "Andreas Krause",
        "M Sham",
        "Matthias W Kakade",
        "Seeger"
      ],
      "year": "2010",
      "venue": "Proceedings of the 27th International Conference on Machine Learning (ICML-10)",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Roformer: Enhanced transformer with rotary position embedding",
      "authors": [
        "Jianlin Su",
        "Murtadha Ahmed",
        "Yu Lu",
        "Shengfeng Pan",
        "Wen Bo",
        "Yunfeng Liu"
      ],
      "year": "2024",
      "venue": "Neurocomputing",
      "doi": ""
    },
    {
      "id": "b29",
      "title": "Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models",
      "authors": [
        "Hugo Touvron",
        "Thibaut Lavril",
        "Gautier Izacard",
        "Xavier Martinet",
        "Marie-Anne Lachaux",
        "Timothée Lacroix",
        "Baptiste Rozière",
        "Naman Goyal",
        "Eric Hambro"
      ],
      "year": "",
      "venue": "Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "2023b. Llama 2: Open foundation and fine-tuned chat models",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava",
        "Shruti Bhosale"
      ],
      "year": "",
      "venue": "2023b. Llama 2: Open foundation and fine-tuned chat models",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "Attention is all you need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan N Gomez",
        "Lukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Fei Xia",
        "Ed Chi",
        "V Quoc",
        "Denny Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b33",
      "title": "Large language models are human-level prompt engineers",
      "authors": [
        "Yongchao Zhou",
        "Andrei Ioan Muresanu",
        "Ziwen Han",
        "Keiran Paster",
        "Silviu Pitis",
        "Harris Chan",
        "Jimmy Ba"
      ],
      "year": "2022",
      "venue": "NeurIPS 2022 Foundation Models for Decision Making Workshop",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Position Engineering: Boosting Large Language Models Through Positional Information Manipulation",
      "text": "Zhiyuan He, Huiqiang Jiang, Zilong Wang, Yuqing Yang, Luna Qiu, Lili Qiu Microsoft Research {zhiyuhe,hjiang,wangzilong,yuqyang,lunaqiu,liliqiu}@microsoft.com"
    },
    {
      "title": "Abstract",
      "text": "The performance of large language models (LLMs) is significantly influenced by the quality of the prompts provided. In response, researchers have developed enormous prompt engineering strategies aimed at modifying the prompt text to enhance task performance. In this paper, we introduce a novel technique termed _position engineering_, which offers a more efficient way to guide large language models. Unlike prompt engineering, which requires substantial effort to modify the text provided to LLMs, position engineering merely involves altering the positional information in the prompt without modifying the text itself. We have evaluated position engineering in two widely-used LLM scenarios: retrieval-augmented generation (RAG) and in-context learning (ICL). Our findings show that position engineering substantially improves upon the baseline in both cases. Position engineering thus represents a promising new strategy for exploiting the capabilities of large language models."
    },
    {
      "title": "1 Introduction",
      "text": "Recent advancements in Large Language Models (LLMs) have demonstrated significant strides towards achieving artificial general intelligence. These models exhibit a wide range of capabilities, such as in-context learning Brown et al. (2020), answering questions based on documents Lewis et al. (2020); Guu et al. (2020), solving complex mathematical problems Frieder et al. (2024), and generating code Romera-Paredes et al. (2024); Ma et al. (2023). When utilizing LLMs, user prompts are inputted, converted into sequences of tokens, and then processed through multiple attention layers Vaswani et al. (2017). These attention layers employ two types of information derived from the token sequences: (i) Semantic information, where the tokens are converted into text embeddings, and (ii) Positional information, where the indices of the tokens are converted into positional embeddings Vaswani et al. (2017); Su et al. (2024). The attention mechanism then combines the semantic and positional information to predict the distribution of the next token in the sequence. Extensive research has been conducted on modifying prompt text to alter semantic information, aiming to boost task performances. For instance, few-shot prompting is introduced, enabling LLMs to learn new tasks in an in-context manner Brown et al. (2020). Moreover, the Chain-of-Thought methodology has been introduced to enhance LLMs' reasoning abilities by prompting them to produce intermediate tokens Wei et al. (2022); Kojima et al. (2022). Additionally, Automatic Prompt Engineer has been developed to autonomously design the prompting text for better task-specific performance Zhou et al. (2022). In this study, we investigate the potential of improving performance by solely modifying po Figure 1: Comparison of prompt engineering and position engineering. “Para” refers to paragraphs, and “Sent” to sentences in prompts. Prompt engineering involves either adding, replacing, or removing paragraphs and sentences from prompts. In contrast, the proposed position engineering maintains the original prompt text but incorporates placeholder tokens instead. These placeholders are not involved in the computation of attention scores, thus the computation overhead is not increased. However, they do hold position indices, thereby affecting the position information of other tokens in the text. sitional information, without any semantic information change. For the first time, we reveal that downstream task performance can be significantly enhanced by simply adjusting the positional indices of tokens, without modifying the text itself. As illustrated in Figure 1, our approach involves the introduction of placeholder tokens to modify positional information. These placeholder tokens do not contribute to the computation of attention scores; however, they do occupy token indices. Consequently, the relative position of other tokens is altered, which could optimize the attention weights among different segments within the prompts. We refer to this approach as _position engineering_, highlighting the exclusive focus on manipulating positional information. We propose a simple yet effective method based on brutal force to discover the optimal placeholder token number for each downstream task, and experiment it within two prevalent scenarios of LLMs: Retrieval-Augmented Generation (RAG) and InContext Learning (ICL). Our method significantly enhances performance in both tasks, achieving up to a 15.4% absolute increase in accuracy for RAG and a 3.6% absolute increase for ICL. We also discover that the same placeholder number can consistently improves the RAG's performance for different datasets and models. In all, our contributions can be summarized as follows: * For the first time, we discover that different downstream tasks' performances can be improved by merely changing the positional information in prompts. * We propose a method to help find a better positional information setting. * We demonstrate that RAG performance can be consistently improved by a universal positional information setting on different datasets and models."
    },
    {
      "title": "2 Methodology",
      "text": ""
    },
    {
      "title": "Preliminary",
      "text": "In this section, we provide a brief overview of how large language models (LLMs) integrate position information. Let \\(\\{t_{i}\\}_{i=1}^{N}\\) represent the input tokens to language models, and let \\(\\{\\mathbf{e}_{i}\\}_{i=1}^{N}\\) denote the corresponding token embeddings. Initially, the attention layer computes \\(\\mathbf{q},\\mathbf{k},\\mathbf{v}\\): \\[\\begin{split}\\mathbf{q}_{m}&=f_{q}(\\mathbf{e}_{m},m )\\\\ \\mathbf{k}_{n}&=f_{k}(\\mathbf{e}_{n},n)\\\\ \\mathbf{v}_{n}&=f_{v}(\\mathbf{e}_{n},n)\\end{split} \\tag{1}\\] where \\(m\\) and \\(n\\) are the position indices of tokens. The self-attention is then calculated as follows: \\[\\begin{split} a_{m,n}&=\\frac{e^{\\frac{\\mathbf{q}_{m} ^{\\text{T}}\\mathbf{k}_{n}}{\\sqrt{d}}}}{\\sum_{j=1}^{N}e^{\\frac{\\mathbf{q}_{m}^{ \\text{T}}\\mathbf{k}_{j}}{\\sqrt{d}}}}\\\\ \\mathbf{o}_{m}&=\\sum_{n=1}^{N}a_{m,n}\\mathbf{v}_{n} \\end{split} \\tag{2}\\] where \\(a_{m,n}\\) is a scalar capturing the attention score between \\(m\\)-th token in the query and \\(n\\)-th token in the value and key sets. \\(d\\) denotes the dimension of the attention layer, and \\(o_{m}\\) indicates the output for the \\(m\\)-th query token. Absolute positioning is initially introduced by incorporating a positional embedding vector \\(\\mathbf{p}_{n}\\), which is related to \\(m\\) and \\(n\\)(Vaswani et al., 2017): \\[\\begin{split} f_{q}(\\mathbf{e}_{m},m)&=\\mathbf{W}_{ q}(\\mathbf{e}_{m}+\\mathbf{p}_{m})\\\\ f_{k}(\\mathbf{e}_{n},n)&=\\mathbf{W}_{k}(\\mathbf{e }_{n}+\\mathbf{p}_{n})\\\\ f_{v}(\\mathbf{e}_{n},n)&=\\mathbf{W}_{v}(\\mathbf{e }_{n}+\\mathbf{p}_{n})\\end{split} \\tag{3}\\] The \\(2i\\) and \\(2i+1\\) dimension of the positional embedding \\(\\mathbf{p}_{n}\\) is calculated as follows: \\[\\begin{split}\\mathbf{p}_{n,2i}&=sin(n/10000^{\\frac {2i}{d}})\\\\ \\mathbf{p}_{n,2i+1}&=cos(n/10000^{\\frac{2i}{d}})\\end{split} \\tag{4}\\] Recently, RoPE adopts the relative position information instead of the absolute information (Su et al., 2024). It utilizes a specifically designed matrix \\(\\mathbf{R}_{i}^{d}\\), of dimensions \\(d\\times d\\) and parameterized by \\(i\\), to modify the query and key vectors in the following manner: \\[\\begin{split} f_{q}(\\mathbf{e}_{m},m)&=\\mathbf{R}_{ m}^{d}\\mathbf{W}_{q}\\mathbf{e}_{m}\\\\ f_{k}(\\mathbf{e}_{n},n)&=\\mathbf{R}_{n}^{d} \\mathbf{W}_{k}\\mathbf{e}_{m}\\\\ f_{v}(\\mathbf{e}_{n},n)&=\\mathbf{W}_{v}\\mathbf{e} _{n}\\end{split} \\tag{5}\\] The matrix \\(\\mathbf{R}_{i}^{d}\\) has a unique property, namely \\((\\mathbf{R}_{i}^{d})^{\\text{T}}\\mathbf{R}_{j}^{d}=\\mathbf{R}_{j-i}^{d}\\), which leads to: \\[\\mathbf{q}_{m}^{\\text{T}}\\mathbf{k}_{n}=\\mathbf{e}_{m}\\mathbf{W}_{q}\\mathbf{R }_{n-m}^{d}\\mathbf{W}_{k}\\mathbf{e}_{n} \\tag{6}\\] Consequently, in Equation (2), the model solely focuses on the relative position \\(n-m\\), instead of the absolute positions \\(n\\) and \\(m\\). RoPE has been adopted by recent LLMs, including Llama2 and Mistral (Touvron et al., 2023, 2023)."
    },
    {
      "title": "Altering Position Information In Prompts",
      "text": "The performance of LLMs is significantly influenced by the quality of the prompts used. To enhance the effectiveness of these prompts, researchers have developed a wide range of prompt engineering strategies. This refinement process involves transforming the initial input tokens \\(\\{t_{i}\\}_{i=1}^{N}\\) into revised inputs \\(\\{\\widehat{t_{j}}\\}_{j=1}^{\\bar{N}}\\), which necessitates modifications to the text. For instance, the Zero-shot chain-of-thought technique enhances the reasoning abilities of LLMs by appending the sentence \"Let's think step by step.\" to the prompts Kojima et al. (2022). In this paper, we propose a novel methodology termed \"position engineering\" to further exploit the capabilities of LLMs. Unlike prompt engineering, position engineering requires no modification to the input tokens themselves. Instead, it solely modifies the position information utilized in Equation (1). Through empirical experiments, we have discovered that such adjustments to position information can significantly improve performance. Formally, we aim at discovering a position editing function, \\(\\tau(\\cdot):\\mathbb{N}\\rightarrow\\mathbb{N}\\), that boosts LLM performance. This function changes the token position information, which is incorporated into the model as shown below: \\[\\widehat{\\mathbf{q}_{m}} =f_{q}(\\mathbf{e}_{m},\\tau(m)) \\tag{7}\\] \\[\\widehat{\\mathbf{k}_{n}} =f_{k}(\\mathbf{e}_{n},\\tau(n))\\] \\[\\widehat{\\mathbf{v}_{n}} =f_{v}(\\mathbf{e}_{n},\\tau(n))\\] We impose a condition on \\(\\tau\\) that \\(\\forall i>j,\\tau(i)>\\tau(j)\\). This requirement ensures that: (1) No two distinct tokens are assigned the same new position index, and (2) The causality in language modeling remains intact, meaning only query vectors with a larger index can access the key and value vectors with an equal or smaller index. The concept of position engineering can be also explained through placeholder tokens. Placeholder tokens are defined as tokens that are excluded the computation of attention scores, yet they are allocated position indices. To elaborate, when the calculation of \\(a_{m,n}\\) is undertaken as described in the Equation (2), and either the \\(m\\)-th or \\(n\\)-th token is identified as a placeholder, the conventional computation is bypassed, and \\(a_{m,n}\\) is set to \\(0\\). While placeholder tokens do not directly influence the attention scores at their positions, they do alter the position indices of other input tokens. As depicted in Figure 0(b), the insertion of placeholder tokens between sentences 1 and 2 affects the relative positional information between them, which in turn influences the calculation of attention scores between tokens of the two sentences. The connection between the position editing function and the placeholder tokens can be described as follows: Employing a position editing function \\(\\tau\\) translates to adding \\(\\tau(i+1)-\\tau(i)-1\\) placeholder tokens after the \\(i\\)-th token, and specifically, adding \\(\\tau(0)\\) placeholder tokens before the \\(0\\)-th token."
    },
    {
      "title": "Position Engineering",
      "text": "Consider a particular task defined by \\((Q,A)\\), for which a training set \\(\\{(Q_{i},A_{i})\\}_{i=1}^{N}\\) has been sampled according to the task distribution \\(\\Gamma\\). We transform each question \\(Q_{i}\\) into its corresponding text prompt \\(P_{i}\\). A large language model \\(\\mathcal{M}\\) is utilized, which operates based on the prompt \\(P_{i}\\), and its output is evaluated through a scoring function \\(r\\), denoted as \\(r(\\mathcal{M},P_{i})\\). To potentially enhance the performance, a position editing function might be applied to each question prompt. This function is assumed to be parameterized by a vector \\(\\boldsymbol{\\theta}\\), and is denoted as \\(\\tau_{P_{i};\\boldsymbol{\\theta}}\\). After the application of the positional editing function, a new score is generated, formulated as \\(r(\\mathcal{M},P_{i},\\tau_{P_{i};\\boldsymbol{\\theta}})\\). For instance, in retrieval-augmented generation (RAG) tasks, the prompt \\(P_{i}\\) is typically composed of three segments: the instruction, the documents, and the question. It can be possible to define \\(\\boldsymbol{\\theta}=[\\theta_{1},\\theta_{2}]\\), while \\(\\theta_{1}\\) translates to inserting \\(\\theta_{1}\\) placeholder tokens between the instruction and the document segment, and \\(\\theta_{2}\\) translates to inserting placeholder tokens between the document segment and the question. Formally, prompt engineering is framed as an optimization problem. We aim at finding the optimal \\(\\boldsymbol{\\theta}\\) that maximizes the score: \\[\\boldsymbol{\\theta}^{*}=\\arg\\max_{\\boldsymbol{\\theta}}\\frac{1}{N}\\sum_{i=1}^{N }r(\\mathcal{M},P_{i},\\tau_{P_{i};\\boldsymbol{\\theta}}) \\tag{8}\\] In this research, we utilize a basic algorithm for tackling the optimization problem by initially defining a limited number of candidates for \\(\\boldsymbol{\\theta}\\) and assessing each candidate's score via brute force. Notably, since \\(\\boldsymbol{\\theta}\\) is a numeric vector, the search process can be accelerated by adopting various optimizers, such as Gaussian processes of Bayesian optimization Srinivas et al. (2010). The exploration of more sophisticated optimization methods will be considered in future works. Experiments In this section, we present our experiments and findings for position engineering. We evaluate two prevalent tasks for LLMs, namely Retrieval-Augmented Generation (RAG) and In-context Learning (ICL). Our primary testing model is Llama2-13B-chat (Touvron et al., 2023), although we also expand our experiments to include additional models in the Appendix."
    },
    {
      "title": "Position Engineering For Rag",
      "text": "**Datasets:** To explore the effectiveness of position engineering on RAG tasks, we utilize four open-domain QA datasets: NQ open (Lee et al., 2019), EntityQuestions (Sciavolino et al., 2021), TrivialQA (Joshi et al., 2017), and WebQuestions (Berant et al., 2013). These datasets each include a training and an evaluation (or test) set, with each set comprising a series of question-and-answer pairs. From the original training set of each dataset, we randomly select 300 QA pairs to serve as our training set for position engineering. Similarly, we randomly select 2,000 pairs from their original test sets to constitute our test set. In cases where a dataset lack a test set, we utilize its evaluation set instead. The Contriever model, which has been fine-tuned on the MS-MARCO dataset, is employed as the retrieval model (Izacard et al., 2021). We employ document passages from Wikipedia as our source for retrieval, with each passage containing a total of 100 words (Karpukhin et al., 2020). \\(k\\) document passages, specifically \\(k=1,3,5\\), are retrieved, and subsequently concatenated and fed into LLMs. Our evaluation metric is the best exact match accuracy, judging whether any correct answer is in the output, which is a common practice in previous works (Kandpal et al., 2023; Mallen et al., 2023). **Search Space:** We adopt the following prompt template for all RAG experiments. The prompt template is divided into three segments. The first segment provides instructions for the task; the second segment presents a list of retrieved documents, each accompanied by its title and a passage; and the third segment combines the instruction with a specific question. These segments are referred to as the instruction segment, the document segment, and the question segment for convenience. As presented in Figure 2, our study explores the methodology of position engineering for RAG by strategically inserting \\(\\theta_{A}\\) placeholder tokens between the instruction and document segments, and \\(\\theta_{B}\\) placeholder tokens between the document and question segments. To narrow down the search space, the values of \\(\\theta_{A}\\) and \\(\\theta_{B}\\) are limited to a predefined set \\(\\{0,100,...,2500\\}\\). Additionally, we impose a restriction that \\(\\theta_{A}+\\theta_{B}\\leq 2500\\), due to the constraints of the context window size. We evaluate the performance of all combinations on the training set with the Llama2-13B-chat model, and then apply the best configuration to the test set. **Results:** Table 1 displays the results for RAG, indicating that position engineering substantially en Figure 2: Position Engineering for RAG. In the figure, the term “PH tokens” refers to the placeholder tokens introduced in Section 2.2. We investigate a defined search space, with inserting \\(\\theta_{A}\\) placeholder tokens between the instruction and document segments, and \\(\\theta_{B}\\) placeholder tokens between the document and question segments. Both \\(\\theta_{A}\\) and \\(\\theta_{B}\\) range from \\(\\{0,100,...,2500\\}\\), subject to \\(\\theta_{A}+\\theta_{B}\\leq 2500\\). hance the RAG's performance across all settings. The most notable improvement is 15.4%, observed in the WebQuestions dataset with a single retrieved document. The best-performing parameters, \\(\\theta^{*}_{A}\\) and \\(\\theta^{*}_{B}\\), reveal a consistent trend: \\(\\theta^{*}_{A}\\) tends to be a large number, usually in the range of 1,000 to 2,000, while \\(\\theta^{*}_{B}\\) is a smaller figure, ranging between 200 and 600."
    },
    {
      "title": "Universal Position Configuration For Rag",
      "text": "It has been observed that the most effective position configurations, represented as \\(\\theta^{*}_{A}\\) and \\(\\theta^{*}_{B}\\) in Section 3.1, demonstrate a consistent trend across all examined datasets. In this section, we aim to determine a single position setting that can enhance RAG performance universally across different datasets and various numbers of retrieved documents. Given that absolute accuracy scores vary across datasets, we adopt the percentile value of the accuracy score as a metric to assess each position setting. In this context, we define \"experiment setting\" as the combination of one dataset and a specific number of retrieved documents, and \"position setting\" as a specific pair of \\(\\theta_{A}\\) and \\(\\theta_{B}\\). For every experiment setting, we accumulate the scores from all position settings. The effectiveness of each position setting is then evaluated based on its percentile ranking, which varies from 0 to 100, within the experiment setting. Finally, The overall efficacy of a position setting is determined by averaging its percentile rankings across all experiment settings. The baseline configuration without position engineering (\\(\\theta_{A}=\\theta_{B}=0\\)) achieves an average percentile of \\(31.6\\). This suggests that approximately 68% of configurations can surpass the baseline performance by simply adjusting positional information. The visualization of averaged percentiles for all position settings is provided in Figure 3. Generally, it is advantageous to select a \\(\\theta_{A}\\) value within the range of \\(1300\\) to \\(2000\\), and set \\(\\theta_{B}\\) within the range of \\(300\\) to \\(500\\). Setting \\(\\theta_{B}\\) to an excess \\begin{table} \\begin{tabular}{c c c c c c} \\hline \\hline **Dataset** & **N Doc** & **Baseline** & **Position Engineering** & **Abs Impr.** & \\(\\mathbf{\\theta^{*}_{A}}\\) & \\(\\mathbf{\\theta^{*}_{B}}\\) \\\\ \\hline NQ Open & 1 & 0.341 & **0.435** & **+9.5\\%** & 2,000 & 400 \\\\ NQ Open & 3 & 0.424 & **0.490** & **+6.6\\%** & 2,100 & 300 \\\\ NQ Open & 5 & 0.452 & **0.501** & **+5.0\\%** & 1,600 & 600 \\\\ \\hline EntityQuestions & 1 & 0.452 & **0.511** & **+5.8\\%** & 1,400 & 500 \\\\ EntityQuestions & 3 & 0.501 & **0.531** & **+3.0\\%** & 1,200 & 300 \\\\ EntityQuestions & 5 & 0.535 & **0.558** & **+2.3\\%** & 1,300 & 400 \\\\ \\hline TrivialQA & 1 & 0.582 & **0.657** & **+7.5\\%** & 1,300 & 200 \\\\ TrivialQA & 3 & 0.646 & **0.697** & **+5.1\\%** & 1,500 & 300 \\\\ TrivialQA & 5 & 0.669 & **0.698** & **+2.9\\%** & 2,300 & 200 \\\\ \\hline WebQuestions & 1 & 0.319 & **0.473** & **+15.4\\%** & 1,900 & 500 \\\\ WebQuestions & 3 & 0.410 & **0.507** & **+9.7\\%** & 2,100 & 400 \\\\ WebQuestions & 5 & 0.434 & **0.514** & **+8.1\\%** & 1,600 & 800 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 1: The test results for RAG. We initially examine all possible combinations to determine the optimal configuration on the training set, which is denoted as \\(\\theta^{*}_{A}\\) and \\(\\theta^{*}_{B}\\). This optimal configuration is then applied on the test set, and the results are presented in the table. The baseline is \\(\\theta_{A}=\\theta_{B}=0\\). The term ”Abs Impr.” represents absolute accuracy improvement in percentage. The Llama2-13B-chat model is utilized for the experimentation. Figure 3: We visualize the average percentile values for each positional configuration \\((\\theta_{A},\\theta_{B})\\). These values are initially obtained by aggregating all accuracy scores for a given dataset and a specific number of retrieved documents, and calculate the percentile scores. Subsequently, they are averaged across all configurations, as detailed in Section 3.2. sively high figure (for instance, more than \\(1500\\)) significantly deteriorates performance, possibly because it leads to the neglect of document information in prompts. Moreover, for each specified \\(\\theta_{B}\\), an increase in \\(\\theta_{A}\\) is generally associated with better performance. On the training set, \\(\\theta_{A}=1900,\\theta_{B}=400\\) exhibits the highest percentile value of \\(92.9\\). We apply this configuration to the test set across all datasets and retrieved document numbers. Results presented in Table 2 demonstrate that it leads to a universal performance improvement. In Appendix A.1, we also demonstrate that such configuration remains effective for other models."
    },
    {
      "title": "Without The Instruction Segment",
      "text": "From Figure 3, it is observed that a larger \\(\\theta_{A}\\) is preferred for optimal performance. \\(\\theta_{A}\\) represents the gap between the instruction segment and the document segment. A larger \\(\\theta_{A}\\) reduces the instruction segment's impact. This raises the question of whether eliminating the instruction segment entirely could further enhance performance. To explore this, we conduct tests, and the outcomes are presented in Table 3. It is discovered that the performance of removing the instruction segment is comparable to the baseline setting. The most significant improvement, a 2% increase, is observed with the WebQuestions dataset when one retrieved document is utilized. However, the enhancement from position engineering in the same experiment setting is 15.4%. Thus, to achieve the best performance, it is essential to lessen but not eliminate the effect of the instruction segment, a goal that is easy for position engineering, but difficult to accomplish by prompt engineering."
    },
    {
      "title": "Position Engineering For Icl",
      "text": "**Datasets:** To explore the impact of positional engineering on ICL tasks, we employ two datasets: TREC [11, 10] and SST2 [3]. The TREC dataset includes a variety of questions, with the aim being to categorize these questions into 6 coarse and 50 fine-grained question types. We focus on the 6 coarse question types. The SST2 dataset contains movie reviews, with the objective being to categorize these reviews as either positive or negative. For our training set, we randomly choose 300 samples from the original training sets of TREC and SST2. For our test set, we utilize TREC's entire 500-sample test set. For the SST2 dataset, due to the lack of labels in its original test set, we use all 842 samples from its validation set as our test set. For each sample tested, we randomly select 3 examples of each label from the training set as the in-context demonstrations, leading to 18 examples for TREC and 6 for SST2. The exact match score is adopted as the evaluation metric. \\begin{table} \\begin{tabular}{c c c} \\hline \\hline **Dataset** & **N Doc** & **Abs Impr.** \\\\ \\hline NQ Open & 1 & +9.6\\% \\\\ NQ Open & 3 & +7.1\\% \\\\ NQ Open & 5 & +4.9\\% \\\\ \\hline EntityQuestions & 1 & +5.6\\% \\\\ EntityQuestions & 3 & +3.4\\% \\\\ EntityQuestions & 5 & +1.9\\% \\\\ \\hline TrivialQA & 1 & +8.1\\% \\\\ TrivialQA & 3 & +4.9\\% \\\\ TrivialQA & 5 & +3.2\\% \\\\ \\hline WebQuestions & 1 & +14.8\\% \\\\ WebQuestions & 3 & +9.4\\% \\\\ WebQuestions & 5 & +9.1\\% \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 2: The universal position configuration, \\(\\theta_{A}=1900,\\theta_{B}=400\\), is tested on the test split of all datasets employing the Llama2-13B-chat model. The Table presents the absolute accuracy improvements over the baseline configuration (\\(\\theta_{A}=\\theta_{B}=0\\)). \\begin{table} \\begin{tabular}{c c c c} \\hline \\hline **Dataset** & **N Doc** & **Baseline** & **No Inst.** \\\\ \\hline NQ Open & 1 & 0.341 & **0.353** \\\\ NQ Open & 3 & **0.424** & 0.417 \\\\ NQ Open & 5 & **0.452** & 0.449 \\\\ \\hline EntityQuestions & 1 & 0.452 & **0.454** \\\\ EntityQuestions & 3 & **0.501** & 0.492 \\\\ EntityQuestions & 5 & **0.535** & 0.532 \\\\ \\hline TrivialQA & 1 & **0.582** & **0.582** \\\\ TrivialQA & 3 & 0.646 & **0.650** \\\\ TrivialQA & 5 & **0.669** & 0.668 \\\\ \\hline WebQuestions & 1 & 0.319 & **0.335** \\\\ WebQuestions & 3 & **0.410** & **0.410** \\\\ WebQuestions & 5 & 0.434 & **0.440** \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 3: We test the RAG performance without the instruction segment on the Llama2-13B-chat model. The results are comparable to the baseline, with a slight improvement ranging from 1% to 2% on the NQ Open and WebQuestions datasets when a single document is retrieved. **Search Space:** The prompt template provided below is designed for evaluating performance on the SST2 dataset and is divided into three sections: an initial instruction segment that outlines the task, a middle segment that provides examples demonstrating the task, and a final segment that combines the instruction with a query. These segments are referred to as the instruction segment, the example segment, and the query segment, respectively. For the TREC dataset, we employ a similar prompt template, altering only the terms \"Review\" to \"Question\" and \"Sentiment\" to \"Question Type\" with Llama2-13B-chat. To investigate the impact of position engineering, we conduct experiments by inserting \\(\\theta_{A}\\) placeholder tokens between the instruction and example segments, \\(\\theta_{B}\\) placeholder tokens between the example segment and the query segment, and \\(\\theta_{mid}\\) placeholder tokens among the examples, as depicted in Figure 4. The candidate value set of \\(\\theta_{A}\\) and \\(\\theta_{B}\\) is set to \\(\\{0,100,...,600\\}\\), and while \\(\\theta_{mid}\\) is set to \\(\\{0,20,...,100\\}\\). We evaluate the performance of all possible combinations within the training set and apply the optimal configuration to the test set. **Results:** The results for ICL are presented in Table 4, indicating an enhancement in performance across both datasets, with an absolute 3.6% improvement observed on the TREC dataset and an absolute 1.9% improvement on the SST2 dataset. The optimal position settings, represented as \\(\\theta_{A}^{*}\\), \\(\\theta_{B}^{*}\\), and \\(\\theta_{mid}^{*}\\), vary between datasets. Specifically, TREC requires adjusting \\(\\theta_{mid}\\) to 40, with \\(\\theta_{A}\\) and \\(\\theta_{B}\\) set to 0, whereas SST2 requires setting \\(\\theta_{B}\\) to 100, with \\(\\theta_{A}\\) and \\(\\theta_{mid}\\) to 0. We observe a significant performance drop when \\(\\theta_{B}\\) is set within the \\(\\{200,300,...,600\\}\\) range, mirroring the trends observed in RAG tasks where a high \\(\\theta_{B}\\) value leads to poor outcomes. \\(\\theta_{B}\\) can be interpreted as a parameter to adjust the impact of the example segment. In the case of SST2, which involves classifying sentiments of re \\begin{table} \\begin{tabular}{l c c c c c c} \\hline \\hline **Dataset** & **Baseline** & **Position Engineering** & **Abs Impr.** & \\(\\theta_{A}^{*}\\) & \\(\\theta_{mid}^{*}\\) & \\(\\theta_{B}^{*}\\) \\\\ \\hline TREC & 0.692 & **0.728** & **+3.6\\%** & 0 & 40 & 0 \\\\ SST2 & 0.915 & **0.935** & **+1.9\\%** & 0 & 0 & 100 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 4: The test results for ICL. We initially examine all possible combinations to determine the optimal configuration on the training set, which is denoted as \\((\\theta_{A}^{*},\\theta_{mid}^{*},\\theta_{B}^{*})\\). This optimal configuration is then applied on the test set, and the results are presented in the table. The baseline is \\(\\theta_{A}=\\theta_{mid}=\\theta_{B}=0\\). The term ”Abs Impr.” represents absolute accuracy improvement in percentage. The Llama2-13B-chat model is utilized for this experimentation. Figure 4: Position Engineering for ICL. In the figure, the term ”PH tokens” refers to the placeholder tokens introduced in Section 2.2. We investigate a defined search space, with inserting \\(\\theta_{A}\\) placeholder tokens between the instruction and document segments, \\(\\theta_{B}\\) placeholder tokens between the document and question segments, and \\(\\theta_{mid}\\) placeholder tokens among the examples. The candidate value set of \\(\\theta_{A}\\) and \\(\\theta_{B}\\) is set to \\(\\{0,100,...,600\\}\\), and while \\(\\theta_{mid}\\) is set to \\(\\{0,20,...,100\\}\\). views--a domain that LLMs might have common knowledge--the choice of \\(\\theta^{*}_{B}=100\\) is intended to slightly reduce the example segment's influence. For TREC, which requires LLMs to learn question types from examples, maintaining \\(\\theta^{*}_{B}=0\\) is optimal."
    },
    {
      "title": "4 Discussion",
      "text": "We hypothesize that position engineering serves as a technique to finely adjust the attention weights assigned to different segments within prompts. By extending the positional gap between two segments, the interaction between them is lessened, thereby increasing the attention allocated to other segments. For example, in RAG experiments, an increased value of \\(\\theta_{A}\\) could potentially reduce the impact of the instruction segment while amplifying the attention allocated to the retrieved documents. It is important to note, however, that the initial instruction remains essential, as evidenced in Section 3.3. Position engineering offers a nuanced approach to adjusting the weights of different blocks without the need for direct addition or removal of text. Position engineering offers several advantages: (i) It is easier to optimize due to its numerical search space \\(\\{\\mathbf{\\theta}\\}\\), in contrast to prompt engineering, which requires searching over a more complex text space. (ii) It is computationally efficient, as altering position information merely involves updating the position indices input into LLMs, without increasing the overall computational overhead. (iii) It is orthogonal to prompt engineering, meaning the two approaches can be effectively combined. Future works may advance in the following directions. Firstly, investigating the internal dynamics of LLMs can enhance our understanding of position engineering's underlying mechanisms. Secondly, employing more sophisticated optimizers, such as Gaussian processes or multi-armed bandits, could reduce the search time and discover more refine-grained position editing functions. Finally, the exploration of merging position engineering with prompt engineering could harness the full power of LLMs."
    },
    {
      "title": "5 Related Works",
      "text": "**Prompt engineering:** Prompt engineering has emerged as a technique to enhance the performance of LLMs by modifying the instructions given to them. For instance, few-shot prompting allows LLMs to learn from demonstrations, a process also known as in-context learning Brown et al. (2020). Additionally, Chain-of-Thought prompting encourages LLMs to produce intermediate tokens, thereby improving their reasoning capabilities Wei et al. (2022); Kojima et al. (2022). Another technique, Retrieval-Augmented Generation (RAG), involves retrieving relevant document passages and incorporating them into the prompts Lewis et al. (2020). It has been discovered that the RAG performance can be improved by adding random documents to the mix of relevant documents Cuconasu et al. (2024), a technique that is relevant to our study. However, this approach demands significant additional computational resources. In contrast, our proposed method does not require extra computation. **Positional Information in LLMs:** Positional embedding has been introduced to integrate the position information of tokens within the attention layers Vaswani et al. (2017). Initially, this concept relied on absolute position indices. However, subsequent developments have introduced methods based on relative positions, such as the relative positional encodings in Transformer-XL Dai et al. (2019), and RoPE Su et al. (2024). ALiBi is a different method for integrating positional information into LLMs Press et al. (2022), which does not utilize embeddings but introduces a fixed bias based on relative positions during the computation of attention scores. More recent studies have focused on modifying positional embeddings to increase the context window size in LLMs Ding et al. (2024); Peng et al. (2024). Apart from positional embeddings, the performance of LLMs has been found to correlate with document positions in prompts. In RAG tasks, documents that are positioned in the middle are often more neglected than those at the beginning or the end Liu et al. (2024). However, to the best of our knowledge, there has been no similar effort on improving task performance by modifying positional indices."
    },
    {
      "title": "6 Conclusion",
      "text": "In this study, we introduce position engineering, an innovative technique to enhance task performances of LLMs by merely altering the position information in the prompts. Our experimentation with position engineering across a range of tasks and models demonstrates its effectiveness. This approach provides a new avenue for maximizing the capabilities of LLMs."
    },
    {
      "title": "7 Limitations",
      "text": "Our method needs an explicit search process to discover the optimal position setting for a given task. Such search process will cost computation resource and time. Sometimes, the search process can be omitted if a universal good positional setting exists, e.g. the universal setting for RAG tasks with Llama2-13B-chat model. Besides, the internal mechanism of position engineering remains unclear. We hypothesize that position engineering serves as a technique to finely adjust the attention weights assigned to different segments within prompts. Future efforts can be made to further investigate it."
    },
    {
      "title": "References",
      "text": "* J. Berant, A. Chou, R. Frostig, and P. Liang (2013)Semantic parsing on Freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Seattle, Washington, USA, pp. 1533-1544. External Links: Link, Document Cited by: SS1, SS2. * T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei (2020)Language models are few-shot learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Cited by: SS1, SS2. * F. Cuconsu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano, Y. Maarek, N. Tonellotto, and F. Silvestri (2024)The power of noise: redefining retrieval for rag systems. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '24, New York, NY, USA, pp. 719-729. External Links: ISBN 978-1-4503-3811-1, Link, Document Cited by: SS1, SS2. * Z. Dai, Z. Yang, Y. Yang, J. Carbonell, Q. Le, and R. Salakhutdinov (2019)Transformer-XL: attentive language models beyond a fixed-length context. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Florence, Italy, pp. 2978-2988. External Links: Link, Document Cited by: SS1, SS2. * Y. Ding, L. L. Zhang, C. Zhang, Y. Xu, N. Shang, J. Xu, F. Yang, and M. Yang (2024)Longrope: extending llm context window beyond 2 million tokens. ArXiv preprintabs/2402.13753. External Links: Link, 2402.13753 Cited by: SS1, SS2. * S. Frieder, L. Pinchetti, R. Griffiths, T. Salvatori, T. Lukasiewicz, P. Petersen, and J. Berner (2024)Mathematical capabilities of chatgpt. Advances in Neural Information Processing Systems36, pp.. External Links: Link, 2402.13753 Cited by: SS1, SS2. * K. Guu, K. Lee, Z. Tung, P. Pasupat, and M. Chang (2020)Retrieval augmented language model pre-training. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, Vol. 119, pp. 3929-3938. External Links: Link, 2002.13753 Cited by: SS1, SS2. * E. Hovy, L. Gerber, U. Hermjakob, C. Lin, and D. Ravichandran (2001)Toward semantics-based answer pinpointing. In Proceedings of the First International Conference on Human Language Technology Research, Cited by: SS1, SS2. * G. Izacard, M. Caron, L. Hosseini, S. Riedel, P. Bojanowski, A. Joulin, and E. Grave (2021)Unsupervised dense information retrieval with contrastive learning. ArXiv preprintabs/2112.09118. External Links: Link, 2112.09118 Cited by: SS1, SS2. * A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. Singh Chaplot, D. de las Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, et al. (2023)Mistral 7b. ArXiv preprintabs/2310.06825. External Links: Link, 2310.06825 Cited by: SS1, SS2. * M. Joshi, E. Choi, D. Weld, and L. Zettlemoyer (2017)TriviaQA: a large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Vancouver, Canada, pp. 1601-1611. External Links: Link, Document Cited by: SS1, SS2. * N. Kandpal, H. Deng, A. Roberts, E. Wallace, and C. Raffel (2023)Large language models struggle to learn long-tail knowledge. In International Conference on Machine Learning, pp. 15696-15707. External Links: Link, 2309.15696 Cited by: SS1, SS2. * V. Karpukhin, B. Oguz, S. Min, P. Lewis, L. Wu, S. Edunov, D. Chen, and W. Yih (2020)Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online, pp. 6769-6781. External Links: Link, 2009.11080 Cited by: SS1, SS2. * T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa (2022)Large language models are zero-shot reasoners. Advances in neural information processing systems35, pp. 22199-22213. * Le Scao et al. (2023) Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagne, Alexandra Sasha Luccioni, Francois Yvon, Matthias Galle, et al. 2023. Bloom: A 176b-parameter open-access multilingual language model. * Lee et al. (2019) Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. 2019. Latent retrieval for weakly supervised open domain question answering. In _Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics_, pages 6086-6096, Florence, Italy. Association for Computational Linguistics. * Lewis et al. (2020) Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kuttler, Mike Lewis, Wen-tau Yih, Tim Rocktaschel, Sebastian Riedel, and Douwe Kiela. 2020. Retrieval-augmented generation for knowledge-intensive NLP tasks. In _Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual_. * Li and Roth (2002) Xin Li and Dan Roth. 2002. Learning question classifiers. In _COLING 2002: The 19th International Conference on Computational Linguistics_. * Liu et al. (2024) Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2024. Lost in the middle: How language models use long contexts. _Transactions of the Association for Computational Linguistics_, 12:157-173. * Ma et al. (2023) Yecheng Jason Ma, William Liang, Guanzhi Wang, De-An Huang, Osbert Bastani, Dinesh Jayaraman, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023. Evreka: Human-level reward design via coding large language models. _ArXiv preprint_, abs/2310.12931. * Mallen et al. (2023) Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. 2023. When not to trust language models: Investigating effectiveness of parametric and non-parametric memories. In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 9802-9822, Toronto, Canada. Association for Computational Linguistics. * Muennighoff et al. (2023) Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, and Colin Raffel. 2023. Crosslingual generalization through multitask finetuning. In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 15991-16111, Toronto, Canada. Association for Computational Linguistics. * Peng et al. (2024) Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. 2024. YaRN: Efficient context window extension of large language models. In _The Twelfth International Conference on Learning Representations_. * Press et al. (2022) Ofir Press, Noah A. Smith, and Mike Lewis. 2022. Train short, test long: Attention with linear biases enables input length extrapolation. In _The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022_. OpenReview.net. * Romera-Paredes et al. (2024) Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, et al. 2024. Mathematical discoveries from program search with large language models. _Nature_, 625(7995):468-475. * Sciavolino et al. (2021) Christopher Sciavolino, Zexuan Zhong, Jinhyuk Lee, and Danqi Chen. 2021. Simple entity-centric questions challenge dense retrievers. In _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, pages 6138-6148, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics. * Socher et al. (2013) Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In _Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing_, pages 1631-1642, Seattle, Washington, USA. Association for Computational Linguistics. * Srinivas et al. (2010) Niranjan Srinivas, Andreas Krause, Sham M. Kakade, and Matthias W. Seeger. 2010. Gaussian process optimization in the bandit setting: No regret and experimental design. In _Proceedings of the 27th International Conference on Machine Learning (ICML-10), June 21-24, 2010, Haifa, Israel_, pages 1015-1022. Omnipress. * Su et al. (2024) Jianlin Su, Murdatha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu. 2024. Roformer: Enhanced transformer with rotary position embedding. _Neurocomputing_, 568:127063. * Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models. _ArXiv preprint_, abs/2302.13971. * Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajwal Bhargava, Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models. _ArXiv preprint_, abs/2307.09288. * Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In _Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA_, pages 5998-6008. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. _Advances in neural information processing systems_, 35:24824-24837. * Zhou et al. (2022) Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. 2022. Large language models are human-level prompt engineers. In _NeurIPS 2022 Foundation Models for Decision Making Workshop_. Appendix"
    },
    {
      "title": "Applying The Universal Rag Configuration To Other Models",
      "text": "In Section 3.2, we identified a universal position configuration,\\(\\theta_{A}=1900\\) and \\(\\theta_{B}=400\\), on RAG tasks for the Llama2-13B-chat model. In this section, we further investigate whether such configuration remains effective for other models by applying it to the Llama2-7B-chat (Touvron et al., 2023) and Mistral-7B-instruct-v0.2 (Jiang et al., 2023) model. The configuration is evaluated on the test splits across all datasets, with the results presented in Table 5. The findings indicate a consistent enhancement in the performance with the Llama2-7B-chat model under the universal position configuration. It is noteworthy that this configuration is initially identified with the Llama2-13B-chat model, suggesting that the Llama2-7B-chat model exhibits similar positional characteristics with Llama2-13B-chat. Furthermore, the Mistral-7B-instruct-v0.2 model also demonstrates consistent performance improvements when utilizing a single retrieved document. However, the performance gains become inconsistent with the use of multiple retrieved documents, indicating a potential need for model-specific adjustments."
    },
    {
      "title": "Applying Position Engineering To Non-Rope Models",
      "text": "In our previous evaluation section, Llama2-13B-chat was utilized as the primary model for testing. This model employs RoPE (Su et al., 2024) to integrate positional information. Furthermore, in this section, we aim to assess the effectiveness of position engineering using models with a different method for incorporating positional information. To this end, we apply position engineering to BLOOMZ-7b1 (Muennighoff et al., 2023) under the same experimental settings for the ICL tasks. BLOOMZ-7b1 is an instruction-fined version of BLOOM (Le Scao et al., 2023), which incorporates position information using ALiBi (Press et al., 2022). Unlike RoPE, ALiBi introduces a fixed position-related bias term during the computation of attention scores. Specifically, we follow the search space in Figure 4 for ICL tasks. We determine the optimal position configuration on the training dataset by evaluating all configuration candidates in the search space, subsequently applying this configuration to the test set. Both the training and test sets remain the same with the previous settings. The results are presented in Table 6. Notably, there is a significant improvement in ICL tasks, with the SST2 dataset showing an absolute improvement of \\(11.0\\%\\). It demonstrates that position engineering can be also effective in non-RoPE models. \\begin{table} \\begin{tabular}{c c c c} \\hline \\hline **Dataset** & **N** & **Llama2-7B** & **Mistral-7B** \\\\ \\hline NQ Open & 1 & +8.9\\% & +2.2\\% \\\\ NQ Open & 3 & +4.6\\% & +0.2\\% \\\\ NQ Open & 5 & +1.0\\% & -0.3\\% \\\\ \\hline EntityQuestions & 1 & +7.1\\% & +0.8\\% \\\\ EntityQuestions & 3 & +5.8\\% & -0.1\\% \\\\ EntityQuestions & 5 & +0.9\\% & -0.4\\% \\\\ \\hline TrivialQA & 1 & +7.9\\% & +3.1\\% \\\\ TrivialQA & 3 & +4.0\\% & +0.7\\% \\\\ TrivialQA & 5 & +1.6\\% & +0.5\\% \\\\ \\hline WebQuestions & 1 & +18.5\\% & +3.8\\% \\\\ WebQuestions & 3 & +10.0\\% & +2.2\\% \\\\ WebQuestions & 5 & +5.9\\% & 0.0\\% \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 5: We evaluate the universal position configuration for RAG, as identified in Section 3.2 with \\(\\theta_{A}=1900\\) and \\(\\theta_{B}=400\\), across the test splits of all datasets employing the Llama2-7B-chat and Mistral-7B-instruct-v0.2 models. The results showcase the absolute accuracy improvements over the baseline configuration, where \\(\\theta_{A}\\) and \\(\\theta_{B}\\) are both set to 0. \\begin{table} \\begin{tabular}{c c c c c c c} \\hline **Dataset** & **Baseline** & **Position Engineering** & **Abs Impr.** & \\(\\mathbf{\\theta^{*}_{A}}\\) & \\(\\mathbf{\\theta^{*}_{mid}}\\) & \\(\\mathbf{\\theta^{*}_{B}}\\) \\\\ \\hline TREC & 0.724 & **0.782** & **+5.8\\%** & 0 & 0 & 200 \\\\ SST2 & 0.836 & **0.946** & **+11.0\\%** & 0 & 20 & 500 \\\\ \\hline \\end{tabular} \\end{table} Table 6: We apply position engineering to the BLOOMZ-7b1 model on ICL tasks. The same search space setting is employed as shown in Figure 4. \\(\\theta^{*}_{A}\\), \\(\\theta^{*}_{mid}\\), and \\(\\theta^{*}_{B}\\) is the optimal configuration identified in the training set, which is then applied on the test set. The baseline is \\(\\theta_{A}=\\theta_{mid}=\\theta_{B}=0\\). The term ”Abs Impr.” represents absolute accuracy improvement in percentage compared to the baseline."
    }
  ]
}
{
  "title": "OLaLa: Ontology Matching with Large Language Models",
  "authors": [
    "Sven Hertling",
    "Heiko Paulheim"
  ],
  "abstract": "\n Ontology (and more generally: Knowledge Graph) Matching is a challenging task where information in natural language is one of the most important signals to process. With the rise of Large Language Models, it is possible to incorporate this knowledge in a better way into the matching pipeline. A number of decisions still need to be taken, e.g., how to generate a prompt that is useful to the model, how information in the KG can be formulated in prompts, which Large Language Model to choose, how to provide existing correspondences to the model, how to generate candidates, etc. In this paper, we present a prototype that explores these questions by applying zero-shot and few-shot prompting with multiple open Large Language Models to different tasks of the Ontology Alignment Evaluation Initiative (OAEI). We show that with only a handful of examples and a well-designed prompt, it is possible to achieve results that are en par with supervised matching systems which use a much larger portion of the ground truth. \n",
  "references": [
    {
      "id": null,
      "title": "OLaLa: Ontology Matching with Large Language Models",
      "authors": [
        "Sven Hertling",
        "Heiko Paulheim"
      ],
      "year": "",
      "venue": "",
      "doi": "10.1145/3587259.3627571"
    },
    {
      "id": "b0",
      "title": "Dbpedia: A nucleus for a web of open data",
      "authors": [
        "Sören Auer",
        "Christian Bizer",
        "Georgi Kobilarov",
        "Jens Lehmann",
        "Richard Cyganiak",
        "Zachary Ives"
      ],
      "year": "2007",
      "venue": "international semantic web conference",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Efficient Selection of Mappings and Automatic Quality-Driven Combination of Matching Methods",
      "authors": [
        "Isabel F Cruz",
        "Flavio Palandri Antonelli",
        "Cosmin Stroe"
      ],
      "year": "2009",
      "venue": "Proceedings of the 4th International Conference on Ontology Matching -Volume",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019",
      "doi": "10.18653/V1/N19-1423"
    },
    {
      "id": "b3",
      "title": "BERTMap: a BERT-based ontology alignment system",
      "authors": [
        "Yuan He",
        "Jiaoyan Chen",
        "Denvar Antonyrajah",
        "Ian Horrocks"
      ],
      "year": "2022",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching",
      "authors": [
        "Yuan He",
        "Jiaoyan Chen",
        "Hang Dong",
        "Ernesto Jiménez-Ruiz",
        "Ali Hadian",
        "Ian Horrocks"
      ],
      "year": "2022",
      "venue": "The Semantic Web -ISWC 2022",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "Language Model Analysis for Ontology Subsumption Inference",
      "authors": [
        "Yuan He",
        "Jiaoyan Chen",
        "Ernesto Jimenez-Ruiz",
        "Hang Dong",
        "Ian Horrocks"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: ACL 2023. Association for Computational Linguistics",
      "doi": "10.18653/v1/2023.findings-acl.213"
    },
    {
      "id": "b6",
      "title": "The Knowledge Graph Track at OAEI -Gold Standards, Baselines, and the Golden Hammer Bias",
      "authors": [
        "Sven Hertling",
        "Heiko Paulheim"
      ],
      "year": "2020",
      "venue": "The Semantic Web -17th International Conference",
      "doi": "10.1007/978-3-030-49461-2_20"
    },
    {
      "id": "b7",
      "title": "Transformer Based Semantic Relation Typing for Knowledge Graph Integration",
      "authors": [
        "Sven Hertling",
        "Heiko Paulheim"
      ],
      "year": "2023",
      "venue": "The Semantic Web -20th International Conference, ESWC 2023",
      "doi": "10.1007/978-3-031-33455-9_7"
    },
    {
      "id": "b8",
      "title": "MELT -Matching EvaLuation Toolkit",
      "authors": [
        "Sven Hertling",
        "Jan Portisch",
        "Heiko Paulheim"
      ],
      "year": "2019",
      "venue": "Semantic Systems. The Power of AI and Knowledge Graphs",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "KERMIT -A Transformer-Based Approach for Knowledge Graph Matching",
      "authors": [
        "Sven Hertling",
        "Jan Portisch",
        "Heiko Paulheim"
      ],
      "year": "2022",
      "venue": "KERMIT -A Transformer-Based Approach for Knowledge Graph Matching",
      "doi": "10.48550/ARXIV.2204.13931"
    },
    {
      "id": "b10",
      "title": "Large language models are zero-shot reasoners",
      "authors": [
        "Takeshi Kojima",
        "Shane Shixiang",
        "Machel Gu",
        "Yutaka Reid",
        "Yusuke Matsuo",
        "Iwasawa"
      ],
      "year": "2022",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Deep Entity Matching with Pre-Trained Language Models",
      "authors": [
        "Yuliang Li",
        "Jinfeng Li",
        "Yoshihiko Suhara",
        "Anhai Doan",
        "Wang-Chiew Tan"
      ],
      "year": "2020",
      "venue": "Proc. VLDB Endow",
      "doi": "10.14778/3421424.3421431"
    },
    {
      "id": "b12",
      "title": "Self-Alignment Pretraining for Biomedical Entity Representations",
      "authors": [
        "Fangyu Liu",
        "Ehsan Shareghi",
        "Zaiqiao Meng",
        "Marco Basaldella",
        "Nigel Collier"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021",
      "doi": "10.18653/V1/2021.NAACL-MAIN.334"
    },
    {
      "id": "b13",
      "title": "Generated Knowledge Prompting for Commonsense Reasoning",
      "authors": [
        "Jiacheng Liu",
        "Alisa Liu",
        "Ximing Lu",
        "Sean Welleck",
        "Peter West",
        "Le Ronan",
        "Yejin Bras",
        "Hannaneh Choi",
        "Hajishirzi"
      ],
      "year": "2022",
      "venue": "Annual Meeting of the Association for Computational Linguistics ACL. ACL",
      "doi": "10.18653/v1/2022.acl-long.225"
    },
    {
      "id": "b14",
      "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "year": "2019",
      "venue": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "Ontology engineering with Large Language Models",
      "authors": [
        "Patricia Mateiu",
        "Adrian Groza"
      ],
      "year": "2023",
      "venue": "Ontology engineering with Large Language Models",
      "doi": "10.48550/ARXIV.2307.16699"
    },
    {
      "id": "b16",
      "title": "Towards Automatic Ontology Alignment using BERT",
      "authors": [
        "Sophie Neutel",
        "H T Maaike",
        "De Boer"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI 2021 Spring Symposium on Combining Machine Learning and Knowledge Engineering (AAAI-MAKE 2021)",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Conversational Ontology Alignment with ChatGPT",
      "authors": [
        "Saki Sanaz",
        "Mohammad Norouzi",
        "Pascal Saeid Mahdavinejad",
        "Hitzler"
      ],
      "year": "2023",
      "venue": "Conversational Ontology Alignment with ChatGPT",
      "doi": "10.48550/ARXIV.2308.09217"
    },
    {
      "id": "b18",
      "title": "Large Language Models and Knowledge Graphs: Opportunities and Challenges",
      "authors": [
        "Jeff Z Pan",
        "Simon Razniewski",
        "Jan-Christoph Kalo",
        "Sneha Singhania",
        "Jiaoyan Chen",
        "Stefan Dietze",
        "Hajira Jabeen",
        "Janna Omeliyanenko",
        "Wen Zhang",
        "Matteo Lissandrini",
        "Russa Biswas",
        "Gerard De Melo",
        "Angela Bonifati",
        "Edlira Vakaj",
        "Mauro Dragoni",
        "Damien Graux"
      ],
      "year": "2023",
      "venue": "Large Language Models and Knowledge Graphs: Opportunities and Challenges",
      "doi": "10.48550/ARXIV.2308.06374"
    },
    {
      "id": "b19",
      "title": "Using ChatGPT for Entity Matching",
      "authors": [
        "Ralph Peeters",
        "Christian Bizer"
      ],
      "year": "2023",
      "venue": "Using ChatGPT for Entity Matching",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "",
      "authors": [
        "Mina Abd",
        "Nikooie Pour",
        "Alsayed Algergawy",
        "Patrice Buche",
        "Leyla Jael Castro",
        "Jiaoyan Chen",
        "Hang Dong",
        "Omaima Fallatah",
        "Daniel Faria",
        "Irini Fundulaki",
        "Sven Hertling",
        "Yuan He",
        "Ian Horrocks",
        "Martin Huschka",
        "Liliana Ibanescu",
        "Ernesto Jiménez-Ruiz",
        "Naouel Karam",
        "Amir Laadhar",
        "Patrick Lambrix",
        "Huanyu Li",
        "Ying Li",
        "Franck Michel"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Results of the Ontology Alignment Evaluation Initiative 2022",
      "authors": [
        "Cássia Shvaiko",
        "Chantelle Trojahn",
        "Mingfang Verhey",
        "Beyza Wu",
        "Ondrej Yaman",
        "Lu Zamazal",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Proceedings of the 17th International Workshop on Ontology Matching (OM 2022) co-located with the 21th International Semantic Web Conference (ISWC 2022)",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
      "authors": [
        "Nils Reimers",
        "Iryna Gurevych"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019",
      "doi": "10.18653/V1/D19-1410"
    },
    {
      "id": "b23",
      "title": "Dis-tilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
      "authors": [
        "Victor Sanh",
        "Lysandre Debut",
        "Julien Chaumond",
        "Thomas Wolf"
      ],
      "year": "2019",
      "venue": "Dis-tilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "Subsumption Prediction for E-Commerce Taxonomies",
      "authors": [
        "Jingchuan Shi",
        "Jiaoyan Chen",
        "Hang Dong",
        "Ishita Khan",
        "Lizzie Liang",
        "Qunzhi Zhou",
        "Zhe Wu",
        "Ian Horrocks"
      ],
      "year": "2023",
      "venue": "The Semantic Web -20th International Conference, ESWC 2023",
      "doi": "10.1007/978-3-031-33455-9_15"
    },
    {
      "id": "b25",
      "title": "A contrastive framework for neural text generation",
      "authors": [
        "Yixuan Su",
        "Tian Lan",
        "Yan Wang",
        "Dani Yogatama",
        "Lingpeng Kong",
        "Nigel Collier"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models",
      "authors": [
        "Hugo Touvron",
        "Thibaut Lavril",
        "Gautier Izacard",
        "Xavier Martinet",
        "Marie-Anne Lachaux",
        "Timothée Lacroix",
        "Baptiste Rozière",
        "Naman Goyal",
        "Eric Hambro"
      ],
      "year": "2023",
      "venue": "Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava"
      ],
      "year": "2023",
      "venue": "Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Attention is all you need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan N Gomez",
        "Łukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b29",
      "title": "Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking",
      "authors": [
        "Qinyong Wang",
        "Zhenxiang Gao",
        "Rong Xu"
      ],
      "year": "2023",
      "venue": "Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "2. Related Work",
      "text": "This section is divided into two parts. We first show approaches based on pre-trained language model which are related to the ontology matching task and afterwards we list related work based on large language models (both ChatGPT and open-source LLMs)."
    },
    {
      "title": "Pretrained Language Models For Ontology Matching",
      "text": "One of the first systems which applied transformer-based models to ontology matching was DITTO [(12)] in 2020. They used BERT [(3)], DistilBERT [(23)], and RoBERTa [(15)] to detect if two entities are similar. One difference is that the schema is fixed (meaning that each entity has the same attributes). They overcome the issue of small input sizes by reducing the amount of text with tf-idf weighting. Neutel et al. [(17)] provides a system based on BERT but mainly for the automatic alignment of two occupation ontologies. The BERTMap [(4)] system evaluates on datasets from the Ontology Alignment Evaluation Initiative (OAEI) [(21)]. It includes a fine-tuning of the LMs and finally repairs the mapping in case of inconsistencies. The corresponding candidates are generated by sub-word inverted indices (which only include entity pairs that share many (sub-)words. Our previous approach KERMIT [(10)] is also fine-tuned either supervised (based on a fraction of the reference alignment) or unsupervised (based on a high precision matcher). One difference to BERTMap is that the candidates are generated with Sentence-BERT [(22)]. This embedding-based retrieval system can also include matching candidates that do not share any tokens (such as synonyms). For ontology and KG integration, it is not only important to find equivalence relations between concepts and especially between classes but also other types of relations such as subsumption or meronymy relations. He et al. [(6)] thus applied a language model to detect also the type of relation whereas [(8)] provides an already fine-tuned model based on various KGs such as DBpedia [(1)] and Wikidata. [(24)] used BERT models to predict subsumption relations in the e-commerce setting."
    },
    {
      "title": "Large Language Models For Ontology Matching",
      "text": "Due to the fact that large language models (LLMs) are relatively new, only a few papers already exist. We first present papers using ChatGPT: Peeters et al. [(20)] use the chatbot to check if two product descriptions refer to the same product. [(18)] use ChatGPT for ontology alignment by providing the whole source and target ontology to the bot and asking for the final alignment between them. They applied their approach to the conference track of OAEI (the ontologies are rather small) and achieved a high recall but the final F1 score is below the baseline (string equivalence) because of a low precision. For ontology engineering, Mateiu et al. [(16)] tuned a GPT-3 model to translate between natural language text and OWL Functional Syntax. Thus it is used mainly to add axioms to an ontology and enrich it. The closest related work is from Wang et al. [(29)]. They apply LLaMa 65B [(26)], GPT3.5, and GPT4 to the Biomedical Datasets for Equivalence and Subsumption Matching [(5)]. The candidate generation is done by computing top k neighbors in an embedding space generated out of SapBERT [(13)] (a pre-trained BERT model designed for the biomedical domain). It is shown that especially GPT4 can outperform the state-of-the-art by a large margin. Pan et al. [(19)] provide an overview of how LLMs can be used for Knowledge Graphs in general. Section 4.1.1 discusses the application of entity resolution and matching and section 4.3.3 ontology alignment. Most of the presented approaches use closed-source LLMs. This means that the results might not be reproducible after OpenAI discontinues some models or changes the models behind the API. Thus we focus in this work on open-source models and present the system _OLaLa_."
    },
    {
      "title": "3. Approach",
      "text": "Figure 1 shows an overview of the architecture of the _OLaLa_ system. All components are implemented in MELT [(9)], a framework for matcher development and evaluation. MELT is also used by the OAEI to package, submit, and evaluate the systems. Thus, it is possible for the ontology matching community to reuse and customize each component in their own matching pipeline. The implementation of _OLaLa_ is publicly available, and we provide a command line application2 which allows to run the system and modify the most important parameters. Footnote 2: [https://github.com/dwslab/melt/tree/master/examples/llm-transformers](https://github.com/dwslab/melt/tree/master/examples/llm-transformers) At the beginning, matching candidates need to be extracted from the two given input ontologies O1 and O2. Afterwards, those candidates are included in the user-defined prompt and presented to the LLM. Two options are possible: 1) each correspondence is analyzed independently of each other 2) given a source entity, all possible target entities are presented and the LLM needs to decide which one is correct (or none of them). The output of the high-precision matcher is added to ensure that the simple matches are included as well. Finally, some filters are applied to fulfill the usual requirements for an alignment such as a 1:1 mapping (cardinality filter). [MISSING_PAGE_FAIL:3] would not be possible with a model accessed by an API such as ChatGPT.3 Footnote 3: We also explored prompt engineering as an alternative to get to confidences, using prompts such as ”and also provide a confidence score with your answer”, but we observed that the LIM will often respond that it is not able to provide a specific confidence value, and even if it does, it is not easy to extract it out of the generated text. Therefore, we discarded that idea again. The default generation strategy4 is greedy such that each token with the highest probability is chosen and the generation process is continued with this text. The implementation also allows to switch to e.g. contrastive search (Krishnan et al., 2017) but due to the usual short answers, it is neither necessary nor helpful. Footnote 4: [https://huggingface.co/docs/transformers/main/en/generation_strategies](https://huggingface.co/docs/transformers/main/en/generation_strategies)"
    },
    {
      "title": "3.2.2. Multiple Choice Decisions",
      "text": "Multiple choice decisions are implemented in the class LLMChooseGiveEntityFilter. It provides the LLM with more context such that for a given source entity all possible target entities with identifying letters are also shown. The task is to pick the one that represents the same entity or to generate a default answer such as \"none\". Confidences are extracted in the same ways as before. The normalization is applied to all possible outcomes including \"none\". There is also the possibility to use it directly for filtering such that the one with the highest confidence is kept and all others are removed. In case of a \"none\" prediction, all correspondences are removed."
    },
    {
      "title": "Textextractors / Verbalizers",
      "text": "In all the above cases, the extracted/verbalized texts for a given resource should be only one text and not multiple texts as for the candidate generation step. Thus some of the possible extractors are now explained. In addition to combining all texts from the TextExtractorSet explained before, an even simpler extractor called TextExtractorOnlyLabels is implemented. It extracts only one textual label which can originate from the following properties(in decreasing importance): skos:prefLabel, rdfs:label, URI fragment, skos:altLabel, skos:hiddenLabel. This means if a skos:prefLabel is detected, only this label is used. Including more context in those examples is achieved by the TextExtractorVerbalizedRDF. It selects all RDF triples from the corresponding KG where the resource is in the subject position. Those triples are verbalized - meaning that each subject, predicate, and object is replaced by the text of OnlyLabels extractor. All triples with a label-like property are skipped because the information is already included. As an example, the statement\":MA_0000002 rdfs:subClassOf :MA_0001112\" is converted to \"spinal cord grey matter sub class of grey matter\". As a variation of the previous extractor, it is also tried out to provide the triples directly as serialized RDF. The default of the ResourceDescriptionInRDF extractor is to serialize to turtle format where the prefixes are used but the prefix definition is excluded from the generated text to make it shorter (other serializations can also be configured). If there are resources in the object position of the triples, they will be also replaced by a literal containing the corresponding label."
    },
    {
      "title": "High-Precision Matcher",
      "text": "The high-precision matcher is a simple matcher in MELT that efficiently searches for concepts with the exact same normalized label (or URI fragment if a label is not available).5 The normalization includes lowercasing, camel case, and deletion of non alpha-numeric characters. If there is only one such candidate for a concept, then it is matched. Footnote 5: [https://dwslahgithub.io/melt/matcher-components/full-matcher-list](https://dwslahgithub.io/melt/matcher-components/full-matcher-list)"
    },
    {
      "title": "Postprocessing",
      "text": "After the application of the LLM, the resulting alignment is further post-processed by filters. To keep the matching pipeline simple, only two additional filters are applied. The _cardinality filter_ ensures a one-to-one mapping which is usually required. To solve the assignment problem, it is reduced to the maximum weight matching in a bipartite graph (Bordes and Kresse, 2015) (class MaxWeightBipartitextractor in MELT). To further improve the alignment and remove correspondences that are likely to be incorrect, the confidence filter is applied. All correspondences that do not have a higher or the same confidence as a predefined threshold value are excluded."
    },
    {
      "title": "4. Evaluation",
      "text": "We evaluate our approach on the anatomy, biodiv, and commonk tracks of OAEI6. Moreover, we show results on the Knowledge Graph track (Kresse and Kresse, 2015), where only class correspondences are considered. For all tracks, we compare _OLaL_ against the three best-performing systems in the different OEAI tracks in the 2022 edition of the OAEI (OAEI, 2022). The evaluation was performed using the MELT framework on a server running RedHat with 256 GB of RAM, 2x64 CPU cores (2.6 GHz), and 4 Nvidia A100 (40GB) graphics cards. Footnote 6: [https://huggingface.co/docs/transformers/main/en/main_classes/text_generation/transformers.GenerationConfig](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation/transformers.GenerationConfig)"
    },
    {
      "title": "Final Configuration",
      "text": "For the final configuration, a lot of parameters need to be fixed. The SBERT model for the candidate generation step is set to multi-qa-mpnet-base-dot-v1,7 and the value k during the top-k neighbors search is set to five. This gives a balance between the number of generated correspondences as well as the achieved recall. The TextExtractorSet is used to generate multiple text representations of the resource to run the search in the embedding space. Footnote 7: [https://huggingface.co/docs/transformers/main/en/main_classes/text_generation/transformers.GenerationConfig](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation/transformers.GenerationConfig) The LLM model is set to upstage/llama-2-70b-instruct-v28 and to generate the text in prompt 7 (see table 6), i.e., a few-shot prompt with three positive and negative examples each9, TextExtractorOnlyLabels is used. With this prompt, the binary decision approach is automatically selected. For the text generation, the maximum number of tokens (max_new_tokens10) is set to 10 but this number of tokens is usually not reached because a positive or negative word is detected before. The next parameter which is fixed is the temperature. The lower the value, the more deterministic the results are (the token with the highest probability is chosen as the predicted token). With increased temperature, the outputs are more randomized (resulting in more creative texts). We set the temperature to zero such that the results are reproducible. Other generation parameters are set to their default values. The cardinality filter does not require any parameters, and the value of the confidence filter is set to 0.5. With this setting, we filter out all correspondences where the LLM predicts a negative word (such as \"no\" or \"false\"). Thus we do not need to tune the confidence value and do not require any training alignment for it."
    },
    {
      "title": "Results And Discussion",
      "text": "Table 1 shows the overall results of _OLaLa_ across the different tracks in the configuration above. Although it might be possible to tweak the parameters per track to achieve better results, we use only one configuration across all tracks in order to show a fair comparison. We can see that in many test cases, _OLaLa_ scores among the top 3 systems, delivering good results with an out-of-the-box setup. It is worth mentioning that the other approaches often use domain-specific knowledge (especially in the biomedical domain) and/or extensively utilize the structure of the ontologies, while _OLaLa_ solely relies on the textual descriptions of entities.11 Footnote 11: For reasons of completeness, we should mention that we use three examples from the anatomy track for our few-shot prompt. Thus, one could argue that there is minimal information leakage for the anatomy track. However, given the alignment size, we consider this neglectable. Moreover, we could have used examples from other tracks for anatomy, but we wanted to keep the prompt constant across all tracks. At the same time, it can be observed that the runtimes utilizing LLMs are very often much higher than those for other models. This can be observed in particular in the Biodiv track, where the runtime of _OLaLa_ is often a few hours, compared to other systems which can solve the respective tasks in under a minute."
    },
    {
      "title": "Ablation Study",
      "text": "In this section, we investigate the impact of the different parts and parameters of the system on the final result. Due to the fact that all combinations on all tracks would drastically increase the number of experiments, we restrict ourselves to the anatomy track and only modify one component while keeping the rest of the system stable to the final configuration introduced in section 4.1."
    },
    {
      "title": "4.3.1. Candidate Generation",
      "text": "In this stage, the SBERT model and corresponding k value for neighbor search need to be selected. The available pretrained models are already evaluated on 14 datasets which checks the performance of the sentence embeddings as well \\begin{table} \\begin{tabular}{|c|l|c|c|c|c|c|} \\hline **Test case** & **System** & Prec & Rec & \\(F_{1}\\) & Size & Time \\\\ \\hline \\hline \\multicolumn{6}{|c|}{**Anatomy**} \\\\ \\hline & Matcha & 0.951 & **0.930** & **0.941** & 1482 & 0.90:37 \\\\ \\cline{2-6} & SEMRatcher & 0.945 & 0.874 & 0.908 & 1402 & 9.53:22 \\\\ \\cline{2-6} mouse-human & 0.914 & 0.914 & 0.991 & 0.902 & 1478 & 2.41:23 \\\\ \\cline{2-6} & LogMapBio & 0.873 & 0.919 & 0.985 & 1956 & 0.19:43 \\\\ \\cline{2-6} & String Baseline & **0.997** & 0.622 & 0.766 & 946 & - \\\\ \\hline \\hline \\multicolumn{6}{|c|}{**Common KG**} \\\\ \\hline \\multirow{6}{*}{nell-dbpedia} & **OLaLa** & **1.000** & **0.922** & **0.960** & 120 & 0.06:34 \\\\ \\cline{2-6} & KGMatcher+ & **1.000** & 0.910 & 0.950 & 117 & 2.43:50 \\\\ \\cline{2-6} & Matcha & **1.000** & 0.910 & 0.900 & 104 & 0.01:00 \\\\ \\cline{2-6} & ATMatcher & **1.000** & 0.800 & 0.890 & 104 & 0.03:10 \\\\ \\cline{2-6} & String Baseline & **1.000** & 0.600 & 0.750 & 78 & 0.90:37 \\\\ \\hline \\hline \\multicolumn{6}{|c|}{**Knowledge Graph (only class matches)**} \\\\ \\hline \\multirow{6}{*}{\\begin{tabular}{c} maxrel-cineine{2-6} & **OLaLa** & **1.000** & **1.000** & **1.000** & 11 & 0.17:40 \\\\ \\cline{2-6} & ATMatcher & **1.000** & **1.000** & **1.000** & 11 & 0.94:36 \\\\ \\cline{2-6} & LogMap & **1.000** & **1.000** & **100** & 10 & 0.32:40 \\\\ \\cline{2-6} & LSMatch & **1.000** & **1.000** & **1.000** & 8 & 1.46:01 \\\\ \\cline{2-6} & String Baseline & **1.000** & **0.600** & 0.750 & 8 & 0.02:40 \\\\ \\hline \\multirow{6}{*}{\\begin{tabular}{c} memorylapha- \\\\ memorypheta \\\\ \\end{tabular} } & ATMatcher & 0.830 & **0.710** & **0.770** & 39 & 0.03:23 \\\\ \\cline{2-6} & LogMap & 0.880 & 0.500 & 0.640 & 21 & 0.05:09 \\\\ \\cline{2-6} & **OLaLa** & **1.000** & 0.350 & 0.530 & 24 & 0.35:03 \\\\ \\cline{2-6} & LSMatch & **1.000** & 0.290 & 0.440 & 26 & 0.57:37 \\\\ \\cline{2-6} & String Baseline & **1.000** & 0.290 & 0.440 & 19 & 0.01:50 \\\\ \\hline \\multirow{6}{*}{\\begin{tabular}{c} memorylapha- \\\\ stepand \\\\ \\end{tabular} } & ATMatcher & **1.000** & **0.770** & **0.870** & 34 & 0.02:04 \\\\ \\cline{2-6} & **OLaLa** & **1.000** & 0.540 & 0.700 & 28 & 0.29:41 \\\\ \\cline{2-6} & KGMatcher & **1.000** & 0.540 & 0.700 & 29 & 0.25:42 \\\\ \\cline{2-6} & LSMatch & **1.000** & 0.540 & 0.700 & 25 & 0.20:38 \\\\ \\hline \\multirow{6}{*}{\\begin{tabular}{c} starwars- \\\\ swg \\\\ \\end{tabular} } & String Baseline & **1.000** & 0.460 & 0.630 & 19 & 0.01:11 \\\\ \\cline{2-6} & LogMap & **1.000** & **0.800** & **0.890** & 12 & 0.07:44 \\\\ \\cline{2-6} & **OLaLa** & **1.000** & 0.600 & 0.750 & 13 & 0.38:49 \\\\ \\cline{2-6} & ATMatcher & **1.000** & 0.600 & 0.750 & 13 & 0.94:24 \\\\ \\cline{2-6} & LSMatch & **1.000** & 0.600 & 0.750 & 19 & 0.38:50 \\\\ \\cline{2-6} & String Baseline & **1.000** & 0.400 & 0.570 & 9 & 0.20:52 \\\\ \\hline \\multirow{6}{*}{\\begin{tabular}{c} starwars- \\\\ swor \\\\ \\end{tabular} } & ATMatcher & **1.000** & **0.870** & **0.930** & 30 & 0.94:20 \\\\ \\cline{2-6} & KGMatcher & **1.000** & **0.870** & **0.930** & 30 & 0.43:57 \\\\ \\cline{2-6} & String Baseline & **1.000** & 0.800 & 0.890 & 27 & 0.02:51 \\\\ \\cline{2-6} & **OLaLa** & 0.920 & 0.800 & 0.860 & 30 & 0.45:47 \\\\ \\cline{2-6} & LogMap & **1.000** & 0.730 & 0.850 & 28 & 0.07:10 \\\\ \\hline \\hline \\multicolumn{6}{|c|}{**Biodiv**} \\\\ \\cline{2-6} & LogMap & 0.781 & **0.656** & **0.713** & 676 & 0.00:25 \\\\ \\cline{2-6} & LogMapBio & 0.753 & 0.652 & 0.699 & 697 & 1.00:03 \\\\ \\cline{2-6} & LogMapInt & **0.829** & 0.594 & 0.692 & 576 & 0.07:32 \\\\ \\cline{2-6} & **OLaLa** & 0.431 & 0.613 & 0.510 & 1145 & 0.35:19 \\\\ \\hline \\multirow{6}{*}{ \\begin{tabular}{c} gemet- \\\\ anaee \\\\ \\end{tabular} } & AMI (2021) & **0.976** & 0.764 & **0.839** & 359 & 0.00:21 \\\\ \\cline{2-6} & ATMatcher (2021) & **0.631** & **0.919** & 7.486 & **0.00:08** \\\\ \\cline{2-6} & **OLaLa** & 0.565 & 0.916 & 0.699 & 542 & 4.28:07 \\\\ \\cline{2-6} & LogMapInt & 0.840 & 0.458 & 0.593 & 182 & 0.00:03 \\\\ \\hline \\end{tabular} \\end{table} Table 2. Performance of zero-shot bi-encoders (SBERT models) on the anatomy track. The best recall per \\(k\\) is highlighted with bold print. Time is measured in seconds. as on six datasets for the performance of semantic search12. The best three models of each evaluation are selected to be tested on the anatomy track. All models are publicly available via the huggingface model hub. Table 2 shows the results grouped by the value k. On the one hand, with increasing k, the number of generated candidates gets also much higher and results in a large runtime of the following LLM model. On the other hand, all correspondences which are not found in this stage cannot be part of the final result. Thus, only the recall value and alignment size are important at this step. The results correlate with the performance on the semantic search datasets which is why the multi-qa-mpnet-base-dot-v1 is selected (the top performing system on those 6 datasets). The parameter k is set to five because recall could be increased by 1.2 (from k=3 to k=5), whereas changing from k=5 to k=10 only increases the recall marginally, but nearly doubles the amount of marginally candidates. Footnote 12: [https://www.sbert.net/docs/pretrained](https://www.sbert.net/docs/pretrained) models.html"
    },
    {
      "title": "4.3.2. Llm Model",
      "text": "Table 3 shows the performance achieved with different LLM models. The selection of the analyzed models is done with the help of the huggingface LLM leaderboard13. Many of those models are based on LLama2 (Zhao et al., 2017) and fine-tuned on a specialized dataset. As of 01/09/2023, model jondurbin/airoboros-12-7bb-2.1 is the leading system whereas upstage/Llama-2-7bb-instruct-v2 is a general model which was also the leader of the board at the time of release. Footnote 13: [https://huggingface.co/spaces/HuggingFaceH/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH/open_llm_leaderboard) It can be observed that the F-measure increases with the model size except for the chat variant of LLama2. The reason might be that prompt 7 is more designed for completion than a chat. Model upstage/Llama-2-7bb-instruct-v2 is selected due to a high F-measure as well as a low runtime. For all models, the following parameters for loading the models are used: device_map is set to \" auto\", torch_dtype is set to \"float16\", and load_in_8bit is set to \"true\". With those settings, the memory footprint of the models is reduced such that the 7B and 13B variants fit on one A100 (40GB) GPU and the 70B variants on 2 GPUs of the same type."
    },
    {
      "title": "4.3.3. Text Extractors",
      "text": "Table 4 shows the results if the text extractor is modified. The Only_Label extractor is the worst in terms of F-Measure but it is also the fastest one (due to the small size of the input that needs to be processed). It is nice to see that the LLM can easily deal with RDF serializations (as produced by DescriptionInRDF extractor) and achieve an even higher F-Measure than SEB-Matcher and close to Matcha. For the final configuration, the Only_Label extractor is used to decrease the runtime even though other extractors could improve the final results. The few-shot prompts also contain verbalizations of concepts. Those are created according to the selected text extractor. We also tested to keep the original prompt but achieved better results by using the same text extractor for example creation and testing."
    },
    {
      "title": "4.3.4. Prompts",
      "text": "Table 6 shows the prompts used. Prompts 0-4 are zero-shot, meaning that no examples were provided. Prompt one tests if additional context information (e.g. what are the topics of the ontologies) improves the results. Prompts 2, 3, and 4 further try to guide the model to answer with yes/no. Prompt 5 uses one positive and one negative correspondence whereas prompt 6 uses three positives and three negatives. With those added examples it is possible to reach the best precision but the overall best F-Measure is achieved by adding a description of the task at the very beginning (prompt 7). However, it is remarkable that the second best results are achieved with a simple zero-shot prompt (prompt 0). Prompts 8 and 9 are multiple-choice decisions, which are observed to be inferior to single decision ones. The runtimes vary drastically. The main reason is that for some prompts the target tokens (like yes/no etc.) are generated very late or not at all. In such cases, the text completion takes rather long (even though the maximum number of new tokens is set to 10). Overall 22,288 examples are classified whereas the multiple choice decisions only need to predict 6,035 examples. Multiple choice prompts can reduce the runtimes, but achieve less good results. \\begin{table} \\begin{tabular}{|l|c|c|c|c|} \\hline **Text Extractor** & Prec & Rec & \\(F_{1}\\) & Size & Time \\\\ \\hline OnlyLabels & 0.914 & 0.891 & 0.902 & 1478 & 2:41:23 \\\\ \\hline VerbalizedRDF & 0.929 & 0.884 & 0.906 & 1443 & 3:57:46 \\\\ \\hline DescriptionInRDF & **0.943** & **0.915** & **0.929** & 1471 & 9:02:24 \\\\ \\hline \\end{tabular} \\end{table} Table 4. Performance impact of using different text extraction strategies on the anatomy track. \\begin{table} \\begin{tabular}{|l|c|c|c|c|c|} \\hline **Model** & Prec & Rec & \\(F_{1}\\) & Size & Time \\\\ \\hline meta-llama/ & & & & & \\\\ llama-2-7b-hf & & & & & \\\\ \\hline meta-llama/ & & & & & \\\\ llama-2-13b-hf & 0.806 & 0.820 & 0.813 & 1,543 & 1:35:15 \\\\ \\hline meta-llama/ & & & & & \\\\ llama-2-70b-hf & **0.946** & 0.860 & 0.901 & 1,378 & 6:45:13 \\\\ \\hline meta-llama/ & & & & & \\\\ llama-2-70b-that-hf & 0.663 & 0.801 & 0.725 & 1,832 & 3:55:57 \\\\ \\hline jondurbin/ & & & & & \\\\ airoboros-12-70b-2.1 & 0.804 & 0.877 & 0.839 & 1,654 & 4:00:12 \\\\ \\hline upstage/ & & & & & \\\\ llama-2-70b- & 0.914 & **0.891** & **0.902** & 1,479 & 2:40:18 \\\\ instruct-v2 & & & & & \\\\ \\hline \\end{tabular} \\end{table} Table 3. Performance impact of using different LLM models on the anatomy track. \\begin{table} \\begin{tabular}{|l|c|c|c|c|} \\hline **Postprocessing** & Prec & Rec & \\(F_{1}\\) & Size & Time \\\\ \\hline Candidates & 0.066 & **0.978** & 0.125 & 22,289 & 0:0:37 \\\\ + Cardinality & 0.385 & 0.693 & 0.495 & 2,731 & 0:0:37 \\\\ + Confidence & 0.387 & 0.693 & 0.497 & 2,715 & 0:00:37 \\\\ + LLM + Cardinality & 0.591 & 0.919 & 0.719 & 2,357 & 2:37:51 \\\\ + Confidence & 0.911 & 0.889 & 0.900 & 1,480 & 2:37:51 \\\\ + LLM + HP + Cardinality & 0.593 & 0.921 & 0.721 & 2,356 & 2:37:51 \\\\ + Confidence & **0.914** & 0.891 & **0.902** & **1,478** & 2:37:51 \\\\ \\hline \\end{tabular} \\end{table} Table 5. Impact of the LLM and the different post processing pipelines on the anatomy track. HP represents the high-precision matcher."
    },
    {
      "title": "4.3.5. Postprocessing",
      "text": "In this section, the influence of the postprocessing is analyzed. Table 5 shows the results when only the candidate generation step is executed and when each filter is additionally added. Without the LLM model, we achieve an F-Measure of 0.497 when the full filter chain is applied. When using the LLM and the cardinality filter, the F-Measure is already increased to 0.719. Still, there are a lot of incorrect correspondences even though one entity is only mapped to a maximum of one other entity. Thus, the confidence filter is applied which lifts the F-Measure to 0.9. Adding the results of the high-precision matcher provides a slight increase in both precision and recall."
    },
    {
      "title": "5. Conclusion And Outlook",
      "text": "In this paper, we presented _OLaLa_, an ontology matching system that is built on top of open-source large language models. We have shown that using such a model, especially in a few-shot setting, can yield competitive results, even if only based on textual descriptions. In our ablation study, we have observed that model and parameter combinations can have a strong impact on the overall results, and it is likely that there is no one-parameterization-fits-all solution, i.e., different parameter sets might deliver optimal results for different matching problems. Therefore, we plan to more closely examine the automatic parameterization of our system. OLaLa provides an experimentation base for different variations, such as new prompts (prompt engineering), and also prompting techniques, like generating knowledge in the form of text that is used as additional information during classification (Krizhevsky et al., 2017) or Chain-of-Thought prompting (Krizhevsky et al., 2017) that also allows to generate an explanation why two concepts are the same. In early experiments, we have observed that generating additional explanations for all candidates results in large runtimes (for anatomy, the expected runtime exceeds four days) but it could be useful to generate explanations for the final alignment which contains way less correspondences, or creating explanations on demand. As already shown, the text extractors make a huge difference in terms of F-Measure. The RDF serialization works best but also generates a lot of tokens which could be reduced by selecting important properties to be included. Finally, the system should be more scalable such that it can also be applied to large KGs with instance matching (which is technically possible, but with large runtimes). This could be achieved, e.g., by using a fast high-precision matcher to first find easy matches, and applying the LLM model only to edge cases."
    },
    {
      "title": "Acknowledgements.",
      "text": "The authors acknowledge support by the state of Baden-Wurttemberg through bwHPC and the German Research Foundation (DFG) through grant INST 35/1597-1 FUGG."
    },
    {
      "title": "References",
      "text": "* Soren Auer et al. (2007) Soren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Jves. 2007. Dbpedia: a nucleus for a web of open data. In _international semantic web conference_. Springer, Springer, Heidelberg, Germany, 722-735. * Volume 255 (1)_. (Volume 07), CEUR-WS.org, Aachen, DEU. 49-60. * Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In _Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019_, Volume 1 _(Long and Short Papers)_, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, 4171-4186. External Links: Link Cited by: SS2. * T. He, J. Chen, D. Antonynjah, and I. Horrocks (2022)BERTMap: a BERT-based ontology alignment system. In _Proceedings of the AAAI Conference on Artificial Intelligence_, Vol. 36. AAAI Press, Palo Alto, California, USA, 5684-5691. External Links: Link Cited by: SS2. * ISWC 2022_, Springer, Cham, 575-591. External Links: Link Cited by: SS2. * Y. He, J. Chen, E. Jimenez-Ruiz, H. Dong, and I. Horrocks (2023)Language model analysis for ontology subssumption inference. In _Findings of the Association for Computational Linguistics: ACL 2023_, Association for Computational Linguistics, Toronto, Canada, 3439-3453. External Links: Link Cited by: SS2. * S. Herling and H. Paulheim (2020)The knowledge graph track at oAEI-old standards, baselines, and the golden Hammer bias. In The Semantic Web 17th International Conference, ESWC 2020, Herdna, Crete, Greece, May-31 June 4, 2020, Proceedings (Lecture Notes in Computer Science, Vol. 12123), pp. 395-3994. External Links: Link Cited by: SS2. * 20th International Conference, ESWC 2023, Irisonison, Crete, Greece, May-32 June 4, 2023, Proceedings (Lecture Notes in Computer Science, Vol. 1370), pp. 105-121. External Links: Link, Document Cited by: SS2. * S. Herling, J. Poritsch, and H. Paulheim (2019)METL- matching evaluation Toolkit. In _Semantic Systems: The Power of AI and Knowledge Graphs_. Springer, Heidelberg, Germany, 231-245. External Links: Link Cited by: SS2. * A transformer-based approach for knowledge graph matching. CoRRabs/2204.13931. External Links: Link, 2204.13931 Cited by: SS2. * T. Kojima, S. S. Gu, M. Reid, T. Matsuo, and Y. Iwasawa (2022)Large language models are zero-shot sensors. Advances in neural information processing systems35, pp. 22199-22213. External Links: Link, 2202.12199 Cited by: SS2. * Y. Li, J. H. Solithithova, A. Doan, and W. Tan (2020)Deep entity matching with pre-trained language models. Proc. VLD Endoc. 14 (1), pp. 50-60. External Links: Link, Document Cited by: SS2. * F. Liu, E. Shaheyi, Z. Meng, M. Basallelds, and N. Collier (2021)Self-alignment pretraining for biomedical entity representations. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021, Association for Computational Linguistics, pp. 4228-4238. External Links: Link, Document Cited by: SS2. * J. Liu, A. Liu, X. Liu, X. Lu, S. W. Ren, R. L. Bras, Y. Choi, and H. Hajishriani (2022)Generated knowledge prompting for commonsense reasoning. In Annual Meeting of the Association for Computational Linguistics ACL, pp. 3154-3160. External Links: Link, Document Cited by: SS2. * Y. Liu, A. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, L. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov (2019)RoBERTA: a robustly optimized BERT pretraining approach. CoRRabs/1907.11692. External Links: Link, 1907.11692 Cited by: SS2. * P. Mateiu and A. Groza (2023)Ontopology engineering with large language models. CoRRabs/2307.16699. External Links: Link, 2307.16699 Cited by: SS2. * S. Neutel and M. H. T. de Boer (2021)Towards automatic ontology alignment using BERT. In Proceedings of the AAAI 2021 Spring Symposium on Combining Machine Learning and Knowledge Engineering (AAAI-MAKE 2021), Stanford University, Palo Alto, California, USA, March 22-24, 2021, External Links: Link, Document Cited by: SS2. * S. S. Norouzi, M. Sead Mahavavangal, and P. Fitter (2023)Conversational ontology alignment with chatoff. CoRRabs/2308.09217. External Links: Link, 2308.09217 Cited by: SS2. * J. Z. Pan, S. Ramirewski, J. Kalo, S. Singhania, J. Chen, S. Dietze, H. Jaibeen, J. Omeliyanenko, W. Zhang, M. Issamorii, R. Biswas, G. de Melo, A. Bonfili, Z. Vaya, M. Dragoni, and D. Grava (2023)Large language models and knowledge graphs: opportunities and challenges. CoRRabs/2308.06374. External Links: Link, 2308.06374 Cited by: SS2. * R. Peeters and C. Bizer (2023)Using chatoffert for entity matching. arXiv preprint arXiv:2305.03423. Cited by: SS2. * M. A. Nikoooie Pouri, A. Algergaway, P. Buche, L. Castro, J. Chen, H. Dong, O. Fallaath, D. Faria, I. Fundulaki, S. Herling, Y. He, I. Horrocks, M. Huschka, L. Ibanescu, E. Jimenez-Ruiz, N. Karam, A. Laadhar, P. Latk, H. Vlay, L. I. Dragoni, and D. Grava (2023)Large language models and knowledge graphs: opportunities and challenges. CoRRabs/2308.06374. External Links: Link, 2308.06374 Cited by: SS2. * R. Peeters and C. Bizer (2023)Using chatoffert for entity matching. arXiv preprint arXiv:2305.03423. Cited by: SS2. * M. A. Nikooie Pouri, A. Algergaway, P. Buche, L. Castro, J. Chen, H. Dong, O. Fallaath, D. Faria, I. Fundulaki, S. Herling, Y. He, I. Horrocks, M. Huschka, L. Ibanescu, E. Jimenez-Ruiz, N. Karam, A. Laadhar, P. Latk, H. Vlay, L. I. Dragoni, and D. Grava (2023)Large language models and knowledge graphs: opportunities and challenges. CoRRabs/2308.06374. External Links: Link, 2308.06374 Cited by: SS2. * R. Peeters and C. Bizer (2023)Using chatoffert for entity matching. arXiv preprint arXiv:2305.03423. Cited by: SS2. * M. A. Nikoie Pouri, A. Algergaway, P. Buche, L. Castro, J. Chen, H. Dong, O. Fallaath, D. Faria, I. Fundulaki, S. Herling, Y. He, I. Horrocks, M. Huschka, L. Ibanescu, E. Jimenez-Ruiz, N. Karam, A. Laadhar, P. Latk, H. Vlay, L. I. Dragoni, and D. Grava (2023)Large language models and knowledge graphs: opportunities and challenges. CoRRabs/2308.06374. External Links: Link, 2308.06374 Cited by: SS2. * R. Peeters and C. Bizer (2023)Using chatoffert for entity matching. arXiv preprint arXiv:2305.03423. Cited by: SS2. * M. A. Nikoie Pouri, A. Algergaway, P. Buche, L. Castro, J. Chen, H. Dong, O. Fallaath, D. Faria, I. Fundulaki, S. Herling, Y. He, I. Horrocks, M. Huschka, L. Ibanescu, E. Jimenez-Ruiz, N. Karam, A. Laadhar, P. Latk, H. Vlay, L. I. Dragoni, and D. Grava (2023)Large language models and knowledge graphs: opportunities and challenges. CoRRabs/2308.06374. External Links: Link, 2308.06374 Cited by: SS2. * R. Peeters and C. Bizer (2023)Using chatoffert for entity matching. arXiv preprint arXiv:2305.03423. Cited by: SS2. * M. A. A. Nikoie Pouri, A. Algergaway, P. Buche, L. Castro, J. Chen, H. Dong, O. [MISSING_PAGE_FAIL:8] Shvailo, Cassia Trojahn, Chantelle Verhey, Mingfang Wu, Beyza Yaman, Ondrej Zamazal, and Lu Zhou. 2022. Results of the Ontology Alignment Evaluation Initiative 2022. In _Proceedings of the 17th International Workshop on Ontology Matching (OM2022) co-located with the 21th International Semantic Web Conference (ISWC 2022), Hangzhou, China, held as a virtual conference, October 23, 2022 (CEUR Workshop Proceedings, Vol. 3324)_. CEUR-WS.org, 84-128. [https://ceur-ws.org/VolVol-3324/eaea22.paper.pdf](https://ceur-ws.org/VolVol-3324/eaea22.paper.pdf) * Reimers and Gurevych (2019) Nils Reimers and Lryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019_. Association for Computational Linguistics, 3980-3990. [https://doi.org/10.18653/V1/D19-1410](https://doi.org/10.18653/V1/D19-1410) * Samhysande Debut et al. (2019) Victor Samhysande Debut, Julien Chaumond, and Thomas Wolf. 2019. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. _arXiv preprint arXiv:1910.01108_ (2019). * 20th International Conference, ESWC 2023, Hersonisos, Crete, Greece, May 28 - June 1, 2023, Proceedings (Lecture Notes in Computer Science, Vol. 13870)_. Springer, 244-261. [https://doi.org/10.1007/978-3-031-33455-9_15](https://doi.org/10.1007/978-3-031-33455-9_15) * Su et al. (2022) Yixuan Su, Tian Lan, Yan Wang, Dami Yogatama, Lingpeng Kong, and Nigel Collier. 2022. A contrastive framework for neural text generation. _Advances in Neural Information Processing Systems_ 35 (2022), 21548-21561. * Tuowron et al. (2023) Hugo Tuowron, Thibaut Lavril, Gantier Izzacard, Xavier Martinet, Marie-Anne Lachaux, Timotheto Lacroix, Bapitsie Rozier, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llima: Open and efficient foundation language models. _arXiv preprint arXiv:2302.19971_ (2023). * Touvron et al. (2023) Hugo Tuowron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Bahaei, Nikolay Bashlykov, Soumya Batra, Prajajwal Bhargava, Shruti Bhosale, et al. 2023. Llama: Open foundation and fine-tuned chat models. _arXiv preprint arXiv:2307.09828_ (2023). * Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. _Advances in neural information processing systems_ 30 (2017). * Wang et al. (2023) Qinyong Wang, Zhenxiang Gao, and Rong Xu. 2023. Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking. _arXiv preprint arXiv:2307.01137_ (2023)."
    }
  ]
}
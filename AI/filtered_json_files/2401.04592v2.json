{
  "title": "An Assessment on Comprehending Mental Health through Large Language Models",
  "authors": [
    "Mihael Arcan",
    "Ireland Lua Health",
    "David-Paul Niland"
  ],
  "abstract": "\n Mental health challenges pose considerable global burdens on individuals and communities. Recent data indicates that more than 20% of adults may encounter at least one mental disorder in their lifetime. On the one hand, the advancements in large language models have facilitated diverse applications, yet a significant research gap persists in understanding and enhancing the potential of large language models within the domain of mental health. On the other hand, across various applications, an outstanding question involves the capacity of large language models to comprehend expressions of human mental health conditions in natural language. This study presents an initial evaluation of large language models in addressing this gap. Due to this, we compare the performance of Llama-2 and ChatGPT with classical Machine as well as Deep learning models. Our results on the DAIC-WOZ dataset show that transformer-based models, like BERT or XLNet, outperform the large language models. \n",
  "references": [
    {
      "id": null,
      "title": "An Assessment on Comprehending Mental Health through Large Language Models",
      "authors": [
        "Mihael Arcan",
        "Lua Health",
        "David-Paul Niland"
      ],
      "year": "2024",
      "venue": "",
      "doi": "10.1145/nnnnnnn.nnnnnnn"
    },
    {
      "id": "b0",
      "title": "An overview of the features of chatbots in mental health: A scoping review",
      "authors": [
        "Alaa A Abd-Alrazaq",
        "Mohannad Alajlani",
        "Ali Abdallah Alalwan",
        "Bridgette M Bewick",
        "Peter Gardner",
        "Mowafa Househ"
      ],
      "year": "2019",
      "venue": "International Journal of Medical Informatics",
      "doi": "10.1016/j.ijmedinf.2019.103978"
    },
    {
      "id": "b1",
      "title": "Multi-Task Learning for Mental Health using Social Media Text",
      "authors": [
        "Adrian Benton",
        "Margaret Mitchell",
        "Dirk Hovy"
      ],
      "year": "2017",
      "venue": "Multi-Task Learning for Mental Health using Social Media Text",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "Say 'YES' to Positivity: Detecting Toxic Language in Workplace Communications",
      "authors": [
        "Moorthy Meghana",
        "Saghar Bhat",
        "Ahmed Hosseini",
        "Paul N Hassan Awadallah",
        "Weisheng Bennett",
        "Li"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana",
      "doi": "10.18653/v1/2021.findings-emnlp.173"
    },
    {
      "id": "b3",
      "title": "Fine-tuning a LLM using Reinforcement Learning from Human Feedback for a Therapy Chatbot Application (Independent thesis Basic level, degree of Bachelor)",
      "authors": [
        "Desiree Bill",
        "Theodor Eriksson"
      ],
      "year": "2023",
      "venue": "Fine-tuning a LLM using Reinforcement Learning from Human Feedback for a Therapy Chatbot Application (Independent thesis Basic level, degree of Bachelor)",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Assessing the Usability of a Chatbot for Mental Health Care",
      "authors": [
        "Gillian Cameron",
        "David Cameron",
        "Gavin Megaw",
        "Raymond Bond",
        "Maurice Mulvenna",
        "O' Siobhan",
        "Cherie Neill",
        "Michael Armour",
        "Mctear"
      ],
      "year": "2019",
      "venue": "Assessing the Usability of a Chatbot for Mental Health Care",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "Can AI Help Reduce Disparities in General Medical and Mental Health Care?",
      "authors": [
        "Irene Y Chen",
        "Peter Szolovits",
        "Marzyeh Ghassemi"
      ],
      "year": "2019",
      "venue": "AMA journal of ethics",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "XGBoost: A Scalable Tree Boosting System",
      "authors": [
        "Tianqi Chen",
        "Carlos Guestrin"
      ],
      "year": "2016",
      "venue": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
      "doi": "10.1145/2939672.2939785"
    },
    {
      "id": "b7",
      "title": "Challenges of Large Language Models for Mental Health Counseling",
      "authors": [
        "Neo Christopher",
        "Chung",
        "George Dyer",
        "Lennart Brocki"
      ],
      "year": "2023",
      "venue": "Challenges of Large Language Models for Mental Health Counseling",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "CLPsych 2015 Shared Task: Depression and PTSD on Twitter",
      "authors": [
        "Glen Coppersmith",
        "Mark Dredze",
        "Craig Harman",
        "Kristy Hollingshead",
        "Margaret Mitchell"
      ],
      "year": "2015",
      "venue": "Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality",
      "doi": "10.3115/v1/W15-1204"
    },
    {
      "id": "b9",
      "title": "Passive Diagnosis Incorporating the PHQ-4 for Depression and Anxiety",
      "authors": [
        "Fionn Delahunty",
        "Robert Johansson",
        "Mihael Arcan"
      ],
      "year": "2019",
      "venue": "Proceedings of the Social Media Mining for Health Applications",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "First Insights on a Passive Major Depressive Disorder Prediction System with Incorporated Conversational Chatbot",
      "authors": [
        "Fionn Delahunty",
        "Ian D Wood",
        "Mihael Arcan"
      ],
      "year": "2018",
      "venue": "Irish Conference on Artificial Intelligence and Cognitive Science",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2018",
      "venue": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/N19-1423"
    },
    {
      "id": "b13",
      "title": "Facebook language predicts depression in medical records",
      "authors": [
        "Johannes C Eichstaedt",
        "Robert J Smith",
        "Raina M Merchant",
        "Lyle H Ungar",
        "Patrick Crutchley",
        "Daniel Preoţiuc-Pietro",
        "David A Asch",
        "H Andrew Schwartz"
      ],
      "year": "2018",
      "venue": "Proceedings of the National Academy of Sciences",
      "doi": "10.1073/pnas.1802331115"
    },
    {
      "id": "b14",
      "title": "The Capability of Large Language Models to Measure Psychiatric Functioning",
      "authors": [
        "R Isaac",
        "Daniel Galatzer-Levy",
        "Mcduff",
        "Alan Vivek Natarajan",
        "Matteo Karthikesalingam",
        "Malgaroli"
      ],
      "year": "2023",
      "venue": "The Capability of Large Language Models to Measure Psychiatric Functioning",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "The Distress Analysis Interview Corpus of human and computer interviews",
      "authors": [
        "Jonathan Gratch",
        "Ron Artstein",
        "Gale Lucas",
        "Giota Stratou",
        "Stefan Scherer",
        "Angela Nazarian",
        "Rachel Wood",
        "Jill Boberg",
        "David Devault",
        "Stacy Marsella",
        "David Traum",
        "Skip Rizzo",
        "Louis-Philippe Morency"
      ],
      "year": "2014",
      "venue": "Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14)",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "Understanding and Measuring Psychological Stress using Social Media",
      "authors": [
        "Chandra Sharath",
        "Anneke Guntuku",
        "Kokil Buffone",
        "Johannes C Jaidka",
        "Lyle H Eichstaedt",
        "Ungar"
      ],
      "year": "2018",
      "venue": "Understanding and Measuring Psychological Stress using Social Media",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Detecting depression and mental illness on social media: an integrative review",
      "authors": [
        "Chandra Sharath",
        "Guntuku",
        "Margaret L David B Yaden",
        "Lyle H Kern",
        "Johannes C Ungar",
        "Eichstaedt"
      ],
      "year": "2017",
      "venue": "Current Opinion in Behavioral Sciences",
      "doi": "10.1016/j.cobeha.2017.07.005"
    },
    {
      "id": "b18",
      "title": "Multimodal mental health assessment with remote interviews using facial, vocal, linguistic, and cardiovascular patterns",
      "authors": [
        "Zifan Jiang",
        "Salman Seyedi",
        "Emily Griner",
        "Ahmed Abbasi",
        "Ali Bahrami Rad",
        "Hyeokhyen Kwon",
        "Robert O Cotes",
        "Gari D Clifford"
      ],
      "year": "2023",
      "venue": "medRxiv",
      "doi": "10.1101/2023.09.11.23295212"
    },
    {
      "id": "b19",
      "title": "PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for Mental Health",
      "authors": [
        "Haoan Jin",
        "Siyuan Chen",
        "Mengyue Wu",
        "Kenny Q Zhu"
      ],
      "year": "2023",
      "venue": "PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for Mental Health",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "An ultra-brief screening scale for anxiety and depression: The PHQ-4",
      "authors": [
        "K Kroenke",
        "R L Spitzer",
        "Jbw Williams",
        "B Löwe"
      ],
      "year": "2009",
      "venue": "Psychosomatics",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Designing a Chatbot as a Mediator for Promoting Deep Self-Disclosure to a Real Mental Health Professional",
      "authors": [
        "Yi-Chieh Lee",
        "Naomi Yamashita",
        "Yun Huang"
      ],
      "year": "2020",
      "venue": "Proc. ACM Hum.-Comput. Interact. 4, CSCW1, Article 31",
      "doi": "10.1145/3392836"
    },
    {
      "id": "b22",
      "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "year": "2019",
      "venue": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "Towards automatic text-based estimation of depression through symptom prediction",
      "authors": [
        "Kirill Milintsevich",
        "Kairit Sirts",
        "Gaël Dias"
      ],
      "year": "2023",
      "venue": "Brain Informatics",
      "doi": "10.1186/s40708-023-00185-9"
    },
    {
      "id": "b24",
      "title": "Large Language Models in Neurology Research and Future Practice",
      "authors": [
        "F Michael",
        "Ludy C Romano",
        "Shih",
        "C Ioannis",
        "Rhoda Paschalidis",
        "Vijaya B Au",
        "Kolachalama"
      ],
      "year": "2023",
      "venue": "Neurology",
      "doi": "10.1212/WNL.0000000000207967"
    },
    {
      "id": "b25",
      "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
      "authors": [
        "Victor Sanh",
        "Lysandre Debut",
        "Julien Chaumond",
        "Thomas Wolf"
      ],
      "year": "2020",
      "venue": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Predicting Depression and Anxiety on Reddit: A Multi-Task Learning Approach",
      "authors": [
        "Shailik Sarkar",
        "Abdulaziz Alhamadani",
        "Lulwah Alkulaib",
        "Chang-Tien Lu"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (Istanbul, Turkey) (ASONAM '22)",
      "doi": "10.1109/ASONAM55673.2022.10068655"
    },
    {
      "id": "b27",
      "title": "Large language models could change the future of behavioral healthcare: A proposal for responsible development and evaluation",
      "authors": [
        "Elizabeth C Stade",
        "Shannon Wiltsey Stirman",
        "Lyle Ungar",
        "Cody L Boland",
        "H Andrew Schwartz",
        "David B Yaden",
        "João Sedoc",
        "Robert J Derubeis",
        "Robb Willer",
        "Johannes C Eichstaedt"
      ],
      "year": "2023",
      "venue": "PsyArXiv",
      "doi": "10.31234/osf.io/cuzvr"
    },
    {
      "id": "b28",
      "title": "A Call to Action on Assessing and Mitigating Bias in Artificial Intelligence Applications for Mental Health",
      "authors": [
        "Adela C Timmons",
        "Jacqueline B Duong",
        "Natalia Simo Fiallo",
        "Theodore Lee",
        "Huong Phuc",
        "Quynh Vo",
        "Matthew W Ahle",
        "Jonathan S Comer",
        "La Princess",
        "C Brewer",
        "Stacy L Frazier",
        "Theodora Chaspari"
      ],
      "year": "2023",
      "venue": "Perspectives on Psychological Science",
      "doi": "10.1177/17456916221134490"
    },
    {
      "id": "b29",
      "title": "LLaMA: Open and Efficient Foundation Language Models",
      "authors": [
        "Hugo Touvron",
        "Thibaut Lavril",
        "Gautier Izacard",
        "Xavier Martinet",
        "Marie-Anne Lachaux",
        "Timothée Lacroix",
        "Baptiste Rozière",
        "Naman Goyal",
        "Eric Hambro",
        "Faisal Azhar",
        "Aurelien Rodriguez",
        "Armand Joulin",
        "Edouard Grave",
        "Guillaume Lample"
      ],
      "year": "2023",
      "venue": "LLaMA: Open and Efficient Foundation Language Models",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "Open Foundation and Fine-Tuned Chat Models",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava",
        "Shruti Bhosale",
        "Dan Bikel",
        "Lukas Blecher",
        "Cristian Canton Ferrer",
        "Moya Chen",
        "Guillem Cucurull",
        "David Esiobu",
        "Jude Fernandes",
        "Jeremy Fu",
        "Wenyin Fu",
        "Brian Fuller",
        "Cynthia Gao",
        "Vedanuj Goswami",
        "Naman Goyal",
        "Anthony Hartshorn",
        "Saghar Hosseini",
        "Rui Hou",
        "Hakan Inan",
        "Marcin Kardas",
        "Viktor Kerkez",
        "Madian Khabsa",
        "Isabel Kloumann",
        "Artem Korenev",
        "Punit Singh Koura",
        "Marie-Anne Lachaux",
        "Thibaut Lavril",
        "Jenya Lee",
        "Diana Liskovich",
        "Yinghai Lu",
        "Yuning Mao",
        "Xavier Martinet",
        "Todor Mihaylov",
        "Pushkar Mishra",
        "Igor Molybog",
        "Yixin Nie",
        "Andrew Poulton",
        "Jeremy Reizenstein",
        "Rashi Rungta",
        "Kalyan Saladi",
        "Alan Schelten",
        "Ruan Silva"
      ],
      "year": "2023",
      "venue": "Open Foundation and Fine-Tuned Chat Models",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "Attention is All you Need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan N Gomez",
        "Ł Ukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "Leveraging Collaborative-Filtering for Personalized Behavior Modeling: A Case Study of Depression Detection among College Students",
      "authors": [
        "Xuhai Xu",
        "Prerna Chikersal",
        "Janine M Dutcher",
        "Yasaman S Sefidgar",
        "Woosuk Seo",
        "Michael J Tumminia",
        "Daniella K Villalba",
        "Sheldon Cohen",
        "Kasey G Creswell",
        "J David Creswell",
        "Afsaneh Doryab",
        "Paula S Nurius",
        "Eve Riskin",
        "Anind K Dey",
        "Jennifer Mankoff"
      ],
      "year": "2021",
      "venue": "Proc. ACM Interact. Mob. Wearable Ubiquitous Technol",
      "doi": "10.1145/3448107"
    },
    {
      "id": "b33",
      "title": "Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data",
      "authors": [
        "Xuhai Xu",
        "Bingsheng Yao",
        "Yuanzhe Dong",
        "Saadia Gabriel",
        "Hong Yu",
        "James Hendler",
        "Marzyeh Ghassemi",
        "Anind K Dey",
        "Dakuo Wang"
      ],
      "year": "2023",
      "venue": "Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data",
      "doi": ""
    },
    {
      "id": "b34",
      "title": "MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models",
      "authors": [
        "Kailai Yang",
        "Tianlin Zhang",
        "Ziyan Kuang",
        "Qianqian Xie",
        "Sophia Ananiadou",
        "Jimin Huang"
      ],
      "year": "2023",
      "venue": "MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models",
      "doi": ""
    },
    {
      "id": "b35",
      "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding",
      "authors": [
        "Zhilin Yang",
        "Zihang Dai",
        "Yiming Yang",
        "Jaime Carbonell",
        "Ruslan Salakhutdinov",
        "Quoc V Le"
      ],
      "year": "2019",
      "venue": "Proceedings of the 33rd International Conference on Neural Information Processing Systems",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "2. Related Work",
      "text": "To address Major Depressive Disorder (MDD), (Han et al., 2017) proposes a passive diagnostic system that integrates clinical psychology, machine learning, and conversational dialogue systems. Through the use of sequence-to-sequence neural networks, a real-time dialogue system engages individuals, while specialised machine learning classifiers monitor conversations to predict critical depression symptoms. Evaluation results indicate potential advancements in human-like chatbots and depression identification. Despite acknowledging limitations in data representation and a small sample size, the study suggests the possibility of enhancing support for individuals with MDD through real-time communication tools. Similarly, (Han et al., 2017) introduces a deep neural network for predicting PHQ-4 scores (depression and anxiety levels) from written text. Leveraging the Universal Sentence Encoder and a deep learning Transformer neural network, the model demonstrates efficacy in psychometric score prediction. Exploring application to social media data, the study incorporates psycholinguistic features and a multi-dimensional deep neural network, noting challenges related to domain-specificity and generalizability. In addressing MDD, (Kang et al., 2018) employs natural language processing to create a neural classifier detecting depression from speech transcripts. By predicting individual depression symptoms, the study utilises a symptom network analysis approach and achieves comparable results to state-of-the-art models in binary diagnosis and depression severity prediction. Similarly, (Beng et al., 2017) focuses on toxic workplace communication in emails, introducing ToxiScope, a taxonomy to detect and quantify toxic language patterns. Through annotation tasks and machine learning models, the study reveals insights into implicit and explicit workplace toxicity. The research suggests refining detection methods and exploring correlations between toxicity, power dynamics, and biases in workplace communication for future directions. [19] explore the potential of objective digital biomarkers in assessing psychiatric disorders. By investigating behavioral and physiological signals extracted from remote interviews, the research assesses the complementary information provided by multimodal features. The study derives time series features from four conceptual modes: facial expression, vocal expression, linguistic expression, and cardiovascular modulation. These features are extracted from audio and video recordings of remote interviews, using task-specific and foundation models. Four binary classification tasks are defined, including the detection of clinically-diagnosed psychiatric disorders, major depressive disorder, self-rated depression, and self-rated anxiety. Results indicate statistically significant feature differences between controls and subjects with mental ill-health conditions, with correlations found between features and self-rated depression and anxiety scores. The best unimodal performance is achieved by visual heart rate dynamics, with areas under the receiver-operator curve (AUROCs) ranging from 0.68 to 0.75. Combining multiple modalities enhances performance, yielding AUROCs of 0.72 to 0.82. Task-specific models outperform foundation models, suggesting the effectiveness of specific features. This comprehensive multimodal analysis on 73 subjects, using remotely-recorded telehealth interviews, reveals informative characteristics of clinically diagnosed and self-rated mental health status. The study provides early evidence of the utility of multimodal digital biomarkers extracted from low-cost, non-lab-controlled data, offering insights into the most suitable modalities and methods for automated remote mental health assessments. Large language models (LLMs), such as GPT-3, GPT-4, and Google's PaLM, show potential to revolutionise psychotherapy by supporting, augmenting, or possibly replacing human-led interventions, addressing challenges in mental healthcare capacity and providing personalised treatments. [28] offer a roadmap for the responsible application of clinical LLMs in psychotherapy. It provides a technical overview, discusses integration stages with parallels to autonomous vehicle technology, explores potential applications in clinical care, training, and research, and offers recommendations for responsible development and evaluation. While recognizing the promise of LLMs, the paper urges caution, emphasizing the need for psychologists to approach integration with care, educate the public about risks, and actively engage with technologists. It advocates for ongoing monitoring and advocacy for responsible and ethical use of LLMs in psychotherapy to ensure patient well-being. [8] delves into primary challenges in LLM development for psychological counseling, addressing model hallucination, interpretability, bias, privacy, and clinical effectiveness. Practical solutions are suggested based on the authors' experiences. While medical applications of LLMs have been experimented with, superior performance over human doctors is noted alongside evidence of limitations in mental health counseling. AI acceptance in medicine, especially mental ill-health, requires substantial improvements and responsible development. The paper anticipates LLM integration into the medical field, acknowledging increased regulatory scrutiny. Challenges are detailed from academic research, advocating a holistic approach and emphasizing diverse data representation and cautious model fine-tuning. Regulatory bodies are expected to play pivotal roles, demanding evidence of beneficial model use. Despite potential shifts in the AI landscape, leveraging the current paradigm is deemed imperative amid escalating global mental health disorders. The paper underscores the necessity of enhancing existing LLMs for psychological counseling tools, recognizing exceptional benefits despite formidable challenges. [25] highlight the increasing attention on generative artificial intelligence, particularly large language models (LLMs), and their potential in analyzing extensive medical records for insights into neurology. The paper explores various use cases for LLMs in neurology, including early diagnosis, patient and caregiver support, and assisting clinicians. It acknowledges potential ethical and technical challenges, such as privacy concerns, data security, biases in training data, and the importance of rigorous validation. While recognizing these challenges, the paper emphasises the promising opportunities LLMs present for enhancing the care and treatment of neurologic disorders, underscoring the need for responsible research practices. [35] addresses the growing significance of social media as a valuable source for automatic mental health analysis, focusing on interpretable models. While recent large language models (LLMs) have been explored for this purpose, their unsatisfactory performance in zero-shot/few-shot scenarios poses challenges. To tackle this, the authors introduce the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset, containing 105K data samples from diverse social media sources. They use ChatGPT to generate explanations and rigorously evaluate correctness, consistency, and quality. The resulting MentalLaMA, an open-source instruction-following LLM series, achieves state-of-the-art performance, generating ChatGPT-level explanations and displaying strong generalizability to unseen tasks on the IMHI benchmark. The paper contributes a comprehensive dataset and model for interpretable mental health analysis on social media. [34] present a comprehensive evaluation of various Language Models (LLMs), including Alpaca, Alpaca, FLAN-T5, GPT-3.5, and GPT-4, in the context of mental ill-health prediction tasks using online text data. The experiments cover zero-shot prompting, few-shot prompting, and instruction finetuning, revealing key insights. The context enhancement strategy consistently improves performance for all LLMs, and mental health enhancement proves effective for models with a substantial number of trainable parameters. Few-shot prompting consistently boosts model performance, even with just one example per class. Crucially, instruction finetuning across multiple datasets significantly enhances model performance across various mental health prediction tasks. The top finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform larger models like GPT-3.5 and GPT-4, performing on par with the state-of-the-art task-specific model Mental-RoBERTa. An exploratory case study on reasoning capabilities underscores both promising potential and notable limitations of LLMs. The findings are distilled into guidelines for researchers, developers, and practitioners enhancing LLMs' understanding of mental health for downstream tasks. Emphasis is placed on the ethical considerations in this research domain, highlighting that practical deployment of LLMs in mental health applications is currently distant. [4] focus on fine-tuning an LLM for a specific function in psychology using Reinforcement Learning from Human Feedback (RLHF) and explores its viability. The theoretical foundation of LLMs, RLHF, and the ethical considerations of developing a psychological AI are presented. Previous studies on RLHF and AI in psychology demonstrate the feasibility of the proposed goal. The methodology for training and evaluating the model involves comparing a pre-trained model with the fine-tuned one, whereby the study finds no clear difference between the used models. The study also delves into an ethical framework for a digital psychology assistant, proposing a suitable introduction to the market and the division of responsibilities. The discussion extends to rules and regulations applicable to this research field, emphasizing the need for governments to introduce relevant regulations for AI innovation, encompassing ethics, accountability, and personal data protection. [15] investigate the capability of Large Language Models (LLMs), specifically Med-PaLM 2, trained on extensive medical knowledge, to predict psychiatric functioning from patient interviews and clinical descriptions without specific training for such tasks. Analyzing 145 depression, 115 PTSD assessments, and 46 clinical case studies across various disorders, the results indicate that Med-PaLM 2 can assess psychiatric functioning effectively. The strongest performance is observed in predicting depression scores (Accuracy range= 0.80 - 0.84), which is statistically indistinguishable from human clinical raters. The findings suggest the potential of general clinical language models to flexibly predict psychiatric risk based on free descriptions from both patients and clinicians. [20] address the growing interest in utilizing LLMs in mental health research and identifies a lack of a comprehensive benchmark for evaluating their capabilities in this domain. The authors introduce PsyEval, the first benchmark tailored to the unique characteristics of mental ill-health, consisting of six sub-tasks across three dimensions. Eightadvanced LLMs are evaluated using PsyEval, revealing significant room for improvement in current LLMs in mental health-related tasks. Notably, GPT-4 shows satisfactory performance in mental health Question-Answering (QA) but still requires advancement. The benchmark highlights performance gaps, particularly in tasks involving disease prediction from social media posts and accurate forecasting of depression and suicide severity in simulated doctor-patient dialogues. The results emphasise the need for further advancements in tailoring language models for mental health applications, and PsyEval is positioned as a valuable tool for assessing and guiding such developments."
    },
    {
      "title": "3. Methodology",
      "text": "Within this section we provide our methods on data preprocessing as well as the predictive models used in this work. We further provide insights on leveraging prompts for finetuning the used LLM."
    },
    {
      "title": "Data Preprocessing",
      "text": "For every participant in the dataset, there is a corresponding PHQ-4 score that is divided into four variables. These variables align to each of the variables in the PHQ-4 questionnaire; Generalised Anxiety Disorder 1 and 2 (GAD-1, GAD-2), Patient Health Questionnaire 1 and 2 (PHQ-1 and PHQ-2). GAD 1 and GAD 2 relate to anxiety and PHQ-1 and PHQ-2 relate to depression. One participant may have many messages, but that participant has only one overall PHQ4 score. Their score is divided into the four separate categories; GAD-1, GAD-2, PHQ-1 and PHQ-2. As some of the messages were quite short in the dataset, we decided to lengthen the messages to add more contextual information to a PHQ4 score that might be associated with that particular person. We concatenated messages to a maximum of 50 words per observation. We only concatenated messages together that were from the same person. We did not concatenate messages together that were from two different people. After the concatenation step and duplicates and missing values removed, there were 28,186 observations in the training set and 8,710 in the test set."
    },
    {
      "title": "Xgboost",
      "text": "The messages were loaded into a pre-trained Transformer model, which produced a dense vector representation of the text. This vector was then loaded into the XGBoost classifier. We used five-fold cross validation to find the optimal hyperparameters. The best model was selected based on weighted F1."
    },
    {
      "title": "Prompting Llms",
      "text": "In order to retrieve a specific response from the LLMs, we prompted the targeted LLMs with five different queries and evaluated each of them on their performance. The variation differed in terms of lexicalised outputs as well as the definitions and length of the prompts provided to the LLM. Some initial exploratory experiments led to the formation of templates to structure the prompts that were used. We tailored each prompting strategy to each one of the PHQ or GAD questions. This meant that there was a total of 20 different prompts. Differences between versions of prompts only varied slightly. Some differences were minor, such as using \"on a scale of zero to three\" in one prompt and \"one a scale of 0 to 3\" in another. Some prompts were brief (cf. Version 3 in 1), while others were lengthy and included examples of messages that had been evaluated based on specific GAD or PHQ questions within the prompt. The goal of the prompts was that the LLM would return a number corresponding to the PHQ or GAD question that the prompt was structured around, whereby we had regular expressions to handle the outputs. These consisted of taking the first digit number out of the string or converting numbers in linguistic format to integers. For example,if the chatbot responded with \"This messages looks like it is showing zero levels of anxiety\", then our system would return \"0\". This was to make it easier to analyse and evaluate. \\begin{table} \\begin{tabular}{p{42.7pt}|p{284.5pt}} \\hline \\hline Version 1 & \\\\ \\hline GAD-1 & On a scale of **zero** to **three**, estimate how anxious this person is with zero being a little anxious and three being incredibly anxious: + **TEXT** \\\\ GAD-2 & On a scale of **zero** to **three**, estimate how worried this person is with zero being a little worried and three being incredibly worried: + **TEXT** \\\\ PHQ-1 & On a scale of **zero** to **three**, estimate how depressed this person is with zero being a little depressed and three being incredibly depressed: + **TEXT** \\\\ PHQ-2 & On a scale of **zero** to **three**, estimate if this person is expressing no interest in previously enjoyed activities with zero being a little and three being incredibly: + **TEXT** \\\\ \\hline Version 2 & \\\\ \\hline GAD-1 & On a scale of **0** to **3**, estimate how anxious this person is with 0 being a little anxious and 3 being incredibly anxious: + **TEXT** \\\\ GAD-2 & On a scale of **0** to **3**, estimate how worried this person is with 0 being a little worried and 3 being incredibly worried: + **TEXT** \\\\ PHQ-1 & On a scale of **0** to **3**, estimate how depressed this person is with 0 being a little depressed and 3 being incredibly depressed: + **TEXT** \\\\ PHQ-2 & On a scale of **0** to **3**, estimate if this person is expressing no interest in previously enjoyed activities with 0 being a little and 3 being incredibly: + **TEXT** \\\\ \\hline Version 3 & \\\\ \\hline GAD-1 & On a scale of **zero** to **three**, rate the anxiety of this message: + **TEXT** \\\\ GAD-2 & On a scale of **zero** to **three**, rate the worry in this message: + **TEXT** \\\\ PHQ-1 & On a scale of **zero** to **three**, rate the depression in this message: + **TEXT** \\\\ PHQ-2 & On a scale of **zero** to **three**, rate the interest in previously enjoyed activities in this message: + **TEXT** \\\\ \\hline Version 4 & \\\\ \\hline GAD-1 & **Generalised anxiety disorder is a mental health illness that is defined by people having feelings of excessive anxiety.** On a scale of zero to three, rate the anxiety in this message: + **TEXT** \\\\ GAD-2 & **Generalised anxiety disorder is a mental health illness that is defined by people having feelings of excessive worry.** On a scale of zero to three, rate the anxiety in this message: + **TEXT** \\\\ PHQ-1 & **Depression, or major depressive disorder is a mental health illness that is categorised by people feeling down, depressed or hopeless.** On a scale of zero to three, rate the depression in this message: + **TEXT** \\\\ PHQ-2 & **Depression, or major depressive disorder is a mental health illness that is categorised by people having little interest or pleasure in doing things.** On a scale of zero to three, rate the depression in this message: + **TEXT** \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 1: Examples for different prompting versions for GAD and PHQ questions. * [F \\begin{table} \\begin{tabular}{c|l} \\hline \\hline Version 5 & \\\\ \\hline GAD-1 & Generalised anxiety disorder is a mental health illness that is defined by people having feelings of excessive anxiety. \\\\ & **The anxiety in this example is rated zero:** “like uh a a a guy that likes to see different sights and go different places uh like different i’m a big movie person so i like going to theatres stuff like that try to free myself from the situation to clear my mind usually take a walk or something\" **The anxiety in this example is rated one:** “got stuck out here then i had my baby and i just stayed be doing a little bit of everything a good night’s sleep i grew up not getting to know who my mom was out there just on the food basis they like to give you a lotta food\" **The anxiety in this example is rated two:** “it was it was great and now it’s just okay i’m hardworking i’m uh i care about everyone i yep i suppose going on a trip to canada with my daughter was very memorable i love la i love the traffic on the four o five i love the beach\" **The anxiety in this example is rated three:** “regret right now is um that’s just how she is value we were always what what’s the word i’m looking for um also the weather was just it was absolutely awful there and it was just it was very difficulties in my life she’s very touchy i would say in.\" On a scale of zero to three, rate the anxiety in this message: + Text \\\\ GAD-2 & Generalised anxiety disorder is a mental health illness that is defined by people having feelings of excessive worry. \\\\ & **The worry in this example is rated zero:** “i’ve added that to my life she’s a great woman and uh that started a future in in athletics and that’s what i wanted to do so i accomplished my goals so at the time it was a great a great thing and it still is a great thing it’s\" **The worry in this example is rated one:** “lot of stress every day just everyday stress uh yeah pretty much that’s what triggers it play like games like i like to play video games those are fun stuff like that okay thanks eh my family it’s just eh we’re not like too too close we kinda argue a\" **The worry in this example is rated three:** “guess that and not and then there’s you i don’t completely lose it for days at a time when i can get really into that and sort of shut out the rest of the world um the music and the the thoughts just kind of it really makes me a\" On a scale of zero to three, rate the anxiety in this message: + Text \\\\ PHQ-1 & Depression, or major depressive disorder is a mental health illness that is categorised by people feeling down, depressed or hopeless. **The depression in this example is rated zero:** “like uh a a guy that likes to see different sights and go different places uh like different i’m a big movie person so i like going to theatres stuff like that try to free myself from the situation to clear my mind usually take a walk or something\" **The depression in this example is rated one:** “of my friend i wish i would’ve handled his sister a little differently as far as the dirt it has been yes it was uh it’s very close um no i have not we’ve always maintained our friendship um i can’t recall one off hand no problem and that’s all” **The depression in this example is rated two:** “fight or anything or yeah any of that my grandma she’s always giving me encouragement and um she’s a therapist a licensed therapist so she’s always you know made it really really um yeah i’m okay yeah um i just try to stay positive i try to think like okay” **The depression in this example is rated three:** “to my son my son and daughter-in-law and my daughter and i went out to have hawaiian food got together it’s always fun to get together we got together at my house on christmas i enjoyed just getting together with them i guess the newness wore off that just have” On a scale of zthat’sero to three, rate the depression in this message: + Text \\\\ PHQ-2 & Depression, or major depressive disorder is a mental health illness that is categorised by people having little interest or pleasure in doing things. **The depression in this example is rated zero:** “like uh a a a guy that likes to see different sights and go different places uh like different i’m a big movie person so i like going to theatres stuff like that try to free myself from the situation to clear my mind usually take a walk or something\" **The depression in this example is rated one:** “of my friend i wish i would’ve handled his sister a little differently as far as the dirt it has been yes it was uh it’s very close um no i have not we’ve always maintained our friendship um i can’t recall one off hand no problem and that’s all” **The depression in this example is rated two:** “um feel uninhibited and i was better prepared about three years ago um i was happy that he was safe try not to she has a house i mean a roof over her head to resort to the situation that he was in um because and to have been” **The depression in this example is rated three:** “i don’t sleep well um well i start to like cry a lot and i start to get really irritable um i argued with my mom and sister yesterday it was just something stupid over like yeah i was like okay well this is the problem and it i just” */SYS* On a scale of zero to three, rate the depression in this message: + Text \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 2: Examples for version 5 prompting for the GAD and PHQ questions."
    },
    {
      "title": "Chatgpt",
      "text": "For chatGPT, we used the same prompting structure that worked best for Llama-\\(2\\), which was Version 3 (see Table 1). All other aspects of evaluation and extracting information from the chatbot responses were the same for ChatGPT as it was for Llama-2."
    },
    {
      "title": "4. Experimental Setup",
      "text": "In this section, we provide insights on the models and the dataset used in our work. We further provide information on the questionnaire and the evaluation metrics used to present the outcomes of our work."
    },
    {
      "title": "Models",
      "text": ""
    },
    {
      "title": "4.1.1. Xgboost",
      "text": "XGBoost (Extreme Gradient Boosting) (Beng et al., 2017) is a machine learning algorithm used for both classification and regression tasks. XGBoost is based on the gradient boosting framework, which is an ensemble learning technique. It builds an ensemble of decision trees sequentially, where each tree corrects the errors made by the previous ones. The model uses a customizable objective function that needs to be optimised during training. For regression tasks, the objective is often mean squared error (MSE), while for classification tasks, it can be log loss (binary or multiclass). To prevent overfitting, XGBoost incorporates L1 (Lasso) and L2 (Ridge) regularization techniques into the objective function."
    },
    {
      "title": "4.1.2. Chatgpt",
      "text": "GPT-3 (Generative Pre-trained Transformer) follows the decoder-only Transformer architecture and employs attention mechanisms, allowing it to focus on the most relevant segments of input text, using an extensive context of 2048 tokens and an unprecedented 175 billion parameters. The model exhibited remarkable zero-shot and few-shot learning capabilities across various tasks. The training data for GPT-3 is primarily sourced from a filtered version of Common Crawl, contributing to 60% of the weighted pre-training dataset, comprising 410 billion byte-pair-encoded tokens. Other data sources include 19 billion tokens from WebText\\(2\\), 12 billion tokens from Books\\(1\\), 55 billion tokens from Books\\(2\\), and 3 billion tokens from Wikipedia. GPT-3 was trained on a vast corpus of text and has demonstrated proficiency in programming languages such as CSS, JSX, and Python, among others."
    },
    {
      "title": "4.1.3. Llama",
      "text": "LLaMA-1 (Large Language Model Meta AI) (Lavase et al., 2017) is a series of large language models developed by Meta AI. The initial release included models with varying parameter sizes: 7 billion, 13 billion, 33 billion, and 65 billion parameters. LLaMA employs the Transformer architecture with some architectural differences, including the use of SwiGLU activation functions, rotary positional embeddings, and root-mean-squared layer normalization. The foundational models were trained on a vast dataset comprising 1.4 trillion tokens from various publicly available sources. Human annotators were involved in AI alignment by providing prompts and evaluating model outputs, and reinforcement learning from human feedback (RLHF) was employed with a new technique based on Rejection sampling followed by Proximal Policy Optimization (PPO). Additionally, LLaMA aimed to improve multi-turn consistency in dialogues using the \"Ghost attention\" technique during training to respect system messages throughout conversations. LLaMA-2 (Lavase et al., 2017) remains mostly consistent with that of LLaMA-1 models, with the notable change being the utilization of 40% more data for training the foundational models. LLaMA-2 encompasses both foundational models and models specifically fine-tuned for dialogues, referred to as LLaMA-2 Chat. Within this work, we leveraged Llama2 model with 13B parameters."
    },
    {
      "title": "4.1.4. Transformer Models",
      "text": "For a comparison to LLMs, we leverage the Transformer models (Tang et al., 2019), which rely on a self-attention mechanism, allowing it to capture contextual dependencies in input sequences efficiently. The model consists of an encoder-decoder structure, with multi-head self-attention layers enabling parallelised processing of input tokens. Positional encoding is used to provide information about the token's position in the sequence. The Transformer's attention mechanism facilitates capturing long-range dependencies, making it highly effective for tasks requiring context understanding. Within this work, we compare the BERT and Roberta Transformer models and their distilled versions, i.e. DistilBert and Dsitil-Roberta. In addition to that we leverage the XLNet models as well. The BERT model (Dosov et al., 2017) is pre-trained on large corpora and can then be fine-tuned for specific natural language processing (NLP) tasks, such as text classification, named entity recognition, and question answering, among others. BERT embeddings have been widely adopted and have significantly improved the state-of-the-art performance in various NLP applications. DistilBERT (Dosov et al., 2018) is a distilled version of BERT, offering a more compact and faster alternative for tasks in natural language processing (NLP). Despite having fewer parameters, DistilBERT embeddings can be utilised in various NLP applications, providing a balance between computational efficiency and model performance. RoBERTa (Dosov et al., 2017), or Robustly optimised BERT approach, is a variant of the BERT (Bidirectional Encoder Representations from Transformers) model, uses dynamic masking during pre-training, removing the Next Sentence Prediction (NSP) objective, and training with larger mini-batches and learning rates. These modifications result in a more robust and efficient model. XLNet (Rosenberg et al., 2019) is a Transformer-based language model, which combines ideas from autoregressive language modeling (as seen in models like GPT) and autoencoding (as in BERT) to capture bidirectional context and maintain long-term dependencies in sequences. Instead of predicting the next word in a sentence, XLNet is trained to predict a permutation of the words. This approach allows the model to consider bidirectional context while preventing it from seeing the entire context during training, enhancing its ability to capture dependencies. For all models, we leverage the base version of the transformer models."
    },
    {
      "title": "Daic-Woz Dataset",
      "text": "Within this comparison, we leveraged the DAIC-WOZ dataset (Dosov et al., 2018), which comprises clinical interviews aimed at aiding the assessment of psychological distress conditions like anxiety, depression, and post-traumatic stress disorder. These interviews were gathered as part of a broader initiative to develop a computer-based system that conducts interviews with individuals and recognises verbal and nonverbal cues associated with mental health issues. Specifically, it encompasses data from Wizard-of-Oz interviews, where an animated virtual interviewer named Ellie, under the control of a human interviewer in a separate location, conducted the interviews. The data, which consists of 189 interaction sessions, each lasting between 7 to 33 minutes, has been originally transcribed and annotated to encompass a range of verbal and non-verbal characteristics."
    },
    {
      "title": "Phq-4 Questionnaire",
      "text": "The Patient Health Questionnaire-4 (PHQ-4) (Dosov et al., 2018) was developed to address the challenge posed by the high prevalence of anxiety and depression in the general population. Since these two mood disorders often co-occur and individuals with these conditions may struggle with fatigue or difficulty concentrating, the PHQ-4 offers a concise and accurate assessment tool. The PHQ-4 consists of four questions, each answered on a four-point Likert-type scale. It serves the purpose of providing a very brief yet precise measurement of the fundamental symptoms associated with depression and anxiety. It combines a two-item measure for depression (PHQ-2), which focuses on core depressive criteria, and a two-item measure for anxiety (GAD-2), both of which have been independently proven to be effective screening tools. The total PHQ\\(-4\\) score complements the scores of these subscales, offering an overall assessment of symptom burden, functional impairment, and disability. While an elevated PHQ\\(-4\\) score is not diagnostic, it serves as an indicator for further evaluation to confirm the presence or absence of a clinical disorder that requires treatment."
    },
    {
      "title": "Evaluation Metrics",
      "text": "Besides analysing the widely used metrics, i.e., **weighted precision**, **recall** and **F1** for our experiments, we extend our metrics with further metrics in the field of statistics and medicine. **Weighted specificity** describes the accuracy of a test that reports the presence or absence of a medical condition. It can be useful for \"ruling in\" disease since the test rarely gives positive results in healthy patients. A test with a specificity of 1.0 will recognise all patients without the disease by testing negative, therefore a positive test result would rule in the presence of the disease. Nevertheless, a negative result from a test with high specificity is not necessarily useful for \"ruling out\" a disease. As an example, a test that always returns a negative test result will have a specificity of 1.0 because specificity does not consider false negatives. A test like that would return negative for patients with the disease, making it useless for \"ruling out\" the disease. Furthermore, we leverage the Hamming loss and the AUC-ROC Curve. The **Hamming loss** is a metric used in multi-label classification to quantify the accuracy of predictions by measuring the fraction of incorrectly predicted labels across all instances. It is calculated as the average fraction of incorrectly predicted labels per instance, with a score of 0 indicating perfect predictions and 1 indicating complete misclassification. The Hamming loss accounts for both false positives and false negatives in the predicted label sets, making it a valuable measure for evaluating the overall performance of multi-label classification models. The **AUC-ROC** (Area Under the Receiver Operating Characteristic Curve) is a graphical representation of a binary classification model's performance across various threshold settings. It plots the true positive rate against the false positive rate, illustrating the trade-off between sensitivity and specificity. The AUC-ROC value quantifies the model's ability to distinguish between classes, with a higher AUC indicating better overall performance."
    },
    {
      "title": "5. Results",
      "text": "Within this section, we provide the insights on evaluating different prompting strategies, as well as how Llama-\\(2\\) and ChatGPT resorm compared to XGBoost and different Transformer models."
    },
    {
      "title": "Llama-2 Prompting",
      "text": "Leveraging Llama-\\(2\\), we prompted the LLM with different lexical inputs as seen in Tables 1 and 2. As seen in Table 3, we evaluated each GAD and PHQ question separately. For GAD-1, prompting Version 3, i.e., _On a scale of **zero to three**, _rate the anxiety of this message_, showed the best performance in terms of weighted F1, as well in weighted precision, recall, Hamming loss and AUC-ROC. For the specificity metric, version 1 slightly outperforms all other prompting options. For GAD-2, the best F1 score is obtained by various prompting versions, with the highest F1 score of 0.53. The best specificity for GAD-2 is achieved by version 3 while prompting with version 1 provides the best AUC-ROC result. In terms of PHQ-1, the best weighted F1 score is obtained using prompting version 1, while the best precision is obtained using version 3 prompting. Similar to the GAD questions, leveraging prompting version 3 for the PHQ-2 question provided the best results in terms of F1, as well as precision and specificity."
    },
    {
      "title": "Transformer Models",
      "text": "As a comparison to LLMs, we deployed different baseline transformer models, which were fine-tuned on the DAIC-WOZ dataset. Table 4 shows the results for the different GAD and PHQ questions, whereby Distil-Roberta performs best for GAD-1 and GAD-2 in terms of F1. Specificity scores were best using BERT, RoBERTa or XLNet for GAD-1, while for GAD-2, specificity was best using DistilBERT or XLNet. \\begin{table} \\begin{tabular}{r c c c c c c|c c c c c c} \\hline \\hline & \\multicolumn{8}{c}{GAD-1} & \\multicolumn{8}{c}{GAD-2} \\\\ \\hline & Prec & Rec & F1 & Spec & HammL & AUC-ROC & Prec & Rec & F1 & Spec & HammL & AUC-ROC \\\\ \\cline{2-13} BERT & 0.56 & 0.56 & 0.53 & **0.44** & **0.59** & 0.66 & 0.67 & 0.69 & 0.67 & 0.31 & 0.62 & **0.52** \\\\ DistilBERT & **0.59** & **0.58** & **0.56** & 0.42 & 0.63 & **0.72** & 0.65 & 0.67 & 0.65 & **0.33** & 0.58 & **0.52** \\\\ Distil-RoBERTa & 0.57 & **0.58** & **0.56** & 0.42 & 0.63 & 0.70 & **0.69** & **0.70** & **0.68** & 0.30 & 0.62 & **0.52** \\\\ RoBERTa & 0.55 & 0.56 & 0.55 & **0.44** & 0.62 & 0.70 & 0.67 & **0.70** & 0.65 & 0.30 & **0.56** & 0.48 \\\\ XLNet & 0.55 & 0.56 & 0.54 & **0.44** & 0.61 & 0.70 & 0.64 & 0.67 & 0.62 & **0.33** & **0.56** & 0.45 \\\\ \\hline \\hline \\end{tabular} \\begin{tabular}{r c c c c c c|c c c c c c} \\hline \\hline & \\multicolumn{8}{c}{PHQ-1} & \\multicolumn{8}{c}{PHQ-2} \\\\ \\hline & Prec & Rec & F1 & Spec & HammL & AUC-ROC & Prec & Rec & F1 & Spec & HammL & AUC-ROC \\\\ \\cline{2-13} BERT & 0.50 & 0.52 & 0.49 & **0.48** & **0.59** & 0.68 & 0.53 & 0.54 & 0.52 & **0.46** & **0.61** & 0.71 \\\\ DistilBERT & 0.53 & 0.54 & 0.52 & 0.46 & 0.60 & 0.69 & 0.57 & 0.57 & 0.54 & 0.43 & **0.61** & 0.72 \\\\ Distil-RoBERTa & 0.55 & 0.55 & 0.53 & 0.45 & 0.61 & **0.71** & 0.55 & 0.57 & 0.54 & 0.43 & 0.62 & **0.73** \\\\ RoBERTa & 0.56 & 0.56 & 0.54 & 0.44 & 0.61 & 0.69 & 0.57 & 0.57 & **0.56** & 0.43 & 0.64 & **0.73** \\\\ XLNet & **0.58** & **0.58** & **0.55** & 0.42 & 0.64 & 0.70 & **0.58** & **0.58** & **0.56** & 0.42 & 0.63 & **0.73** \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 4. Insights on weighted precision, recall, F1, Hamming loss (HammL) and AUC-ROC (Area Under the Receiver Operating Characteristic Curve for different Transformer models (bold scores represent best result for each metric). \\begin{table} \\begin{tabular}{r c c c c c c|c c c c c c} \\hline \\hline & \\multicolumn{8}{c}{GAD-1} & \\multicolumn{8}{c}{GAD-2} \\\\ \\hline & Prec & Rec & F1 & Spec & HammL & AUC-ROC & Prec & Rec & F1 & Spec & HammL & AUC-ROC \\\\ \\cline{2-13} Version 1 & 0.31 & 0.29 & 0.22 & **0.69** & 0.71 & 0.49 & 0.53 & 0.52 & 0.50 & 0.48 & 0.48 & **0.51** \\\\ Version 2 & 0.33 & 0.32 & 0.21 & 0.66 & 0.68 & 0.50 & 0.44 & 0.66 & **0.53** & 0.33 & 0.34 & 0.50 \\\\ Version 3 & **0.38** & **0.33** & **0.33** & 0.68 & **0.67** & **0.52** & **0.56"
    },
    {
      "title": "Overall Comparison",
      "text": "We further summarise all best approaches obtained by prompting Llama-2, i.e. prompting version 3, and Distil-RoBERTa, which performed overall best on the GAD and PHQ questions. In addition to that, we evaluate the predictions using XGBoost (see Section 4.1.1) as well as ChatGPT, a commercial LLM built by OpenAI. As seen in Table 5, XGBoost always outperforms all used models in terms of the Hamming loss metric. Comparing Llama-2 with ChatGPT, we observe minor advantages using ChatGPT, which outperforms Llama-2 on the GAD-2, PHQ-1 and PHQ-2 questions. Finally, we compare the Distil-RoBERTa transformer model with Llama-2 and ChatGPT. Our study shows that the later outperforms all targeted models for all GAD and PHQ questions in terms of weighted precision, recall and F1 score."
    },
    {
      "title": "6. Conclusions",
      "text": "In conclusion, mental ill-health challenges globally impact a significant portion of the population, highlighting the pressing need for effective interventions. Despite the advancements of large language models in various NLP tasks and their diverse applications, a substantial research gap persists regarding their understanding and optimisation within the realm of mental health. This study addresses this gap by conducting an initial evaluation of large language models, comparing the performance of Llama-2 and ChatGPT with the classical machine and deep learning models. Leveraging Llama-2 and ChatGPT, we explore different prompting strategies and evaluate their effectiveness on GAD and PHQ questions. The results indicate that transformer-based models, such as BERT or XLNet, outperform large language models with a significantly larger parameter set. Notably, Distil-RoBERTa consistently outperforms all models for all GAD and PHQ questions in terms of weighted precision, recall, and F1 score. These findings contribute valuable insights for the future development and application of language models in addressing mental health concerns. Nevertheless the outcomes of our initial study, we will further study large language models and how to adapt them to the challenges in mental ill-health. Due to the sensitive nature of mental health information, we will further analyse biases in training data and the dynamic nature of mental health that are the biggest hurdles in achieving comprehensive and unbiased model performance. \\begin{table} \\begin{tabular}{c c c c c c c|c c c c c c} \\hline \\hline & \\multicolumn{8}{c}{GAD-1} & \\multicolumn{8}{c}{GAD-2} \\\\ \\hline & Prec & Rec & F1 & Spec & HammL & AUC-ROC & Prec & Rec & F1 & Spec & HammL & AUC-ROC \\\\ XGBoost & 0.45 & 0.55 & 0.48 & 0.64 & **0.45** & 0.56 & 0.63 & 0.69 & 0.60 & 0.34 & **0.31** & 0.51 \\\\ Llama-2 (v3) & 0.38 & 0.33 & 0.33 & 0.68 & 0.67 & 0.52 & 0.56 & 0.23 & 0.27 & **0.78** & 0.77 & 0.50 \\\\ ChatGPT 3.5 & 0.36 & 0.29 & 0.31 & **0.71** & 0.71 & 0.51 & 0.54 & 0.37 & 0.44 & 0.62 & 0.63 & **0.53** \\\\ Distil-RoBERTa & **0.57** & **0.58** & **0.56** & 0.42 & 0.63 & **0.70** & **0.69** & **0.70** & **0.68** & 0.30 & 0.62 & 0.52 \\\\ \\hline \\multicolumn{10}{c}{PHQ-1} & \\multicolumn{8}{c}{PHQ-2} \\\\ \\hline & Prec & Rec & F1 & Spec & HammL & AUC-ROC & Prec & Rec & F1 & Spec & HammL & AUC-ROC \\\\ XGBoost & 0.51 & 0.54 & 0.48 & 0.61 & **0.46** & 0.55 & 0.52 & 0.53 & 0.48 & 0.66 & **0.47** & 0.56 \\\\ Llama-2 (v3) & 0.43 & 0.29 & 0.30 & **0.76** & 0.71 & 0.53 & 0.34 & 0.34 & 0.32 & 0.65 & 0.66 & 0.49 \\\\ ChatGPT 3.5 & 0.38 & 0.39 & 0.39 & 0.64 & 0.61 & 0.52 & 0.37 & 0.31 & 0.33 & **0.71** & 0.69 & 0.50 \\\\ Distil-RoBERTa & **0.55** & **0.55** & **0.53** & 0.45 & 0.61 & **0.71** & **0.55** & **0.57** & **0.54** & 0.43 & 0.62 & **0.73** \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 5. Comparison on weighted precision, recall, F1, Hamming loss (HammL) and AUC-ROC (Area Under the Receiver Operating Characteristic Curve for XGBoost, Llama-2, ChatGPT and Distil-Roberta (bold scores represent best result for each metric)."
    },
    {
      "title": "References",
      "text": "* (1) * Abd-alrazaq et al. (2019) Alaa A. Abd-alrazaq, Mohammad Alajlani, Ali Abdallah Alalwan, Bridgette M. Bewick, Peter Gardner, and Mowafa Househ. 2019. An overview of the features of chatbots in mental health: A scoping review. _International Journal of Medical Informatics_ 132 (2019), 103978. [https://doi.org/10.1016/j.ijmedinf.2019.103978](https://doi.org/10.1016/j.ijmedinf.2019.103978) * Benton et al. (2017) Adrian Benton, Margaret Mitchell, and Dirk Hovy. 2017. Multi-Task Learning for Mental Health using Social Media Text. arXiv:1712.03538 [cs.CL]. * Bhatt et al. (2021) Meghana Moorthy Bhat, Saghar Hosseini, Ahmed Hassan Awadallah, Paul N. Bennett, and Weisheng Li. 2021. Say 'YES' to Positivity: Detecting Toxic Language in Workplace Communications. In _Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November, 2021_, Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (Eds.). Association for Computational Linguistics, 2017-2029. [https://doi.org/10.18653/v1/2021.findings-emnlp.173](https://doi.org/10.18653/v1/2021.findings-emnlp.173) * Bill and Eriksson (2023) Desiree Bill and Theodor Eriksson. 2023. Fine-tuning a LIM using Reinforcement Learning from Human Feedback for a Therapy Chatbot Application (Independent thesis Basic level, degree of Bachelor), KTH, School of Electrical Engineering and Computer Science (EECS). * Cameron et al. (2019) Gillian Cameron, David Cameron, Gavin Megaw, Raymond Bond, Maurice Mulvenna, Siobhan O'Neill, Cherie Armour, and Michael McTear. 2019. Assessing the Usability of a Chatbot for Mental Health Care. In _Internet Science_, Svetlama S. Bodrunova, Olessia Kolskova, Asbjorn Folstad, Harry Halpin, Polina Kolozaridi, Leonid Yuldashev, Anna Smoliarova, and Heiko Niedermayer (Eds.). Springer International Publishing, Cham, 121-132. * Chen et al. (2019) Irene Y. Chen, Peter Szolovits, and Marzyeh Ghassemi. 2019. Can AI Help Reduce Disparities in General Medical and Mental Health Care? _AMA journal of ethics_ 21 2 (2019), E167-179. [https://api.semanticscholar.org/CorpusID/?3498305](https://api.semanticscholar.org/CorpusID/?3498305) * Chen and Guestrin (2016) Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree Boosting System. In _Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_ (San Francisco, California, USA) _(KDD '16)_. ACM, New York, NY, USA, 785-794. [https://doi.org/10.1145/2939672.2939785](https://doi.org/10.1145/2939672.2939785) * Chung et al. (2023) Neo Christopher Chung, George Dyer, and Lennart Brocki. 2023. Challenges of Large Language Models for Mental Health Counseling. arXiv:2311.13857 [cs.CL] * Coppersmith et al. (2015) Glen Coppersmith, Mark Dredze, Craig Harman, Kristy Hollingshead, and Margaret Mitchell. 2015. CLPsych 2015 Shared Task: Depression and PTSD on Twitter. In _Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality_. Association for Computational Linguistics, Denver, Colorado, 31-39. [https://doi.org/10.3115/v1/W15-1204](https://doi.org/10.3115/v1/W15-1204) * Delahunty et al. (2019) Fionn Delahunty, Robert Johansson, and Mihael Arcan. 2019. Passive Diagnosis Incorporating the PHQ-4 for Depression and Anxiety. In _Proceedings of the Social Media Mining for Health Applications (SMMIH) Workshop_. Florence, Italy. * Delahunty et al. (2018) Fionn Delahunty, Ian D. Wood, and Mihael Arcan. 2018. First Insights on a Passive Major Depressive Disorder Prediction System with Incorporated Conversational Chatbot. In _Irish Conference on Artificial Intelligence and Cognitive Science_. Dublin, Ireland. * Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. [http://arxiv.org/abs/1810.04805c](http://arxiv.org/abs/1810.04805c) after arXiv:1810.04805Comment: 13 pages. * Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In _Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)_, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, Minneapolis, Minnesota, 4171-4186. [https://doi.org/10.18653/v1/N19-1423](https://doi.org/10.18653/v1/N19-1423) * Eichstaedt et al. (2018) Johannes C. Eichstaedt, Robert J. Smith, Raina M. Merchant, Lyle H. Ungar, Patrick Crutchley, Daniel Preqituc-Pietro, David A. Asch, and H. Andrew Schwartz. 2018. Facebook language predicts depression in medical records. _Proceedings of the National Academy of Sciences_ 115, 44 (2018), 11203-11208. [https://doi.org/10.1073/pnas.1802331115](https://doi.org/10.1073/pnas.1802331115) * Galtzter-Levy et al. (2023) Isaac R. Galtzter-Levy, Daniel McDuff, Vivek Natarajan, Alan Karthikesalingam, and Matteo Malgaroli. 2023. The Capability of Large Language Models to Measure Psychiatric Functioning. arXiv:2308.01834 [cs.CL] * Gratch et al. (2014) Jonathan Gratch, Ron Artstein, Gale Lucas, Giota Stratou, Stefan Scherer, Angela Nazarian, Rachel Wood, Jill Boberg, David DeVault, Stacy Marsella, David Traum, Skip Rizzo, and Louis-Philippe Morency. 2014. The Distress Analysis Interview Corpus of human and computer interviews. In _Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14)_, Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Hrafin Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis (Eds.). European Language Resources Association (ELRA), Reykjavik, Iceland, 3123-3128. [http://www.lrec-conf.org/proceedings/lrec2014/pdf/508_Paper.pdf](http://www.lrec-conf.org/proceedings/lrec2014/pdf/508_Paper.pdf) * Guntuku et al. (2018) Sharath Chandra Guntuku, Anneke Buffone, Kokil Jaidka, Johannes C. Eichstaedt, and Lyle H. Ungar. 2018. Understanding and Measuring Psychological Stress using Social Media. _ArXiv_ abs/1811.07430 (2018). [https://api.semanticscholar.org/CorpusID/:53717562](https://api.semanticscholar.org/CorpusID/:53717562) * Guntuku et al. (2017) Sharath Chandra Guntuku, David B Yaden, Margaret L Kern, Lyle H Ungar, and Johannes C Eichstaedt. 2017. Detecting depression and mental illness on social media: an integrative review. _Current Opinion in Behavioral Sciences_ 18 (2017), 43-49. [https://doi.org/10.1016/j.cobeha.2017.07.005](https://doi.org/10.1016/j.cobeha.2017.07.005). Big data in the behavioural sciences. * Jiang et al. (2023) Zifan Jiang, Salman Seyedi, Emily Griner, Ahmed Abbasi, Ali Bahrami Rad, Hyeokhyen Kwon, Robert O. Cotes, and Gari D. Clifford. 2023. Multimodal mental health assessment with remote interviews using facial, vocal, linguistic, and cardiovascular patterns. _medRxiv_ (2023). [https://doi.org/10.1101/2023.09.11.23295212](https://doi.org/10.1101/2023.09.11.23295212) * Jin et al. (2023) Haoan Jin, Siyuan Chen, Mengyue Wu, and Kenny Q. Zhu. 2023. PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for Mental Health. arXiv:2311.09189 [cs.CL]* Kronke et al. (2009) Kroenke K, Spitzer RL, Williams JBW, and Lowe B. 2009. An ultra-brief screening scale for anxiety and depression: The PHQ-4. _Psychosomatics_, _50_, _613-621_ (2009). * Lee et al. (2020) Yi-Chieh Lee, Naomi Yamashita, and Yun Huang. 2020. Designing a Chatbot as a Mediator for Promoting Deep Self-Disclosure to a Real Mental Health Professional. _Proc. ACM Hum.-Comput. Interact._ 4, CSCW1, Article 31 (may 2020), 27 pages. [https://doi.org/10.1145/3392836](https://doi.org/10.1145/3392836) * Liu et al. (2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach. arXiv:1907.11692 [http://arxiv.org/abs/1907.11692](http://arxiv.org/abs/1907.11692) * Milintsevich et al. (2023) Kirill Milintsevich, Kairit Sirts, and Gael Dias. 2023. Towards automatic text-based estimation of depression through symptom prediction. _Brain Informatics_ 10, 1 (2023), 4. [https://doi.org/10.1186/s40708-023-00185-9](https://doi.org/10.1186/s40708-023-00185-9) * Romano et al. (2023) Michael F. Romano, Ludy C. Shih, Ioannis C. Paschalidis, Rhoda Au, and Vijaya B. Kolachalama. 2023. Large Language Models in Neurology Research and Future Practice. _Neurology_ 101, 23 (2023), 1058-1067. [https://doi.org/10.1212/WNL.0000000000207967](https://doi.org/10.1212/WNL.0000000000207967) arXiv:[https://www.neurology.org/doi/pdf/10.1212/WNL.00000000000207967](https://www.neurology.org/doi/pdf/10.1212/WNL.00000000000207967) * Sanh et al. (2020) Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2020. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. arXiv:1910.01108 [cs.CL] * Sarkar et al. (2023) Shailik Sarkar, Abdulaziz Alhamadani, Luwah Alkulaib, and Chang-Tien Lu. 2023. Predicting Depression and Anxiety on Reddit: A Multi-Task Learning Approach. In _Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining_ (Istanbul, Turkey) _(ASONAM '22)_. IEEE, 427-435. [https://doi.org/10.1109/ASONAM55673.2022.10068655](https://doi.org/10.1109/ASONAM55673.2022.10068655) * Stade et al. (2023) Elizabeth C. Stade, Shannon Wiltsey Stirman, Lyle Ungar, Cody L. Boland, H. Andrew Schwartz, David B. Yaden, Joao Sedoc, Robert J. DeRubeis, Robb Willer, and Johannes C. Eichstaedt. 2023. Large language models could change the future of behavioral healthcare: A proposal for responsible development and evaluation. PsyArXiv. [https://doi.org/10.31234/osf.io/culyr](https://doi.org/10.31234/osf.io/culyr) * Timmons et al. (2023) Adela C. Timmons, Jacqueline R. Duong, Natalia Simo Finallo, Theodore Lee, Huong Phuc Quynh Vo, Matthew W. Ahle, Jonathan S. Comer, La Princess C. Brewer, Stacy L. Frazier, and Theodora Chaspari. 2023. A Call to Action on Assessing and Mitigating Bias in Artificial Intelligence Applications for Mental Health. _Perspectives on Psychological Science_ 18, 5 (Sept. 2023), 1062-1096. [https://doi.org/10.1177/17456916221134490](https://doi.org/10.1177/17456916221134490) Publisher Copyright: \\(\\copyright\\) The Author(s) 2022. * Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Iacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. ILAMA: Open and Efficient Foundation Language Models. arXiv:2302.13971 [cs.CL] * Touvron et al. (2017) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esibbu, Jude Fernandes, Jeremy Fu, Wenyn Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkee, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jens Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288 [cs.CL] * Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, L Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In _Advances in Neural Information Processing Systems_, I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Curran Associates, Inc. [https://proceedings.neurips.cc/paper_files/paper/2017/file/3/5ee243547ee91fbd053c1c4a845aa-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2017/file/3/5ee243547ee91fbd053c1c4a845aa-Paper.pdf) * Xu et al. (2021) Xuhai Xu, Prerna Chikersal, Janine M. Dutcher, Yasaman S. Sefidgar, Woosuk Seo, Michael J. Tumminia, Daniella K. Villalba, Sheldon Cohen, Kasey G. Creswell, J. David Creswell, Afsaneh Doryab, Paula S. Nurius, Eve Riskin, Anind K. Dey, and Jennifer Mankoff. 2021. Leveraging Collaborative-Filtering for Personalized Behavior Modeling: A Case Study of Depression Detection among College Students. _Proc. ACM Interact. Mob. Wearable Ubiquitous Technol._ 5, 1, Article 41 (mar 2021), 27 pages. [https://doi.org/10.1145/3448107](https://doi.org/10.1145/3448107) * Xu et al. (2023) Xuhai Xu, Bingsheng Yao, Yuanzhe Dong, Saadia Gabriel, Hong Yu, James Hendler, Marzyeh Ghassemi, Anind K. Dey, and Dakuo Wang. 2023. Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data. arXiv:2307.14385 [cs.CL] * Yang et al. (2023) Kailai Yang, Tianlin Zhang, Ziyan Kuang, Qianqian Xie, Sophia Ananiadou, and Jimin Huang. 2023. MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models. arXiv:2309.13567 [cs.CL] * Yang et al. (2019) Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding. In _Proceedings of the 33rd International Conference on Neural Information Processing Systems_. Curran Associates Inc., Red Hook, NY, USA, Article 517, 11 pages."
    }
  ]
}
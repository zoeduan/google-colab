{
  "title": "Using Large Language Models to Enhance Programming Error Messages",
  "authors": [
    "Juho Leinonen",
    "Arto Hellas",
    "Sami Sarsa",
    "Brent Reeves",
    "Paul Denny",
    "James Prather",
    "Brett A Becker"
  ],
  "abstract": "\n A key part of learning to program is learning to understand programming error messages. They can be hard to interpret and identifying the cause of errors can be time-consuming. One factor in this challenge is that the messages are typically intended for an audience that already knows how to program, or even for programming environments that then use the information to highlight areas in code. Researchers have been working on making these errors more novice friendly since the 1960s, however progress has been slow. The present work contributes to this stream of research by using large language models to enhance programming error messages with explanations of the errors and suggestions on how to fix the error. Large language models can be used to create useful and novice-friendly enhancements to programming error messages that sometimes surpass the original programming error messages in interpretability and actionability. These results provide further evidence of the benefits of large language models for computing educators, highlighting their use in areas known to be challenging for students. We further discuss the benefits and downsides of large language models and highlight future streams of research for enhancing programming error messages. \n CCS CONCEPTS • Social and professional topics → Computing education; • Computing methodologies → Natural language generation. \n",
  "references": [
    {
      "id": null,
      "title": "Using Large Language Models to Enhance Programming Error Messages",
      "authors": [
        "Juho Leinonen",
        "Arto Hellas",
        "Sami Sarsa",
        "Brent Reeves",
        "Paul Denny",
        "James Prather",
        "Brett A Becker"
      ],
      "year": "2022",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "SYNFIX: Automatically Fixing Syntax Errors using Compiler Diagnostics",
      "authors": [
        "Toufique Ahmed",
        "Noah Rose Ledesma",
        "Premkumar Devanbu"
      ],
      "year": "2021",
      "venue": "SYNFIX: Automatically Fixing Syntax Errors using Compiler Diagnostics",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Compilation Error Repair: For the Student Programs, From the Student Programs",
      "authors": [
        "Z Umair",
        "Pawan Ahmed",
        "Amey Kumar",
        "Purushottam Karkare",
        "Sumit Kar",
        "A Gulwani"
      ],
      "year": "2018",
      "venue": "ICSE-SEET 2018 : 2018 ACM/IEEE 40th International Conference on Software Engineering : Software Engineering Education and Training : proceedings",
      "doi": "10.1145/3183377.3183383"
    },
    {
      "id": "b2",
      "title": "Error Messages as Rational Reconstructions",
      "authors": [
        "Titus Barik"
      ],
      "year": "2018",
      "venue": "Error Messages as Rational Reconstructions",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "",
      "authors": [
        "D Ph",
        "Dissertation"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Do Developers Read Compiler Error Messages?",
      "authors": [
        "Titus Barik",
        "Justin Smith",
        "Kevin Lubick",
        "Elisabeth Holmes",
        "Jing Feng",
        "Emerson Murphy-Hill",
        "Chris Parnin"
      ],
      "year": "2017",
      "venue": "Proceedings of the 39th International Conference on Software Engineering",
      "doi": "10.1109/ICSE.2017.59"
    },
    {
      "id": "b5",
      "title": "What Does Saying That 'Programming is Hard' Really Say, and About Whom?",
      "authors": [
        "A Brett",
        "Becker"
      ],
      "year": "2021",
      "venue": "Commun. ACM",
      "doi": "10.1145/3469115"
    },
    {
      "id": "b6",
      "title": "Compiler Error Messages Considered Unhelpful: The Landscape of Text-Based Programming Error Message Research",
      "authors": [
        "Brett A Becker",
        "Paul Denny",
        "Raymond Pettit",
        "Durell Bouchard",
        "Dennis J Bouvier",
        "Brian Harrington",
        "Amir Kamil",
        "Amey Karkare",
        "Chris Mcdonald",
        "Peter-Michael Osera",
        "Janice L Pearce",
        "James Prather"
      ],
      "year": "2019",
      "venue": "Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education",
      "doi": "10.1145/3344429.3372508"
    },
    {
      "id": "b7",
      "title": "Towards Assessing the Readability of Programming Error Messages",
      "authors": [
        "Brett A Becker",
        "Paul Denny",
        "James Prather",
        "Raymond Pettit",
        "Robert Nix",
        "Catherine Mooney"
      ],
      "year": "2021",
      "venue": "Australasian Computing Education Conference (Virtual, SA, Australia) (ACE '21)",
      "doi": "10.1145/3441636.3442320"
    },
    {
      "id": "b8",
      "title": "Effective Compiler Error Message Enhancement for Novice Programming Students",
      "authors": [
        "Brett A Becker",
        "Graham Glanville",
        "Ricardo Iwashima",
        "Claire Mcdonnell",
        "Kyle Goslin",
        "Catherine Mooney"
      ],
      "year": "2016",
      "venue": "Computer Science Education",
      "doi": "10.1080/08993408.2016.1225464"
    },
    {
      "id": "b9",
      "title": "The Effects of Enhanced Compiler Error Messages on a Syntax Error Debugging Test",
      "authors": [
        "Brett A Becker",
        "Kyle Goslin",
        "Graham Glanville"
      ],
      "year": "2018",
      "venue": "Proceedings of the 49th ACM Technical Symposium on Computer Science Education",
      "doi": "10.1145/3159450.3159461"
    },
    {
      "id": "b10",
      "title": "Categorizing Compiler e Error Messages with Principal Component Analysis",
      "authors": [
        "A Brett",
        "Catherine Becker",
        "Mooney"
      ],
      "year": "2016",
      "venue": "12th China-Europe International Symposium on Software Engineering Education (CEISEE 2016)",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Language Models are Few-shot Learners",
      "authors": [
        "Tom Brown",
        "Benjamin Mann",
        "Nick Ryder",
        "Melanie Subbiah",
        "Jared D Kaplan",
        "Prafulla Dhariwal",
        "Arvind Neelakantan",
        "Pranav Shyam",
        "Girish Sastry",
        "Amanda Askell"
      ],
      "year": "2020",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Evaluating Large Language Models Trained on Code",
      "authors": [
        "Mark Chen",
        "Jerry Tworek",
        "Heewoo Jun",
        "Qiming Yuan",
        "Henrique Ponde De Oliveira Pinto",
        "Jared Kaplan",
        "Harri Edwards",
        "Yuri Burda",
        "Nicholas Joseph",
        "Greg Brockman"
      ],
      "year": "2021",
      "venue": "Evaluating Large Language Models Trained on Code",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "Enhancing Syntax Error Messages Appears Ineffectual",
      "authors": [
        "Paul Denny",
        "Andrew Luxton-Reilly",
        "Dave Carpenter"
      ],
      "year": "2014",
      "venue": "Proceedings of the 19th Conference on Innovation and Technology in Computer Science Education",
      "doi": "10.1145/2591708.2591748"
    },
    {
      "id": "b14",
      "title": "Understanding the Syntax Barrier for Novices",
      "authors": [
        "Paul Denny",
        "Andrew Luxton-Reilly",
        "Ewan Tempero",
        "Jacob Hendrickx"
      ],
      "year": "2011",
      "venue": "Proceedings of the 16th Annual Joint Conference on Innovation and Technology in Computer Science Education",
      "doi": "10.1145/1999747.1999807"
    },
    {
      "id": "b15",
      "title": "Error Message Readability and Novice Debugging Performance",
      "authors": [
        "Paul Denny",
        "James Prather",
        "Brett A Becker"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "On Designing Programming Error Messages for Novices: Readability and Its Constituent Factors",
      "authors": [
        "Paul Denny",
        "James Prather",
        "Brett A Becker",
        "Catherine Mooney",
        "John Homer",
        "Zachary C Albrecht",
        "Garrett B Powell"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI '21)",
      "doi": "10.1145/3411764.3445696"
    },
    {
      "id": "b17",
      "title": "The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming",
      "authors": [
        "James Finnie-Ansley",
        "Paul Denny",
        "Brett A Becker",
        "Andrew Luxton-Reilly",
        "James Prather"
      ],
      "year": "2022",
      "venue": "Australasian Computing Education Conference",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Deep Reinforcement Learning for Syntactic Error Repair in Student Programs",
      "authors": [
        "Rahul Gupta",
        "Aditya Kanade",
        "Shirish Shevade"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "Deepfix: Fixing common C Language Errors by Deep Learning",
      "authors": [
        "Rahul Gupta",
        "Soham Pal",
        "Aditya Kanade",
        "Shirish Shevade"
      ],
      "year": "2017",
      "venue": "Thirty-First AAAI conference on artificial intelligence",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "The Expertise Reversal Effect",
      "authors": [
        "Slava Kalyuga"
      ],
      "year": "2009",
      "venue": "Managing cognitive load in adaptive multimedia learning",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "The Effects of Compilation Mechanisms and Error Message Presentation on Novice Programmer Behavior",
      "authors": [
        "Ioannis Karvelas",
        "Annie Li",
        "Brett A Becker"
      ],
      "year": "2020",
      "venue": "Proceedings of the 51st ACM Technical Symposium on Computer Science Education",
      "doi": "10.1145/3328778.3366882"
    },
    {
      "id": "b22",
      "title": "The Error Behind The Message: Finding the Cause of Error Messages in Python",
      "authors": [
        "Tobias Kohn"
      ],
      "year": "2019",
      "venue": "Proceedings of the 50th ACM Technical Symposium on Computer Science Education",
      "doi": "10.1145/3287324.3287381"
    },
    {
      "id": "b23",
      "title": "The Measurement of Observer Agreement for Categorical Data",
      "authors": [
        "Richard Landis",
        "Gary G Koch"
      ],
      "year": "1977",
      "venue": "biometrics",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "Language Models: Past, Present, and Future",
      "authors": [
        "Hang Li"
      ],
      "year": "2022",
      "venue": "Commun. ACM",
      "doi": "10.1145/3490443"
    },
    {
      "id": "b25",
      "title": "Static Analyses in Python Programming Courses",
      "authors": [
        "David Liu",
        "Andrew Petersen"
      ],
      "year": "2019",
      "venue": "Proceedings of the 50th ACM Technical Symposium on Computer Science Education",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",
      "authors": [
        "Pengfei Liu",
        "Weizhe Yuan",
        "Jinlan Fu",
        "Zhengbao Jiang",
        "Hiroaki Hayashi",
        "Graham Neubig"
      ],
      "year": "2021",
      "venue": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Generating Diverse Code Explanations using the GPT-3 Large Language Model",
      "authors": [
        "Stephen Macneil",
        "Andrew Tran",
        "Dan Mogil",
        "Seth Bernstein",
        "Erin Ross",
        "Ziheng Huang"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 ACM Conference on International Computing Education Research",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions",
      "authors": [
        "Hammond Pearce",
        "Baleegh Ahmad",
        "Benjamin Tan",
        "Brendan Dolan-Gavitt",
        "Ramesh Karri"
      ],
      "year": "2022",
      "venue": "2022 IEEE Symposium on Security and Privacy (SP)",
      "doi": ""
    },
    {
      "id": "b29",
      "title": "Do Enhanced Compiler Error Messages Help Students? Results Inconclusive",
      "authors": [
        "Raymond S Pettit",
        "John Homer",
        "Roger Gee"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education",
      "doi": "10.1145/3017680.3017768"
    },
    {
      "id": "b30",
      "title": "Metacognitive Difficulties Faced by Novice programmers in Automated Assessment Tools",
      "authors": [
        "James Prather",
        "Raymond Pettit",
        "Kayla Mcmurry",
        "Alani Peters",
        "John Homer",
        "Maxine Cohen"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 ACM Conference on International Computing Education Research",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "On Novices' Interaction with Compiler Error Messages: A Human Factors Approach",
      "authors": [
        "James Prather",
        "Raymond Pettit",
        "Kayla Holcomb Mcmurry",
        "Alani Peters",
        "John Homer",
        "Nevan Simone",
        "Maxine Cohen"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 ACM Conference on International Computing Education Research",
      "doi": "10.1145/3105726.3106169"
    },
    {
      "id": "b32",
      "title": "PUFFT-The Purdue University Fast FORTRAN Translator",
      "authors": [
        "Saul Rosen",
        "Robert A Spurgeon",
        "Joel K Donnelly"
      ],
      "year": "1965",
      "venue": "Commun. ACM",
      "doi": "10.1145/365660.365671"
    },
    {
      "id": "b33",
      "title": "Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models",
      "authors": [
        "Sami Sarsa",
        "Paul Denny",
        "Arto Hellas",
        "Juho Leinonen"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 ACM Conference on International Computing Education Research V",
      "doi": ""
    },
    {
      "id": "b34",
      "title": "An Empirical Investigation into Programming Language Syntax",
      "authors": [
        "Andreas Stefik",
        "Susanna Siebert"
      ],
      "year": "2013",
      "venue": "ACM Transactions on Computing Education",
      "doi": "10.1145/2534973"
    },
    {
      "id": "b35",
      "title": "Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models",
      "authors": [
        "Priyan Vaithilingam",
        "Tianyi Zhang",
        "Elena L Glassman"
      ],
      "year": "2022",
      "venue": "CHI Conference on Human Factors in Computing Systems Extended Abstracts",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Large Language Models",
      "text": "Large Language Models (LLMs), particularly pre-trained transformer models, have rapidly become the core technologies of natural language processing (Karkare, 2017). One such model is OpenAI GPT-3 (third-generation Generative Pre-trained Transformer) (Garshan et al., 2016). GPT-3 can translate between natural languages, compose poetry in the style of human poets, generate convincing essays, and more. GPT-3 also powers several other tools such as OpenAI Codex which is essentially a GPT-3 model that has also been fine-tuned with more than 50 million repositories representing the majority of Python code available on GitHub totalling 159 GB of source code (Garshan et al., 2016). Codex is available via the OpenAI API (beta.openai.com) and also powers tools such as GitHub Copilot.github.com. Given the recent emergence of these models, little is yet known about the impact they are likely to have on the computing education landscape. In this context, the few evaluations conducted to date have focused on the accuracy of such models for solving typical introductory programming problems and on the potential for the models to generate learning resources. Early work by Finnie-Ansley et al. assessed the accuracy of Codex by presenting it with typical CS1-type problems, and comparing its performance against that of students. They found that it outperformed most students, and was capable of generating a variety of correct solutions to any given problem (Garshan et al., 2016). Sarsa et al. investigated the content generation capabilities of Codex, by providing input examples as prompts and using it to generate novel programming problems and code explanations (Sarsa et al., 2016). They found that most of the problems generated by Codex were novel and sensible, and that the generated code explanations were generally correct and thorough. Given their capability for generating output of human-like quality from contextual inputs, such as code explanations from code, there is potential in applying large language models to the problem of enhancing PEMs."
    },
    {
      "title": "3. Methodology",
      "text": ""
    },
    {
      "title": "Error Messages And Programs",
      "text": "For the present study, we collected Python error messages that had been reported as the most unreadable in (Sarshan et al., 2016) and (Bauer et al., 2017). These error messages were as follows: 1. can't assign to function call 2. invalid token 3. illegal target for annotation 4. unindent does no match any outer indentation level 5. positional argument follows keyword argument 6. unexpected EOF while parsing 7. EOL while scanning string literal 8. EOF while scanning triple-quoted string literal 9. (unicodeerror) 'unicodeescape' codec can't decode bytes To control whether the complexity of the program that results in a given error message affects the ability of large language models to create useful explanations of the message, we constructed three example programs that generated each error message. The first program was very simple, often only a few lines long. The second incorporated the usage of strings and functions. The third included the use of libraries (e.g., the PyGame game library, pandas, scikit-learn) and was more complex. To create the same error messages as in the works by (Sarshan et al., 2016) and (Bauer et al., 2017), we used Python version 3.6."
    },
    {
      "title": "Generating Programming Error Messages",
      "text": "Programming error messages were generated using the Codex model that was most recent and performant at the time of analysis, which was the code-davinci-002 -model. As the utility of large language models depends on the used prompts (see e.g., (Karkare, 2017)), it is important to do \"prompt engineering\" where the performance of different types of prompts is evaluated (Karkare, 2017). We evaluated a number of prompts to identify a version that seemed to provide useful explanations. We tried five different prompt messages: 1. Plain English explanation of why does running the above code cause an error and how to fix the problem 2. Plain English explanation of why running the above code causes the above error in the output and instructions on how to fix the problem 3. Explanation of why running the above code causes the above error and instructions on how to fix the problem 4. Why does the code result in an error message? How can the code be fixed? 5. Why does the above code cause the above error message in the output? How can the code be fixed? We generated explanations with all five prompts and checked which version led to the fewest empty responses from Codex. The number of empty responses was 4, 6, 7, 16 and 27 out of 81 generated explanations respectively for the prompts 1 to 5 above. We [MISSING_PAGE_FAIL:3]"
    },
    {
      "title": "5. Discussion",
      "text": ""
    },
    {
      "title": "Are Error Message Explanations Useful?",
      "text": "Our results suggest that using large language models to explain programming error messages (PEMs) is feasible and shows promise. Overall, the explanation was considered an improvement over the original programming error message in over half of the cases. If we only consider the results from using temperature value 0, which were overall better, over 70% of the Codex outputs were considered an improvement over the original programming error message. The results are more sobering when it comes to using large language models to generate correct fixes. Although 70% included a fix, when a fix was included it was correct only under half of the time (47%). While the fixes created with the temperature value of 0 were better on average compared to those created with a value of 0.7, they were still correct in only around half of the cases - 42%, 56%, and 61% of the cases for functions with strings, simple programs, and library related programs respectively. We propose that the generated content could be useful to students if it were delivered so that it is clear that the content is AI-generated and might not be correct. And even with this initial exploratory setup, we found some outputs (two examples seen in Codex Example 1 and Codex Example 2) that we consider good enough to be shown to students without modifications."
    },
    {
      "title": "Common Pitfalls And Ways Around Them",
      "text": "Two examples of outputs where both the explanation and suggested fix generated by Codex were incorrect are shown in Codex Examples 3 and 4. Comparing these incorrect outputs with the correct outputs in Examples 1 and 2, we observe that the messages seem similarly confident in their tone, which could potentially mislead students. In both of the examples where the output is incorrect, Codex suggests that the issue is related to indentation. As novices often struggle with indentation (Zang et al., 2015; Zhang et al., 2016), these incorrect suggestions could exacerbate this by potentially misleading students and even introduce misconceptions related to correct indentation. In general, we observed a few common pitfalls that Codex seemed to often struggle with: (1) source code clearly missing a part of the content (resulting in \"unexpected EOF while parsing\", see e.g., Codex Example 3), (2) incorrectly capitalized control statements \\begin{table} \\begin{tabular}{l|c c c c c|c c} & & \\multicolumn{4}{c|}{RQ1} & \\multicolumn{4}{c}{RQ2} \\\\ Program category & Temperature & Comprehensible & Unnecessary content & Has explanation & Explanation correct & Improvement & Has fix & Fix correct \\\\ \\hline Simple & 0.0 & 100\\% & 6\\% & 100\\% & 67\\% & 72\\% & 78\\% & 44\\% \\\\ Function with strings & 0.0 & 100\\% & 22\\% & 100\\% & 56\\% & 72\\% & 78\\% & 33\\% \\\\ Library & 0.0 & 100\\% & 28\\% & 100\\% & 78\\% & 78\\% & 72\\% & 44\\% \\\\ \\hline Simple & 0.7 & 83\\% & 31\\% & 78\\% & 47\\% & 42\\% & 64\\% & 31\\% \\\\ Function with strings & 0.7 & 89\\% & 42\\% & 86\\% & 36\\% & 39\\% & 75\\% & 25\\% \\\\ Library & 0.7 & 72\\% & 44\\% & 64\\% & 33\\% & 50\\% & 61\\% & 31\\% \\\\ \\hline \\end{tabular} \\end{table} Table 2. Effect of temperature and program category on Codex performance in the task. \\begin{table} \\begin{tabular}{l|c c c c c c|c c} & & \\multicolumn{4}{c|}{RQ1} & \\multicolumn{4}{c}{RQ2} \\\\ Error message & Comprehensible & Unnecessary content & Has explanation & Explanation correct & Improvement & Has fix & Fix correct \\\\ \\hline em*t assign to function call & 100\\% & 17\\% & 94\\% & 83\\% & 78\\% & 72\\% & 28\\% \\\\ invalid token & 100\\% & 39\\% & 89\\% & 50\\% & 78\\% & 83\\% & 44\\% \\\\ illegal target for annotation & 67\\% & 22\\% & 67\\% & 33\\% & 33\\% & 50\\% & 28\\% \\\\ unindent does not match any outer indentation level & 100\\% & 39\\% & 100\\% & 56\\% & 56\\% & 67\\% & 28\\% \\\\ positional argument follows keyword argument & 89\\% & 22\\% & 89\\% & 61\\% & 56\\% & 78\\% & 39\\% \\\\ unexpected EOF while parsing & 67\\% & 11\\% & 67\\% & 11\\% & 22\\% & 44\\% & 22\\% \\\\ EOL while scanning string literal & 89\\% & 28\\% & 89\\% & 22\\% & 50\\% & 67\\% & 17\\% \\\\ COF while scanning triple-guided string literal & 89\\% & 56\\% & 78\\% & 44\\% & 44\\% & 89\\% & 33\\% \\\\ unindececerror* unindecdegree’ code can’t decode bytes & 89\\% & 56\\% & 83\\% & 72\\% & 67\\% & 78\\% & 56\\% \\\\ Average over all error messages & 88\\% & 32\\% & 84\\% & 48\\% & 54\\% & 70\\% & 33\\% \\\\ \\end{tabular} \\end{table} Table 1. Error message analysis for each research question. The cells show the percentage of “yes” answers out of all (“yes” and “no”) answers for the analysis. (resulting in \"illegal target for annotation\", see e.g., Codex Example 4), and (3) missing quotation marks (resulting in either \"EOL while scanning string literal\" or \"EOF while scanning triple-quoted string literal\"). For the first case, Codex would often suggest to fix the indentation of the program, even though the problem was that the implementation was far from complete (as in Codex Example 3). Similar suggestions for fixing the indentation were observed for the second case as well, even though the problem is in the capitalization. This can be seen in Codex Example 4, where the issue is that the if-statement is capitalized, but the message claims the issue is with indentation. For the third case, Codex was often unable to correctly identify whether the quotation mark was missing from the beginning or the end of the string, and sometimes suggested that the issue is related to parentheses instead of missing quotation marks. Indeed, the program category \"function with strings\" had the lowest scores overall (see Table 2). While it was relatively rare, we did observe some outputs that were not just incorrect, but even contradictory and confusing. In one case, Codex seems to have focused too much on the \"Plain English\" portion of the input and started generating irrelevant content related to \"looking for a plain English explanation\". To add to the confusion, the generated output actually does include a correct explanation of the problem - \"You need to end your string with three single quotes at the end of your string to make it work.\", but the output also states that \"this is not a correct explanation\". As there were common pitfalls and clear differences between explanation quality, we see one stream of future work in using a two-tiered approach for creating explanations. Codex could be relied upon in cases where it is known that it likely performs well, while in other cases other means could be exercised. One possibility is using ILMs to pre-generate explanations of common error messages that the instructor could validate (essentially, a \"human-in-the-loop\" approach). Another possibility would be the use of rearrangements, where students could ask for help from their peers; classic approaches such as discussion forums would also work, although the response times would be lower when compared to the near-instantaneous feedback from Codex."
    },
    {
      "title": "Explanations And Context",
      "text": "When considering the usefulness of Codex-generated explanations, they need to be interpreted and evaluated in context. First, the original error messages might be more useful for more experienced students who have learned to interpret them. The importance of context was present also in some of the disagreements of the two [MISSING_PAGE_FAIL:6]"
    },
    {
      "title": "References",
      "text": "* T. Ahmed, N. R. Ledesma, and P. Devanbu (2021)SYNTK: automatically rising syntax errors using compiler diagnostics. arXiv preprint arXiv:2104.1467. Cited by: SS1. * 1 June 2018, Gothenburg, Sweden, ACM Press, New York, NY, USA, 78-87, pp. 10. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * T. Barik (2018)Error messages as national reconstructions. Ph.D. Dissertation North Carolina State University, Raleigh, [https://repository.ib.ncsu.edu/handle/1840.2035439](https://repository.ib.ncsu.edu/handle/1840.2035439). Cited by: SS1. * T. Barik, J. Smith, K. Lubick, E. Holmes, J. Feng, E. Murphy-Hill, and C. Parmin (2017)Do developers need compiler error messages?. In Proceedings of the 39th International Conference on Software Engineering (Buenos Aires, Argentina) (ICSE '17), Piscataway, NJ, USA, pp. 575-585. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * B. A. Becker, P. Deyang, J. Petttir, D. Bouchard, D. J. Boucvier, B. Harrington, A. Kamal, A. Karkare, C. McDonald, P. Osera, J. L. Pearce, and J. Pettini (2019)Compiler error messages considered unhelpful. The Landscape of Text-Based Programming Error Message Research In Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education (Aberberdeen, Scotland USA) (ITCSE-WGR '19), New York, NY, USA, pp. 177-210. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * B. A. Becker, P. Deyang, J. Petttir, R. Nix, and C. Mooney (2021)Towards assessing the readability of programming error messages. In Australasian Computing Education Conference (Virtual, SA, Australia) (ACE '21), pp. 181-188. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * B. A. Becker, G. Gamville, R. Iwashim, C. McDonnell, K. Goolin, and C. Mooney (2016)Effective compiler error message enhancement for novice programming students. Computer Science Education26 (2-3), pp. 148-175. External Links: ISSN 0038-9348, Link, Document Cited by: SS1. * B. A. Becker, F. Goslin, and G. G. Gauville (2018)The effects of enhanced compiler error messages on a syntax error debugging test. In Proceedings of the 49th ACM Technical Symposium on Computer Science Education, Mal-Mandel, USA, pp. 640-645. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * B. A. Becker, F. Goslin, and G. Gauville (2018)The effects of enhanced compiler error messages on a syntax error debugging test. In Proceedings of the 49th ACM Technical Symposium on Computer Science Education, Mal-Mandel, USA, pp. 187-190. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * B. A. Becker and C. Mooney (2016)Categorizing compiler error messages with principal component analysis. In The China-Europe International Symposium on Software Engineering Education (CESEE 2016), Shenyang, China, pp. 28-29 May 2016, External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. (2020)Language models are re-watt learners. Advances in neural information processing systems33, pp. 1877-1901. Cited by: SS1. * M. Chen, J. Tworek, H. Jun, Q. Yuan, H. Panda, and G. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, et al. (2021)Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374. Cited by: SS1. * P. Denny, A. Mento-Reilly, and D. Carpentier (2014)Enhancing syntax error messages appears ineffect. In Proceedings of the 19th Conference on Innovation and Technology in Computer Science Education, Mal-Mandel, USA, pp. 273-278. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * P. Denny, A. Mento-Reilly, E. Temperpe, and J. Hendrickx (2011)Understanding the syntax barrier for novices. In Proceedings of the 16th Annual Joint Conference on Innovation and Technology in Computer Science Education, Mal-Mandel, USA, pp. 208-212. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * P. Denny, J. Petttir, and B. A. Becker (2020)Error message readability and novice debugging performance. In Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education, Mal-Mandel, USA, pp. 480-486. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * P. Denny, J. Petttir, B. A. Becker, C. Mooney, J. Homer, Z. C. Albrecht, and G. R. Powell (2021)On Designing programming error messages for novices: readability and its constituent factors. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Tokohama, Japan) (CHI '21), pp.. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * J. Finnie-Ansley, P. Denny, R. A. Becker, A. Luston-Reilly, and J. Praftner (2022)The robots are coming: exploring the implications of open ai code on introductory programming. In Australasian Computing Education Conference, Mal-Mandel, USA, pp. 10-19. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * R. Gupta, A. Kanade, and S. Shewade (2019)Deep reinforcement learning for syntactic error repair in student programs. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33, pp. 930-937. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * R. Gupta, S. Pal, A. Kanade, and S. Shewade (2017)Deepfix: reading common to language errors by deep learning. In Thirty-First AAAI conference on artificial intelligence, Cited by: SS1. * S. Kalyuga (2009)The expertise Reversal effect. In Managing cognitive load in adaptive multimedia learning, IGI Global, pp. 58-80. Cited by: SS1. * I. Karevelas, A. Li, and B. A. Becker (2020)The effects of compilation mechanisms and error message presentation on novice program behavior. In Proceedings of the 51st ACM Technical Symposium on Computer Science Education (Portland, OR, USA), pp. 795-796. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * T. Kohn (2019)The error behind the message: finding the cause of error messages in python. In Proceedings of the 50th ACM Technical Symposium on Computer Science Education, Mal-Mandel, USA, pp. 524-530. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * J. Landis and G. G. Koch (1977)The measurement of observer agreement for categorical data. In Interiors, pp. 159-174. Cited by: SS1. * H. Li (2022)Language models: past, present, and future. Commun. ACM65 (7), pp. 56-63. External Links: ISSN 0014-5349-1, Link, Document Cited by: SS1. * D. Lui and A. Petersen (2019)SeptML: arrays in Python programming courses. In Proceedings of the 50th ACM Technical Symposium on Computer Science Education, Mal-Mandel, USA, pp. 666-671. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig (2021)Pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing. arXiv preprint arXiv:2107.13586. Cited by: SS1. * S. MacNeil, A. Tran, D. Mogil, S. Bernstein, E. Ross, and Z. Huang (2022)Generating diverse code explanations using the gtf-3 large language model. In Proceedings of the 2022 ACM Conference on International Computing Education Research-Volume 2, pp. 37-39. Cited by: SS1. * H. Pearce, R. Ahmad, B. Tam, B. Dolan-Gavitt, and R. Karrri (2022)Alstep at the keyboard? assessing the security of GitHub copilot's code contributions. In 2022 IEEE Symposium on Security and Privacy (SP), pp. 754-768. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * R. S. Petit, J. Homer, and R. Gee (2017)Do enhanced compiler error message help students? results inconclusive. In Proceedings of the 2017 ACM SIGCSE International Symposium on Computer Science Education, Washington, USA, pp. 4605-470. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * J. Frather, R. Pettit, K. McMurry, A. Peters, J. Homer, and M. Cohen (2018)MatoSTO: microoptimizing principles faced by novice programmers in automated assessment tools. In Proceedings of the 2018 ACM Conference on International Computing Education Research, Mal-Mandel, USA, pp. 41-50. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * J. Prabher, R. Pettit, K. Holcomb McMurry, A. Peters, J. Homer, N. Simone, and M. Cohen (2017)On novices' interaction with compiler error messages: a human factors approach. In Proceedings of the 2017 ACM Conference on International Computing Education Research, Mal-Mandel, USA, pp. 74-82. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * S. Rosen, R. A. Sopro, and J. K. Donnelly (1965)PUFFT--the prudue university fast rotfran/n translation. Commun. ACM81 (10), pp. 661-666. External Links: ISSN 00014-5349-1, Link, Document Cited by: SS1. * S. Sarsa, P. Denny, A. Hellas, and J. Leinonen (2022)Automatic generation of programming exercises and code explanations using large language models. In Proceedings of the 2022 ACM Conference on International Computing Education Research, Mal-Mandel, USA, pp. 27-43. External Links: ISBN 978-1-4503-319-1, Link, Document Cited by: SS1. * A. Steffik and S. Siebert (2013)An empirical investigation into programming language syntax. ACM Transactions on Computing Education13 (4), pp. 1-40. External Links: ISSN 0038-9348-19-1, Link, Document Cited by: SS1. * P. V. Vaithilhimgan, T. Zhang, and E. I. Glassman (2022)Expection vs. Experience: evaluating the usability of code generation tools powered by large language models. In CHI Conference on Human Factors in Computing Systems Extended Abstracts, pp. 1-7. Cited by: SS1."
    }
  ]
}
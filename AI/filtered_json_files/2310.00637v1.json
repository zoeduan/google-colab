{
  "title": "Knowledge Engineering using Large Language Models",
  "authors": [
    "Bradley P Allen",
    "Lise Stork",
    "Paul Groth"
  ],
  "abstract": "\n Knowledge engineering is a discipline that focuses on the creation and maintenance of processes that generate and apply knowledge. Traditionally, knowledge engineering approaches have focused on knowledge expressed in formal languages. The emergence of large language models and their capabilities to effectively work with natural language, in its broadest sense, raises questions about the foundations and practice of knowledge engineering. Here, we outline the potential role of LLMs in knowledge engineering, identifying two central directions: 1) creating hybrid neuro-symbolic knowledge systems; and 2) enabling knowledge engineering in natural language. Additionally, we formulate key open research questions to tackle these directions. \n ACM Subject Classification Computing methodologies → Natural language processing, Computing methodologies → Machine learning, Computing methodologies → Philosophical/theoretical foundations of artificial intelligence, Software and its engineering → Software development methods Keywords and Phrases knowledge engineering, large language models Digital Object Identifier 10. \n",
  "references": [
    {
      "id": null,
      "title": "Knowledge Engineering using Large Language Models",
      "authors": [
        "Bradley P Allen",
        "Lise Stork",
        "Paul Groth"
      ],
      "year": "2023",
      "venue": "",
      "doi": "10.1234/0000000.00000000"
    },
    {
      "id": "b0",
      "title": "A research agenda for hybrid intelligence: augmenting human intellect with collaborative, adaptive, responsible, and explainable artificial intelligence",
      "authors": [
        "Dan Akata",
        "Maarten Balliet",
        "Frank De Rijke",
        "Virginia Dignum",
        "Guszti Dignum",
        "Antske Eiben",
        "Davide Fokkens",
        "Koen Grossi",
        "Holger Hindriks",
        "Hoos"
      ],
      "year": "2020",
      "venue": "Computer",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Prompting as probing: Using language models for knowledge base construction",
      "authors": [
        "Dimitrios Alivanistos",
        "Selene Báez Santamaría",
        "Michael Cochez",
        "Jan",
        "Christoph Kalo",
        "Emile Van Krieken",
        "Thiviyan Thanapalasingam"
      ],
      "year": "2022",
      "venue": "Sneha Singhania, Tuan-Phong Nguyen, and Simon Razniewski, editors, LM-KBC 2022 Knowledge Base Construction from Pre-trained Language Models 2022, CEUR Workshop Proceedings",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "A review on language models as knowledge bases",
      "authors": [
        "Millicent Alkhamissi",
        "Asli Li",
        "Mona Celikyilmaz",
        "Marjan Diab",
        "Ghazvininejad"
      ],
      "year": "2022",
      "venue": "A review on language models as knowledge bases",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Identifying and consolidating knowledge engineering requirements",
      "authors": [
        "Filip Allen",
        "Saurav Ilievski",
        "Joshi"
      ],
      "year": "2023",
      "venue": "Identifying and consolidating knowledge engineering requirements",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Fine-tuning pre-trained transformer language models to distantly supervised relation extraction",
      "authors": [
        "Marc Alt",
        "Leonhard Hübner",
        "Hennig"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "Program synthesis with large language models",
      "authors": [
        "Augustus Austin",
        "Maxwell Odena",
        "Maarten Nye",
        "Henryk Bosma",
        "David Michalewski",
        "Ellen Dohan",
        "Carrie Jiang",
        "Michael Cai",
        "Quoc Terry",
        "Le"
      ],
      "year": "2023",
      "venue": "Agnes Axelsson and Gabriel Skantze. Using large language models for zero-shot natural language generation from knowledge graphs",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "PromptSource: An integrated development environment and repository for natural language prompts",
      "authors": [
        "Victor Bach",
        "Zheng Xin Sanh",
        "Albert Yong",
        "Colin Webson",
        "Raffel",
        "V Nihal",
        "Abheesht Nayak",
        "Taewoon Sharma",
        "M Kim",
        "Thibault Saiful Bari",
        "Zaid Fevry",
        "Manan Alyafeai",
        "Andrea Dey",
        "Zhiqing Santilli",
        "Srulik Sun",
        "Canwen Ben-David",
        "Gunjan Xu",
        "Han Chhablani",
        "Jason Wang",
        "Maged Fries",
        "Shanya Al-Shaibani",
        "Urmish Sharma",
        "Khalid Thakker",
        "Xiangru Almubarak",
        "Dragomir Tang",
        "Mike Radev",
        "Tian-Jian",
        "Alexander Jiang",
        "Rush"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
      "doi": "10.18653/v1/2022.acl-demo.9"
    },
    {
      "id": "b7",
      "title": "Self-driving cars: A survey",
      "authors": [
        "Rânik Badue",
        "Raphael Guidolini",
        "Pedro Vivacqua Carneiro",
        "Azevedo",
        "B Vinicius",
        "Avelino Cardoso",
        "Luan Forechi",
        "Rodrigo Jesus",
        "Berriel",
        "M Thiago",
        "Filipe Paixao",
        "Mutz"
      ],
      "year": "2021",
      "venue": "Expert Systems with Applications",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Tdwg standards documentation specification",
      "authors": [
        "Roger Baskauf",
        "Stanley Hyam",
        "Robert A Blum",
        "Jonathan Morris",
        "Joel Rees",
        "Greg Sachs",
        "John Whitbread",
        "Wieczorek"
      ],
      "year": "2017",
      "venue": "Biodiversity Information Standards",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "The semantic web",
      "authors": [
        "James Berners-Lee",
        "Ora Hendler",
        "Lassila"
      ],
      "year": "2001",
      "venue": "Scientific american",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "Evaluating ontologies with competency questions",
      "authors": [
        "Fred Bezerra",
        "Filipe Freitas",
        "Santana"
      ],
      "year": "2013",
      "venue": "2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Proceedings of the 17th international conference on World Wide Web",
      "authors": [
        "Tom Bizer",
        "Kingsley Heath",
        "Tim Idehen",
        "Berners-Lee"
      ],
      "year": "2008",
      "venue": "Proceedings of the 17th international conference on World Wide Web",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "No specimen left behind: industrial scale digitization of natural history collections",
      "authors": [
        "Ian J Blagoderov",
        "Laurence Kitching",
        "Thomas J Livermore",
        "Vincent S Simonsen",
        "Smith"
      ],
      "year": "2012",
      "venue": "ZooKeys",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "On the opportunities and risks of foundation models",
      "authors": [
        "Rishi Bommasani"
      ],
      "year": "2021",
      "venue": "CoRR",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "",
      "authors": [],
      "year": "",
      "venue": "",
      "doi": "10.48550/arXiv.2108.07258"
    },
    {
      "id": "b15",
      "title": "A review of biomedical datasets relating to drug discovery: a knowledge graph perspective",
      "authors": [
        "Ian P Bonner",
        "Cheng Barrett",
        "Rowan Ye",
        "Ola Swiers",
        "Andreas Engkvist",
        "Charles Tapley Bender",
        "William L Hoyt",
        "Hamilton"
      ],
      "year": "2022",
      "venue": "Briefings in Bioinformatics",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "Thinking fast and slow in ai",
      "authors": [
        "Francesco Booch",
        "Lior Fabiano",
        "Kiran Horesh",
        "Jonathan Kate",
        "Nick Lenchner",
        "Andreas Linck",
        "Keerthiram Loreggia",
        "Nicholas Murgesan",
        "Francesca Mattei",
        "Rossi"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "COMET: Commonsense transformers for automatic knowledge graph construction",
      "authors": [
        "Hannah Bosselut",
        "Maarten Rashkin",
        "Chaitanya Sap",
        "Asli Malaviya",
        "Yejin Celikyilmaz",
        "Choi"
      ],
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P19-1470"
    },
    {
      "id": "b18",
      "title": "Andreea Iana, Heiko Paulheim, Jan Portisch, Artem Revenko, Annette ten Teije, et al. Combining machine learning and semantic web: A systematic mapping study",
      "authors": [
        "Laura Breit",
        "Waltersdorfer",
        "J Fajar",
        "Marta Ekaputra",
        "Andreas Sabou",
        "Ekelhart"
      ],
      "year": "2023",
      "venue": "Andreea Iana, Heiko Paulheim, Jan Portisch, Artem Revenko, Annette ten Teije, et al. Combining machine learning and semantic web: A systematic mapping study",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "Language models are fewshot learners. Advances in neural information processing systems",
      "authors": [
        "Benjamin Brown",
        "Nick Mann",
        "Melanie Ryder",
        "Jared D Subbiah",
        "Prafulla Kaplan",
        "Arvind Dhariwal",
        "Pranav Neelakantan",
        "Girish Shyam",
        "Amanda Sastry",
        "Askell"
      ],
      "year": "2020",
      "venue": "Language models are fewshot learners. Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "Knowledge-based biomedical data science",
      "authors": [
        "J Callahan",
        "Ignacio J Tripodi",
        "Harrison Pielke-Lombardo",
        "Lawrence E Hunter"
      ],
      "year": "2020",
      "venue": "Annual Review of Biomedical Data Science",
      "doi": "10.1146/annurev-biodatasci-010820-091627"
    },
    {
      "id": "b21",
      "title": "Making AI intelligible: Philosophical foundations",
      "authors": [
        "Cappelen",
        "Josh Dever"
      ],
      "year": "2021",
      "venue": "Making AI intelligible: Philosophical foundations",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "Emerging properties in selfsupervised vision transformers",
      "authors": [
        "Hugo Caron",
        "Ishan Touvron",
        "Hervé Misra",
        "Julien Jégou",
        "Piotr Mairal",
        "Armand Bojanowski",
        "Joulin"
      ],
      "year": "2021",
      "venue": "Proceedings of the IEEE/CVF international conference on computer vision",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "Carnap and twentieth-century thought: Explication as enlightenment",
      "authors": [
        "Carus"
      ],
      "year": "2007",
      "venue": "Carnap and twentieth-century thought: Explication as enlightenment",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "A survey on evaluation of large language models",
      "authors": [
        "Xu Chang",
        "Jindong Wang",
        "Yuan Wang",
        "Kaijie Wu",
        "Hao Zhu",
        "Linyi Chen",
        "Xiaoyuan Yang",
        "Cunxiang Yi",
        "Yidong Wang",
        "Wang"
      ],
      "year": "2023",
      "venue": "A survey on evaluation of large language models",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "Natural language processing (almost) from scratch",
      "authors": [
        "Jason Collobert",
        "Léon Weston",
        "Michael Bottou",
        "Koray Karlen",
        "Pavel Kavukcuoglu",
        "Kuksa"
      ],
      "year": "2011",
      "venue": "Journal of machine learning research",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Data journeys: explaining ai workflows through abstraction. Semantic Web",
      "authors": [
        "Paul Daga",
        "Groth"
      ],
      "year": "2023",
      "venue": "Data journeys: explaining ai workflows through abstraction. Semantic Web",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Ming-Wei Devlin",
        "Kenton Chang",
        "Kristina Lee",
        "Toutanova",
        "Bert"
      ],
      "year": "2018",
      "venue": "Pre-training of deep bidirectional transformers for language understanding",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Personalized nichesourcing: Acquisition of qualitative annotations from niche communities",
      "authors": [
        "29chris Dijkshoorn",
        "Archana Mieke Hr Leyssen",
        "Jasper Nottamkandath",
        "Myriam C Oosterman",
        "Lora Traub",
        "Alessandro Aroyo",
        "Wan J Bozzon",
        "Geert-Jan Fokkink",
        "Henrike Houben",
        "Hovelmann"
      ],
      "year": "2013",
      "venue": "UMAP Workshops",
      "doi": ""
    },
    {
      "id": "b29",
      "title": "Explainable artificial intelligence: A survey",
      "authors": [
        "Karlo Došilović",
        "Mario Brčić",
        "Nikica Hlupić"
      ],
      "year": "2018",
      "venue": "2018 41st International convention on information and communication technology, electronics and microelectronics (MIPRO)",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "32Edward A Feigenbaum. The art of artificial intelligence: Themes and case studies of knowledge engineering",
      "authors": [
        "Majlinda Ekaputra",
        "Marta Llugiqi",
        "Andreas Sabou",
        "Heiko Ekelhart",
        "Anna Paulheim",
        "Artem Breit",
        "Laura Revenko",
        "Kheir Eddine Waltersdorfer",
        "Sören Farfar",
        "Auer"
      ],
      "year": "1977",
      "venue": "Proceedings of the Fifth International Joint Conference on Artificial Intelligence",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "Survey of hallucination in natural language generation",
      "authors": [
        "A Feigenbaum ; Ziwei",
        "Nayeon Ji",
        "Rita Lee",
        "Tiezheng Frieske",
        "Dan Yu",
        "Yan Su",
        "Etsuko Xu",
        "Ye Ishii",
        "Jin Bang",
        "Andrea Madotto",
        "Pascale Fung"
      ],
      "year": "2023",
      "venue": "Annals of the New York Academy of Sci-48",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "Thinking, fast and slow. macmillan",
      "authors": [
        "Kahneman"
      ],
      "year": "2011",
      "venue": "Thinking, fast and slow. macmillan",
      "doi": ""
    },
    {
      "id": "b33",
      "title": "Phylogenetic tree building in the genomic age",
      "authors": [
        "Ziheng Kapli",
        "Maximilian J Yang",
        "Telford"
      ],
      "year": "2020",
      "venue": "Nature Reviews Genetics",
      "doi": ""
    },
    {
      "id": "b34",
      "title": "Ontology engineering",
      "authors": [
        "F Kendall",
        "Deborah L Mcguinness"
      ],
      "year": "2019",
      "venue": "Ontology engineering",
      "doi": ""
    },
    {
      "id": "b35",
      "title": "Large language models are zero-shot reasoners",
      "authors": [
        "Shixiang Shane Kojima",
        "Machel Gu",
        "Yutaka Reid",
        "Yusuke Matsuo",
        "Iwasawa"
      ],
      "year": "2022",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b36",
      "title": "Column type annotation using chatgpt",
      "authors": [
        "Christian Korini",
        "Bizer"
      ],
      "year": "2023",
      "venue": "Column type annotation using chatgpt",
      "doi": ""
    },
    {
      "id": "b37",
      "title": "Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models",
      "authors": [
        "Morgan Kung",
        "Arielle Cheatham",
        "Czarina Medenilla",
        "Lorie De Sillos",
        "Camille Leon",
        "Maria Elepaño",
        "Rimel Madriaga",
        "Giezel Aggabao",
        "James Diaz-Candido",
        "Maningo"
      ],
      "year": "2023",
      "venue": "PLoS digital health",
      "doi": ""
    },
    {
      "id": "b38",
      "title": "Rethinking explainability as a dialogue: A practitioner's perspective",
      "authors": [
        "Dylan Lakkaraju",
        "Yuxin Slack",
        "Chenhao Chen",
        "Sameer Tan",
        "Singh"
      ],
      "year": "2022",
      "venue": "Rethinking explainability as a dialogue: A practitioner's perspective",
      "doi": ""
    },
    {
      "id": "b39",
      "title": "Toward keyword generation through large language models",
      "authors": [
        "Minki Lee",
        "Hyeonhak Chun",
        "Hyunggu Jeong",
        "Jung"
      ],
      "year": "2023",
      "venue": "Companion Proceedings of the 28th International Conference on Intelligent User Interfaces, IUI '23 Companion",
      "doi": "10.1145/3581754.3584126"
    },
    {
      "id": "b40",
      "title": "Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing",
      "authors": [
        "Weizhe Liu",
        "Jinlan Yuan",
        "Zhengbao Fu",
        "Hiroaki Jiang",
        "Graham Hayashi",
        "Neubig"
      ],
      "year": "2023",
      "venue": "ACM Computing Surveys",
      "doi": ""
    },
    {
      "id": "b41",
      "title": "Data-to-text generation for severely under-resourced languages with gpt-3.5: A bit of help needed from google translate",
      "authors": [
        "Anya Lorandi",
        "Belz"
      ],
      "year": "2023",
      "venue": "Data-to-text generation for severely under-resourced languages with gpt-3.5: A bit of help needed from google translate",
      "doi": ""
    },
    {
      "id": "b42",
      "title": "Naturalists in the field: collecting, recording and preserving the natural world from the fifteenth to the twenty-first century",
      "authors": [
        "Macgregor"
      ],
      "year": "2018",
      "venue": "Naturalists in the field: collecting, recording and preserving the natural world from the fifteenth to the twenty-first century",
      "doi": ""
    },
    {
      "id": "b43",
      "title": "Dissociating language and thought in large language models: a cognitive perspective",
      "authors": [
        "Anna A Mahowald",
        "Idan A Ivanova",
        "Nancy Blank",
        "Joshua B Kanwisher",
        "Evelina Tenenbaum",
        "Fedorenko"
      ],
      "year": "2023",
      "venue": "Dissociating language and thought in large language models: a cognitive perspective",
      "doi": ""
    },
    {
      "id": "b44",
      "title": "Information extraction meets the semantic web: A survey",
      "authors": [
        "L Martinez-Rodriguez",
        "Aidan Hogan",
        "Ivan Lopez-Arevalo"
      ],
      "year": "2020",
      "venue": "Semantic Web",
      "doi": "10.3233/sw-180333"
    },
    {
      "id": "b45",
      "title": "Writing as thinking",
      "authors": [
        "Menary"
      ],
      "year": "2007",
      "venue": "Language sciences",
      "doi": ""
    },
    {
      "id": "b46",
      "title": "64Hugo Mercier and Dan Sperber. The enigma of reason",
      "authors": [
        "Menary"
      ],
      "year": "2010",
      "venue": "Dimensions of mind. Phenomenology and the Cognitive Sciences",
      "doi": ""
    },
    {
      "id": "b47",
      "title": "Augmented language models: a survey",
      "authors": [
        "Roberto Mialon",
        "Maria Dessì",
        "Christoforos Lomeli",
        "Ram Nalmpantis",
        "Roberta Pasunuru",
        "Raileanu",
        "Timo Baptiste Rozière",
        "Jane Schick",
        "Asli Dwivedi-Yu",
        "Celikyilmaz"
      ],
      "year": "2023",
      "venue": "Augmented language models: a survey",
      "doi": ""
    },
    {
      "id": "b48",
      "title": "Recent advances in natural language processing via large pre-trained language models: A survey",
      "authors": [
        "Hayley Min",
        "Elior Ross",
        "Amir Sulem",
        "Ben Pouran",
        "Thien Veyseh",
        "Oscar Huu Nguyen",
        "Eneko Sainz",
        "Ilana Agirre",
        "Dan Heintz",
        "Roth"
      ],
      "year": "2023",
      "venue": "ACM Comput. Surv",
      "doi": "10.1145/3605943"
    },
    {
      "id": "b49",
      "title": "67Staffan Müller-Wille. Names and numbers:\"data\" in classical natural history",
      "authors": [],
      "year": "2017",
      "venue": "67Staffan Müller-Wille. Names and numbers:\"data\" in classical natural history",
      "doi": ""
    },
    {
      "id": "b50",
      "title": "Named entity recognition and relation extraction: State-ofthe-art",
      "authors": [
        "Syed Waqar Nasar",
        "Muhammad Jaffry",
        "Malik Kamran"
      ],
      "year": "2021",
      "venue": "ACM Computing Surveys (CSUR)",
      "doi": ""
    },
    {
      "id": "b51",
      "title": "Formal languages in logic: A philosophical and cognitive analysis",
      "authors": [
        "Dutilh Novaes"
      ],
      "year": "2012",
      "venue": "Formal languages in logic: A philosophical and cognitive analysis",
      "doi": ""
    },
    {
      "id": "b52",
      "title": "70Catarina Dutilh Novaes. The dialogical roots of deduction: Historical, cognitive, and philosophical perspectives on reasoning",
      "authors": [],
      "year": "2020",
      "venue": "70Catarina Dutilh Novaes. The dialogical roots of deduction: Historical, cognitive, and philosophical perspectives on reasoning",
      "doi": ""
    },
    {
      "id": "b53",
      "title": "Encoding the haunting of an object catalogue: on the potential of digital technologies to perpetuate or subvert the silence and bias of the early-modern archive",
      "authors": [
        "Alexandra Ortolja",
        "- Baird",
        "Julianne Nyhan"
      ],
      "year": "2022",
      "venue": "Digital Scholarship in the Humanities",
      "doi": ""
    },
    {
      "id": "b54",
      "title": "Biodiversity informatics: the challenge of linking data and the role of shared identifiers",
      "authors": [
        "Page"
      ],
      "year": "2008",
      "venue": "Briefings in bioinformatics",
      "doi": ""
    },
    {
      "id": "b55",
      "title": "Unifying large language models and knowledge graphs: A roadmap",
      "authors": [
        "Linhao Pan",
        "Yufei Luo",
        "Chen Wang",
        "Jiapu Chen",
        "Xindong Wang",
        "Wu"
      ],
      "year": "2023",
      "venue": "Unifying large language models and knowledge graphs: A roadmap",
      "doi": ""
    },
    {
      "id": "b56",
      "title": "Generative agents: Interactive simulacra of human behavior",
      "authors": [
        "Sung Park",
        "C O' Joseph",
        "Carrie J Brien",
        "Meredith Ringel Cai",
        "Percy Morris",
        "Michael S Liang",
        "Bernstein"
      ],
      "year": "2023",
      "venue": "Generative agents: Interactive simulacra of human behavior",
      "doi": ""
    },
    {
      "id": "b57",
      "title": "Language models as knowledge bases? arXiv preprint",
      "authors": [
        "Tim Petroni",
        "Patrick Rocktäschel",
        "Anton Lewis",
        "Yuxiang Bakhtin",
        "Alexander H Wu",
        "Sebastian Miller",
        "Riedel"
      ],
      "year": "2019",
      "venue": "Language models as knowledge bases? arXiv preprint",
      "doi": ""
    },
    {
      "id": "b58",
      "title": "extreme design with content ontology design patterns",
      "authors": [
        "Enrico Presutti",
        "Aldo Daga",
        "Eva Gangemi",
        "Blomqvist"
      ],
      "year": "2009",
      "venue": "Proc. Workshop on Ontology Patterns",
      "doi": ""
    },
    {
      "id": "b59",
      "title": "Towards a digital infrastructure for illustrated handwritten archives",
      "authors": [
        "Mahya Weber",
        "Katherine Ameryan",
        "Lise Wolstencroft",
        "Maarten Stork",
        "Lambert Heerlien",
        "Schomaker"
      ],
      "year": "2017",
      "venue": "Digital Cultural Heritage: Final Conference of the Marie Skłodowska-Curie Initial Training Network for Digital Cultural Heritage",
      "doi": ""
    },
    {
      "id": "b60",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Xuezhi Wei",
        "Dale Wang",
        "Maarten Schuurmans",
        "Fei Bosma",
        "Ed Xia",
        "Chi",
        "V Quoc",
        "Denny Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b61",
      "title": "Toward general design principles for generative ai applications",
      "authors": [
        "Michael Weisz",
        "Jessica Muller",
        "Stephanie He",
        "Houde"
      ],
      "year": "2023",
      "venue": "Toward general design principles for generative ai applications",
      "doi": ""
    },
    {
      "id": "b62",
      "title": "Chatgpt prompt patterns for improving code quality, refactoring, requirements elicitation, and software design",
      "authors": [
        "Sam White",
        "Quchen Hays",
        "Jesse Fu",
        "Douglas C Spencer-Smith",
        "Schmidt"
      ],
      "year": "2023",
      "venue": "Chatgpt prompt patterns for improving code quality, refactoring, requirements elicitation, and software design",
      "doi": "10.48550/arXiv.2303.07839"
    },
    {
      "id": "b63",
      "title": "Kads: A modelling approach to knowledge engineering",
      "authors": [
        "Th Wielinga",
        "Jost A Schreiber",
        "Breuker"
      ],
      "year": "1992",
      "venue": "Knowledge acquisition",
      "doi": ""
    },
    {
      "id": "b64",
      "title": "The FAIR guiding principles for scientific data management and stewardship",
      "authors": [
        "D Wilkinson",
        "Michel Dumontier",
        "Jan Ijsbrand",
        "Gabrielle Aalbersberg",
        "Myles Appleton",
        "Arie Axton",
        "Niklas Baak",
        "Jan-Willem Blomberg",
        "Luiz Boiten",
        "Silva Bonino Da",
        "Philip E Santos",
        "Jildau Bourne",
        "Anthony J Bouwman",
        "Tim Brookes",
        "Mercè Clark",
        "Ingrid Crosas",
        "Olivier Dillo",
        "Scott Dumon",
        "Chris T Edmunds",
        "Richard Evelo",
        "Alejandra Finkers",
        "Alasdair J G Gonzalez-Beltran",
        "Paul Gray",
        "Carole Groth",
        "Jeffrey S Goble",
        "Jaap Grethe",
        "Peter A Heringa",
        "Rob C 't Hoen",
        "Tobias Hooft",
        "Ruben Kuhn",
        "Joost Kok",
        "Scott J Kok",
        "Maryann E Lusher",
        "Albert Martone",
        "Abel L Mons",
        "Bengt Packer",
        "Philippe Persson",
        "Marco Rocca-Serra",
        "Rene Roos",
        "Susanna-Assunta Van Schaik",
        "Erik Sansone",
        "Thierry Schultes",
        "Ted Sengstag",
        "George Slater",
        "Morris A Strawn",
        "Mark Swertz",
        "Johan Thompson",
        "Erik Van Der Lei",
        "Jan Van Mulligen",
        "Andra Velterop",
        "Peter Waagmeester",
        "Katherine Wittenburg",
        "Jun Wolstencroft",
        "Barend Zhao",
        "Mons"
      ],
      "year": "2016",
      "venue": "Scientific Data",
      "doi": "10.1038/sdata.2016.18"
    },
    {
      "id": "b65",
      "title": "From word models to world models: Translating from natural language to the probabilistic language of thought",
      "authors": [
        "Gabriel Wong",
        "Alexander K Grand",
        "Noah D Lew",
        "Goodman",
        "K Vikash",
        "Jacob Mansinghka",
        "Joshua B Andreas",
        "Tenenbaum"
      ],
      "year": "2023",
      "venue": "From word models to world models: Translating from natural language to the probabilistic language of thought",
      "doi": ""
    },
    {
      "id": "b66",
      "title": "Pre-trained language models with domain knowledge for biomedical extractive summarization",
      "authors": [
        "Qianqian Xie",
        "Jennifer",
        "Amy Bishop",
        "Prayag Tiwari",
        "Sophia Ananiadou"
      ],
      "year": "2022",
      "venue": "Knowledge-Based Systems",
      "doi": ""
    },
    {
      "id": "b67",
      "title": "Logical reasoning over natural language as knowledge representation: A survey",
      "authors": [
        "Xinya Yang",
        "Rui Du",
        "Jinjie Mao",
        "Erik Ni",
        "Cambria"
      ],
      "year": "2023",
      "venue": "Logical reasoning over natural language as knowledge representation: A survey",
      "doi": "10.48550/arXiv.2303.12023"
    },
    {
      "id": "b68",
      "title": "Gpt3mix: Leveraging large-scale language models for text augmentation",
      "authors": [
        "Min Yoo",
        "Dongju Park",
        "Jaewook Kang",
        "Sang-Woo Lee",
        "Woomyeong Park"
      ],
      "year": "2021",
      "venue": "Gpt3mix: Leveraging large-scale language models for text augmentation",
      "doi": ""
    },
    {
      "id": "b69",
      "title": "Coca: Contrastive captioners are image-text foundation models",
      "authors": [
        "Zirui Yu",
        "Vijay Wang",
        "Legg Vasudevan",
        "Mojtaba Yeung",
        "Yonghui Seyedhosseini",
        "Wu"
      ],
      "year": "2022",
      "venue": "Coca: Contrastive captioners are image-text foundation models",
      "doi": ""
    },
    {
      "id": "b70",
      "title": "Structure pretraining and prompt tuning for knowledge graph transfer",
      "authors": [
        "Yushan Zhang",
        "Mingyang Zhu",
        "Yuxia Chen",
        "Yufeng Geng",
        "Yajing Huang",
        "Wenting Xu",
        "Huajun Song",
        "Chen"
      ],
      "year": "2023",
      "venue": "Proceedings of the ACM Web Conference 2023, WWW '23, page 2581-2590",
      "doi": "10.1145/3543507.3583301"
    },
    {
      "id": "b71",
      "title": "Learning to prompt for visionlanguage models",
      "authors": [
        "Jingkang Zhou",
        "Chen Change Yang",
        "Ziwei Loy",
        "Liu"
      ],
      "year": "2022",
      "venue": "International Journal of Computer Vision",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "2 Forms Of Knowledge And Their Engineering",
      "text": "In the history of the computational investigation of knowledge engineering, knowledge has been often treated primarily as symbolic expressions. However, as [39] noted, knowledge is actually encoded in a variety of media and forms, most notably in natural language (e.g. English) but also in images, video, or even spreadsheets. This fact becomes even more apparent when looking at institutional knowledge practices that have developed over centuries, for example, in the sciences or archives [44]. We now illustrate this point by describing the many ways in which knowledge manifests itself in the context of biodiversity informatics."
    },
    {
      "title": "The Multimodal Richness Of Knowledge: An Example From Biodiversity Sciences",
      "text": "The ultimate goal of biodiversity science is to understand species evolution, variation, and distribution, but finds applications in a variety of other fields such as climate science and policy. At its heart is the collection and observation of organisms, providing evidence for deductions about the natural world [59]. Such knowledge is inherently multimodal in nature, most commonly appearing in the form of images, physical objects, tree structures and sequences, i.e., molecular data. Historically, organism sightings have been carefully logged in handwritten field diaries to describe species behaviour and environmental conditions. Detailed drawings and later photographs were made to capture colour, organs and other knowledge about an organism's traits used for identification, which is best conveyed visually but which is challenging to preserve in natural specimens. These manuscripts are housed, together with the physical zoological specimens and herbaria which they describe, in museums and collection facilities across the world. Both the multimodal nature of these knowledge sources as well as their distributed nature hamper knowledge integration and synthesis. Metadata describes the specimen's provenance: where specimens were found, who found them, and provides an attempt at identifying the type of organism (such as the preserved squid specimen shown in Figure 1). Such knowledge is paramount, as it allows researchers to understand resources within the context in which they were produced, enabling researchers to carry out ecological studies such as distribution modeling over time. For a systematic comparison of the multitude of resources available, the biodiversity sciences have had a long-standing tradition of developing information standards [67]. From Linnaeus' Systema nature mid 18th century as well as his formal introduction of zoological nomenclature, taxonomists have started categorizing natural specimens according to tree-like hierarchical structures. The process is challenging, given that biologist up until this day do not have a full picture of all living organisms on earth, and incomplete, naturally evolved and fuzzy knowledge is not easily systematized. The development of digital methods has opened up new pathways for comparison and analysis. Gene sequencing technology has lead biologist to the genetic comparison of species, by the calculation of ancestry and construction of evolutionary tree structures in the study of phylogeny [50]. More importantly, digital methods allowed the transfer of analog resources, such as specimen collection scans [14] and metadata, to the digital world. Such techniques have furthered formalisation and thereby interoperability of collected data through the use of Web standards, such as globally unique identifiers for species names [72] as well as shared vocabularies for data integration across collections [10]. The Global Biodiversity Information Facility (GBIF) and their data integration toolkit serves as a great example of such integration efforts [97, 81]. Currently,there is a large emphasis on linking up disparate digital resources in the creation of an interconnected network of digital collection objects on the Web, linked up with relevant ecological, environmental and other related data in support of machine actionability (i.e., the ability of computational systems to find, access, interoperate, and reuse data with minimal intervention) for an array of interdisciplinary tasks such as fact-based decision-making and forecasting [41].Using data standards for describing and reasoning over collection data can aid researchers counter unwanted biases via transparency. However, making data comply with data standards can also lead to oversimplification or reinterpretation [71]. Machine learning and knowledge engineering strategies can help to (semi-)automatically extract and structure biodiversity knowledge according [102, 91], for instance using state-of-the-art computer vision or natural language processing techniques as well as crowd-sourcing platforms for the annotation of field diaries and other collection objects with formal language [92, 29]. Nevertheless, a bottleneck in the digitization of collections and their use for machine actionability is the amount of work and domain expertise required for the formalisation of such knowledge, and the extraction from unstructured texts, images and video's. Historical resources, i.e. handwritten texts, pose an additional challenge, as they are exceptionally challenging to interpret within the current scientific paradigm [107]. The variety and usefulness of different forms of knowledge both natural and formal and the challenges they pose is not limited to the biodiversity domain as described above. We see the same diversity happening in law [82], medicine [16, 21] and even self-driving vehicles [9]. To summarize: * domain knowledge is often best represented in a variety of modalities, i.e., images, taxonomies, or free text, each modality with its own data structure and characteristics which should be preserved, and no easy way of integrating, interfacing with or reasoning over multimodal knowledge in a federated way exists; * provenance of data is paramount in understanding knowledge within the context in which it was produced; * fuzzy, incomplete, or complex knowledge is not easily systematized; * using data standards for describing and reasoning over collection data can aid researchers counter unwanted biases via transparency; * making data comply with data standards can lead to oversimplification or reinterpretation; Figure 1: A specimen of the _Loligo vulgaris Lamarck, 1798_ species from the _Naturalis–Zoology and Geology_ catalogues.1 Images free of known restrictions under copyright law (Public Domain Mark 1.0). * the production of structured domain knowledge, for instance from images or free text, requires domain expertise, and is therefore labour intensive and costly; * knowledge evolves, and knowledge-based systems are required to deal with updates in their knowledge bases. _KE as the transformation of knowledge expressed in natural language into knowledge expressed in a formal language_ This sort of rich and complex array of modalities for the representation of knowledge has traditionally posed a challenge to knowledge engineers [33]. Much of the literature on knowledge engineering methodology has focused on the ways in which knowledge in these naturally-occurring forms can be recast into a structured symbolic representation, e.g., using methods of knowledge elicitation from subject matter experts [88], for instance by the formulation of competency questions for analysing application ontologies [12]. One way to think about this is as the process of expressing knowledge presented in a natural, humanly evolved language in a formally-defined language. This notion of the transformation of natural language into a formal language as a means of enabling effective reasoning has a deep history rooted in methodologies developed by analytical philosophers of the early twentieth century [24, 69], but dating even further back to Liebniz's _lingua rationalis_[35] and the thought of Ramon Lull [37]. Catarina Dutilh Novaes [69] has argued that formal languages enable reasoning that is less skewed by bias and held beliefs, an effect achieved through _de-semantification_, i.e., the process of replacing terms in a natural language with symbols that can be manipulated without interpretation using a system of rules of transformation. Coupled with sensorimotor manipulation of symbols in a notational system, people can reason in a manner that outstrips their abilities unaided by such a technology. While Dutilh Novaes' analysis focuses on this idea of formal languages as a cognitive tool used by humans directly, e.g. through the manipulation of a system of notation using paper and pencil, she notes that this manipulation of symbols is the route to the mechanization of reasoning through computation. When externally manifested as a function executed by a machine through either interpretation by an inference engine, or through compilation into a machine-level language, this approach of formalization yields the benefits of reliability, greater speed and efficiency in reasoning. This idea captures precisely the essence of the practice of knowledge engineering: Starting from sources of knowledge expressed in natural language and other modalities of human expression, through the process of formalization [51, 95], knowledge engineers create computational artifacts embodying this knowledge. These computational artifacts then enable us to reason using this knowledge in a predictable, efficient, and repeatable fashion. This is done either by proxy through the action of autonomous agents, or in the context of human-mediated decision-making processes."
    },
    {
      "title": "_Llms As A General-Purpose Technology For Transforming Natural Language Into Formal Language_",
      "text": "Until recently, there have been two ways in which this sort of formalization could be performed: through the manual authoring of symbolic/logical representations, e.g., as in the traditional notion of expert systems [34], or through the use of machine learning and natural language processing to extract such representations automatically from natural language text [61]. But what has become evident with the emergence of LLMs, with their capabilities for language learning and processing, is that they provide a new and powerful type of general purpose tool for mappingbetween natural language2 and formal language, as well as other modalities. LLMs have shown state-of-the-art performance on challenging NLP tasks such as relation extraction [5] or text abstraction/summarization [114], and have been used to translate between other modalities, such as images and text (called vision-language models [119, 77]) in computer vision tasks, or from natural language to code [113, 47], in which a pretrained task-agnostic language model can be zero-shot and few-shot transferred to perform a certain task [20, 52]. If one accepts the position that KE can be generally described as the process of transforming knowledge in natural language into knowledge in formal language, then it becomes clear that LLMs provide an advance in our ability to perform knowledge engineering tasks. Footnote 2: Again, we note that natural language should be read to include all modalities. Hence, the term “foundation model”[15] to refer to LLMs."
    },
    {
      "title": "3 The Use Of Llms In The Practice Of Knowledge Engineering: Two Scenarios",
      "text": "Given the above discussion, the natural question that arises is: what might be the utility and impact of the use of LLMs for the transformation of natural language into formal language, when applied in the context of the practice of knowledge engineering? When LLMs emerged as a new technology in the mid-2010s, two views of the relationship between LLMs and knowledge bases (KBs) were put forward. One was the LLM can be a useful component for various processes that are part of a larger knowledge engineering workflow (i.e. \"LMs for KBs\" [3]); the other was that that the LLM is a cognitive artifact that can be treated as a knowledge base in and of itself (i.e., \"LMs as KBs\" [75]). We exploit this dichotomy to formulate a pair of possible future scenarios for the use of LLMs in the practice of KE. One is to use LLMs as a technology for or tool in support of implementing knowledge tasks that have traditionally been build using older technologies such as rule bases and natural language processing (NLP). Another is to use LLMs to remove the need for knowledge engineers to be fluent in a formal language, i.e., by allowing knowledge for a given knowledge task to be expressed in natural language, and then using prompt engineering as the primary paradigm for the implementation of reasoning and learning. We now explore each of these scenarios in turn, and consider the open research problems that they raise."
    },
    {
      "title": "Llms As Components Or Tools Used In Knowledge Engineering",
      "text": "We illustrate the first scenario through reference to CommonKADS [86], a structured methodology that has been used by knowledge engineers since the early 2000's. CommonKADS is the refinement of an approach to providing a disciplined approach to the development of knowledge systems. This approach saw initial development in the nineteen-eighties as a reaction to both the ad-hoc nature of early expert systems development [111] and to the frequency of failures in the deployment of expert systems in an organizational context [34]. Stemming from early work on making expert systems development understandable and repeatable [42], CommonKADS is distinguished from methodologies more focused on ontology development (e.g., NeON [94], Kendall and McGuinness's \"Ontology 101\" framework [51], and Presutti's ontology design patterns [76]) in that it provides practical guidance for specification and implementation of knowledge systems components in a broader sense. It attempts to provide a synoptic guide to the full scope of activities involved in the practice of KE, and show how it relates to the activities of the organization in which that engineering is taking place. As such, in the context of this paper we can use it as a framework to explore for what tasks and in what ways LLMs can be used for KE. Some tasks identified by CommonKADS as part of the KE process may remain largely unchanged by the use of LLMs. These include knowledge task identification and project organizational design. But others can involve the use of LLMs. LLMs can assist knowledge engineers and/or knowledge providers in the performance of knowledge engineering tasks. They can also be a means for the implementation of modules performing knowledge-intensive tasks. Examples of these uses include the following:"
    },
    {
      "title": "Knowledge Acquisition And Elicitation",
      "text": "LLMs can be used to support knowledge acquisition and elicitation in a given domain of interest. Engineers can create prompts that target specific aspects of the domain, using the responses as a starting point for building the knowledge base. Dialogs between LLMs trained using such prompts and knowledge providers, the subject matter experts, can support the review, validation, and refinement of the acquired knowledge [8]."
    },
    {
      "title": "Knowledge Organization",
      "text": "LLMs can be used to organize the acquired knowledge into a coherent structure using natural language, making it easy to understand and update. Prompt engineering can be used to develop a set of prompts that extract formal language using the LLM, e.g., for text to graph generation [40] or vice versa [18, 2]. Moreover, LLMs are used for program synthesis [113, 47], the generation of metadata [56] or for fusing knowledge graphs [118]."
    },
    {
      "title": "Data Augmentation",
      "text": "LLMs can be used to generate synthetic training data to aid in testing the knowledge system by evaluating its performance on instances of the specific task [116]."
    },
    {
      "title": "Testing And Refinement",
      "text": "Feedback from subject matter experts and users can be used to prompt an LLM to refine the natural language knowledge base and improve the system's accuracy and efficiency through self-correction of prompts and tuning of the LLM model settings as needed to optimize the system's performance [110]."
    },
    {
      "title": "Maintenance",
      "text": "LLMs can be used to monitor new information and trends, and to then propose new prompts integrating those updates into the knowledge base. Consider the CommonKADS knowledge task hierarchy shown in Figure 2. Synthetic knowledge-intensive tasks, e.g. design or configuration, are amenable to generative approaches [109]; analytic knowledge-intensive tasks can involve LLM components within a hybrid neuro-symbolic knowledge system. A shortcoming of using CommonKADS for our purposes, however, is that it predates the widespread use of machine learning and statistical natural language processing in KE. A number of architectural approaches have since been developed that extend the CommonKADS concepts of a knowledge-intensive task type hierarchy and knowledge module templates. These include modeling the fine-grained data flows and workflows associated with knowledge systems that combine components that ingest, clean, transform, aggregate and generate data, as well as generate and apply models built using machine learning [103, 19, 27, 31, 101]. These architectures are put forward as providing a general framework for composing heterogeneous tools for knowledge representation and inference into a single integrated hybrid neuro-symbolic system. The design pattern notations put forward in recent work [103, 101, 31] treat data, models, and symbolic representations as the inputs and outputs of components composed into a variety of knowledge system design patterns. Generalizing these into natural language and formal language inputs and outputs can provide a simple way to extend these design notations to accommodate both LLMs as well as a richer set of knowledge representations."
    },
    {
      "title": "Knowledge Engineering As Prompt Engineering",
      "text": "Given that LLMs enable knowledge modeling in natural language, it is conceivable that the programming of knowledge modules could take place entirely in natural language. Consider that prompt programming is \"finding the most appropriate prompt to allow an LLM to solve a task\" [57]. One can through this lens view knowledge engineering as the crafting of dialogues in which a subject matter expert (SME) arrives at a conclusion by considering the preceding context and argumentation [80, 109, 89, 60]. This framing of knowledge engineering as prompt engineering is the second scenario we wish to explore. From the perspective of the CommonKADS knowledge-intensive task type hierarchy, this would involve a redefinition of the types and hierarchy to use LLMs and prompt programming design patterns, e.g. as described in [57]. Several aspects of this redefinition could include: **Natural language inference**: LLMs can be used to build natural language inference engines that use the organized knowledge to perform the specific task by taking input queries and generate output using prompt engineering to guide the LLM towards generating accurate inferences, e.g. using zero- or few-shot chain-of-thought design patterns. The benefit here is that the gap between the knowledge engineer, knowledge provider (the subject matter expert) and the user is smaller since a translation to a formal language (the language of the engineer) is no longer required. **Knowledge-intensive task execution through human/machine dialog**: LLMs can be used to a conversational interface that allows users to interact with the knowledge system and receive task-specific support. **Testing and refinement through human/machine dialog**: Feedback from subject matter experts and users can be used to prompt an LLM to refine the natural language knowledge base and improve the system's accuracy and efficiency through self-correction of prompts and tuning Figure 2: Hierarchy of knowledge-intensive task types from CommonKADS ([86], p.125)of the LLM model settings as needed to optimize the system's performance. One possible benefit of this approach would be that the barrier to adoption of knowledge engineering as a practice could be lowered significantly. Knowledge elicitation could be conducted entirely within natural language, meaning that subject matter experts without training in formal knowledge representations could perform these tasks directly. However, this approach assumes that predictable inference [101] using natural language is satisfactory. The propensity of current LLMs to \"hallucinate\", i.e., to confabulate facts, is an obstacle to the realization of this idea [48]. Multiple efforts have been devoted to the creation of prompt programming patterns that address this issue, ranging from chain-of-thought approaches [108] to retrieval-assisted generation, i.e. the augmentation of LLMs with authoritative document indexes and stores [84, 65]. Recent work [73] has described ways in which knowledge graphs as a formal language can be integrated with natural language and LLM-based language processing and reasoning to provide knowledge systems architectures that directly address this issue. [115] surveys work in this direction."
    },
    {
      "title": "4 Open Research Questions",
      "text": "Using the scenarios outlined above, we can identify a number of open research questions to be addressed to realize either or both of these two possible approaches to the use of LLMs in knowledge engineering. These questions touch on three general areas: the impact of LLMs on the methodologies used to build knowledge systems, on the architectural design of knowledge systems incorporating and/or based on LLMs, and on the evaluation of such systems. For each of these open questions, we provide a link back to the biodiversity scenario discussed in Section 2.1 denoted by a \\(\\clubsuit\\)."
    },
    {
      "title": "Methodology",
      "text": ""
    },
    {
      "title": "How Can Knowledge Engineering Methodologies Best Be Adapted To Use Llms?",
      "text": "How can we harmoniously medl the considerable body of work on knowledge engineering methodologies [51, 36, 76, 94, 87, 85, 90] with the new capabilities presented by LLMs? Schreiber's conceptualization of knowledge engineering as the construction of different aspect models of human knowledge [86], as discussed above, offers a framework for further elaboration. The distinctive characteristics of LLMs, coupled with prompt engineering, present unique challenges and opportunities for building agents within a knowledge system, one that is consistent with the CommonKADS approach. While the role definitions within KE methodologies might mostly remain the same, the skills required for knowledge engineers will need morphing to adapt to the LLM environment. This evolution of roles calls for an extensive investigation into what these new skills might look like, and how they can be cultivated. Additionally, the adaptability of the various knowledge-intensive task type hierarchies described by CommonKADS and its descendants in the literature on hybrid neuro-symbolic systems (e.g., as described in [19]) to accommodate LLMs is another fertile area for exploration. LLM-based applications, likened to synthetic tasks within these knowledge engineering frameworks, raise compelling research questions regarding accuracy and the prevention of hallucinations. LLM-based applications have a lower bar to reach with respect to notions of accuracy and avoidance of hallucinations, but still must provide useful and reliable guidance to users and practitioners. Connecting back to the biodiversity domain, answering these questions would provide guidance on the appropriate methodology to adopt when developing a new specimen curation and collection knowledge management system that needs to deal with multimodal assets like handwritten text or images."
    },
    {
      "title": "How Do Principles Of Content And Data Management Apply To Prompt Engineering?",
      "text": "Applying content and/or data management principles to collections of prompts and prompt templates, integral to work with LLMs, is an area ripe for exploration. Properly managing these resources could improve efficiency and guide the development of improved methodologies in knowledge engineering. This calls for a rigorous investigation of current data management practices, their applicability to LLMs, and potential areas of refinement. Ensuring the reproducibility of LLM engineering from a FAIR data standpoint [112] is a crucial yet complex challenge. Developing and validating practices and protocols that facilitate easy tracing and reproduction of LLM-based processes and outputs is central to this endeavour. Addressing this challenge will aid researchers in applying LLM engineering in a FAIR way. Doing so is critical for biodiversity research and science in general where precision, reproducibility and provenance are key for knowledge discovery and research integrity."
    },
    {
      "title": "What Are The Cognitive Norms That Govern The Conduct Of Ke?",
      "text": "A crucial area of inquiry involves the identification and understanding of _cognitive norms_, as described by Menary [62], that govern the practice of knowledge engineering. Cognitive norms are established within a human community of practice as a way of governing the acceptable use of \"external representational vehicles to complete a cognitive task\" [63]. As the consumer adoption of LLM technology has progressed, we see a great deal of controversy about when and how it is appropriate to use, e.g. in the context of education or the authoring of research publications. Understanding how these norms shape the use of LLMs in this context is an under-explored field of study. By unravelling the interplay between these cognitive norms and LLM usage, we can gain valuable insights into the dynamics of knowledge engineering practices and possibly foster more effective and responsible uses of LLMs. In the biodiversity sciences, this means understanding the cognitive norms specific to the domain, to understand how LLMs can be used in a way that respects the domain's practices and standards."
    },
    {
      "title": "How Do Llms Impact The Labor Economics Of Ke?",
      "text": "A related but distinct question pertains to the impact of LLMs on the economic costs associated with knowledge engineering. The introduction and application of LLMs in this field may significantly alter the economic landscape, either by driving costs down through automation and efficiency or by introducing new costs tied to system development, maintenance, and oversight. Thoroughly exploring these economic implications can shed light on the broader effects of integrating LLMs into knowledge engineering. The realm of labor economics as it pertains to hybrid or _centaur_ systems [1], is another area ripe for investigation. Understanding how the deployment of these systems influences labor distribution, skill requirements, and job roles could provide valuable input into the planning and implementation of such technologies. Additionally, it could reveal the potential societal and economic impacts of this technological evolution. Developments for LLM-based KE can help mitigate labour of knowledge experts in the biodiversity sciences, for instance by the development of more efficient KE workflows for the digitization of museum specimens or manuscripts."
    },
    {
      "title": "4.2 Architecture",
      "text": ""
    },
    {
      "title": "How Can Hybrid Neuro-Symbolic Architectural Models Incorporate Llms?",
      "text": "Design patterns for hybrid neuro-symbolic systems, as described in [103], offer a structured approach to comprehend the flow of data within a knowledge system. Adapting this model to account for the differences between natural and formal language could significantly enhance our ability to trace and manage data within knowledge systems. A salient research question emerging from this scenario pertains to the actual process of integrating LLMs into knowledge engineering data processing flows [27]. Understanding the nuances of this process will involve a deep examination of the shifts in methodologies, practices, and the potential re-evaluations of existing knowledge engineering paradigms. The perspective of KE enabled by LLMs as focused on the transformation of natural language into formal language provides insights that can be used to improve the motivation for hybrid neuro-symbolic systems; e.g., [19] references [17] in using dual process theories of reasoning (i.e. the \"System 1/System 2\" model described in [49]) as a motivation for hybridization in knowledge systems, but more recent analyses [69, 64] cast doubt on the validity of such models, and point to more nuanced perspectives that provide a better grounding for the benefits of hybridization. Addressing these questions would shed light on tasks for which hybridization using LLMs would prove favourable, e.g., image classification of species."
    },
    {
      "title": "How Can Prompt Engineering Patterns Support Reasoning In Natural Language?",
      "text": "One fundamental question that arises is how prompt engineering patterns can be utilized to facilitate reasoning in natural language. Exploring this topic involves understanding the mechanics of these patterns and their implications on natural language processing capabilities of LLMs. This line of research could open new possibilities for enhancing the functionality and efficiency of these models. A related inquiry concerns the structure, controllability, and repeatability of reasoning facilitated by LLMs. Examining ways to create structured, manageable, and reproducible reasoning processes within these models could significantly advance our capacity to handle complex knowledge engineering tasks and improve the reliability of LLMs. The interaction of LLMs and approaches to reasoning based on probabilistic formalisms is also an underexplored area of research. A particularly evocative effort in this area is that described in [113], which describes the use of LLMs to transform natural language into programs in a probabilistic programming language, which can then be executed to support reasoning in a particular problem domain. We note that this work provides an excellent example of the knowledge engineering as the transformation of natural language into formal language perspective and of the impact of LLMs in advancing that perspective. Investigating how to automatically generate and assess other nuanced forms of knowledge within LLMs could lead to a more refined understanding of these models and their capabilities. Given that biodiversity knowledge is often best represented in a variety of modalities each with their own data structures and characteristics, research may explore how LLMs can act as natural language interfaces to such multimodal knowledge bases."
    },
    {
      "title": "How Can We Manage Bias, Trust And Control In Llms Using Knowledge Graphs?",
      "text": "Trust, control, and bias in LLMs, especially when these models leverage knowledge graphs, are critical areas to explore. Understanding how to detect, measure, and mitigate bias, as well as establish trust and exert control in these models, is an essential aspect of ensuring ethical and responsible use of LLMs. Furthermore, investigating methods to update facts in LLMs serving as knowledge graphs is a crucial area of research. Developing strategies for efficient and reliable fact updating could enhance the accuracy and usefulness of these models. Another key question involves understanding how we can add provenance to statements produced by LLMs. This line of research could prove vital in tracking the origin of information within these models, thus enhancing their reliability and usability. It opens the door to more robust auditing and validation practices in the use of LLMs. Addressing this challenge can help biodiversity researchers detect and mitigate biases, as use of LLMs might further exacerbate knowledge gaps, e.g., groups of individuals omitted from historical narratives in archival collections. Moreover, novel update mechanisms can aid researchers to reliably update facts or changing knowledge structures learned by LLMs, for instance when domain knowledge evolves."
    },
    {
      "title": "Is Extrinsic Explanation Sufficient?",
      "text": "A significant area of interest pertains to how we can effectively address the explainability of answers generated using LLMs [30]. This exploration requires a deep dive into the functioning of LLMs and the mechanisms that govern their responses to prompts. Developing a thorough understanding of these processes can aid in creating transparency and trust in LLMs, as well as fostering their effective use. The need for explanation in LLMs also leads to the question of whether extrinsic explanation is sufficient for the purposes of justifying a knowledge system's reasoning, as argued in general for the intelligibility of knowledge systems by Cappelen and Devers [22], or if intrinsic explainability is a necessary requirement [55]. This question calls for a thoughtful exploration of the value and limitations of both extrinsic and intrinsic explanation methodologies, and their implications for the understanding and usage of LLMs. An exciting research avenue arises from the work of Tiddi [99], concerning explainability with formal languages. The exploration of this topic could reveal significant insights into how we can leverage formal languages to enhance the explainability of LLMs. This could pave the way for new methods to increase transparency and intelligibility in these models. In the sciences in general, answering these questions would aid explainability of LLM-generated answers via curated facts, increasing transparency and trust."
    },
    {
      "title": "How Can Llms Support The Engineering Of Hybrid Human/Machine Knowledge Systems?",
      "text": "Another topic of interest involves exploring the potential of hybrid systems that combine human cognition with machine capabilities within a dialogical framework [64, 70]. As an exciting example of the possibilities for new approaches to human/machine collaboration in this vein, we point to the recent results reported by [74] on the creation of conversational agents that simulate goal-directed human conversation and collaboration on tasks. One can imagine coupling LLM-basedagents with human interlocutors working collaboratively in this manner on specific knowledge-intensive tasks. Understanding how to develop these types of systems, and what their implications might be for the practice of knowledge engineering presents a fertile research line. It requires the careful analysis of human-machine interaction, the study of system design principles, and the investigation of their potential impact. Research in this avenue can help mitigate the workload of the knowledge expert, for instance in the elicitation of domain knowledge, or crowdsourcing of annotations from unstructured sources such as herbaria or manuscripts."
    },
    {
      "title": "Evaluation",
      "text": ""
    },
    {
      "title": "How Do We Evaluate Knowledge Systems With Llm Components?",
      "text": "The first point of interest involves the evaluation of knowledge-based systems, with a focus beyond just logic. This area calls for innovative methodologies to assess the system's capacity to manage and utilize knowledge efficiently, going beyond traditional logical evaluations. This topic of evaluation naturally extends to the question of how we evaluate ontologies and design patterns within knowledge engineering. Evaluating these aspects would require a deep dive into the structures and mechanisms underpinning these elements, potentially leading to the development of refined evaluation metrics and methodologies. Interestingly, the long-standing paradigm of machine learning evaluation, relying on benchmarking against a standard train/test dataset, seems to falter in the era of LLMs [25]. This presents an intriguing challenge for researchers and engineers alike. It is quite possible that traditional methods may need to be significantly buttressed by methodologies and supporting tools for the direct human evaluation of knowledge system performance. This has implications concerning the cost and speed of evaluation processes, encouraging the rethink of current approaches to perhaps develop new strategies that balance accuracy, cost-effectiveness, and timeliness. Reimagining evaluation methodologies in this new context could provide transformative insights into how we can gain confidence in the reliability engineering of knowledge systems that use LLMs. Developments in this direction may aid biodiversity researchers to get a better understanding of the real-world efficacy of employing knowledge-based systems with LLM components in their institutions. One can think of improving access to collections, knowledge discovery, or accuracy in describing institutional knowledge."
    },
    {
      "title": "What Is The Relationship Between Evaluation And Explainability?",
      "text": "Lastly, there is an inherent dependency of evaluation on effective solutions for explainability within knowledge systems. Understanding this relationship could help in the creation of more comprehensive evaluation models that take into account not only the performance of a system but also its explainability."
    },
    {
      "title": "5 Summary",
      "text": "In this paper, we have advocated for a reconsideration of the practice and methodology of knowledge engineering in light of the emergence of LLMs. We argued that LLMs allow naturally-occurring and humanly-evolved means of conveying knowledge to be brought to bear in the automation of knowledge tasks. We described how this can enhance the engineering of hybrid neuro-symbolic knowledge systems, and how this can make knowledge engineering possible by people who do not necessarily have the experience of recasting natural language into formal, structured representation languages. Both of these possibilities will involve addressing a broad range of open questions, which we have attempted to outline above. Given the rapid pace of the development of this area of research, it is our earnest hope that the coming months and years will yield results shedding light on these questions. This work was partially supported by the EU's Horizon Europe research and innovation programme within the ENEXA project (grant Agreement no. 101070305)."
    },
    {
      "title": "References",
      "text": "* [1]Z. Akata, D. Balliet, M. De Rijke, F. Dignum, V. Dignum, G. Eiben, A. Fokkens, D. Grossi, K. Hindirks, H. Hoos, et al. (2020) A research agenda for hybrid intelligence: augmenting human intellect with collaborative, adaptive, responsible, and explainable artificial intelligence. Computer53 (8), pp. 18-28. Cited by: SS1. * [2]D. Alivanistos, S. B. Santamaria, M. Cochez, J. Christoph Kalo, E. van Kriken, and T. Thanapalasingam (2022) Prompting as probing: using language models for knowledge base construction. In Theaia Singhania, Tuan-Phong Nguyen, and S. Ranziewski, editors, LML-KBC 2022 Knowledge Base Construction from Pre-trained Language Models 2022, CEUR Workshop Proceedings, pp. 11-34. Cited by: SS1. * [3]B. AlKhamissi, M. Li, A. Celikyilmaz, M. Diab, and M. Ghazvininejad (2022) A review on language models as knowledge bases. arXiv preprint arXiv:2204.06031. Cited by: SS1. * [4]B. Allen, F. Ilievski, and S. Joshi (2023) Identifying and consolidating knowledge engineering requirements. arXiv preprint arXiv:2306.15124. Cited by: SS1. * [5]C. Alt, M. Hubner, and L. Hennig (2019) Fine-tuning pre-trained transformer language models to distantly supervised relation extraction. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 1388-1398. Cited by: SS1. * [6]J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dahan, E. Jiang, C. Cai, M. Terry, Q. Le, et al. (2021) Program synthesis with large language models. arXiv preprint arXiv:2108.07732. Cited by: SS1. * [7]A. Askleson and G. Skantze (2023) Using large language models for zero-shot natural language generation from knowledge graphs. arXiv preprint arXiv:2307.07312. Cited by: SS1. * [8]S. Bach, V. Sanh, Z. X. Yong, A. Webson, C. Raffel, N. V. Nayak, A. Sharma, T. Sharma, T. Kim, M. Bari, T. Fevry, Z. Alyafaei, M. Dey, A. Santilli, Z. Sun, S. Ben-David, C. Xu, G. Chabalani, H. Wang, J. Fries, M. Al-shahani, S. Sharma, U. Thakker, K. Almubarak, X. Tang, D. Radev, M. Tian-jian Jiang, and A. Rush (2021) PromptSource: an integrated development environment and repository for natural language prompts. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pp. 93-104. Cited by: SS1. * [9]A. Bosevelt, H. Rashkin, M. Sap, C. Malaviya, A. Celikyilmaz, and Y. Choi (2019) COMET: commonsense transformers for automatic knowledge graph construction. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Florence, Italy, July 2019, pp. 4762-4779. Cited by: SS1. * [10]A. Bosevelt, H. Rashkin, M. Sap, C. Malaviya, A. Celikyilmaz, and Y. Choi (2019) COMET: commonsense transformers for automatic knowledge graph construction. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Florence, Italy, July 2019, pp. 4762-4779. Cited by: SS1. * [11]A. Bosevelt, H. Rashkin, M. Sap, C. Malaviya, A. Celikyilmaz, and Y. Choi (2019) COMET: commonsense transformers for automatic knowledge graph construction. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Florence, Italy, July 2019, pp. 4762-4779. Cited by: SS1. * [12]C. Baderra, F. Freitas, and F. Santana (2013) Evaluating ontologies with competency questions. In 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT), Vol. 3, pp. 284-285. Cited by: SS1. * [13]C. Bader, T. Heath, K. Idehen, and T. Berners-Lee (2008) Linked data on the web (ldow2008). In Proceedings of the 17th international conference on World Wide Web, pp. 1265-1266. Cited by: SS1. * [14]T. B. Anderson, I. J. Kitching, L. Livermore, T. J. Simonsen, and V. S. Smith (2012) No specimen left behind: industrial scale digitization of natural history collections. ZooKeys209, pp. 133-146. Cited by: SS1. * [15]F. B. Bommansani and et al. (2018) On the opportunities and risks of foundation models. CoRRabs/1208.07258. External Links: Link, 1708.07258 Cited by: SS1. * [16]G. Bonner, I. P. Barrett, C. Ye, R. Swiers, O. Engkvist, A. Bender, C. T. Hoyt, and W. L. Hamilton (2021) A review of biomedical datasets relating to drug discovery: a knowledge graph perspective. Briefings23 (6), pp. bbac40. Cited by: SS1. * [17]G. Booselt, H. Rashkin, M. Sap, C. Malaviya, A. Celikyilmaz, and Y. Choi (2019) COMET: commonsense transformers for automatic knowledge graph construction. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Florence, Italy, July 2019, pp. 4762-4779. Cited by: SS1. * [18]A. Bosevelt, H. Rashkin, M. Sap, C. Malaviya, A. Celikyilmaz, and Y. Choi (2019) COMET: commonsense transformers for automatic knowledge graph construction. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Florence, Italy, July 2019, pp. 4762-4779. Cited by: SS1. * [19]A. Bosevelt, H. Rashkin, M. Sap, C. Malaviya, A. Celikyilmaz, and Y. Choi (2022) COMET: commonsense transformers for automatic knowledge graph construction. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Florence, Italy, July 2019, pp. 4762-4779. Cited by: SS1. * [20]T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry,Amanda Askell, et al. Language models are few-shot learners. _Advances in neural information processing systems_, 33:1877-1901, 2020. * [21] Tiffany J. Callahan, Ignacio J. Tripodi, Harrison Pielle-Lombardo, and Lawrence E. Hunter. Knowledge-based biomedical data science. _Annual Review of Biomedical Data Science_, 3(1):23-41, 2020. doi:10.1146/annurev-biodatasci-010820-091627. * [22] Herman Cappelen and Josh Dever. _Making AI intelligible: Philosophical foundations_. Oxford University Press, 2021. * [23] Mathilde Caron, Hugo Touvron, Ishan Misra, Herve Jegou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerging properties in self-supervised vision transformers. In _Proceedings of the IEEE/CVF international conference on computer vision_, pages 9650-9660, 2021. * [24] Andre W Carus. _Carnap and twentieth-century thought: Exploration as enlightenment_. Cambridge University Press, 2007. * [25] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. A survey on evaluation of large language models. _arXiv preprint arXiv:2307.03109_, 2023. * [26] Ronan Collobert, Jason Weston, Leon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. Natural language processing (almost) from scratch. _Journal of machine learning research_, 12(ARTICLE):2493-2537, 2011. * [27] Enrico Daga and Paul Groth. Data journeys: explaining ai workflows through abstraction. _Semantic Web_, Preprint:1-27, 2023. * [28] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. _arXiv preprint arXiv:1810.04805_, 2018. * [29] Chris Dijkshoorn, Mieke HR Leyssen, Archana Nottamkandath, Jasper Oosterman, Myriam C Traub, Lora Aroyo, Alessandro Bozzon, Wan J Fokkink, Geert-Jan Houben, Henrike Hovelmann, et al. Personalized nichesourcing: Acquisition of qualitative annotations from niche communities. In _UMAP Workshops_, 2013. * [30] Filip Karlo Dosilovic, Mario Brecic, and Nikica Hlupic. Explainable artificial intelligence: A survey. In _2018 41st International convention on information and communication technology, electronics and microelectronics (MIPRO)_, pages 0210-0215. IEEE, 2018. * [31] Fajar J Ekaputra, Majlinda Llugiqi, Marta Sabou, Andreas Ekelhart, Heiko Paulheim, Anna Breit, Artem Revenko, Laura Waltersdorfer, Kheir Eddine Farfar, and Soren Auer. Describing and organizing semantic web and machine learning systems in the swemsk-kg. In _European Semantic Web Conference_, pages 372-389. Springer, 2023. * [32] Edward A Feigenbaum. The art of artificial intelligence: Themes and case studies of knowledge engineering. In _Proceedings of the Fifth International Joint Conference on Artificial Intelligence_, volume 2. Boston, 1977. * [33] EDWARD A. FEIGENBAUM. Knowledge engineering. _Annals of the New York Academy of Sciences_, 426(1 Computer Cult):91-107, November 1984. doi:10.1111/j.1749-6632.1984.tb16513.x. * [34] Edward A Feigenbaum. _A personal view of expert systems: Looking back and looking ahead_. Knowledge Systems Laboratory, Department of Computer Science, Stanford..., 1992. * [35] Dov M Gabbay and John Woods. _The rise of modern logic: from Leibniz to Frege_. Elsevier, 2004. * [36] Aldo Gangemi and Valentina Presutti. Ontology design patterns. In _Handbook on ontologies_, pages 221-243. Springer, 2009. * [37] Clark Glymour, Kenneth M Ford, and Patrick J Hayes. Ramon lull and the infidels. _AI Magazine_, 19(2):136-136, 1998. * [38] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. _Communications of the ACM_, 63(11):139-144, 2020. * [39] Paul Groth, Aidan Hogan, Lise Stork, Katherine Thornton, and Vrandecic Denny. Knowledge graphs vs. other forms of knowledge representation. _Dagstuhl Reports_, 12(9):101-105, 2023. * [40] Qipeng Guo, Zhijing Jin, Xipeng Qiu, Weinan Zhang, David Wipf, and Zheng Zhang. Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training. _arXiv preprint arXiv:2006.04702_, 2020. * [41] Alex R Hardisty, Elizabeth R Ellwood, Gil Nelson, Breda Zimikus, Jutta Buschbom, Wouter Addink, Richard K Rabeler, John Bates, Andrew Bentley, Jose AB Fortes, et al. Digital extended specimens: Enabling an extensible network of biodiversity data records as integrated digital objects on the internet. _BioScience_, 72(10):978-987, 2022. * [42] Frederick Hayes-Roth, Donald A Waterman, and Douglas B Lenat. _Building expert systems_. Addison-Wesley Longman Publishing Co., Inc., 1983. * [43] James Hendler, Fabien Gandon, and Dean Allemang. _Semantic web for the working ontologist: Effective modeling for linked data, RDFS, and OWL_. Morgan & Claypool, 2020. * [44] Birger Hjorland. What is knowledge organization (ko)? _KO Knowledge Organization_, 35(2-3):86-101, 2008. * [45] Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia d'Amato, Gerard de Melo, Claudio Guerrerez, Sabrina Kirrane, Jose Emilio Labra Gayo, Roberto Navigli, Sebastian Neumaier, et al. Knowledge graphs. _ACM Computing Surveys (CSUR)_, 54(4):1-37, 2021. * [46] Madelon Hulsebos, Kevin Hu, Michiel Bakker, Emanuel Zgraggen, Arvind Satyanarayan, Tim Kraska, Cagatay Demiralp, and Cesar Hidalgo. Sherlock: A deep learning approach to semantic data type detection. In _Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_, pages 1500-1508, 2019. * [47] Naman Jain, Skanda Vaidyanath, Arun Iyer, Nagarajan Natarajan, Suresh Parthasarathy, Sriram Rajamani, and Rahul Sharma. Jigsaw: Large language models meet program synthesis. In _Proceedings of the 44th International Conference on Software Engineering_, pages 1219-1231, 2022. * [48] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Maddot, and Pascale Fung. Survey of hallucination in natural language generation. _ACM Computing Surveys_, 55(12):1-38, 2023. * [49] Daniel Kahneman. _Thinking, fast and slow_. macroillan, 2011. * [50] Paschalia Kapli, Ziheng Yang, and Maximilian J Telford. Phylogenetic tree building in the genomic age. _Nature Reviews Genetics_, 21(7):428-444, 2020. * [51] Elisa F Kendall and Deborah L McGuinness. _Ontology engineering_. Morgan & Claypool Publishers, 2019. * [52] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. _Advances in neural information processing systems_, 35:22199-22213, 2022. * [53] Keti Korini and Christian Bizer. Column type annotation using chatgtgt. _arXiv preprint arXiv:2306.00745_, 2023. * [54] Tiffany R Kung, Morgan Cheatham, Arielle Gneolla, Cazrina Sillos, Lorie De Leon, Camille Elepano, Maria Madriaga, Rimel Aggabao, Giezel Diaz-Candido, James Maningo, et al. Performance of chatgtgt on usable: Potential for ai-assisted medical education using large language models. _PLoS digital health_, 2(2):e0000198, 2023. * [55] Himabindu Lakkaraju, Dylan Slack, Yuxin Chen, Chenhao Tan, and Sameer Singh. Rethinking explainability as a dialogue: A practitioner's perspective. _CoRR_, abs/2202.01875, 2022. URL: [https://arxiv.org/abs/2202.01875](https://arxiv.org/abs/2202.01875), arXiv:2202.01875. * [56] Wahnae Lee, Minki Chun, Hyeonhak Jeong, and Hyunggu Jung. Toward keyword generation through large language models. In _Companion Proceedings of the 28th International Conference on Intelligent User Interfaces_, IUI '23 Companion, page 37-40, New York, NY, USA, 2023. Association for Computing Machinery. doi:10.1145/3861754.3864126. * [57] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengba Jiang, Hiroaki Hayashi, and Graham Neubig. Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. _ACM Computing Surveys_, 55(9):1-35, 2023. * [58] Michela Lorandi and Anya Belz. Data-to-text generation for severely under-resourced languages with gpt-3.5: A bit of help needed from google translate. _arXiv preprint arXiv:2308.09957_, 2023. * [59] Arthur MacGregor. _Naturalists in the field: collecting, recording and preserving the natural world from the fifteenth to the twenty-first century_, volume 2. Brill, 2018. * [60] Kyle Mahowald, Anna A Ivanova, Idan A Blank, Nancy Kanwisher, Joshua B Tenenbaum, and Evelina Fedorenko. Dissociating language and thought in large language models: a cognitive perspective. _arXiv preprint arXiv:2301.06627_, 2023. * [61] Jose L. Martinez-Rodriguez, Aidan Hogan, and Ivan Lopez-Arevaolo. Information extraction meets the semantic web: A survey. _Semantic Web_, 11(2):255-335, February 2020. doi:10.3233/sw-180333. * [62] Richard Menary. Writing as thinking. _Language sciences_, 29(5):621-632, 2007. * [63] Richard Menary. Dimensions of mind. _Phenomenology and the Cognitive Sciences_, 9:561-578, 2010. * [64] Hugo Mercier and Dan Sperber. _The enigma of reason_. Harvard University Press, 2017. * [65] Gregoire Mialon, Roberto Dessi, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Railenau, Baptiste Roziere, Timo Schick, Jane Dwivedi-Yu, Asil Celikyilmaz, et al. Augmented language models: a survey. _arXiv preprint arXiv:2302.07842_, 2023. * [66] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thieu Huu Nguyen, Oscar Sainz, Eneko Agirre, Ihana Heintz, and Dan Roth. Recent advances in natural language processing via large pre-trained language models: A survey. _ACM Comput. Surv._, jun 2023. Just Accepted. doi:10.1145/3605943. * [67] Staffan Muller-Wille. Names and numbers:\"data\" in classical natural history, 1758-1859. _Osiris_, 32(1):109-128, 2017. * [68] Zara Nasar, Syed Waqar Jaffry, and Muhammad Kamran Malik. Named entity recognition and relation extraction: State-of-the-art. _ACM Computing Surveys (CSUR)_, 54(1):1-39, 2021. * [69] Catarina Dutilh Novaes. _Formal languages in logic: A philosophical and cognitive analysis_. Cambridge University Press, 2012. * [70] Catarina Dutilh Novaes. _The dialogical roots of deduction: Historical, cognitive, and philosophical perspectives on reasoning_. Cambridge University Press, 2020. * [71] Alexandra Ortolja-Baird and Julianne Nyhan. Encoding the haunting of an object catalogue: on the potential of digital technologies to perpetuate or subvert the silence and bias of the early-modern archive. _Digital Scholarship in the Humanities_, 37(3):844-867, 2022. * [72] Roderic DM Page. Biodiversity informatics: the challenge of linking data and the role of shared identifiers. _Briefings in bioinformatics_, 9(5):345-354, 2008. * [73] Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. Unifying large language models and knowledge graphs: A roadmap. _arXiv preprint arXiv:2306.08302_, 2023. * [74] Joon Sung Park, Joseph C O'Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. _arXiv preprint arXiv:2304.03442_, 2023. * [75] Fabio Petroni, Tim Rocktaschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, and Sebastian Riebel. Language models as knowledge bases? _arXiv preprint arXiv:1909.01066_, 2019. * [76] Valentina Presutti, Enrico Daga, Aldo Gangemi, and Eva Blomqvist. extreme design with content ontology design patterns. In _Proc. Workshop on Ontology Patterns_, pages 83-97, 2009. * [77] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In _International conference on machine learning_, pages 8748-8763. PMLR, 2021. * [78] Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. Robust speech recognition via large-scale weak supervision. In _International Conference on Machine Learning_, pages 28492-28518. PMLR, 2023. * [79] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. _arXiv preprint arXiv:2204.06125_, 1(2):3, 2022. * [80] Laria Reynolds and Kyle McDonell. Prompt programming for large language models: Beyond the few-shot paradigm. In _Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems_, pages 1-7, 2021. * [81] Tim Robertson, Markus Doring, Robert Guralnick, David Bloom, John Wieczorek, Kyle Braak, Javier Otegui, Laura Russell, and Peter Dernst. The gbfi integrated publishing toolkit: facilitating the efficient publishing of biodiversity data on the internet. _PloS one_, 9(8):e102623, 2014. * [82] Victor Rodriguez-Doncel and Elena Montiel-Ponsoda. Lynx: Towards a legal knowledge graph for multilingual europe. _Law Context: A Socio-Legal J._, 37:175, 2020. * [83] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image synthesis with latent diffusion models. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 10684-10695, 2022. * [84] Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools, 2023. arXiv:2302.04761, doi:10.48505/arXiv.2302.04761. * [85] Guus Schreiber. Knowledge engineering. _Foundations of Artificial Intelligence_, 3:929-946, 2008. * [86] Guus Schreiber, Hans Akkermans, Anjo Anjewierden, Nigel Shadbolt, Robert de Hoog, Walter Van de Velde, and Bob Wielinga. _Knowledge engineering and management: the CommonKADS methodology_. MIT press, 2000. * [87] Guus Schreiber and Lora Aroyo. Principles for knowledge engineering on the web. In _AAAI Spring Symposium: Symbiotic Relationships between Semantic Web and Knowledge Engineering_, pages 78-82, 2008. * [88] Nigel R Shadbolt, Paul R Smart, J Wilson, and S Sharples. Knowledge elicitation. _Evaluation of human work_, pages 163-200, 2015. * [89] Murray Shanahan. Talking about large language models. _arXiv preprint arXiv:2212.03551_, 2022. * [90] Steffen Staab and Rudi Studer. _Handbook on ontologies_. Springer Science & Business Media, 2010. * [91] Lise Stork. _Knowledge extraction from archives of natural history collections_. PhD thesis, Ph. D. Dissertation, Leiden University, 2021. * [92] Lise Stork, Andreas Weber, Eulalia Gasso Miracle, Fons Verbeek, Aske Plaat, Jaap van den Herik, and Katherine Wolstencroft. Semantic annotation of natural history collections. _Journal of Web Semantics_, 59:100462, 2019. * [93] Rudi Studer, V Richard Benjamins, and Dieter Fensel. Knowledge engineering: Principles and methods. _Data & knowledge engineering_, 25(1-1):161-197, 1998. doi:10.1016/S0169-023X(97)00056-6. * [94] Mari Carmen Suarez-Figueroa, Asuncion Gomez-Perez, and Mariano Fernandez-Lopez. The neon methodology for ontology engineering. In _Ontology engineering in a networked world_, pages 9-34. Springer, 2011. * [95] Mari Carmen Suarez-Figueroa, Asuncion Gomez-Perez, Enrico Motta, and Aldo Gangemi. _Introduction: Ontology engineering in a networked world_. Springer, 2012. * [96] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. _Advances in neural information processing systems_, 27, 2014. * [97] Anders Telenius. Biodiversity information goes public: Golf at your service. _Nordic Journal of Botany_, 29(3):378-381, 2011. * [98] Ian Tenney, Dipanjan Das, and Ellie Pavlick. Bert rediscovers the classical nlp pipeline. _arXiv preprint arXiv:1905.05950_, 2019. * [99] Ilaria Tiddi and Stefan Schlobach. Knowledge graphs as tools for explainable machine learning: A survey. _Artificial Intelligence_, 302:103627, 2022. * [100] Priyan Vaithilingam, Tianyi Zhang, and Elena L Glassman. Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models. In _Chi conference on human factors in computing systems extended abstracts_, pages 1-7, 2022. * [101] Michael van Bekkum, Maaike de Boer, Frank van Harmelen, Andre Meyer-Vitali, and Annette ten Teije. Modular design patterns for hybrid learning and reasoning systems: a taxonomy, patterns and use cases. _Applied Intelligence_, 51(9):6528-6546, 2021. * [102] M.G.J. van Erp. _Accessing natural history: Discoveries in data cleaning, structuring, and retrieval_. PhD thesis, Tilburg University, 2010. Series: TiCC Ph.D. Series Volume: 13. * [103] Frank Van Harmelen and Annette ten Teije. A boxology of design patterns for hybrid learning and reasoning systems. _arXiv preprint arXiv:1905.12389_, 2019. * [104] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017. * [105] Chengyi Wang, Sanyuan Chen, Yu Wu, Ziqiang Zhang, Long Zhou, Shujie Liu, Zhuo Chen, Yanqing Liu, Huaming Wang, Jinyu Li, et al. Neural codec language models are zero-shot text to speech synthesizers. _arXiv preprint arXiv:2301.02111_, 2023. * [106] Haohan Wang and Bhiksha Raj. On the origin of deep learning. _arXiv preprint arXiv:1702.07800_, 2017. * [107] Andreas Weber, Mahya Ameryan, Katherine Wolstencroft, Lise Stork, Maarten Heerlien, and Lambert Schomaker. Towards a digital infrastructure for illustrated handwritten archives. In _Digital Cultural Heritage: Final Conference of the Marie Sklodowska-Curie Initial Training Network for Digital Cultural Heritage, ITN-DCH 2017, Olimig, Slovenia, May 23-25, 2017, Revised Selected Papers_, pages 155-166. Springer, 2018. * [108] Jason Wei, Xuenli Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. _Advances in Neural Information Processing Systems_, 35:24824-24837, 2022. * [109] Justin D Weisz, Michael Muller, Jessica He, and Stephanie Houde. Toward general design principles for generative ai applications. _arXiv preprint arXiv:2301.05578_, 2023. * [110] Jules White, Sam Hays, Quchen Fu, Jesse Spencer-Smith, and Douglas C. Schmidt. Chatgt report prompt patterns for improving code quality, refactoring, requirements elicitation, and software design, 2023. arXiv:2303.07839, doi:10.48550/arXiv.2303.07839. * [111] Bob J Wielinga, A Th Schreiber, and Jost A Breuker. Kads: A modelling approach to knowledge engineering. _Knowledge acquisition_, 4(1):5-53, 1992. * [112] Mark D. Wilkinson, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, Jan-Willem Boiten, Luiz Bonino da Silva Santos, Philip E. Bourne, Jildau Bowman, Anthony H. Brookes, Tim Clark, Merck Cross, Ingrid Dillo, Olivier Dumon, Scott Edmunds, Chris T. Evelo, Richard Finkers, Alejandra Gonzalez-Beltran, Alasdair J.G. Gray, Paul Groth, Carole Goble, Jeffrey S. Grethe, Jaap Heringa, Peter A.C. 't Hoen, Rob Hooft, Tobias Kuhn, Ruben Kok, Joost Kok, Scott J. Lusher, Maryann E. Martone, Albert Mons, Abel L. Packer, Bengt Persson, Philippe Rocca-Serra, Marco Roos, Rene van Schaik, Susanna-Assunta Sansone, Erik Schultes, Thierry Sengstag, Ted Slater, George Strawn, Morris A. Swertz, Mark Thompson, Johan van der Lei, Erik van Mulligen, Jan Veltenop, Andrea Waagmeester, Peter Wittenburg, Katherine Wolstencroft, Jun Zhao, and Barend Mons. The FAIR guiding principles for scientific data management and stewardship. _Scientific Data_, 3(1), March 2016. doi:10.1038/data.2016.18. * [113] Lionel Wong, Gabriel Grand, Alexander K Lew, Noah D Goodman, Vikash K Mansighka, Jacob Andreas, and Joshua B Tenenbaum. From word models to world models: Translating from natural language to the probabilistic language of thought. _arXiv preprint arXiv:2306.12672_, 2023. * [114] Qianqian Xie, Jennifer Amy Bishop, Prayag Tiwari, and Sophia Ananiadou. Pre-trained language models with domain knowledge for biomedical extractive summarization. _Knowledge-Based Systems_, 252:109460, 2022. * [115] Zonglin Yang, Xinya Du, Rui Mao, Jinjie Ni, and Erik Cambria. Logical reasoning over natural language as knowledge representation: A survey, 2023. arXiv:2303.12023, doi:10.48550/arXiv.2303.12023. * [116] Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, and Woomyeong Park. Cpt3mix: Leveraging large-scale language models for text augmentation. _arXiv preprint arXiv:2104.08826_, 2021. * [117] Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and Yonghui Wu. Coca: Contrastive captioners are image-text foundation models. _arXiv preprint arXiv:2205.01917_, 2022. * [118] Wen Zhang, Yushan Zhu, Mingyang Chen, Yuxia Geng, Yufeng Huang, Yajing Xu, Wenting Song, and Huajun Chen. Structure pretraining and prompt tuning for knowledge graph transfer. In _Proceedings of the ACM Web Conference 2023_, WWW '23, page 2581-2590, New York, NY, USA, 2023. Association for Computing Machinery. doi:10.1145/3543507.35883301. * [119] Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei Liu. Learning to prompt for vision-language models. _International Journal of Computer Vision_, 130(9):2337-2348, 2022."
    }
  ]
}
{
  "title": "Leveraging Large Language Models (LLMs) for Process Mining (",
  "authors": [
    "Alessandro Berti",
    "Mahnaz Sadat Qafari"
  ],
  "abstract": "\n This technical report describes the intersection of process mining and large language models (LLMs), specifically focusing on the abstraction of traditional and object-centric process mining artifacts into textual format. We introduce and explore various prompting strategies: direct answering, where the large language model directly addresses user queries; multi-prompt answering, which allows the model to incrementally build on the knowledge obtained through a series of prompts; and the generation of database queries, facilitating the validation of hypotheses against the original event log. Our assessment considers two large language models, GPT-4 and Google's Bard, under various contextual scenarios across all prompting strategies. Results indicate that these models exhibit a robust understanding of key process mining abstractions, with notable proficiency in interpreting both declarative and procedural process models. In addition, we find that both models demonstrate strong performance in the object-centric setting, which could significantly propel the advancement of the object-centric process mining discipline. Additionally, these models display a noteworthy capacity to evaluate various concepts of fairness in process mining. This opens the door to more rapid and efficient assessments of the fairness of process mining event logs, which has significant implications for the field. \n",
  "references": [
    {
      "id": null,
      "title": "Leveraging Large Language Models (LLMs) for Process Mining (",
      "authors": [
        "Alessandro Berti",
        "Mahnaz Sadat Qafari"
      ],
      "year": "2023",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Natural language-based detection of semantic execution anomalies in event logs",
      "authors": [
        "H Van Der Aa",
        "A Rebmann",
        "H Leopold"
      ],
      "year": "2021",
      "venue": "Inf Syst",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "for modeling business processes",
      "authors": [
        "G Aagesen",
        "J Krogstie"
      ],
      "year": "2015",
      "venue": "Handbook on Business Process Management 1, Introduction, Methods, and Information Systems",
      "doi": "10.1007/978-3-642-45100-3_10"
    },
    {
      "id": "b2",
      "title": "The application of petri nets to workflow management",
      "authors": [
        "Wmp Van Der Aalst"
      ],
      "year": "1998",
      "venue": "J Circuits Syst Comput",
      "doi": "10.1142/S0218126698000043"
    },
    {
      "id": "b3",
      "title": "Process Mining -Data Science in Action",
      "authors": [
        "Wmp Van Der Aalst"
      ],
      "year": "2016",
      "venue": "Process Mining -Data Science in Action",
      "doi": "10.1007/978-3-662-49851-4"
    },
    {
      "id": "b4",
      "title": "Workflow mining: Discovering process models from event logs",
      "authors": [
        "Wmp Van Der Aalst",
        "A ; Berti",
        "T Weijters",
        "L Maruster"
      ],
      "year": "2004",
      "venue": "FI-2020-1946 van der Aalst WMP",
      "doi": "10.1109/TKDE.2004.47"
    },
    {
      "id": "b5",
      "title": "IEEE 1849: The XES standard: The second IEEE standard sponsored by IEEE computational intelligence society [society briefs]",
      "authors": [
        "G Acampora",
        "A Vitiello",
        "Bnd Stefano"
      ],
      "year": "2017",
      "venue": "IEEE Comput Intell Mag",
      "doi": "10.1109/MCI.2017.2670420"
    },
    {
      "id": "b6",
      "title": "A framework for extracting and encoding features from object-centric event data",
      "authors": [
        "J N Adams",
        "G Park",
        "S Levich"
      ],
      "year": "2022",
      "venue": "Service-Oriented Computing -20th International Conference, ICSOC 2022",
      "doi": "10.1007/978-3-031-20984-0_3"
    },
    {
      "id": "b7",
      "title": "Defining cases and variants for object-centric event data",
      "authors": [
        "J N Adams",
        "D Schuster",
        "S Schmitz"
      ],
      "year": "2022",
      "venue": "th International Conference on Process Mining, ICPM 2022",
      "doi": "10.1109/ICPM57379.2022.9980730"
    },
    {
      "id": "b8",
      "title": "Reducing false positives in fraud detection: Combining the red flag approach with process mining",
      "authors": [
        "G Baader",
        "H Krcmar"
      ],
      "year": "2018",
      "venue": "Int J Account Inf Syst",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "Bridging abstraction layers in process mining",
      "authors": [
        "T Baier",
        "J Mendling",
        "M Weske"
      ],
      "year": "2014",
      "venue": "Inf Syst",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "Verification of quantitative temporal compliance requirements in process descriptions over event logs",
      "authors": [
        "L Barbieri",
        "E Madeira",
        "K Stroeh"
      ],
      "year": "2022",
      "venue": "Advanced Information Systems Engineering -35th International Conference, CAiSE 2023",
      "doi": "10.1007/978-3-031-34560-9_25"
    },
    {
      "id": "b11",
      "title": "OC-PM: analyzing object-centric event logs and process models",
      "authors": [
        "A Berti",
        "Wmp Van Der Aalst"
      ],
      "year": "2023",
      "venue": "Int J Softw Tools Technol Transf",
      "doi": "10.1007/s10009-022-00668-w"
    },
    {
      "id": "b12",
      "title": "Process mining for python (pm4py): Bridging the gap between process-and data science",
      "authors": [
        "A Berti",
        "S J Van Zelst",
        "Van Der Aalst",
        "Wmp"
      ],
      "year": "2019",
      "venue": "Proceedings of the 1st International Conference on Process Mining (ICPM 2019)",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "a) Graph-based feature extraction on object-centric event logs",
      "authors": [
        "A Pdf Berti",
        "J Herforth",
        "M S Qafari"
      ],
      "year": "2023",
      "venue": "International Journal of Data Science and Analytics URL",
      "doi": "10.1007/s41060-023-00428-2"
    },
    {
      "id": "b14",
      "title": ") Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study",
      "authors": [
        "A Berti",
        "D Schuster",
        "Wmp Van Der Aalst"
      ],
      "year": "2023",
      "venue": ") Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study",
      "doi": "10.48550/arXiv.2307.02194"
    },
    {
      "id": "b15",
      "title": "On the opportunities and risks of foundation models",
      "authors": [
        "R Bommasani",
        "D A Hudson",
        "E Adeli"
      ],
      "year": "2021",
      "venue": "On the opportunities and risks of foundation models",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "Just tell me: Prompt engineering in business process management",
      "authors": [
        "K Busch",
        "A Rochlitzer",
        "D Sola"
      ],
      "year": "2023",
      "venue": "Enterprise, Business-Process and Information Systems Modeling -24th International Conference, BPMDS 2023, and 28th International Conference, EMMSAD 2023",
      "doi": "10.1007/978-3-031-34241-7_1"
    },
    {
      "id": "b17",
      "title": "Transformers as soft reasoners over language",
      "authors": [
        "P Clark",
        "O Tafjord",
        "K Richardson"
      ],
      "year": "2020",
      "venue": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020. ijcai.org",
      "doi": "10.24963/ijcai.2020/537"
    },
    {
      "id": "b18",
      "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M Chang",
        "K Lee"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019",
      "doi": "10.18653/v1/n19-1423"
    },
    {
      "id": "b19",
      "title": "Semantics and analysis of business process models in BPMN",
      "authors": [
        "R M Dijkman",
        "M Dumas",
        "C Ouyang"
      ],
      "year": "2008",
      "venue": "Inf Softw Technol",
      "doi": "10.1016/j.infsof.2008.02.006"
    },
    {
      "id": "b20",
      "title": "Enhancing process mining results using domain knowledge",
      "authors": [
        "P M Dixit",
        "Jcam Buijs",
        "Wmp Van Der Aalst"
      ],
      "year": "2015",
      "venue": "Proceedings of the 5th International Symposium on Data-driven Process Discovery and Analysis",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Multi-dimensional event data in graph databases",
      "authors": [
        "S Esser",
        "D Fahland"
      ],
      "year": "2021",
      "venue": "J Data Semant",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "Feed forward pre-training for recurrent neural network language models",
      "authors": [
        "S R Gangireddy",
        "F Mcinnes",
        "S Renals"
      ],
      "year": "2014",
      "venue": "INTERSPEECH 2014, 15th Annual Conference of the International Speech Communication Association",
      "doi": "10.21437/Interspeech.2014-561"
    },
    {
      "id": "b23",
      "title": "OCEL: A standard for object-centric event logs",
      "authors": [
        "A F Ghahfarokhi",
        "G Park",
        "A Berti"
      ],
      "year": "2021",
      "venue": "New Trends in Database and Information Systems -ADBIS 2021",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "Proceedings",
      "authors": [
        "Simpda Doing",
        "Madeisd",
        "Megadata",
        "Caons",
        "Estonia Tartu"
      ],
      "year": "2021",
      "venue": "Doctoral Consortium and Workshops",
      "doi": "10.1007/978-3-030-85082-1_16"
    },
    {
      "id": "b25",
      "title": "Domain adaptation of recurrent neural networks for natural language understanding",
      "authors": [
        "A Jaech",
        "L P Heck",
        "M Ostendorf"
      ],
      "year": "2016",
      "venue": "17th Annual Conference of the International Speech Communication Association",
      "doi": "10.21437/Interspeech.2016-1598"
    },
    {
      "id": "b26",
      "title": "Evaluating trace encoding methods in process mining",
      "authors": [
        "S B Junior",
        "P Ceravolo",
        "E Damiani"
      ],
      "year": "2020",
      "venue": "From Data to Models and Back -9th International Symposium, DataMod 2020, Virtual Event",
      "doi": "10.1007/978-3-030-70650-0_11"
    },
    {
      "id": "b27",
      "title": "Process mining using BPMN: relating event logs and process models",
      "authors": [
        "A A Kalenkova",
        "Wmp Van Der Aalst",
        "I A Lomazova"
      ],
      "year": "2017",
      "venue": "Softw Syst Model",
      "doi": "10.1007/s10270-015-0502-0"
    },
    {
      "id": "b28",
      "title": "Discovering high-level BPMN process models from event data",
      "authors": [
        "A A Kalenkova",
        "A Burattin",
        "M De Leoni"
      ],
      "year": "2019",
      "venue": "Bus Process Manag J",
      "doi": "10.1108/BPMJ-02-2018-0051"
    },
    {
      "id": "b29",
      "title": "Quantifying chatbots' ability to learn business processes",
      "authors": [
        "C Kecht",
        "A Egger",
        "W Kratsch"
      ],
      "year": "2023",
      "venue": "Inf Syst",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "Conversational process modelling: State of the art, applications, and implications in practice",
      "authors": [
        "N Klievtsova",
        "J Benzin",
        "T Kampik"
      ],
      "year": "2023",
      "venue": "Conversational process modelling: State of the art, applications, and implications in practice",
      "doi": "10.48550/arXiv.2304.11065"
    },
    {
      "id": "b31",
      "title": "Natural language querying of process execution data",
      "authors": [
        "M Kobeissi",
        "N Assy",
        "W Gaaloul"
      ],
      "year": "2023",
      "venue": "Inf Syst",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "Discovering blockstructured process models from event logs -A constructive approach",
      "authors": [
        "Sjj Leemans",
        "D Fahland",
        "Wmp Van Der Aalst"
      ],
      "year": "2013",
      "venue": "eds) Application and Theory of Petri Nets and Concurrency -34th International Conference, PETRI NETS 2013",
      "doi": "10.1007/978-3-642-38697-8_17"
    },
    {
      "id": "b33",
      "title": "A general process mining framework for correlating, predicting and clustering dynamic behavior based on event logs",
      "authors": [
        "M De Leoni",
        "Wmp Van Der Aalst",
        "M Dees"
      ],
      "year": "2016",
      "venue": "Inf Syst",
      "doi": "10.1016/j.is.2015.07.003"
    },
    {
      "id": "b34",
      "title": "User-guided discovery of declarative process models",
      "authors": [
        "F M Maggi",
        "A J Mooij",
        "Wmp Van Der Aalst"
      ],
      "year": "2011",
      "venue": "Proceedings of the IEEE Symposium on Computational Intelligence and Data Mining, CIDM 2011, part of the IEEE Symposium Series on Computational Intelligence",
      "doi": "10.1109/CIDM.2011.5949297"
    },
    {
      "id": "b35",
      "title": "Connecting databases with process mining: a meta model and toolset",
      "authors": [
        "Egl De Murillas",
        "H A Reijers",
        "Van Der Aalst",
        "Wmp"
      ],
      "year": "2019",
      "venue": "Softw Syst Model",
      "doi": ""
    },
    {
      "id": "b36",
      "title": "From BPMN process models to BPEL web services",
      "authors": [
        "C Ouyang",
        "M Dumas",
        "Ahm Hofstede"
      ],
      "year": "2006",
      "venue": "2006 IEEE International Conference on Web Services (ICWS 2006)",
      "doi": "10.1109/ICWS.2006.67"
    },
    {
      "id": "b37",
      "title": "Un)Fair Process Mining Event Logs",
      "authors": [
        "T Pohl",
        "Berti A"
      ],
      "year": "2023",
      "venue": "Un)Fair Process Mining Event Logs",
      "doi": "10.5281/zenodo.8059488"
    },
    {
      "id": "b38",
      "title": "Discrimination-aware process mining: A discussion",
      "authors": [
        "T Pohl",
        "M S Qafari",
        "Wmp Van Der Aalst"
      ],
      "year": "2022",
      "venue": "Process Mining Workshops -ICPM 2022 International Workshops",
      "doi": "10.1007/978-3-031-27815-0_8"
    },
    {
      "id": "b39",
      "title": "A collection of simulated event logs for fairness assessment in process mining",
      "authors": [
        "T Pohl",
        "A Berti",
        "M S Qafari"
      ],
      "year": "2023",
      "venue": "A collection of simulated event logs for fairness assessment in process mining",
      "doi": "10.48550/arXiv.2306.11453"
    },
    {
      "id": "b40",
      "title": "Process querying: Enabling business intelligence through query-based process analytics",
      "authors": [
        "A ; Polyvyanyy",
        "A Springer Polyvyanyy",
        "C Ouyang",
        "A Barros"
      ],
      "year": "2017",
      "venue": "Process Querying Methods",
      "doi": ""
    },
    {
      "id": "b41",
      "title": "Fairness-aware process mining",
      "authors": [
        "M S Qafari",
        "Wmp Van Der Aalst"
      ],
      "year": "2019",
      "venue": "On the Move to Meaningful Internet Systems: OTM 2019 Conferences -Confederated International Conferences: CoopIS, ODBASE, C&TC 2019",
      "doi": "10.1007/978-3-030-33246-4_11"
    },
    {
      "id": "b42",
      "title": "Case level counterfactual reasoning in process mining",
      "authors": [
        "M S Qafari",
        "Wmp Van Der Aalst"
      ],
      "year": "2021",
      "venue": "Intelligent Information Systems -CAiSE Forum 2021",
      "doi": "10.1007/978-3-030-79108-7_7"
    },
    {
      "id": "b43",
      "title": "Efficient and customisable declarative process mining with SQL",
      "authors": [
        "S Schönig",
        "A Rogge-Solti",
        "C Cabanillas"
      ],
      "year": "2016",
      "venue": "Advanced Information Systems Engineering",
      "doi": ""
    },
    {
      "id": "b44",
      "title": "Utilizing domain knowledge in data-driven process discovery: A literature review",
      "authors": [
        "D Schuster",
        "S J Van Zelst",
        "Van Der Aalst",
        "Wmp"
      ],
      "year": "2022",
      "venue": "Comput Ind",
      "doi": ""
    },
    {
      "id": "b45",
      "title": "Cortado: A dedicated process mining tool for interactive process discovery",
      "authors": [
        "D Schuster",
        "S J Van Zelst",
        "Van Der Aalst",
        "Wmp"
      ],
      "year": "2023",
      "venue": "SoftwareX",
      "doi": "10.1016/j.softx.2023.101373"
    },
    {
      "id": "b46",
      "title": "Temporal conformance checking at runtime based on time-infused process models",
      "authors": [
        "F Stertz",
        "J Mangler",
        "S Rinderle-Ma"
      ],
      "year": "2020",
      "venue": "Temporal conformance checking at runtime based on time-infused process models",
      "doi": ""
    },
    {
      "id": "b47",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b48",
      "title": "Large language models for business process management: Opportunities and challenges",
      "authors": [
        "M Vidgof",
        "S Bachhofner",
        "J Mendling"
      ],
      "year": "2023",
      "venue": "Large language models for business process management: Opportunities and challenges",
      "doi": "10.48550/arXiv.2304.04309"
    },
    {
      "id": "b49",
      "title": "Celonis PQL: A query language for process mining",
      "authors": [
        "T Vogelgesang",
        "J Ambrosy",
        "D Becher"
      ],
      "year": "2022",
      "venue": "Process Querying Methods",
      "doi": ""
    },
    {
      "id": "b50",
      "title": "Flexible heuristics miner (FHM)",
      "authors": [
        "Ajmm Weijters",
        "Jts Ribeiro"
      ],
      "year": "2011",
      "venue": "Proceedings of the IEEE Symposium on Computational Intelligence and Data Mining, CIDM 2011, part of the IEEE Symposium Series on Computational Intelligence",
      "doi": "10.1109/CIDM.2011.5949453"
    },
    {
      "id": "b51",
      "title": "A generic framework for trace clustering in process mining",
      "authors": [
        "F Zandkarimi",
        "J Rehse",
        "P Soudmand"
      ],
      "year": "2020",
      "venue": "2nd International Conference on Process Mining, ICPM 2020",
      "doi": "10.1109/ICPM49681.2020.00034"
    }
  ],
  "sections": [
    {
      "title": "Leveraging Large Language Models (Llms) For Process Mining (Technical Report)",
      "text": "Alessandro Berti\\({}^{1,2^{*}}\\) and Mahnaz Sadat Qafari \\({}^{1^{*}}\\)Process and Data Science Group, RWTH Aachen University, Ahornstrasse 55, Aachen, 52074, NRW, Germany. \\({}^{2^{*}}\\)Center for Process Intelligence, Fraunhofer FIT, Schloss Birlinghoven, Konrad-Adenauer-Strasse, Sankt Augustin, 53757, NRW, Germany. *Corresponding author(s). E-mail(s): a.berti@pads.rwth-aachen.de; Contributing authors: sadatghafari@gmail.com;"
    },
    {
      "title": "Abstract",
      "text": "This technical report describes the intersection of process mining and large language models (LLMs), specifically focusing on the abstraction of traditional and object-centric process mining artifacts into textual format. We introduce and explore various prompting strategies: direct answering, where the large language model directly addresses user queries; multi-prompt answering, which allows the model to incrementally build on the knowledge obtained through a series of prompts; and the generation of database queries, facilitating the validation of hypotheses against the original event log. Our assessment considers two large language models, GPT-4 and Google's Bard, under various contextual scenarios across all prompting strategies. Results indicate that these models exhibit a robust understanding of key process mining abstractions, with notable proficiency in interpreting both declarative and procedural process models. In addition, we find that both models demonstrate strong performance in the object-centric setting, which could significantly propel the advancement of the object-centric process mining discipline. Additionally, these models display a noteworthy capacity to evaluate various concepts of fairness in process mining. This opens the door to more rapid and efficient assessments of the fairness of process mining event logs, which has significant implications for the field. The integration of these large language models into process mining applications may open new avenues for exploration, innovation, and insight generation in the field. Large Language Models, Process Mining, GPT-4, Querying Language"
    },
    {
      "title": "1 Preliminaries",
      "text": "The following subsections delve into some key preliminaries to provide the necessary background for our discussion. This encompasses the nature of traditional and object-centric event logs (Section 1.1), the distinctions between procedural and declarative process models (Section 1.2), the techniques for extracting numerical features from event logs (Section 1.4), and the understanding of fairness concepts within the scope of process mining (Section 1.5). These topics form the cornerstone of our exploration into the integration of large language models within process mining."
    },
    {
      "title": "Traditional And Object-Centric Event Logs",
      "text": "Event logs are pivotal to process mining, representing empirical data that drives operations such as process discovery, conformance checking, and model enhancement. Extracted from information systems, these logs comprise collections of events, each characterized by an activity and timestamp and associated with a particular process. As primary artifacts, event logs provide a robust basis for data-driven process analysis. Traditional event logs adhere to a format where each event is tied to a specific case, signifying a unique execution of the process. Every event is defined by its activity--representing the operation performed, and a timestamp--indicating when the operation took place. The Extensible Event Stream (XES) standard Acampora et al (2017) has been established for storing and exchanging these event logs, facilitating systematic documentation and analysis of process events. An example of traditional event logs is reported in \\begin{table} \\begin{tabular}{|c|c|c|} \\hline **Case ID** & **Activity** & **Timestamp** \\\\ \\hline Case1 & Activity A & 2023-07-13 09:00:00 \\\\ Case1 & Activity B & 2023-07-13 09:15:00 \\\\ Case1 & Activity C & 2023-07-13 09:30:00 \\\\ Case2 & Activity A & 2023-07-13 10:00:00 \\\\ Case2 & Activity B & 2023-07-13 10:30:00 \\\\ Case3 & Activity A & 2023-07-13 11:00:00 \\\\ Case3 & Activity C & 2023-07-13 11:30:00 \\\\ Case3 & Activity D & 2023-07-13 11:45:00 \\\\ \\hline \\end{tabular} \\end{table} Table 1: Simple example of a traditional event log Object-centric event logs, on the other hand, cater to more complex scenarios by associating each event with multiple objects of different types. Each event still holds information about its activity and timestamp, but instead of relating to a single process execution, it ties into multiple entities. The OCEL standard Ghahfarokhi et al (2021) has been proposed as a standard for the storage of object-centric event logs, capturing detailed interaction patterns between diverse process entities. An example is reported in Table 2. For example, we see that the event with identifier _Event1_ is related to one object of type order, two objects of type order item, and one object of type invoice. Object-centric event logs allow for the capture of complex, intertwined, multi-object scenarios, opening avenues for more nuanced process mining tasks. However, the complexity of these logs presents unique challenges for process mining, such as how to structure the data for analysis. A significant stride has been made in addressing these challenges with the proposal by Adams et al. in their 2022 study Adams et al (2022) to partition object-centric event logs into \"executions\". Their methodology, inspired by traditional case-oriented process mining, breaks down the intricate graph structure of object-centric event logs into manageable \"process executions\", effectively the equivalent of cases in traditional event logs. By extending the case concept to object-centric data, the authors enable a more refined application of process mining tasks to these logs, enabling practitioners to query specific aspects of a process. Furthermore, through the application of graph isomorphism, they are able to identify equivalent process executions with respect to an attribute, thereby discovering object-centric variants. This approach offers a method for handling the complexities inherent in object-centric event logs without resorting to flattening the data, thereby preserving information and structure. As example, the object-centric event log in Table 2 is split in four distinct connected components ( {_Order1_, _Item1_, _Item2_, _Invoice1_}, {_Order2_, _Item3_, _Invoice2_}, {_Order3_, _Item5_, _Item6_, _Invoice3_}, {_Order4_, _Item8_, _Invoice4_} ). \\begin{table} \\begin{tabular}{|c|c|c|c|c|c|} \\hline **Event ID** & **Activity** & **Timestamp** & **Order** & **OrderItems** & **Invoices** \\\\ \\hline Event1 & Activity A & 2023-07-13 09:00:00 & Order1 & Item1, Item2 & Invoice1 \\\\ Event2 & Activity B & 2023-07-13 09:15:00 & Order1 & Item1, Item2 & Invoice1 \\\\ Event3 & Activity C & 2023-07-13 09:30:00 & Order2 & Item3 & Invoice2 \\\\ Event4 & Activity A & 2023-07-13 10:00:00 & Order2 & Item3 & Invoice2 \\\\ Event5 & Activity B & 2023-07-13 10:30:00 & Order2 & Item4 & Invoice2 \\\\ Event6 & Activity A & 2023-07-13 11:00:00 & Order3 & Item5, Item6 & Invoice3 \\\\ Event7 & Activity C & 2023-07-13 11:30:00 & Order3 & Item5 & Invoice3 \\\\ Event8 & Activity D & 2023-07-13 11:45:00 & Order3 & Item6 & Invoice3 \\\\ Event9 & Activity A & 2023-07-13 12:00:00 & Order4 & Item7, Item8 & Invoice4 \\\\ Event10 & Activity B & 2023-07-13 12:15:00 & Order4 & Item8 & Invoice4 \\\\ \\hline \\end{tabular} \\end{table} Table 1: We have three cases. For _Case1_, we have three events with activities A,B,C. For _Case2_, we have two events with activities A and B. For _Case3_, we have three events with activities A,C,D. \\begin{table} \\begin{tabular}{|c|c|c|c|c|c|} \\hline **Event ID** & **Activity** & **Timestamp** & **Order** & **OrderItems** & **Invoices** \\\\ \\hline Event1 & Activity A & 2023-07-13 09:00:00 & Order1 & Item1, Item2 & Invoice1 \\\\ Event2 & Activity B & 2023-07-13 09:15:00 & Order1 & Item1, Item2 & Invoice1 \\\\ Event3 & Activity C & 2023-07-13 09:30:00 & Order2 & Item3 & Invoice2 \\\\ Event4 & Activity A & 2023-07-13 10:00:00 & Order2 & Item3 & Invoice2 \\\\ Event5 & Activity B & 2023-07-13 10:30:00 & Order2 & Item4 & Invoice2 \\\\ Event6 & Activity A & 2023-07-13 11:00:00 & Order3 & Item5, Item6 & Invoice3 \\\\ Event7 & Activity C & 2023-07-13 11:30:00 & Order3 & Item5 & Invoice3 \\\\ Event8 & Activity D & 2023-07-13 11:45:00 & Order3 & Item6 & Invoice3 \\\\ Event9 & Activity A & 2023-07-13 12:00:00 & Order4 & Item7, Item8 & Invoice4 \\\\ Event10 & Activity B & 2023-07-13 12:15:00 & Order4 & Item8 & Invoice4 \\\\ \\hline \\end{tabular} \\end{table} Table 2: Simple example of an object-centric event log"
    },
    {
      "title": "Procedural Process Models",
      "text": "Procedural process models, as a fundamental tool in process mining, systematically depict the order of activities and their interrelations within a process. These models capture the idea that some activities must precede others, clearly indicating the sequence or procedure that needs to be followed to attain a particular outcome. They represent a step-by-step visualization of a process, guiding us from the beginning to the end, hence the name 'procedural.' In such models, each step is contingent on the output of the preceding one, reinforcing a precise flow of tasks in a process. Now, let's delve into some common types of procedural process models. Figure 1: Example directly-follows graph (DFG) computed on the event log described in Table 1. Figure 2: Example Petri net obtained from the event log described in Table 1 using the Inductive miner process discovery algorithm Leemans et al (2013). A primary example of a procedural process model is the directly-follows graph (DFG) van der Aalst (2016). This model encapsulates the succession relationship between activities, where an edge from activity A to activity B signifies that B has directly followed A in the process. DFGs provide an intuitive, visual way to comprehend the sequence of activities in a process and can be an effective starting point for process discovery. An example of a directly-follows graph, annotated with frequency and performance information, is reported in Figure 1. In the realm of formal procedural process models, Petri nets have gained wide acceptance in process mining van der Aalst (1998). They offer a graphical and mathematical modelling tool well suited to capture concurrency, synchronization and shared resources. In a Petri net, places (represented as circles) can contain tokens, and transitions (represented as rectangles) can consume and produce these tokens, in line with predefined rules. Different process discovery algorithms have Petri nets as eventual output, including the Alpha van der Aalst et al (2004), the Inductive Leemans et al (2013) and the Heuristics Weijters and Ribeiro (2011) miners. An example of Petri net model, discovered from Table 1 using the Inductive miner, is presented in Figure 2. Another common procedural modelling notation used in business process management is the Business Process Model and Notation (BPMN 2.0 Aagesen and Krogstie (2015)). It is a rich, graphical representation for specifying business processes in a business process model, offering a more extensive set of symbols compared to Petri nets, thereby allowing more precise business communication Kalenkova et al (2017, 2019). However, the expressiveness of BPMN can lead to ambiguity due to the potential for different interpretations of its constructs Dijkman et al (2008); Ouyang et al (2006). An example of BPMN model is represented in Figure 3. We also provide an example of BPMN 2.0 XML1. Footnote 1: Available at the address [https://github.com/pm4py/pm4py-core/blob/release/tests/input_data/running-example.bpmn](https://github.com/pm4py/pm4py-core/blob/release/tests/input_data/running-example.bpmn) In the realm of object-centric process mining, procedural process models extend their scope to encapsulate the multiple object types involved in a process. This leads to the creation of two key variants: object-centric directly-follows graphs and object-centric Petri nets. An _object-centric directly-follows Figure 3: Example BPMN model obtained from the event log described in Table 1 using the Inductive miner process discovery algorithm Leemans et al (2013). graph_Berti and van der Aalst (2023) represents a direct evolution from the traditional directly-follows graph, with each object type having its own graph portraying the succession of activities involving that particular object. This collation of graphs offers a nuanced view of the process, maintaining the simplicity of the traditional format. On the other hand, the _object-centric Petri net_van der Aalst and Berti (2020) extends traditional Petri nets to capture the lifecycle of each individual object type within the process. Each object type is represented by its own Petri net, and their integration forms the object-centric Petri net. This detailed representation provides a comprehensive view of the process, accounting for the interactions between the multiple object types. Figure 4: Example object-centric directly-follows graph computed on the object-centric log contained in Table 2. Different annotations (i.e., frequency and performance) are computed Berti and van der Aalst (2023). types. These models provide a powerful means for analyzing complex, object-centric processes, enabling an in-depth understanding of the process from the perspective of individual object types and their interaction."
    },
    {
      "title": "Declarative Process Models",
      "text": "Declarative process models provide a different perspective compared to the traditional procedural process models. While procedural models specify the explicit sequence of activities in a process, declarative models describe the process through a set of constraints or rules that prescribe what cannot happen, leaving a degree of flexibility for what can happen. A common notation used for declarative modeling in the process mining field is the DECLARE framework Maggi et al (2011). It targets the control-flow perspective of a process by specifying constraints on the sequence, choice, and parallelism of activities. For instance, a DECLARE model can express that if activity 'A' happens, then activity 'B' must eventually follow, capturing the interdependence between activities. Furthermore, declarative process models extend beyond control-flow constraints to capture other aspects of the process. Temporal declarative models incorporate temporal constraints into the process Stertz et al (2020); Barrientos et al (2023), providing further refinement on when activities should occur. Data-driven declarative models integrate data conditions to determine the valid sequence of activities, thus introducing a context-sensitive dimension to the process model. An example temporal model is presented in Table 3. Overall, declarative process models offer a flexible and holistic approach to process modeling, allowing for a wide range of scenarios and conditions to be incorporated, thereby addressing the complex, dynamic nature of many real-world processes."
    },
    {
      "title": "Extraction Of Numerical Features",
      "text": "Feature extraction is a fundamental process in transforming raw event log data into a format that machine learning algorithms can interpret and learn from. In the context of process mining, feature extraction plays a significant role in various tasks, including predictive process monitoring, anomaly detection, and process enhancement, among others de Leoni et al (2016). \\begin{table} \\begin{tabular}{|c|c|c|c|} \\hline **Source Activity** & **Target Activity** & **Average Time** & **Standard Deviation** \\\\ \\hline Activity A & Activity B & 1350.0 & 636.40 \\\\ Activity A & Activity C & 1800.0 & 0.00 \\\\ Activity B & Activity C & 900.0 & 0.00 \\\\ Activity A & Activity D & 2700.0 & 0.00 \\\\ Activity C & Activity D & 900.0 & 0.00 \\\\ \\hline \\end{tabular} \\end{table} Table 3: Temporal profile model Stertz et al (2020) for the traditional event log presented in Table 1. The primary strategy to convert an event log into numeric features is through the use of encoding techniques such as one-hot encoding. In this strategy, each unique activity in the event log is assigned a distinct binary (0 or 1) feature, thus creating a binary vector representation for each case in the log. This enables machine learning algorithms to effectively capture and learn the presence or absence of specific activities within each case. This transformation is crucial since machine learning algorithms primarily work with numeric data. A numeric feature table computed on the traditional event log in Table 1 is presented in Table 4. Apart from the straightforward one-hot encoding, more advanced feature extraction methods can be considered. For instance, there are aggregate features that summarize specific characteristics of a case, like the total number of events, the mean time between events, or the standard deviation of the time between events. Another advanced technique is sequence encoding, where the order of activities is preserved. This is particularly beneficial when the sequence of activities is of paramount importance to the process. Other techniques include using n-grams Zandkarimi et al (2020), which capture sequences of 'n' consecutive activities, or using methods from natural language processing, such as word embeddings Junior et al (2020), to encode activities and their context within the case. In the realm of object-centric event logs, numeric feature extraction expands to accommodate the complexity and multidimensionality of these logs. Features are designed to represent the intricate dynamics involving multiple object types, their interactions, and temporal associations Berti et al (2023); Adams et al (2022). A numeric feature table computed on the object-centric event log in Table 2 is presented in Table 5. Activity features from object-centric event logs encapsulate the actions occurring on specific objects or types of objects. For each unique activity, a binary indicator or count variable can be created to signify whether a particular activity has occurred or how often it has taken place on each object. This not only helps encapsulate the inherent processes but also provides a granular understanding of different object types' behaviors. Inter-object features delve into the relationships between different objects in an object-centric log. When objects of different types consistently appear together, a feature is devised to symbolize this co-occurrence. This might be a binary flag signaling the presence of such a relationship or a count of \\begin{table} \\begin{tabular}{|c|c|c|c|c|c|} \\hline **Case ID** & **Activity A** & **Activity B** & **Activity C** & **Activity D** & **Count** & **Total Duration** \\\\ \\hline Case1 & 1 & 1 & 1 & 0 & 3 & 30 \\\\ Case2 & 1 & 1 & 0 & 0 & 2 & 30 \\\\ Case3 & 1 & 0 & 1 & 1 & 3 & 45 \\\\ \\hline \\end{tabular} \\end{table} Table 4: Numeric feature table for the traditional event log presented in Table 1. the frequency of these interactions, offering insight into patterns of object interdependencies and interplay. Temporal features are instrumental in encapsulating the timing aspects associated with events. For each object type, these can include the timestamp of the first or last event, the mean time between events, or the overall duration of processes involving the object. The temporal features help shed light on the pace and sequence of events across different objects, an essential aspect of understanding the overall process flow. Finally, data attribute features cater to any additional attributes tied to the events or objects themselves. If an event or object comes with associated data attributes such as cost or resource allocation, these attributes can be incorporated as features. This inclusion ensures any vital context-specific or process-related information is not overlooked during the feature extraction process Qafari and van der Aalst (2021), thereby enhancing the explanatory power of the derived features. By generating suitable features from event logs, we can create informative inputs for machine learning algorithms, enhancing their ability to model and predict complex process behaviors."
    },
    {
      "title": "Fairness Concepts In Process Mining",
      "text": "Fairness in process mining is a central theme of increasing importance Qafari and van der Aalst (2019). In essence, it aims to ensure that the algorithms and models developed based on event data do not unfairly favor or disadvantage certain instances or groups. This is crucial because process mining techniques are often used to inform operational decisions and business strategies that can significantly impact people and resources. For example, they may be used to optimize workflows, allocate resources, or make predictive decisions. If these models or algorithms are biased or unfair, the resulting decisions can be unjust, leading to significant negative consequences. Therefore, maintaining fairness in process mining is not just an ethical imperative, but also a necessary condition for building trust and ensuring the overall sustainability of business processes. Fairness in process mining can be thought of as a continuum that spans from the individual to the group level, incorporating notions of procedural and counterfactual fairness along the way Pohl et al (2022). \\begin{table} \\begin{tabular}{|c|c|c|c|c|c|} \\hline **Order** & **Activity A** & **Activity B** & **Activity C** & **Activity D** & **Related Items** & **Related Invoices** \\\\ \\hline Order1 & 1 & 1 & 0 & 0 & 2 & 1 \\\\ Order2 & 1 & 1 & 1 & 0 & 2 & 1 \\\\ Order3 & 1 & 0 & 1 & 1 & 2 & 1 \\\\ Order4 & 1 & 1 & 0 & 0 & 2 & 1 \\\\ \\hline \\end{tabular} \\end{table} Table 5: Numeric feature table (for the object type _Order_) derived from the object-centric event log presented in Table 2. At the _individual level_, fairness centers on ensuring that every case in a process is treated equitably. This could involve examining each instance independently to determine whether the same rules and decisions were applied consistently. For example, in a loan application process, individual fairness would imply that each application is evaluated based on the same set of criteria and not influenced by irrelevant attributes such as the applicant's race or gender. Progressing towards the _group level_, fairness becomes about ensuring equitable outcomes across different groups within a process. This could mean analyzing whether certain groups are systematically disadvantaged compared to others. For example, in an employee onboarding process, group fairness would imply that new hires from all backgrounds receive equal access to resources and opportunities for training and development. The notion of _procedural fairness_ emphasizes the importance of the process itself being fair, beyond merely the outcomes it produces. Procedural fairness is concerned with the transparency, consistency, and unbiased nature of the processes. For instance, in a complaint handling process, procedural fairness would mean that all complaints are handled following the same, predefined steps and procedures without any bias. _Counterfactual fairness_Qafari and van der Aalst (2021) introduces a more complex, hypothetical element into the fairness equation. It considers whether the outcome of a process would have been the same had an irrelevant attribute been different. For example, in an employee promotion process, counterfactual fairness would mean that an employee's promotion decision would have been the same, irrespective of their gender. One of the key challenges in the development of fairness-oriented techniques in process mining is the scarcity of publicly available event logs that feature fairness concerns. Such data sets are crucial for testing and refining techniques. They not only provide a ground truth against which the effectiveness of methods can be evaluated, but also highlight the real-world complexities and nuances that such techniques need to handle. Currently, the only public collection of simulated event logs that are designed to exhibit fairness issues is provided in Pohl and Berti (2023). These logs and their characteristics are described in detail in the paper Pohl et al (2023). This availability gap underlines the need for greater openness and collaboration in the field, and the importance of creating and sharing more such resources, so as to advance the development and validation of fairness-oriented process mining techniques."
    },
    {
      "title": "2 Approach",
      "text": "In the forthcoming section, we unpack our unique approach to leveraging large language models for process mining tasks. Initially, we focus on developing textual abstractions for process mining artifacts Section 2.1, a vital foundation for enabling the language model's comprehension of process-related entities. This step includes particular emphasis on process modelsand event logs Section2.1.1 Section2.1.2. Subsequently, we delineate various prompting strategies Section2.2 to guide the model in problem resolution. These strategies span from direct answering to multi-prompt answering, and even generation of database queries Section2.2.1 Section2.2.2 Section2.2.3. Through an effective synergy between these components, we navigate the nuanced landscape of process mining with large language models, ensuring efficient analysis and meaningful insights."
    },
    {
      "title": "Textual Abstractions Of Process Mining Artifacts",
      "text": "In order to leverage the capabilities of Large Language Models (LLMs) for process mining, we need to convert process mining artifacts into a format that these models can understand and interpret effectively. The initial and crucial step in this transformation process is the textual encoding of these artifacts. The goal of this encoding is to convey the essential information embedded in the artifacts while maintaining the constraints imposed by the context window of the LLM. In our research, we have developed distinct textual abstractions for different types of event logs and process models. On the one hand, we address traditional and object-centric event logs, which provide a chronological record of events related to a particular process. On the other hand, we also consider procedural and declarative process models. Procedural models focus on the sequence of activities necessary to accomplish a process, while declarative models describe the rules and constraints that govern the execution of the process. Our textual abstractions offer a balanced summary of these artifacts that preserve their critical properties while remaining accessible to LLMs."
    },
    {
      "title": "Textual Abstractions Of Process Models",
      "text": "One of the fundamental process mining artifacts is the directly-follows graph (DFG) introduced in Section1.2. To translate this information into a form digestible by Large Language Models (LLMs), we need to convert the DFG into a textual abstraction. This conversion, as exemplified in Listing1, is a careful process that aims to maintain the core information contained in the graph while conforming to the text-based input restrictions of the LLMs. Each arc in the DFG is translated into a textual sentence that describes the transition from one activity to another, along with its frequency and performance. Frequency signifies how often a particular sequence of activities occurs in the process, while performance captures the average time it takes to move from one activity to the next. The arcs are listed in order of decreasing frequency to prioritize the most common transitions in the process. If the total length of the textual abstraction threatens to exceed the context window limitation of the LLM, some of the less frequent arcs may be omitted. This ensures that the model is fed with the most representative information about the process within the imposed text length constraint, thus enabling effective query answering and process analysis. In addition to the standard textual encoding of the DFG, it is worth noting that advanced large language models exhibit significant flexibility in understanding various text representations of process flows. They are capable of interpreting and reasoning about different encodings for the same underlying information. For instance, the transition from \"Activity A\" to \"Activity B\" could be expressed in several ways, such as \"Activity A is followed by Activity B\", \"Activity A \\(\\rightarrow\\) Activity B\", or even as a pair \"(Activity A, Activity B)\". Despite the stylistic differences, the LLMs can recognize these expressions as conveying the same transition in the process. This flexibility makes LLMs robust and adaptable tools for analyzing process mining artifacts represented in different textual formats. ``` IfI have a Petri net: ``` 1places:[ p_3, p_4, p_5, sink, source ] 2transitions:[ (0309dbbf9--52fg9--42a5--a73a--79da3a2ea20a, 'Activity B'), (37ede306 --4d81--499a--8dbe--b23b5a31372a, 'Activity C'), (5f5a9dd2--b140--4e88--ac73--b05c3ab17bf36, 'Activity A'), (eball1fc0--143b--4765--adb0--2 --b736b34888, 'Activity D'), (skip1, None), (skip2, None), (skip3, None) ] 3 arcs:[ (0309dbbf9--52fg9--42a5--a73a--79da3a2ea20a, 'Activity B')-->p_4, (37ede306 --4d81--499a--8dbe--b23b5a31372a, 'Activity C')-->p_5, (55a9dd2--b140--4e88--ac73--b05c3ab17bf36, 'Activity A')-->p_3, (eball1fc0--143b--4765--adb0 --2b736b34888, 'Activity D')-->sink, (skip1, None)-->p_4, (skip2, None) -->sink, (skip3, None)-->sink, p_3-->(0309dbbf9--52fg9--42a5--a73a--79 --da3a2ea20a, 'Activity B'), p_3-->(skip1, None), p_4-->(37ede306--4d81--499 a--8dbe--b23b5a31372a, 'Activity C'), p_4-->(skip2, None), p_5-->(ebal1fc0 --143b--4765--adb0--2b736b348f88, 'Activity D'), p_5-->(skip3, None), source-->(5f5a9dd2--b140--4e88--ac73--b05c3ab17bf63, 'Activity A') ] 4 initial marking:['source:1'] final marking:['sink:1'] ``` Listing 2: Textual abstraction of the Petri net presented in Figure 2 (obtained using the method pm4py.llm.abstract_petri_net). In our process of creating a textual representation of Petri nets (Section 1.2), we assign unique identifiers to both places and transitions within the net, as demonstrated in Listing 2. Visible transitions are accompanied by a specific label, while arcs serve as the connectors between places and transitions and are depicted accurately. This approach enables a clear and precise representation of the Petri net's structure, making it easy for large language models to comprehend and reason about. As with directly-follows graphs, it is important to note that there is not a single \"correct\" way to textually encode Petri nets. Advanced large language models are capable of understanding a wide range of textual encodings, provided the chosen method clearly communicates the structure and components of the Petri net. Different encodings might express the same Petri net, using various terminologies or formatting conventions to depict places, transitions, and arcs. As long as the encoding is clear and unambiguous, the language model will be able to understand and analyze the underlying Petri net effectively. In addition, it is crucial to note that, unlike with directly-follows graphs, we cannot employ the same approach to addressing the context window limitation when dealing with Petri nets. The nature of Petri nets makes it necessary to abstract the entire model textually. The interconnected structure of places, transitions, and arcs in a Petri net forms a unified whole that cannot be easily segmented or reduced without potentially losing critical information or misrepresenting the process logic. Hence, the complete Petri net, regardless of its size, needs to be translated into text for the large language model to process effectively. This characteristic emphasizes the importance of developing efficient, concise and clear abstraction methods to avoid exceeding the context window of the large language model. When it comes to DECLARE process models (Section 1.3), a declarative process modeling notation, our approach to abstraction changes. These models are expressed as a set of constraints, each representing specific interdependencies and relationships between process activities. Given the non-trivial nature of these constraints, it becomes crucial to adequately explain them to the large language model. A textual representation of a DECLARE model, as shown in Listing 3, translates these constraints into a readable format. However, unlike with procedural models, the form in which the constraints and explanations are presented is not rigid. Advanced large language models are capable of interpreting the constraints, regardless of how they're expressed, as long as the explanation remains clear and coherent. However, one of the significant challenges when dealing with DECLARE models is the context window limitation. Real-life processes often involve hundreds of constraints, making their textual representations considerably long. To tackle this issue, one possible preprocessing strategy could be to rename the activities using alphabet letters or abbreviations. This approach considerably reduces the length of the textual encoding, ensuring it fits within the context window of the large language model, without losing the integrity of the model's information. In addition to the abstractions we've discussed, there are also temporal profile models to consider. A temporal profile model, another type of declarative process model (Section 1.3), is primarily concerned with the timing aspects of a process. The abstraction for such a model, as shown in Listing 4, encapsulates the temporal dependencies between various pairs of activities. Specifically, for each pair of activities that can potentially follow one another in the process, the abstraction provides the average and standard deviation of the time elapsed between them. Just as with other models, advanced large language models are flexible in terms of the representation used for these constraints. As long as the pairs of activities and their corresponding time intervals are clearly stated, the large language model can interpret them, regardless of how they are presented in the abstraction. This versatility makes advanced large language models a potent tool for generating meaningful insights from abstracted temporal profile models. When it comes to object-centric event logs, we often utilize object-centric directly-follows graphs (Section 1.2) as part of the abstraction process. An example of such an abstraction is depicted in Listing 5. In this case, each type of object within the log has a corresponding set of arcs in its directly-follows graph. These arcs illustrate the flow and sequence of activities involving that particular object type. However, similar to traditional directly-follows graphs, we must be mindful of the context window limitation. As a result, arcs with fewer occurrences may be omitted from the textual abstraction to maintain a manageable size. Regardless of this omission, the critical insight here is the pattern of activities and interactions concerning each object type. Like the previously discussed abstractions, the way in which these object-specific arcs are represented in the abstraction does not significantly affect how advanced large language models interpret them. As long as the arcs are clearly stated, the large language model can efficiently process and generate useful insights from them. This flexibility underlines the applicability and utility of advanced large language models in understanding and analyzing complex object-centric artifacts."
    },
    {
      "title": "Textual Abstractions Of Event Logs",
      "text": "Process variants provide a crucial view of a traditional event log by giving us a glimpse into the different paths or sequences of activities that cases may follow in a process. They can be textually abstracted and presented to a Large Language Model (LLM), as illustrated in Listing 6. Each variant is represented along with its frequency and average throughput time. This structure enables the LLM to understand both the variant's prevalence and the time typically required for its completion. Given the frequency-based ordering of the variants, it is possible to handle limitations imposed by the context window. If the number of process variants is large and exceeds the context window size, less frequent variants can be omitted from the textual abstraction. Despite this omission, the abstraction would still retain the most common patterns, which likely capture a substantial portion of the overall process behavior. The ability of advanced LLMs to understand different textual representations is particularly beneficial here. The representation of process variants does not have to adhere to a strict syntax. It could be a sequence of activities separated by symbols or a plain text description. When dealing with traditional event logs (Section 1.1), which are essentially organized collections of events grouped into cases, we can utilize textual abstractions to distill the key features of a specific case, as shown in Listing 7. In this type of abstraction, we highlight the key attributes at the case level and provide a detailed list of all events associated with that case. Each event is principally characterized by an activity and a timestamp, but other event-level attributes can be included as necessary, providing a more detailed snapshot of each event. The crucial aspect of this textual abstraction is that it presents all necessary information to evaluate the progression of a specific case. Consequently, it enables the large language model to answer questions that pertain to a specific case in question, such as identifying any potential issues or irregularities within that case. This makes case-level textual abstraction a powerful tool for detailed, case-specific analysis in process mining. \\begin{table} \\begin{tabular}{l} \\hline \\hline If I have a process with the following process variants: \\\\ Activity A –\\(>\\) Activity C –\\(>\\) Activity D ( frequency = 1 performance = 2700.0 ) \\\\ Activity A –\\(>\\) Activity B –\\(>\\) Activity C ( frequency = 1 performance = 1800.0 ) \\\\ Activity A –\\(>\\) Activity B ( frequency = 1 performance = 1800.0 ) \\\\ \\hline \\hline \\end{tabular} \\end{table} Listing 6: Textual abstraction of the process variants in Table 1 (obtained using the method pm4py.llm.abstract_variants). A traditional event log can also be translated into a matrix of numerical features (Section 1.4), a format often used in machine learning. Each row in this matrix represents a case from the event log, and each column, or feature, provides some quantitative characteristic of that case. The textual abstraction of this type of matrix can be illustrated as in Listing 8. For every feature in the matrix, we provide its support, i.e., the number of cases where this feature is present or significant. Additionally, we supply quantiles of the feature values, giving a more detailed understanding of the distribution of these values. These aspects combined allow us to understand the relevance and descriptive power of each feature. Given the potential breadth of this kind of matrix, it is essential to consider the context window limitation when producing a textual abstraction. As a solution, one could decide to omit features that have a low support. Such a choice would ensure that the most impactful features, those that occur more frequently, are represented in the abstraction, providing a succinct yet representative snapshot of the event log's numerical features. This strategy makes this type of textual abstraction extremely valuable for a broad understanding of the event log's characteristics from a numerical perspective. Similar to the abstraction of traditional event logs, object-centric event logs can also be textually abstracted (Section1.1), as exemplified in Listing 9. In an object-centric event log, each event is characterized not only by an activity and a timestamp, as in traditional event logs, but also by a set of related objects. These objects extend the dimensionality of the event log, providing more nuanced and contextually rich information about each event. The textual abstraction of an object-centric event log essentially reflects this richer structure. Each event is paired with its associated objects, hence providing a thorough picture of the specific process instance that the event belongs to. However, due to the typically large size of object-centric event logs, a direct abstraction of the entire log could easily exceed the context window limitation of the large language model. To address this issue, it is advisable to execute the textual abstraction against a specific process execution (as in Listing 9), which can be a connected component of related objects, rather than the entire log. This approach allows for localized question answering on a given process execution, ensuring that the resulting prompts are meaningful and contextually appropriate while staying within the context window limitation. The ability to abstract and question specific process executions provides an extra level of flexibility when investigating process behaviours. It can help to unveil patterns or anomalies that are localized to specific instances of the process, contributing to a more granular understanding of the process dynamics. As with traditional event logs, object-centric event logs can also be transformed into a matrix of numerical features (Section 1.4), each representing a unique aspect of the process. These features often delve deeper, exploring the lifecycles of individual objects or interactions between them within the event log's graph structure. The textual abstraction of such features is presented in Listing 10, with each feature detailed by its support and quantiles of its values, mirroring the approach used for traditional logs. However, due to the increased complexity and the larger number of features that object-centric event logs can offer, dealing with the context window limitation of Large Language Models can be more challenging. The primary strategy here is to focus on the most relevant features - those with the highest support. This prioritization helps to manage the amount of information fed into the LLM, ensuring that the most significant features are included, while those with less support can be omitted to fit within the context window. This approach allows for an effective trade-off between information detail and the size constraints imposed by the LLMs. [MISSING_PAGE_FAIL:21]"
    },
    {
      "title": "Prompting Strategies",
      "text": "This section introduces three prompting strategies for utilizing large language models (LLMs) in the field of process mining: \"direct answering,\" \"multi-prompt answering,\" and \"generation of database queries.\" These strategies vary in complexity and are chosen based on the problem at hand. They make use of textual abstractions and questions, and leverage the capabilities of LLMs for hypothesis generation, result interpretation, and even SQL query formulation, providing an interactive and adaptive approach to process mining."
    },
    {
      "title": "Direct Answering",
      "text": "The \"direct answering\" strategy is the most straightforward prompting approach used with large language models in the context of process mining. This strategy involves formulating a prompt which combines a textual abstraction of a process mining artifact with a direct question related to it. Example questions might be \"What are the bottlenecks of the process?\" (starting from the process variants abstraction) or \"What are the main anomalies?\" (starting from the directly-follows graph abstraction). It is important to note that, in this strategy, the output structure of the response is not predetermined. Rather, the large language model will generate a response in the form of free text. Consequently, this means that the user, while freed from the task of analyzing the event log themselves, must have sufficient background knowledge to interpret the answer correctly. Another key factor for success with the direct answering strategy is the formulation of the question itself. It needs to be concise, clear, and well-structured to enable the large language model to provide a meaningful and relevant response. This strategy, therefore, represents a delicate balance between user expertise, question formulation, and the interpretability of the model's responses."
    },
    {
      "title": "Multi-Prompt Answering",
      "text": "In certain scenarios, more complex process mining tasks require a series of distinct prompts, each involving different abstractions and questions. This approach, known as multi-prompt answering, leverages the iterative nature of inquiry, where the answer to one question informs the formulation of the next. In this way, the user guides the large language model (LLM) through a sequence of steps to ultimately resolve the overarching process mining problem. A classic example where the multi-prompt answering strategy is useful is in assessing fairness in process mining. Initially, a user might use a feature table abstraction to identify attributes that could potentially lead to discrimination. Once the LLM provides this information, the user formulates a subsequent prompt to investigate if the process execution differs for cases belonging to the protected and non-protected groups. The second prompt is contingent on the results from the first one, as it is necessary to distinguish between cases before delving deeper into potential discrepancies in process execution. In another example, the user might want to analyze process conformance. An initial prompt could be used to compare the process model to a log abstraction to identify non-conforming activities. Subsequent prompts could then be designed to examine why these non-conformities are occurring, perhaps by examining specific cases or focusing on particular process variants. Multi-prompt answering is a powerful strategy, as it allows users to conduct a step-by-step, deep-dive analysis. However, it requires careful formulation of prompts and the ability to interpret and act on the LLM responses to guide the inquiry effectively. Therefore, it demands more user engagement than the direct answering strategy."
    },
    {
      "title": "Generation Of Database Queries",
      "text": "The third strategy is \"generation of database queries\", which is particularly useful for complex process mining problems that are too intricate to be directly abstracted or solved by the large language model (LLM). Questions like \"What is the average throughput time when activity B occurs more than one day after the start of the case?\" or \"Measure the correlation between throughput time and rework in the case\" fall into this category. In these situations, the LLM can be leveraged to generate SQL queries based on the user's initial natural language inquiry. These generated queries can then be executed against the event log, enabling complex data analysis without the user having to manually construct the intricate SQL statements. Yet, this strategy's potential goes beyond translating natural language questions into SQL queries. It can also be used to generate hypotheses about the event log, derived from certain abstractions like process variants or log features. For instance, the user can present the LLM with such an abstraction and ask it to formulate an hypothesis about the event log expressed as a SQL query. Once the SQL query (representing the hypothesis) is executed and the results are obtained, the LLM can then be employed again to evaluate if the original hypothesis holds true. Should the initial hypothesis be invalidated, the LLM is capable of formulating alternative hypotheses, which can then be transformed into SQL queries and tested against the data. This iterative method, which encompasses generating hypotheses, testing them, and re-assessing based on the outcomes, allows for a more in-depth exploration and understanding of the underlying processes. This approach significantly expands the scope of possible investigations that can be conducted using the LLM. Nevertheless, while this method can streamline complex query generation and hypothesis testing, it does call for a specific set of skills on the part of the user. While the LLM can assist in generating complex queries and hypotheses, the responsibility of result interpretation and subsequent steps of analysis falls on the user. Thus, a certain degree of analytical acumen and domain knowledge is necessary for this approach to be fully effective."
    },
    {
      "title": "3 Tool Support",
      "text": "In this section, we delve into the tool support available for conducting process mining tasks with large language models. _pm4py_Berti et al (2019), short for Process Mining for Python, is a versatile and comprehensive library that supports the entire spectrum of process mining applications, ranging from data loading and pre-processing, to process discovery, conformance checking, and enhancement. This suite of functionality enables practitioners and researchers to extract valuable insights from event logs and use them for optimizing and monitoring real-world processes. pm4py is developed from the Fraunhofer FIT process mining group and is fully documented at the address https://pm4py. fit.fraunhofer.de. A significant development in version 2.7.5 of pm4py is the integration with Large Language Models (LLM), bolstering the tool's capacity for analysis and understanding of process data. This integration enables pm4py to offer a range of abstractions for process data and models, as detailed in Table 6. More features will be introduced in pm4py 2.7.6. Each method in this module provides a different view or representation of the process data, facilitating diverse avenues for exploration and analysis. In addition to these abstractions, pm4py 2.7.5 allows for direct interaction with LLM through specific methods such as pm4py.llm.openai_query \\begin{table} \\begin{tabular}{|l|p{113.8pt}|} \\hline **Method** & **Abstraction Provided** \\\\ \\hline pm4py.llm.abstract\\_dfg() & Provides the DFG abstraction of a traditional event log \\\\ pm4py.llm.abstract\\_variants() & Provides the variants abstraction of a traditional event log \\\\ pm4py.llm.abstract\\_log\\_attributes() & Provides the abstraction of the attributes/columns of the event log \\\\ pm4py.llm.abstract\\_log\\_features() & Provides the abstraction of the machine learning features obtained from an event log \\\\ pm4py.llm.abstract\\_case() & Provides the abstraction of a case (collection of events) \\\\ pm4py.llm.abstract\\_ocel() & Provides the abstraction of an object-centric event log (list of events and objects) \\\\ pm4py.llm.abstract\\_ocel\\_ocdfg() & Provides the abstraction of an object-centric event log (OC-DFG) \\\\ pm4py.llm.abstract\\_ocel\\_features() & Provides the abstraction of an object-centric event log (features for ML) \\\\ pm4py.llm.abstract\\_event\\_stream() & Provides an abstraction of the (last) events of the stream related to a traditional event log \\\\ pm4py.llm.abstract\\_petri\\_net() & Provides the abstraction of a Petri net \\\\ pm4py.llm.abstract\\_log\\_skeleton() & Provides the abstraction of a log skeleton model \\\\ \\hline \\end{tabular} \\end{table} Table 6: Methods for various types of abstractions available in _pm4py_. (Table 7). This function enables users to directly execute prompts against OpenAI's language models, obtaining textual responses that can be further analyzed or used in subsequent processes. ``` importpm4py log=pm4py.read_xes(\"tests/input_data/roadtraffic100traces.xes\") q1=\"\"\"\"nWhat are the root causes of the performance issues in the process? Please provide only process and data specific considerations, no general considerations.\"\"\"\" print(pm4py.llm.abstract_variants(log) + q1) net, im, fm = pm4py.discover_petri_net_inductive(log) q2 =\"\"\"\"nCan you provide suggestions to improve the process model based on your domain knowledge?\"\" print(pm4py.llm.abstract_petri_net(net, im, fm) + q2) ``` Listing 11: Example usage of the pm4py's LLM integration is shown in Listing 11, where the abstract_variants method is used to retrieve the variants of an event log. Subsequently, the Petri net discovered from the event log is abstracted using abstract_petri_net, and both of these abstractions are used to construct prompts for querying an LLM. ``` importpm4py ocel=pm4py.read_ocel(\"tests/input_data/ocel/example_log.jsonocel\") q1=\"\"nWhat:arethe-strangest:relationships:inthis-graph?\" print(pm4py.llm.abstract_ocel_ocfg(ocel) + q1) q2=\"\"nWhat:arethe-strangest:features'-values?\" print(pm4py.llm.abstract_ocel_features(ocel, \"order\") + q2) ``` Listing 12: Example usage of the pm4py's LLM integration on object-centric process mining objects A distinct advantage of the pm4py tool is its support for object-centric process mining, a relatively recent advancement in the process mining field \\begin{table} \\begin{tabular}{|p{142.3pt}|p{142.3pt}|} \\hline **Method** & **Functionality** \\\\ \\hline pm4py.llm.openai_query() & Executes a prompt against OpenAI, returning the response as string \\\\ \\hline \\end{tabular} \\end{table} Table 7: Method for interacting directly with the LLM APIs available in _pm4py_. that provides a more detailed view of complex processes. Object-centric process mining expands the traditional case-centric perspective, allowing for the consideration of multiple interacting objects in a process, thus enabling a more nuanced understanding of process dynamics. The LLM integration in pm4py embraces this object-centric perspective, as demonstrated in the example given in Listing 12. The script loads an object-centric event log (OCEL) and then uses two specific abstraction methods tailored for this type of data. The method abstract_ocel_ocdfg is used to generate an abstraction of the Object-Centric Directly Follows Graph (OCDFG), a representation that captures the relationships between the different activities and objects in the log. This abstraction is then used to create a query for the LLM, asking for unusual relationships in the process graph. The method abstract_ocel_features is used to generate an abstraction of the features of a specific type of object (in this example, \"order\") in the OCEL. This abstraction is then used to create another query for the LLM, asking for odd feature values. These examples showcase the potential of using LLM in conjunction with object-centric process mining. The intricate process insights offered by object-centric logs, coupled with the rich interpretative capabilities of large language models, provide practitioners and researchers with powerful tools to uncover hidden process knowledge and drive informed process decisions."
    },
    {
      "title": "4 Assessment",
      "text": "In this section, we examine the ability of large language models, specifically Bard and GPT-4, to understand, generate, and answer queries related to process mining tasks. The considered models and their unique characteristics are discussed in Section 4.1. We also outline the specific event logs leveraged in this assessment in Section 4.2. We delve into the models' capabilities in the realm of direct answering to process mining queries in Section 4.3, where we assess their ability to respond directly to various types of prompts. This exploration is then extended in Section 4.4, where we investigate the models' capacity for providing answers across multiple prompts, encapsulating more complex interactions. Finally, we evaluate the models' aptitude in generating database queries from user prompts in Section 4.5. This involves assessing the ability of these models to not just understand a prompt, but to translate that understanding into SQL queries, a crucial aspect in the context of data analysis. By comprehensively assessing these aspects, we aim to gauge the practicality and potential of these large language models in process mining tasks, seeking to illuminate areas of strength as well as identify opportunities for further research and improvement. [MISSING_PAGE_FAIL:27] * _Road Traffic Fine Management Process2_: real-life event log of an information system managing road traffic fines in an Italian municipality. Footnote 2: [https://doi.org/10.4121/uuid:270fd440-1057-4fhg-89a9-b699b47990f5](https://doi.org/10.4121/uuid:270fd440-1057-4fhg-89a9-b699b47990f5) * _BPI Challenge 2020 (Domestic Declarations)3_: the travel expense process consists of an employee's submission, approval by the travel administration, then by the budget owner and supervisor, and possibly a director. The process concludes with a trip or a payment request. There are two types of trips: domestic and international. Domestic trips do not need prior approval, allowing employees to ask for cost reimbursement afterward. Footnote 3: [https://doi.org/10.4121/uuid:270fd440-1057-4fhg-89a9-b699b47990f5](https://doi.org/10.4121/uuid:270fd440-1057-4fhg-89a9-b699b47990f5) * _Sepsis Cases Event Log4_: the dataset is an anonymized real-life event log of sepsis cases from a hospital, where sepsis is a life-threatening condition often resulting from an infection. Each case represents a patient's journey through the hospital, with events captured by the hospital's Enterprise Resource Planning (ERP) system. The events cover a range of different activities, and a multitude of data attributes are recorded such as the group responsible for the activity, test results, and checklist information. While event timestamps have been randomized, the time interval between events within a case remains unchanged. Footnote 3: [https://doi.org/10.4121/uuid:3fd42315-ed9d-4882-891f-e180b5b4feb5](https://doi.org/10.4121/uuid:3fd42315-ed9d-4882-891f-e180b5b4feb5) * _Conformance Checking Challenge 20195_: This past version of the conformance checking challenge was centered around a process involved in medical training. Specifically, it revolved around how medical students were taught to place a central venous catheter (CVC) using ultrasound guidance. The CVC procedure involves inserting a tube into a large vein, a process critical for administering fluids or medicines to patients, among other applications. Footnote 4: [https://data.utm](https://data.utm).|articles/_/12707639/1 For assessment of the multi-prompt answering strategy, we also use the event logs provided in Pohl and Berti (2023) and described in Pohl et al (2023), including: * _Hiring event logs_: these logs chronicle a complex recruitment process with various stages of evaluation and decision-making. The applicant's journey can be as simple as a straightforward rejection or as elaborate as multi-step screening culminating in a job offer, contingent on a host of influencing factors. * _Hospital event logs_: this dataset portrays a patient's journey through a hospital system, starting from the initial check-in at the Emergency Room or Family Department. It progresses through phases of medical \\begin{table} \\begin{tabular}{|l|c|c|c|c|c|c|c|} \\hline Domain & Age & CHintampling & Census Prodictions & Gender & Religion & Years of Education & Underlying Condition & Private Insurance \\\\ \\hline Hiring & x & x & x & x & x & x & x \\\\ \\hline Hospital & x & x & x & x & x & x & \\\\ \\hline Hiring & x & x & x & x & x & & \\\\ \\hline Hiring & x & x & x & x & x & & \\\\ \\hline \\end{tabular} \\end{table} Table 10: Sensitive attributes in the supplied event log dataset. examination, diagnosis, and treatment. It's worth noting that unsuccessful treatments often necessitate repeat examinations and interventions, illustrating the cyclical nature of healthcare delivery. * _Lending event logs_: these logs detail a loan application process starting from the scheduling of an initial appointment. It traverses several steps including validation of provided information and underwriting, leading to either loan approval or denial. Further requirements, such as the involvement of a co-signer or an assessment of collateral, may be needed. Some cases may experience direct appointment refusal, highlighting the process's variability based on applicants' individual financial circumstances. * _Renting event logs_: these logs present a comprehensive rental process that begins with a property viewing request and can end with a contract termination. Between these endpoints, stages such as preliminary vetting, property viewing, decision-making, and possibly, intensive screening occur. If successful, a rental agreement is initiated, with possible outcomes ranging from eviction due to late payments to voluntary contract termination by tenants. It's important to note that not all applications advance to the property viewing phase. The degree of discrimination exhibited in the logs varies across different domains, offering researchers an opportunity to explore tangible real-world situations. Table 9 furnishes fundamental statistics for the log collection, and Table 10 elaborates on the sensitive attributes. It's important to note that the selection of attributes pertaining to fairness can be a subject of debate; hence, we welcome discussions to enhance our grasp of fairness within the realm of process mining. Detailed descriptions of each log's attributes and process have been provided to facilitate the identification of potential instances of discrimination. The event logs provided also include the ground truth concerning the classification of cases - whether they belong to the protected group or not. This inclusion enables a comparison between actual case classifications, which are based on the sensitive attributes, and the actual ground truth. Therefore, the capacity to evaluate the accuracy of case categorization into protected and non-protected groups is significantly enhanced. In our exploration of object-centric process mining using large language models, we utilized several publicly accessible logs available at [https://www.ocel-standard.org](https://www.ocel-standard.org). Specifically, two simulated object-centric event logs were chosen for this analysis: * the 'Order Management' event log, which can be accessed directly at [https://www.ocel-standard.org/1.0/running-example.jsonocel.zip](https://www.ocel-standard.org/1.0/running-example.jsonocel.zip). This log contains the object types 'orders', 'items', and 'packages', all of which were retained for our assessment. * the 'Recruiting' event log, available at [https://www.ocel-standard.org/1.0/recruiting.jsonocel.zip](https://www.ocel-standard.org/1.0/recruiting.jsonocel.zip). In this log, we focused on the 'applications' and 'offers' object types. By leveraging these specific logs, we aimed to evaluate how effectively large language models like Bard and GPT-4 could handle complex, object-centric process mining tasks."
    },
    {
      "title": "Direct Answering",
      "text": "In this section, we conduct an evaluation of the ability of advanced large language models, specifically Bard and GPT-4, to respond effectively to process mining queries, given the required abstraction. Our assessments of Bard and GPT-4 with regards to traditional process mining and event logs are documented in Table 11. In the table, each query is assigned a unique code, and the appropriate acceptance criteria for the responses generated by the large language models are stipulated. Furthermore, each query is examined across four distinct event logs, namely _Road Traffic_, _BPI Challenge 2020_, _Sepsis_, and _CCC19_. Observably, both Bard and GPT-4 demonstrate commendable performance when dealing with descriptive queries such as **TQ1**, **TQ2**, **TQ3**, and **TQ5**. Furthermore, these large language models exhibit a fair understanding of procedural and declarative models, demonstrating capabilities in tasks like play-out and conformance checking, albeit with certain constraints. In particular, GPT-4 displayed a satisfactory level of competency across the diverse range of queries, albeit with some restrictions pertaining to medical processes. Therefore, it is suggested that further refinement and training might be beneficial in enhancing the capability of these models in the realm of process mining. [MISSING_PAGE_EMPTY:31] [MISSING_PAGE_EMPTY:32] In Table 12, we evaluate the performance of large language models in tackling object-centric process mining tasks. Considering the relatively uncomplicated nature of the event logs used for this assessment, both models - Bard and GPT-4 - demonstrate notable proficiency across all tasks. To provide a comprehensive understanding of their capabilities, we document a selection of responses generated by these models in Listing 13, Listing 14, Listing 15, and Listing 16. These examples serve as illustrative evidence of the substantial potential these models exhibit in responding effectively to a diverse set of queries within the realm of object-centric process mining. ``` From the given data, it appears that this process describes the system of incoming, paying, and appealing fines, possibly within the context of a legal system, law enforcement agency, or a governmental body. The different steps represent actions taken in the process and the transitions between steps. I'll describe each step briefly: Create Fine: This is the initial step where a fine is created. This could be due to a traffic violation, non-compliance with regulations, etc. Send Fine: The fine is then sent to the offender. This could be through mail, email, or other means. Insert Fine Notification: A record of the fine notification sent to the offender is inserted, probably in some database or record-keeping systems. Add Penalty: If the fine is not paid within a certain time period, a penalty might be added to the initial amount. Send for Credit Collection: If the offender doesn't pay the fine and the added penalty, the fine might be sent for credit collection. A collection agency might be involved at this point. Payment: This is when the offender pays the fine. This might be done in full, or in parts (as suggested by the Payment -> Payment frequency). Insert Data Appeal to Preference: The offender can appeal the fine to a higher authority, possibly a prefecture. The date of this appeal is recorded. Send Appeal to Preference: The appeal is formally sent to the prefecture. Receive Renault Appeal from Preference: The response or result from the prefecture regarding the appeal is received. Notify Renault Appeal to Offender: The result of the appeal is then notified to the offender. Appeal to Judge: If unsatisfied with the result from the prefecture, the offender might appeal to a judges. Send Fine (again): In some cases, it seems like the fine might be sent again to the offender. The frequency indicates the number of times the transition from one step to the next occurs, while the performance might be indicating the time taken for each transition in milliseconds (though it's not clear from the provided data). The process appears to loop at several points, with possibilities of appeal and repeated notifications or payments. It also seems to have multiple end points including payment, credit collection, or appeal to a judge. ``` Listing 13: Description of the _Road Traffic_ process by GPT-4. ``` The process begins with the creation of a fine. The fine can be paid in full, or the offender can choose to appeal the fine. If the offender appels the fine, they must first send a notification of appeal to the prefecture. The prefecture then reviews the appeal and sends a decision to the offender. If the decision is not in the offender's favor, they can appeal the decision to a judge. The judge will then review the appeal and make a final decision. The data shows that the most common outcome is for the offender to pay the fine in full. However, a significant number of offender also choose to appeal the fine. Of those who appeal, the majority are unsuccessful. However, a small number of offenders are successful in having their fines overturned. The data also shows that the process of appels a fine can be expensive. The offender must pay a fee to send the notification of appeal to the prefecture, and they may also have to pay legal fees if they choose to appeal the decision to a judge. Overall, the data shows that the process of appels a fine can be a lengthy and expensive process. However, for those who are successful, it can be worth the effort. Here are some additional insights that can be drawn from the data: - The most common reason for appels a fine is that the offender believes that the fine was unfair. - The most common outcome of an appeal is that the fine is upheld. - The success rate of appelsa is relatively low. - The cost of appelsing a fine can be significant. - The data can be used to improve the process of appelsing fines. For example, the data could be used to identify the factors that are most likely to lead to a successful appeal. The data could also be used to develop a more streamlined and efficient appels process. [MISSING_PAGE_EMPTY:34]"
    },
    {
      "title": "Multi-Prompt Answering",
      "text": "In our fairness assessment, we employ the multi-prompt strategy, primarily aiming to discern whether GPT-4 and Bard can accurately identify the protected group. For this purpose, SQL queries were generated through the large language model, utilizing prompts that encapsulate the attributes of the log and their corresponding characterization. An exemplar script that generates such prompts is available at [https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/01_1_protected_group_identification.py](https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/01_1_protected_group_identification.py). The aforementioned queries for two event logs are delineated in Figure 5. Upon analysis, we observe that GPT-4's queries display a more encompassing view of the behavior considered as protected. Conversely, Bard's queries precisely target a specific subset of cases that are presumably exposed to discrimination. Subsequently, our focus shifts towards those event logs that signify a substantial degree of discrimination. To assess the classification performance on these logs, we employ an exemplar script accessible at [https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/01_2_protected_group_query.py](https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/01_2_protected_group_query.py). The resulting classification quality of GPT-4 and Bard is presented in Table 13 and Table 14. While Bard demonstrates high precision, it is hindered by a low recall and true negative rate, suggesting that it may fail to identify a considerable number of cases where potential discrimination might have taken place. On the other hand, GPT-4, despite exhibiting lower precision, boasts a high recall and true negative rate. This highlights GPT-4's capability to label a larger number of cases as potentially discriminated, hence reducing the occurrence of false negatives. Having established a set of cases as 'protected' via GPT-4 and Bard, we now shift our focus towards assessing procedural fairness. The objective here is to uncover any process discrepancies that might hint at discrimination. To achieve this, we craft prompts embodying the process variants abstraction of both 'protected' and 'non-protected' cases. These prompts are then fed into the large language model with a request to discern the differences. To ensure a fair and effective comparison, the 'protected' group, as per the ground truth contained within the simulated event logs, is taken into Figure 5: SQL queries generated by Bard and GPT-4 to identify the protected groups in the considered event logs. consideration. This approach is demonstrated in the example script accessible at [https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/02_group_fairness_factors.py](https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/02_group_fairness_factors.py). \\begin{table} \\begin{tabular}{|l|c c c c|c|c|c|} \\hline **Event Log** & **TP** & **FP** & **FN** & **TN** & **Precision** & **Recall** & **True Neg. Rate** \\\\ \\hline _hiring\\_log\\_high_ & 1507 & 606 & 1512 & 6375 & 0.72 & 0.50 & 0.80 \\\\ \\hline _hospital\\_log\\_high_ & 1105 & 1089 & 1417 & 6389 & 0.50 & 0.44 & 0.82 \\\\ \\hline _lending\\_log\\_high_ & 1501 & 688 & 1500 & 6391 & 0.69 & 0.50 & 0.81 \\\\ \\hline _renting\\_log\\_high_ & 1068 & 1056 & 1914 & 5962 & 0.50 & 0.35 & 0.75 \\\\ \\hline \\end{tabular} \\end{table} Table 13: Quality of the classification done by GPT-4 between the ’protected’ and ’non-protected’ groups. \\begin{table} \\begin{tabular}{|l|c c c c|c|c|c|} \\hline **Event Log** & **TP** & **FP** & **FN** & **TN** & **Precision** & **Recall** & **True Neg. Rate** \\\\ \\hline _hiring\\_log\\_high_ & 2977 & 5768 & 42 & 1213 & 0.34 & 0.98 & 0.97 \\\\ \\hline _hospital\\_log\\_high_ & 2922 & 6395 & 88 & 595 & 0.31 & 0.97 & 0.87 \\\\ \\hline _lending\\_log\\_high_ & 2923 & 4555 & 78 & 2444 & 0.39 & 0.97 & 0.96 \\\\ \\hline _renting\\_log\\_high_ & 2716 & 6749 & 266 & 269 & 0.29 & 0.91 & 0.50 \\\\ \\hline \\end{tabular} \\end{table} Table 14: Quality of the classification done by GPT-4 between the ’protected’ and ’non-protected’ groups. The excellent recall and true negative rate should be noticed. ``` Here are the main differences I can identify from your process variant descriptions, taking into account the order of steps, frequency of each variant, and performance (assumed to be the time taken for each process variant). ``` * Earlier Application Rejection: The most common process variant for the 'protected' group is \"Hand In Job Application -> Application Rejected\" with the highest frequency of 873. This suggests that the'protected' group is often rejected right after submitting their job applications, skipping the telephonic screening or any further step. This scenario does not occur as often for the 'unprotected' group, suggesting possible bias in application reviews. * Differences in Interview Steps: The 'unprotected' group seems to undergo more comprehensive interview steps including a \"Coding Interview\", \"ML Interview\", \"Fronted Interview\", \"Behavioral Interview\", and a double \"Make Job Offer\" step. These steps appear less frequently and later in the 'protected' group's process variants. * Performance Time: The performance time, which might refer to the time taken for each process variant, seem to be generally higher for the 'protected' group compared to the 'unprotected' group. This could indicate that the job application process takes longer for the 'protected' group, which could be seen as an unfair burden. * Frequency of Extensive Background Checks: The 'protected' group undergoes \"Extensive Background Check\" more frequently and earlier in the process than the 'unprotected' group. This could be indicative of bias, as it seems the 'protected' group is subjected to more rigorous checks more often. * Job Offers: The 'unprotected' group has more process variants leading to a job offer. This could suggest bias in the final decision--making process. In conclusion, these discrepancies could be indicative of biases or systemic issues within the application process. Further analysis and understanding of the reasons behind theme discrepancies would be needed to determine if they truly represent unfair treatment or if there are other factors at play. ``` Listing 21: Procedural differences between the 'protected' and 'non-protected' group identified by GPT-4 in the _hiring_log_high._res.gz_ event log. ``` Sure, I can help you with that. Here are the main differences between the process variants for the protected and unprotected groups: - The protected group is more likely to have their application rejected at the initial stage, before any interviews have taken place. This is evident in the fact that there are more process variants for the protected group that end in \"Application Rejected\" at the \"Hand In Job Application\" or \"Telephonic Screening\" stage. - The unprotected group is more likely to progress to the later stage of the interview process, including the coding interview, ML interview, and behavioral interview. This is evident in the fact that there are more process variants for the unprotected group that end in \"Make Job Offer\" at the \"Coding Interview\", \"ML Interview\", or \"Behavioral Interview\" stage. - The protected group is more likely to be rejected after the behavioral interview. This is evident in the fact that there are more process variants for the protected group that end in \"Application Rejected\" at the \" Behavioral Interview\" stage. - These differences suggest that the protected group may be facing discrimination in the job application process. Specifically, they may be being rejected at an earlier stage, even though they may be just as qualified as the unprotected group. Additionally, they may be being rejected after the behavioral interview, even though they may have performed well in the interview. It is important to note that these are just some of the differences between the process variants for the protected and unprotected groups. There may be other differences that are not evident in the data. However, the differences that I have identified suggest that the protected group may be facing discrimination in the job application process. ``` Listing 22: Procedural differences between the 'protected' and 'non-protected' group identified by Google Bard in the _hiring_log_high._res.gz_ event log. Refer to Listing 21 and Listing 22 for GPT-4 and Bard's respective responses pertaining to the hiring event log. Similarly, for the renting event log, GPT-4 and Bard's responses can be found in Listing 23 and Listing 24 respectively. ``` Based on the given information, here are some differences that stand out between the 'protected' and'unprotected' groups in terms of the rental process: - Frequency and Extent of Rejecton: It appears that in both groups, the rejection of prospective tenants is a common process variant. However, the 'unprotected' group faces a more frequent rejection after the \" Screen Prospervice Tenant\" step without extensive screening, compared to the 'protected' group. - Paperwork and Screening Process: The 'protected' group more often goes through extensive paperwork and screening process, which includes steps like \"Rand In the \"Paperwork\", \"Check Paperwork\", \"Screen Prospective Tenant\", and \"Extensive Screening: The 'unprotected' group, on the other hand, often seems to get rejected before reaching these steps or even without the extensive screening process. - Contract and Rentis: When it comes to signing contracts, moving in, and starting to pay rent, the unprotected' group seems to have a somewhat easier path. There are several process variants for the'unprotected' group whence they get to sign the contract and move in without undergoing the 'Extensive Screening' step, which isn't the Case for the 'protected' group: - Execution Time: The 'protected' group's process generally take longer, as indicated by the higher'performance' values, which could suggest a more extensive or stringent screening process. - ``` Listing 23: Procedural differences between the 'protected' and 'non-protected' group identified by GPT-4 in the _renting_log_high._res.gz_ event log. ``` Sure, I can help you with that. Here are the main differences between the process variants for the protected and unprotected groups: - The protected group is more likely to be rejected at the initial stage, before any paperwork has been submitted. This is evident in the fact that there are more process variants for the protected group that end in \"Reject Prospective Tenant\" at the \"Apply for Viewing Appointment\" or \"Set Appointment\" stage. - The unprotected group is more likely to progress to the later stage of the process, including the screening, contract signing, and move- in stages. This is evident in the fact that there are more process variants for the unprotected group that end in \"Sign Contract\" or \"Move In\". - The protected group is more likely to cancel their apartment after moving in. This is evident in the fact that there are more process variants for the protected group that end in \"Tenant Canest Apartment\". - ``` Listing 24: Procedural differences between the 'protected' and 'non-protected' group identified by Google Bard in the _renting_log_high._res.gz_ event log. These differences suggest that the protected group may be facing discrimination in the rental process. - Specifically, they may be being rejected at an earlier stage, even though they may be just as qualified as the unprotected group. Additionally, they may be being rejected after moving in, even though they may be good tenants. It is important to note that there are just some of the differences between the process variants for the protected and unprotected groups. There may be other differences that are not evident in the data. However, the differences that I have identified suggest that the protected group may be facing discrimination in the rental process. - Here are some additional thoughts on the matter: - The protected group may be being rejected at an earlier stage because they are being subjected to more stringent screening criteria. For example, they may be being required to provide more documentation or to undergo more extensive background checks. - The protected group may be being rejected after moving in because they are being subjected to more scrutiny by their handler. For example, they may be being more likely to be reported for minor infrections or to be evicted for non-payment of rent. It is important to investigate these differences further to determine whether they are the result of discrimination. If they are, then steps should be taken to ensure that the protected group is not being discriminated against. ``` Listing 25: Procedural differences between the 'protected' and 'non-protected' group identified by Google Bard in the _renting_log_high._res.gz_ event log. Both large language models perform admirably, pinpointing differences in the control-flow and time perspectives. These variances in control-flow correlate with the outcome of a case, the presence of rework, and the number of events in the case. That said, GPT-4's response stands out for being more comprehensive compared to Bard's. In our research, we are investigating how large language models can formulate process queries in mainstream SQL language. Our primary focus lies on two prominent models - Bard and GPT-4 - and their ability to translate user-provided natural language queries into executable SQL statements. Furthermore, we are interested in how adept these models are at spontaneously generating hypotheses based on an event log. The models are given basic abstractions such as the list of attributes and process variants within the log. For our analysis, we utilize DuckDB SQL language, a choice motivated by its seamless compatibility with the event log structure used by pm4py. In the present state of affairs, it is evident that some amount of domain knowledge is indispensable to ensure correct query formulation. This includes: Figure 6: SQL query generation comparison between GPT-4 and Bard for the “What is the average throughput time when activity ‘Send Fine’ occurs more than 50 days after the start of the case?” query executed against the _Road Traffic_ event log. * Knowledge of SQL, such as the functions needed to calculate timestamps. * An understanding of process mining concepts, such as how to compute a case's throughput time or how to derive the process variant from a list of activities. * Awareness of the event log's key attributes, such as the column that identifies the case, the activity, and the timestamp. Figure 7: SQL query generation comparison between GPT-4 and Bard for the “I want to check the average rework for cases below and above the average throughput time.” query executed against the _Road Traffic_ event log. * Knowledge of the variable name that the query should target. While these prerequisites may require specialized knowledge, they are instrumental in ensuring the accuracy and relevance of the SQL queries generated by the large language models. In our study, we endeavored to assess the ability of large language models to convert natural language queries into SQL. Two distinct queries were used for this purpose on the _Road Traffic_ event log.: 1. What is the average throughput time when activity 'Send Fine' occurs more than 50 days after the start of the case? (Refer to Figure 6 for the full query and the corresponding responses from GPT-4 and Bard). 2. I want to check the average rework for cases below and above the average throughput time (Refer to Figure 7 for the full query and the corresponding responses from GPT-4 and Bard). Our analysis reveals that, given sufficient domain knowledge, GPT-4 has an impressive capability to translate natural language queries into accurate SQL statements. Bard, on the other hand, appears to have significant difficulty making sense of the provided information, often failing to generate executable SQL queries. This discrepancy underscores the importance of adequate domain understanding for successful natural language processing tasks in process mining. and attributes in the log: time:timestamp empty: 0 quantiles: {0.0: Timestamp('2000--03--14 23:00:00+0000', tz='UTC'), 0.25: Timestamp('2003--03--05 16:45:00+0000', tz='UTC'), 0.5: Timestamp('2005--12--21 11:00:00+0000', tz='UTC'), 0.75: Timestamp('2009--01--18 23:00:00+0000', tz='UTC'), 1.0: Timestamp ('2013--04--23 22:00:00+0000', tz='UTC')} amount empty: 233 quantiles: {0.0: 21.0, 0.25: 33.6, 0.5: 38.0, 0.75: 68.77, 1.0: 297.0} article empty: 290 quantiles: {0.0: 7.0, 0.25: 7.0, 0.5: 157.0, 0.75: 157.0, 1.0: 181.0} expense empty: 312 quantiles: {0.0: 0.0, 0.25: 10.0, 0.5: 11.0, 0.75: 14.0625, 1.0: 30.0} paymentAmount empty: 332 quantiles: {0.0: 5.6, 0.25: 33.6, 0.5: 37.25, 0.75: 53.0, 1.0: 275.0} totalPaymentAmount empty: 232 quantiles: {0.0: 0.0, 0.25: 0.0, 0.5: 0.0, 0.75: 36.0, 1.0: 275.0} vehicleClass empty: 290 values: (A; freq. 98) (M; freq. 2) concept:name empty: 0 values: (Create Fine; freq. 100) (Send Fine; freq. 78) ( Payment; freq. 58) (Insert Fine Notification; freq. 57) (Add penalty; freq. 57) (Send for Credit Collection; freq. 36) (Send Appeal to Prefecture; freq. 1) ( Receive Result Appeal from Prefecture; freq. 1) (Notify Result Appeal to Offender; freq. 1) (Insert Date Appeal to Prefecture; freq. 1) org:resource empty: 290 values: (541; freq. 8) (538; freq. 6) (537; freq. 6) (559; freq. 4) (555; freq. 4)...... can you formulate some hypothesis on the given process? please also formulate for every hypothesis a SQL query. Can you provide me a DuckDB SQL query. You should use the EPOCH function of DuckDB to get the timestamp from the date. The data is stored in a Pandas dataframe where each row is an event having the provided attributes (so there are no separate table containing the variant). The dataframe is called \"dataframe\". Please consider the following information: the case identifier is called \"case:concept :name\", the activity is stored inside the attribute \"concept:name\", the timestamp is stored inside the attribute \"time:timestamp\", the resource is stored inside the attribute \"org:resource\". There is not a variant column but that can be obtained as concatenation of the activities of a case. There is not a duration column but that can be obtained as difference between the timestamp of the first and the last event. To explore the potential of large language models in autonomously formulating hypotheses about event data, we posed a specific prompt to both GPT-4 and Bard (refer to Listing 25). This prompt was formulated such that it encouraged the models to generate hypotheses, starting from the knowledge of the attributes and the process variants present in the data. Here are some hypotheses generated by GPT-4: 1. The majority of cases conclude with the payment of fines after the addition of a penalty. This suggests that the imposition of a penalty may be a decisive factor prompting payment. The corresponding SQL query formulated by GPT-4, along with the results derived from its execution, are depicted in Figure 8. 2. The process of appealing to the prefecture does not appear to be a common practice. This indicates that offenders rarely dispute their fines. The provided SQL query for this hypothesis, along with the subsequent results, can be viewed in Figure 9. 3. There may be a correlation between the amount of fines and the frequency of credit collections, with higher fines potentially leading to an increase in credit collection instances. This could be attributed to the difficulty in paying larger fines. The SQL query and results corresponding to this hypothesis are presented in Figure 10. Bard's generated hypotheses included the following: 1. The most common process variant is \"Create Fine \\(\\neg\\to\\) Send Fine \\(\\neg\\to\\) Insert Fine Notification \\(\\neg\\to\\) Add penalty \\(\\neg\\to\\) Send for Credit Collection\". 2. The average payment amount for cases that traverse the complete process appears to be higher compared to cases that are concluded prematurely. 3. The longest durations to complete are typically associated with cases that involve an appeal. Both large language models generated valid hypotheses. However, a critical distinction arises from their ability to translate these hypotheses into executable SQL queries. While GPT-4 demonstrated this capability effectively, Bard did not manage to formulate corresponding SQL queries, emphasizing the advantage of incorporating explicit domain knowledge into the language model. SqL query generated by GPT-4. **Case_With_Penalty_Before_Payment** 22426 Result obtained after executing the SQL query. **Fig. 8**: Usage of GPT-4 to verify the hypothesis number 1. [MISSING_PAGE_EMPTY:46]"
    },
    {
      "title": "5 Related Work",
      "text": "The field of process mining is not isolated, but intersects with various domains such as database technologies, natural language processing (NLP), and the use of large language models. Additionally, it relies heavily on domain knowledge for effective task execution. In the subsequent sections, we explore these intersections and dependencies, providing an overview of the state-of-the-art in these domains and their relevance to process mining. We delve into the interaction of database technologies with process mining (Section 5.1), the intersection of process mining and NLP (Section 5.2), and the importance of domain knowledge in process mining tasks (Section 5.3). This is followed by a thorough examination of the current state of large language models (Section 5.4) and their application within the realm of Business Process Management (Section 5.5). This examination helps illuminate the context and motivation behind our study."
    },
    {
      "title": "Database Technologies For Process Mining",
      "text": "Database technologies play a crucial role in process mining, helping manage the increasing amounts of process-related data. They provide ways to extract and analyze this data, leading to valuable insights. In this section, we delve into several of these technologies and their contributions to process mining. The book Polyvyanyy (2022) considers the recognition and management of core techniques for retrieving and manipulating process-related artifacts. These core techniques are deemed reusable across various contexts and use cases such as process compliance, standardization, and monitoring, among others. By focusing on these reusable techniques, their aim is to increase efficiency and streamline the application of process querying across various projects and disciplines. Another approach Polyvyanyy et al (2017) proposes a framework to guide the creation of process querying methods. This framework serves as a blueprint for managing repositories of executed and designed processes and their relationships. This approach is instrumental in facilitating strategic decision-making, as well as laying the groundwork for the next generation of Business Intelligence platforms. The paper Schonig et al (2016) delve into a more specific solution, introducing a mining approach that works directly on relational event data through conventional SQL queries. By leveraging the power of database technologies, this approach is able to efficiently mine data without limiting the detection of certain control-flow constraints, thus proving to be fast and effective. In Baader and Krcmar (2018), the challenging task of fraud detection in large datasets contained in a SQL database by combining process mining with red flag-based approaches is tackled. This combined technique promises a lower rate of false positives, thereby improving the accuracy of fraud detection. Another consideration in the process mining field is the extraction of event logs from databases, which is not a trivial task and demands substantial domain knowledge de Murillas et al (2019). In response to this, a meta modelis proposed to integrate both process and data perspectives in a highly flexible manner, allowing for multiple views on the database at any given moment. The approach desribed in Esser and Fahland (2021) put forward a novel data model for multi-dimensional event data based on labeled property graphs. This model allows the storing of structural and temporal relations in an integrated, graph-based data structure. Such a system can manage complex, multi-dimensional event data efficiently. A unique and highly specialized process querying language, the Celonis Process Query Language (PQL), is presented in Vogelsang et al (2022). This language, designed specifically for business users, translates process-related business questions into queries, which are then executed on a custom-built query engine. With a wide range of operators and a syntax inspired by SQL, Celonis PQL showcases an effective adaptation of querying language for process-related inquiries."
    },
    {
      "title": "Process Mining And Nlp",
      "text": "In recent years, significant advancements have been made in the field of process mining, with a particular focus on making this technology more accessible to non-technical users. For instance, Barbieri et al (2022) proposed a natural language querying interface aimed at democratizing process mining technology. Their reference architecture integrated classic natural language processing techniques such as entity recognition and semantic parsing with an abstract logical representation for process mining queries. The architecture was interfaced with a commercial tool called Everflow, thus enabling users to retrieve process mining insights through questions in plain English. This approach greatly simplifies the process mining experience for line-of-business professionals. Building upon this work, Kobeissi et al (2023) also acknowledged the necessity of a user-friendly process data querying interface. They recognized the lack of a query language targeted at domain analysts, who might lack experience with database technologies, and therefore proposed a natural language interface. This interface, which uses graph-based storage techniques, interprets a user's natural language query and constructs a corresponding structured query over the stored event data. This solution is particularly beneficial for analysts who wish to explore process execution data without in-depth knowledge of database technologies. Semantic considerations have also been integrated into process mining, with a focus on anomaly detection. van der Aa et al (2021) proposed a method of anomaly detection in process mining that uses the natural language associated with events to identify semantically inconsistent execution patterns. This approach, which contrasts with traditional frequency-based techniques, contributes to a more meaningful identification of potential anomalies. By automatically extracting business objects and actions from textual labels of events and comparing these against a process-independent knowledge base,the authors effectively identify anomalies when process behavior does not align with the semantics. In the realm of chatbot technology, Kecht et al (2023) highlighted the importance of the capability of chatbots to learn and adhere to organizations' business processes. They developed an approach that quantifies chatbots' ability to learn business processes using standardized process mining metrics. This approach was demonstrated on a dataset of customer service conversations from three companies on Twitter, showing how it can quantify a chatbot's ability to learn not only the overall business process but also specific variants."
    },
    {
      "title": "Domain Knowledge In Process Mining Tasks",
      "text": "Domain knowledge provides a wealth of insights that can augment the application of process mining techniques. One of the pivotal works in this context is presented in Schuster et al (2022). The study acknowledges that, while automated filtering of event data is a significant contributor to obtaining better process models, it may often be overly rigorous, leading to the removal of relevant data. To mitigate this, the authors introduce a new group of discovery algorithms that leverage domain knowledge in conjunction with event data. This synergistic approach is structured systematically via a taxonomy that classifies and compares existing strategies, offering a comprehensive review of domain knowledge-exploiting process discovery methodologies. In the paper Schuster et al (2023), the authors introduce _Cortado_, a software tool designed specifically for interactive process discovery, a vital branch within process mining. Process discovery involves the data-driven exploration of operational processes. By analyzing event data that record historical process executions, process discovery algorithms are able to generate process models that elucidate the interplay between various activities. Such models become indispensable artifacts used across multiple process mining techniques. However, conventional process discovery methods often function like a black-box approach and may produce models of poor quality from event data. This is where Cortado steps in, taking a novel approach to process discovery by allowing users to progressively learn and refine process models from event data in an interactive manner. Through this approach, Cortado successfully leverages domain knowledge and data-derived insights to develop more nuanced process models. Furthering the notion of domain knowledge incorporation, the research in Dixit et al (2015) addresses the necessity of leveraging domain expertise to refine discovered process models. The authors introduce a modification algorithm that adjusts a discovered process model based on domain knowledge. This work stands as a significant stride towards enhancing process discovery by ensuring that the outputs align more closely with domain expert knowledge, thereby fostering a balance between data-driven and expertise-guided process discovery. Lastly, the paper in Baier et al (2014) presents an approach to align the levels of abstraction in event logs with business activities using extracted domain knowledge. The authors' method allows for n:m relations between events and activities and supports concurrency, addressing common issues encountered when attempting to abstract event logs to match business activities. This research provides a critical bridge between low-level event data and higher-level business process activities, facilitating a more meaningful interpretation of discovered process models."
    },
    {
      "title": "Large Language Models",
      "text": "In the rapidly progressing field of natural language processing (NLP), one of the most significant developments of recent years has been the advent of large language models (LLMs). These models, such as BERT, GPT-2, GPT-3, and T5, represent a transformative shift in the domain, harnessing the power of deep learning and the wealth of available linguistic data to accomplish a broad spectrum of tasks. This subsection provides an overview of the genesis and evolution of these influential models, along with a focus on their computational and reasoning capabilities. Furthermore, we explore the motivation and progression of specific LLMs like ChatGPT as potent question-answering systems across multiple prompts."
    },
    {
      "title": "The Genesis Of Large Language Models",
      "text": "The field of Natural Language Processing (NLP) has been primarily concerned with understanding and generating human language. Early attempts at language modeling were based on statistical approaches, like n-gram models, which consider a fixed number of previous words to predict the next word in a sentence. However, these models suffer from the curse of dimensionality and fail to capture long-term dependencies in text. The introduction of neural network-based approaches, such as feed-forward neural probabilistic language models Gangireddy et al (2014) and recurrent neural networks (RNNs) Jaech et al (2016), was a significant leap forward. These models can theoretically capture arbitrarily long sequences and represent more complex syntactic and semantic relationships. However, in practice, RNNs and their variants (e.g., LSTM, GRU) struggle with long-term dependencies due to issues like vanishing and exploding gradients."
    },
    {
      "title": "Birth Of Transformer Models",
      "text": "The limitations of RNNs were largely overcome by the advent of the Transformer architecture, introduced in the paper Vaswani et al (2017). The Transformer model is based on self-attention mechanisms and foregoes recurrence entirely. It allows for parallelizable computation and better handling of long-range dependencies."
    },
    {
      "title": "Bert, Gpt-2, And T5",
      "text": "BERT (Bidirectional Encoder Representations from Transformers), introduced by Google in 2018, is a Transformer-based model trained on a large corpus of text data. Unlike previous models, BERT Devlin et al (2019) considers context from both directions (left and right of a word) in all layers, giving it a deeper sense of language context and flow. OpenAI introduced GPT-2 (Generative Pretrained Transformer 2) in 20196, focusing on generating human-like text. GPT-2 differs from BERT in its training objective. While BERT is a bidirectional model, GPT-2 is unidirectional (or causal), meaning it predicts the next word based on the preceding words, making it suitable for text generation tasks. Footnote 6: [https://github.com/openai/gpt-2](https://github.com/openai/gpt-2) T5 (Text-to-Text Transfer Transformer)7, introduced by Google in 2019, adopted a unified text-to-text approach where every NLP task is cast as a text generation problem, making the model versatile across multiple tasks. Footnote 7: [https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html)"
    },
    {
      "title": "5.4.4 Chatgpt And Its Motivation",
      "text": "ChatGPT is a variant of the GPT model developed by OpenAI. It is specifically fine-tuned for generating conversational responses, serving as a powerful tool for tasks like drafting emails, writing code, answering questions, tutoring, language translation, and even simulating characters for video games. The model was trained using Reinforcement Learning from Human Feedback (RLHF), using a dataset of dialogues where AI trainers provided both sides of a conversation and sometimes had access to model-written suggestions. The motivation behind ChatGPT was to build an AI system that can generate useful and coherent responses over multiple conversational turns, instead of focusing on individual responses. This has involved addressing challenges such as providing detailed responses, maintaining the context of a conversation, and ensuring that the model doesn't generate harmful or misleading outputs. Despite these challenges, ChatGPT exemplifies the potential of language models in making substantial contributions to many areas of life and work."
    },
    {
      "title": "5.4.5 Computing And Reasoning Capabilities",
      "text": "Large language models like BERT, GPT-3, and T5, have revolutionized the field of natural language processing with their capabilities to understand and generate human-like text. The ability to predict contextually relevant words, translate languages, and even code comes from these models' capacity to identify patterns in extensive textual data. They have been trained on enormous datasets and, as a result, carry within them a broad range of knowledge, from trivial facts to complex concepts. From a computational perspective, these models are capable of more than just text generation and comprehension. They can perform mathematical computations, solve equations, and even tackle problems involving logic and reasoning Bommasani et al (2021), all based on the patterns learned during their training phase. While it's true that these models can simulate reasoning through the recognition of data patterns Clark et al (2020), this is different from the way humans reason. These models don't possess consciousness or understanding; instead, they generate outputs based on statistical patterns. However, it's worth noting that the \"reasoning\" exhibited by these models, despite its fundamental difference from human cognition, is impressive and has wide-ranging practical applications. Large language models are powerful tools, capable of tackling diverse tasks, but they do have limitations. They lack the ability to access real-time knowledge beyond their training data, and their capability to verify information is limited. Nevertheless, they are a testament to the progress in the field and the potential of future developments."
    },
    {
      "title": "Large Language Models And Business Process Management",
      "text": "This subsection explores the promising potential and ongoing advancements of Large Language Models (LLMs), their application in Business Process Management (BPM), and the challenges that need to be addressed to effectively utilize these models in the BPM context. Large language models (LLMs), such as GPT-3, have shown remarkable capabilities in a broad array of natural language processing (NLP) tasks, extending their usefulness beyond text generation into more specialized fields, including business process management (BPM). As detailed in Busch et al (2023), these LLMs have been effectively utilized for predictive process monitoring and process extraction from text. However, the application of such models typically demands fine-tuning, a process that requires an extensive amount of suitable training data. One innovative approach to bypass this necessity is prompt engineering, which exploits the pre-training of LLMs without the need for additional fine-tuning. This paper outlines a research agenda for incorporating prompt engineering into BPM, thereby broadening the capabilities of LLMs within this discipline. Moreover, the study presented in Vidgof et al (2023) emphasizes the lack of systematic investigation into the opportunities offered by LLMs in BPM. Notwithstanding the impressive progress LLMs have made on various tasks, their application to the BPM lifecycle remains less explored. This research foregrounds several BPM tasks and highlights six research directions that call for attention when using LLMs, providing usage guidelines for practitioners. In Klievtsova et al (2023), the authors address the rising interest in the use of chatbots, like ChatGPT, for Business Process Management (BPM) applications. The authors aim to systematically assess existing chatbots for their capacity to support conversational process modelling, a critical function in process-oriented capabilities. They commence by identifying application scenarios across the process life cycle and then conduct a systematic literature review on conversational process modelling. The outcome of this review is a taxonomy that serves as an input for pinpointing application scenarios for conversational process modelling. These scenarios include the paraphrasing and improvement of process descriptions. The authors evaluate these application scenarios for existing chatbots using a real-world test set derived from the higher education domain. This test set comprises process descriptions, their corresponding process models, and an evaluation of the model quality. The authors leverage the insights from the literature review and the scenario analyses to provide practical implications for the usage and potential avenues for further development of conversational process modelling. In our previous work Berti et al (2023), we performed a first exploration of the usage of Large Language Models (LLMs) in the domain of process mining. A key challenge we addressed was the size constraints that limited the amount of data we could feed into the LLM. To overcome this, we first proposed a methodology to abstract information from standard process mining artifacts. This abstraction allowed us to distill complex data into a more concise format that was manageable for the LLM. Secondly, we developed strategic prompts that guided the LLMs to generate insightful and relevant responses from the abstracted inputs. However, we did not cover more advanced abstractions (machine learning features, object-centric event logs/process models,...) or multi-prompt strategies. Also, the evaluation was limited to the GPT-4 large language model."
    },
    {
      "title": "References",
      "text": "* van der Aa et al (2021) van der Aa H, Rebmann A, Leopold H (2021) Natural language-based detection of semantic execution anomalies in event logs. Inf Syst 102:101824 * Aagesen and Krogstie (2015) Aagesen G, Krogstie J (2015) BPMN 2.0 for modeling business processes. In: vom Brocke J, Rosemann M (eds) Handbook on Business Process Management 1, Introduction, Methods, and Information Systems, 2nd Ed. International Handbooks on Information Systems, Springer, p 219-250, URL [https://doi.org/10.1007/978-3-642-45100-3_10](https://doi.org/10.1007/978-3-642-45100-3_10) * van der Aalst WMP (1998) van der Aalst WMP (1998) The application of petri nets to workflow management. J Circuits Syst Comput 8(1):21-66. URL [https://doi.org/10.1142/S0218126698000043](https://doi.org/10.1142/S0218126698000043) * Data Science in Action, Second Edition. Springer, URL [https://doi.org/10.1007/978-3-662-49851-4](https://doi.org/10.1007/978-3-662-49851-4) * van der Aalst WMP and Berti (2020) van der Aalst WMP, Berti A (2020) Discovering object-centric petri nets. Fundam Informaticae 175(1-4):1-40. URL [https://doi.org/10.3233/FI-2020-1946](https://doi.org/10.3233/FI-2020-1946) * van der Aalst WMP et al (2004) van der Aalst WMP, Weijters T, Maruster L (2004) Workflow mining: Discovering process models from event logs. IEEE Trans Knowl Data Eng 16(9):1128-1142. URL [https://doi.org/10.1109/TKDE.2004.47](https://doi.org/10.1109/TKDE.2004.47) * Acampora et al (2017) Acampora G, Vitiello A, Stefano BND, et al (2017) IEEE 1849: The XES standard: The second IEEE standard sponsored by IEEE computational intelligence society [society briefs]. IEEE Comput Intell Mag 12(2):4-8. URL [https://doi.org/10.1109/MCI.2017.2670420](https://doi.org/10.1109/MCI.2017.2670420) * 20th International Conference, ICSOC 2022, Seville, Spain, November 29 - December 2, 2022, Proceedings, Lecture Notes in Computer Science, vol 13740. Springer, pp 36-53, URL [https://doi.org/10.1007/978-3-031-20984-0_3](https://doi.org/10.1007/978-3-031-20984-0_3) * Adams et al (2022b) Adams JN, Schuster D, Schmitz S, et al (2022b) Defining cases and variants for object-centric event data. In: Burattin A, Polyvyanyy A, Weber B (eds) 4th International Conference on Process Mining, ICPM 2022, Bolzano, Italy, October 23-28, 2022. IEEE, pp 128-135, URL [https://doi.org/10.1109/ICPM57379.2022.9980730](https://doi.org/10.1109/ICPM57379.2022.9980730) * Baader and Krcmar (2018) Baader G, Krcmar H (2018) Reducing false positives in fraud detection: Combining the red flag approach with process mining. Int J Account Inf Syst 31:1-16* Baier et al (2014) Baier T, Mendling J, Weske M (2014) Bridging abstraction layers in process mining. Inf Syst 46:123-139 * Barbieri et al (2022) Barbieri L, Madeira E, Stroeh K, et al (2022) A natural language querying interface for process mining. Journal of Intelligent Information Systems pp 1-30 * 35th International Conference, CAiSE 2023, Zaragoza, Spain, June 12-16, 2023, Proceedings, Lecture Notes in Computer Science, vol 13901. Springer, pp 417-433, URL [https://doi.org/10.1007/978-3-031-34560-9_25](https://doi.org/10.1007/978-3-031-34560-9_25) * Berti and van der Aalst WMP (2023) Berti A, van der Aalst WMP (2023) OC-PM: analyzing object-centric event logs and process models. Int J Softw Tools Technol Transf 25(1):1-17. URL [https://doi.org/10.1007/s10009-022-00668-w](https://doi.org/10.1007/s10009-022-00668-w) * Berti et al (2019) Berti A, van Zelst SJ, van der Aalst WMP (2019) Process mining for python (pm4py): Bridging the gap between process- and data science. In: Proceedings of the 1st International Conference on Process Mining (ICPM 2019), Demo Track. CEUR, pp 13-16, URL [https://ceur-ws.org/Vol-2374/paper4.pdf](https://ceur-ws.org/Vol-2374/paper4.pdf) * Berti et al (2023a) Berti A, Herforth J, Qafari MS, et al (2023a) Graph-based feature extraction on object-centric event logs. International Journal of Data Science and Analytics URL [https://doi.org/10.1007/s41060-023-00428-2](https://doi.org/10.1007/s41060-023-00428-2) * Berti et al (2023b) Berti A, Schuster D, van der Aalst WMP (2023b) Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study. CoRR abs/2307.02194. URL [https://doi.org/10.48550/arXiv.2307.02194](https://doi.org/10.48550/arXiv.2307.02194), [https://arxiv.org/abs/2307.02194](https://arxiv.org/abs/2307.02194) * Bommasani et al (2021) Bommasani R, Hudson DA, Adeli E, et al (2021) On the opportunities and risks of foundation models. CoRR abs/2108.07258. URL [https://arxiv.org/abs/2108.07258](https://arxiv.org/abs/2108.07258), [https://arxiv.org/abs/2108.07258](https://arxiv.org/abs/2108.07258) * 24th International Conference, BPMDS 2023, and 28th International Conference, EMMSAD 2023, Zaragoza, Spain, June 12-13, 2023, Proceedings, Lecture Notes in Business Information Processing, vol 479. Springer, pp 3-11, URL [https://doi.org/10.1007/978-3-031-34241-7_1](https://doi.org/10.1007/978-3-031-34241-7_1) * Clark et al (2020) Clark P, Tafjord O, Richardson K (2020) Transformers as soft reasoners over language. In: Bessiere C (ed) Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020. ijcai.org, pp 3882-3890, URL [https://doi.org/10.24963/ijcai.2020/537](https://doi.org/10.24963/ijcai.2020/537) * Devlin et al (2019) Devlin J, Chang M, Lee K, et al (2019) BERT: pre-training of deep bidirectional transformers for language understanding. In: Burstein J, Doran C, Solorio T (eds) Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers). Association for Computational Linguistics, pp 4171-4186, URL [https://doi.org/10.18653/v1/n19-1423](https://doi.org/10.18653/v1/n19-1423) * Dijkman et al (2008) Dijkman RM, Dumas M, Ouyang C (2008) Semantics and analysis of business process models in BPMN. Inf Softw Technol 50(12):1281-1294. URL [https://doi.org/10.1016/j.infsof.2008.02.006](https://doi.org/10.1016/j.infsof.2008.02.006) * Dixit et al (2015) Dixit PM, Buijs JCAM, van der Aalst WMP, et al (2015) Enhancing process mining results using domain knowledge. In: Proceedings of the 5th International Symposium on Data-driven Process Discovery and Analysis (SIMPDA 2015). CEUR-WS.org, pp 79-94 * Esser and Fahland (2021) Esser S, Fahland D (2021) Multi-dimensional event data in graph databases. J Data Semant 10(1-2):109-141 * Gangireddy et al (2014) Gangireddy SR, McInnes F, Renals S (2014) Feed forward pre-training for recurrent neural network language models. In: Li H, Meng HM, Ma B, et al (eds) INTERSPEECH 2014, 15th Annual Conference of the International Speech Communication Association, Singapore, September 14-18, 2014. ISCA, pp 2620-2624, URL [https://doi.org/10.21437/Interspeech.2014-561](https://doi.org/10.21437/Interspeech.2014-561) * ADBIS 2021 Short Papers, Doctoral Consortium and Workshops: DOING, SIMPDA, MADEISD, MegaData, CAoNS, Tartu, Estonia, August 24-26, 2021, Proceedings, Communications in Computer and Information Science, vol 1450. Springer, pp 169-175, URL [https://doi.org/10.1007/978-3-030-85082-1_16](https://doi.org/10.1007/978-3-030-85082-1_16) * Jaech and Heck and Ostendorf (2016) Jaech A, Heck LP, Ostendorf M (2016) Domain adaptation of recurrent neural networks for natural language understanding. In: Morgan N (ed) Interspeech 2016, 17th Annual Conference of the International Speech Communication Association, San Francisco, CA, USA, September 8-12, 2016. ISCA, pp 690-694, URL [https://doi.org/10.21437/Interspeech.2016-1598](https://doi.org/10.21437/Interspeech.2016-1598) * Junior et al (2020) Junior SB, Ceravolo P, Damiani E, et al (2020) Evaluating trace encoding methods in process mining. In: Bowles J, Broccia G, Nanni M (eds) FromData to Models and Back - 9th International Symposium, DataMod 2020, Virtual Event, October 20, 2020, Revised Selected Papers, Lecture Notes in Computer Science, vol 12611. Springer, pp 174-189, URL [https://doi.org/10.1007/978-3-030-70650-0_11](https://doi.org/10.1007/978-3-030-70650-0_11) * Kalenkova et al (2017) Kalenkova AA, van der Aalst WMP, Lomazova IA, et al (2017) Process mining using BPMN: relating event logs and process models. Softw Syst Model 16(4):1019-1048. URL [https://doi.org/10.1007/s10270-015-0502-0](https://doi.org/10.1007/s10270-015-0502-0) * Kalenkova et al (2019) Kalenkova AA, Burattin A, de Leoni M, et al (2019) Discovering high-level BPMN process models from event data. Bus Process Manag J 25(5):995-1019. URL [https://doi.org/10.1108/BPMJ-02-2018-0051](https://doi.org/10.1108/BPMJ-02-2018-0051) * Kecht et al (2023) Kecht C, Egger A, Kratsch W, et al (2023) Quantifying chatbots' ability to learn business processes. Inf Syst 113:102176 * Klievtsova et al (2023) Klievtsova N, Benzin J, Kampik T, et al (2023) Conversational process modelling: State of the art, applications, and implications in practice. CoRR abs/2304.11065. URL [https://doi.org/10.48550/arXiv.2304.11065](https://doi.org/10.48550/arXiv.2304.11065), [https://arxiv.org/abs/2304.11065](https://arxiv.org/abs/2304.11065) * Kobeissi et al (2023) Kobeissi M, Assy N, Gaaloul W, et al (2023) Natural language querying of process execution data. Inf Syst 116:102227 * A constructive approach. In: Colom JM, Desel J (eds) Application and Theory of Petri Nets and Concurrency - 34th International Conference, PETRI NETS 2013, Milan, Italy, June 24-28, 2013. Proceedings, Lecture Notes in Computer Science, vol 7927. Springer, pp 311-329, URL [https://doi.org/10.1007/978-3-642-38697-8_17](https://doi.org/10.1007/978-3-642-38697-8_17) * de Leoni et al (2016) de Leoni M, van der Aalst WMP, Dees M (2016) A general process mining framework for correlating, predicting and clustering dynamic behavior based on event logs. Inf Syst 56:235-257. URL [https://doi.org/10.1016/j.is.2015.07.003](https://doi.org/10.1016/j.is.2015.07.003) * Maggi et al (2011) Maggi FM, Mooij AJ, van der Aalst WMP (2011) User-guided discovery of declarative process models. In: Proceedings of the IEEE Symposium on Computational Intelligence and Data Mining, CIDM 2011, part of the IEEE Symposium Series on Computational Intelligence 2011, April 11-15, 2011, Paris, France. IEEE, pp 192-199, URL [https://doi.org/10.1109/CIDM.2011.5949297](https://doi.org/10.1109/CIDM.2011.5949297) * de Murillas et al (2019) de Murillas EGL, Reijers HA, van der Aalst WMP (2019) Connecting databases with process mining: a meta model and toolset. Softw Syst Model 18(2):1209-1247* Ouyang et al (2006) Ouyang C, Dumas M, ter Hofstede AHM, et al (2006) From BPMN process models to BPEL web services. In: 2006 IEEE International Conference on Web Services (ICWS 2006), 18-22 September 2006, Chicago, Illinois, USA. IEEE Computer Society, pp 285-292, URL [https://doi.org/10.1109/ICWS.2006.67](https://doi.org/10.1109/ICWS.2006.67) * Pohl and Berti (2023) Pohl T, Berti A (2023) (Un)Fair Process Mining Event Logs. [https://doi.org/10.5281/zenodo.8059488](https://doi.org/10.5281/zenodo.8059488), [https://doi.org/10.5281/zenodo.8059488](https://doi.org/10.5281/zenodo.8059488), [Online; published on 2023-06-23] * ICPM 2022 International Workshops, Bozen-Bolzano, Italy, October 23-28, 2022, Revised Selected Papers, Lecture Notes in Business Information Processing, vol 468. Springer, pp 101-113, URL [https://doi.org/10.1007/978-3-031-27815-0_8](https://doi.org/10.1007/978-3-031-27815-0_8) * Pohl et al (2023) Pohl T, Berti A, Qafari MS, et al (2023) A collection of simulated event logs for fairness assessment in process mining. CoRR abs/2306.11453. URL [https://doi.org/10.48550/arXiv.2306.11453](https://doi.org/10.48550/arXiv.2306.11453), [https://arxiv.org/abs/2306.11453](https://arxiv.org/abs/2306.11453) * Polyvyanyy (2022) Polyvyanyy A (2022) Process Querying Methods. Springer * Polyvyanyy et al (2017) Polyvyanyy A, Ouyang C, Barros A, et al (2017) Process querying: Enabling business intelligence through query-based process analytics. Decis Support Syst 100:41-56 * Confederated International Conferences: CoopIS, ODBASE, C&TC 2019, Rhodes, Greece, October 21-25, 2019, Proceedings, Lecture Notes in Computer Science, vol 11877. Springer, pp 182-192, URL [https://doi.org/10.1007/978-3-030-33246-4_11](https://doi.org/10.1007/978-3-030-33246-4_11) * CAiSE Forum 2021, Melbourne, VIC, Australia, June 28 - July 2, 2021, Proceedings, Lecture Notes in Business Information Processing, vol 424. Springer, pp 55-63, URL [https://doi.org/10.1007/978-3-030-79108-7_7](https://doi.org/10.1007/978-3-030-79108-7_7) * Schonig et al (2016) Schonig S, Rogge-Solti A, Cabanillas C, et al (2016) Efficient and customisable declarative process mining with SQL. In: Advanced Information Systems Engineering, LNCS, vol 9694. Springer, pp 290-305 * Schuster et al (2022) Schuster D, van Zelst SJ, van der Aalst WMP (2022) Utilizing domain knowledge in data-driven process discovery: A literature review. Comput Ind * Schuster et al (2023) Schuster D, van Zelst SJ, van der Aalst WMP (2023) Cortado: A dedicated process mining tool for interactive process discovery. SoftwareX 22:101373. URL [https://doi.org/10.1016/j.softx.2023.101373](https://doi.org/10.1016/j.softx.2023.101373) * Stertz et al (2020) Stertz F, Mangler J, Rinderle-Ma S (2020) Temporal conformance checking at runtime based on time-infused process models. CoRR abs/2008.07262. URL [https://arxiv.org/abs/2008.07262](https://arxiv.org/abs/2008.07262) * Vaswani et al (2017) Vaswani A, Shazeer N, Parmar N, et al (2017) Attention is all you need. In: Guyon I, von Luxburg U, Bengio S, et al (eds) Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pp 5998-6008, URL [https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html) * Vidgof et al (2023) Vidgof M, Bachhofner S, Mendling J (2023) Large language models for business process management: Opportunities and challenges. CoRR abs/2304.04309. URL [https://doi.org/10.48550/arXiv.2304.04309](https://doi.org/10.48550/arXiv.2304.04309), [https://arxiv.org/abs/2304.04309](https://arxiv.org/abs/2304.04309) * Vogelgesang et al (2022) Vogelgesang T, Ambrosy J, Becher D, et al (2022) Celonis PQL: A query language for process mining. In: Process Querying Methods. Springer, p 377-408 * Weijters (2011) Weijters AJMM, Ribeiro JTS (2011) Flexible heuristics miner (FHM). In: Proceedings of the IEEE Symposium on Computational Intelligence and Data Mining, CIDM 2011, part of the IEEE Symposium Series on Computational Intelligence 2011, April 11-15, 2011, Paris, France. IEEE, pp 310-317, URL [https://doi.org/10.1109/CIDM.2011.5949453](https://doi.org/10.1109/CIDM.2011.5949453) * Zandkarimi et al (2020) Zandkarimi F, Rehse J, Soudmand P, et al (2020) A generic framework for trace clustering in process mining. In: van Dongen BF, Montali M, Wynn MT (eds) 2nd International Conference on Process Mining, ICPM 2020, Padua, Italy, October 4-9, 2020. IEEE, pp 177-184, URL [https://doi.org/10.1109/ICPM49681.2020.00034](https://doi.org/10.1109/ICPM49681.2020.00034)"
    }
  ]
}
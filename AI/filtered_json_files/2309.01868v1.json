{
  "title": "On the Planning, Search, and Memorization Capabilities of Large Language Models",
  "authors": [
    "Yunhao Yang",
    "Anshul Tomar"
  ],
  "abstract": "\n The rapid advancement of large language models, such as the Generative Pretrained Transformer (GPT) series, has had significant implications across various disciplines. In this study, we investigate the potential of the state-of-the-art large language model (GPT-4) for planning tasks. We explore its effectiveness in multiple planning subfields, highlighting both its strengths and limitations. Through a comprehensive examination, we identify areas where large language models excel in solving planning problems and reveal the constraints that limit their applicability. Our empirical analysis focuses on GPT-4's performance in planning domain extraction, graph search path planning, and adversarial planning. We then propose a way of fine-tuning a domain-specific large language model to improve its Chain of Thought (CoT) capabilities for the above-mentioned tasks. The results provide valuable insights into the potential applications of large language models in the planning domain and pave the way for future research to overcome their limitations and expand their capabilities. \n",
  "references": [
    {
      "id": null,
      "title": "On the Planning, Search, and Memorization Capabilities of Large Language Models",
      "authors": [
        "Yunhao Yang",
        "Anshul Tomar"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Language models are few-shot learners",
      "authors": [
        "B Tom",
        "Benjamin Brown",
        "Nick Mann",
        "Melanie Ryder",
        "Jared Subbiah",
        "Prafulla Kaplan",
        "Arvind Dhariwal",
        "Pranav Neelakantan",
        "Girish Shyam",
        "Amanda Sastry",
        "Sandhini Askell",
        "Ariel Agarwal",
        "Gretchen Herbert-Voss",
        "Tom Krueger",
        "Rewon Henighan",
        "Aditya Child",
        "Daniel M Ramesh",
        "Jeffrey Ziegler",
        "Clemens Wu",
        "Christopher Winter",
        "Mark Hesse",
        "Eric Chen",
        "Mateusz Sigler",
        "Scott Litwin",
        "Benjamin Gray",
        "Jack Chess",
        "Christopher Clark",
        "Sam Berner",
        "Alec Mccandlish",
        "Ilya Radford",
        "Dario Sutskever",
        "Amodei"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Medically aware gpt-3 as a data generator for medical dialogue summarization",
      "authors": [
        "Bharath Chintagunta",
        "Namit Katariya",
        "Xavier Amatriain",
        "Anitha Kannan"
      ],
      "year": "2021",
      "venue": "Machine Learning for Healthcare Conference",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "An introduction to the planning domain definition language",
      "authors": [
        "Patrik Haslum",
        "Nir Lipovetzky",
        "Daniele Magazzeni",
        "Christian Muise"
      ],
      "year": "2019",
      "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Language models as zeroshot planners: Extracting actionable knowledge for embodied agents",
      "authors": [
        "Wenlong Huang",
        "Pieter Abbeel",
        "Deepak Pathak",
        "Igor Mordatch"
      ],
      "year": "2022",
      "venue": "International Conference on Machine Learning",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Inner monologue: Embodied reasoning through planning with language models",
      "authors": [
        "Wenlong Huang",
        "Fei Xia",
        "Ted Xiao",
        "Harris Chan",
        "Jacky Liang",
        "Pete Florence",
        "Andy Zeng",
        "Jonathan Tompson",
        "Igor Mordatch",
        "Yevgen Chebotar",
        "Pierre Sermanet",
        "Tomas Jackson",
        "Noah Brown",
        "Linda Luu",
        "Sergey Levine",
        "Karol Hausman",
        "Brian Ichter"
      ],
      "year": "2022",
      "venue": "Inner monologue: Embodied reasoning through planning with language models",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "Do as I can, not as I say: Grounding language in robotic affordances",
      "authors": [
        "Brian Ichter",
        "Anthony Brohan",
        "Yevgen Chebotar",
        "Chelsea Finn",
        "Karol Hausman",
        "Alexander Herzog",
        "Daniel Ho",
        "Julian Ibarz",
        "Alex Irpan",
        "Eric Jang",
        "Ryan Julian",
        "Dmitry Kalashnikov",
        "Sergey Levine",
        "Yao Lu",
        "Carolina Parada",
        "Kanishka Rao",
        "Pierre Sermanet",
        "Alexander Toshev",
        "Vincent Vanhoucke",
        "Fei Xia",
        "Ted Xiao",
        "Peng Xu",
        "Mengyuan Yan",
        "Noah Brown",
        "Michael Ahn",
        "Omar Cortes",
        "Nicolas Sievers",
        "Clayton Tan",
        "Sichun Xu",
        "Diego Reyes",
        "Jarek Rettinghouse",
        "Jornell Quiambao",
        "Peter Pastor",
        "Linda Luu",
        "Kuang-Huei Lee",
        "Yuheng Kuang",
        "Sally Jesmonth",
        "J Nikhil",
        "Kyle Joshi",
        "Rosario Jeffrey",
        "Jasmine Jauregui Ruano",
        "Keerthana Hsu",
        "Byron Gopalakrishnan",
        "Andy David",
        "Chuyuan Kelly Zeng",
        "Fu"
      ],
      "year": "2022",
      "venue": "Conference on Robot Learning",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "Thus spoke gpt-3: Interviewing a large-language model on climate finance",
      "authors": [
        "Markus Leippold"
      ],
      "year": "2023",
      "venue": "Finance Research Letters",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "On grounded planning for embodied tasks with language models",
      "authors": [
        "Chengsong Bill Yuchen Lin",
        "Qian Huang",
        "Wenda Liu",
        "Sam Gu",
        "Xiang Sommerer",
        "Ren"
      ],
      "year": "2023",
      "venue": "AAAI Conference on Artificial Intelligence",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Capabilities of gpt-4 on medical challenge problems",
      "authors": [
        "Harsha Nori",
        "Nicholas King",
        "Scott Mayer Mckinney",
        "Dean Carignan",
        "Eric Horvitz"
      ],
      "year": "2023",
      "venue": "Capabilities of gpt-4 on medical challenge problems",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "GPT-4 technical report",
      "authors": [],
      "year": "2023",
      "venue": "GPT-4 technical report",
      "doi": "10.48550/arXiv.2303.08774"
    },
    {
      "id": "b10",
      "title": "Alpaca-cot: An instruction fine-tuning platform with instruction data collection and unified large language models interface",
      "authors": [
        "Zheng Lin",
        "Qingyi Si"
      ],
      "year": "2023",
      "venue": "Alpaca-cot: An instruction fine-tuning platform with instruction data collection and unified large language models interface",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action",
      "authors": [
        "Dhruv Shah",
        "Blazej Osinski",
        "Brian Ichter",
        "Sergey Levine"
      ],
      "year": "2022",
      "venue": "Conference on Robot Learning",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Flan-moe: Scaling instruction-finetuned language models with sparse mixture of experts",
      "authors": [
        "Sheng Shen",
        "Le Hou",
        "Yanqi Zhou",
        "Nan Du",
        "Shayne Longpre",
        "Jason Wei",
        "Hyung Won Chung",
        "Barret Zoph",
        "William Fedus",
        "Xinyun Chen",
        "Tu Vu",
        "Yuexin Wu",
        "Wuyang Chen",
        "Albert Webson",
        "Yunxuan Li",
        "Vincent Zhao",
        "Hongkun Yu",
        "Kurt Keutzer",
        "Trevor Darrell",
        "Denny Zhou"
      ],
      "year": "",
      "venue": "Flan-moe: Scaling instruction-finetuned language models with sparse mixture of experts",
      "doi": "10.48550/arXiv.2305.14705"
    },
    {
      "id": "b13",
      "title": "Biomegatron: Larger biomedical domain language model",
      "authors": [
        "Hoo-Chang Shin",
        "Yang Zhang",
        "Evelina Bakhturina",
        "Raul Puri",
        "Mostofa Patwary",
        "Mohammad Shoeybi",
        "Raghav Mani"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2020.emnlp-main.379"
    },
    {
      "id": "b14",
      "title": "Progprompt: Generating situated robot task plans using large language models",
      "authors": [
        "Ishika Singh",
        "Valts Blukis",
        "Arsalan Mousavian",
        "Ankit Goyal",
        "Danfei Xu",
        "Jonathan Tremblay",
        "Dieter Fox",
        "Jesse Thomason",
        "Animesh Garg"
      ],
      "year": "2023",
      "venue": "IEEE International Conference on Robotics and Automation",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "Llmplanner: Few-shot grounded planning for embodied agents with large language models",
      "authors": [
        "Hee Chan",
        "Jiaman Song",
        "Clayton Wu",
        "Brian M Washington",
        "Wei-Lun Sadler",
        "Yu Chao",
        "Su"
      ],
      "year": "",
      "venue": "Llmplanner: Few-shot grounded planning for embodied agents with large language models",
      "doi": "10.48550/arXiv.2212.04088"
    },
    {
      "id": "b16",
      "title": "Large language models in medicine",
      "authors": [
        "Arun James Thirunavukarasu",
        "Darren Shu",
        "Jeng Ting",
        "Kabilan Elangovan",
        "Laura Gutierrez",
        "Ting Fang Tan",
        "Daniel Shu",
        "Wei Ting"
      ],
      "year": "2023",
      "venue": "Nature Medicine",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)",
      "authors": [
        "Karthik Valmeekam",
        "Alberto Olmo",
        "Sarath Sreedharan",
        "Subbarao Kambhampati"
      ],
      "year": "2022",
      "venue": "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Bloomberggpt: A large language model for finance",
      "authors": [
        "Shijie Wu",
        "Ozan Irsoy",
        "Steven Lu",
        "Vadim Dabravolski",
        "Mark Dredze",
        "Sebastian Gehrmann",
        "Prabhanjan Kambadur",
        "David S Rosenberg",
        "Gideon Mann"
      ],
      "year": "",
      "venue": "Bloomberggpt: A large language model for finance",
      "doi": "10.48550/arXiv.2303.17564"
    },
    {
      "id": "b19",
      "title": "Automaton-based representations of task knowledge from generative language models",
      "authors": [
        "Yunhao Yang",
        "Jean-Raphaël Gaglione",
        "Cyrus Neary",
        "Ufuk Topcu"
      ],
      "year": "",
      "venue": "Automaton-based representations of task knowledge from generative language models",
      "doi": "10.48550/arXiv.2212.01944"
    }
  ],
  "sections": [
    {
      "title": "On The Planning, Search, And Memorization Capabilities Of Large Language Models",
      "text": "Yunhao Yang Department of Computer Science University of Texas at Austin Austin, TX 78705 yunhaoyang234@utexas.edu &Anshul Tomar Department of Computer Science University of Texas at Austin Austin, TX 78705 anshulmanas@gmail.com"
    },
    {
      "title": "Abstract",
      "text": "The rapid advancement of large language models, such as the Generative Pretrained Transformer (GPT) series, has had significant implications across various disciplines. In this study, we investigate the potential of the state-of-the-art large language model (GPT-4) for planning tasks. We explore its effectiveness in multiple planning subfields, highlighting both its strengths and limitations. Through a comprehensive examination, we identify areas where large language models excel in solving planning problems and reveal the constraints that limit their applicability. Our empirical analysis focuses on GPT-4's performance in planning domain extraction, graph search path planning, and adversarial planning. We then propose a way of fine-tuning a domain-specific large language model to improve its Chain of Thought (CoT) capabilities for the above-mentioned tasks. The results provide valuable insights into the potential applications of large language models in the planning domain and pave the way for future research to overcome their limitations and expand their capabilities."
    },
    {
      "title": "1 Introduction",
      "text": "The fast growth of large language models, such as the Generative Pretrained Transformer (GPT) series, significantly impacts various disciplines, from natural language processing and artificial intelligence to healthcare (Chintagunta et al., 2021; Nori et al., 2023; Thirunavukarasu et al., 2023), finance (Leipold, 2023; Wu et al., 2023), and beyond (Shin et al., 2020). These models have revolutionized tasks such as machine translation, sentiment analysis, text summarization, and question-answering, enhancing human-computer interactions and enabling more efficient and accurate information retrieval. In addition, the vast amounts of data these models are trained on allow them to generate human-like responses and perform tasks that were once considered exclusive to human intelligence. We examine the capability of the current state-of-the-art language model--GPT-4--on planning and search (OpenAI, 2023). Despite its impressive performance in natural language processing tasks and its ability to generate human-like text, GPT-4 is not explicitly designed for executing planning or search algorithms. However, it can provide valuable insights and guidance on various planning and search techniques and domain-specific knowledge for constructing heuristics or evaluating different approaches. GPT-4's vast knowledge base allows users to ask questions and explore diverse aspects of planning and search. We indicate the fields in planning that can be solved by large language models and the limitations of language models. The introduction of large language models significantly impacts many fields, such as natural language processing; hence we want to examine its impact on the field of planning. Existing works (Valmeekam et al., 2022; Huang et al., 2022; Singh et al., 2023; Lin et al., 2023) demonstrating the capability of language models on planning are heavily focused on plan generation but lack the exploration of path search, memorization in planning, and planning in adversarial settings. We provide a comprehensive examination of the capability of GPT-4 in the field of planning and indicate its limitations for future research. Additionally, we attempt to improve the performance of an LLM by fine-tuning it on tasks like planning domain, graph search, and adversarial search to see if we are able to improve the predictions of these models for these aforementioned tasks. These models are capable of addressing various planning tasks, such as providing general information on planning algorithms, generating heuristics, and discussing different planning techniques. However, they are not specifically designed to perform planning tasks directly, as their primary function is to understand and generate text. Language models have limitations in handling real-time interactive scenarios and lack the ability to learn and adapt beyond their training data. Consequently, while large language models can provide valuable insights and guidance in the realm of planning, their utility is constrained by these limitations, and they cannot fully replace specialized planning algorithms or tools designed to address specific planning problems. We provide an empirical analysis of how GPT-4 performs on planning domain extraction, graph search path planning, and adversarial planning. We found that GPT-4 is effective at extracting key components of planning domains from textual descriptions, allowing for the generation of structured representations suitable for use in automated planning systems. In graph search, GPT-4 exhibits the capability to understand the searching algorithm and find an optimal path based on the algorithm. However, such capability is limited once the graph becomes complicated. Moreover, we show its capability to generate heuristics for adversarial planning and its limitation in performing adversarial search algorithms. The lack of memorization during planning is a main factor that limits the large language model to planning in adversarial settings."
    },
    {
      "title": "2 Related Work",
      "text": "Several works have used large language models for zero-shot planning; however, their planning either assumes the planning domain is acquired, or the outcomes are static. Some works (Yang et al., 2022; Ichter et al., 2022) only generate static outcomes, while LLM-Planner (Song et al., 2022) and LM-Nav (Shah et al., 2022) require prior knowledge of specific fields to define the planning domain. Existing works (Huang et al., 2022; Yang et al., 2022) have demonstrated the capability of these models. Large language models are sources with a wide range of knowledge, including domain-specific knowledge. However, existing works have not dived into the planning and searching capabilities of these models, especially in complex problem or adversarial settings. In this work, we explore the capabilities of large language models on planning domain generation, graph search, planning state memorization, and adversarial planning. The work reveals some limitations of large language models, which lead to potential future directions for improving these models."
    },
    {
      "title": "3 Preliminaries",
      "text": "Large Language Models (LLMs).LLMs are machine learning models designed to process and understand natural language, such as human speech and text. These models are typically large-scale neural networks, trained using massive amounts of data, often on the scale of billions of words or more, to learn patterns and structures in language. LLMs are capable of a wide range of natural language processing tasks, such as language translation, sentiment analysis, text classification, and speech recognition. They can generate new text based on the input prompt they received and create original content such as news articles, essays, or even poetry. One example of a large language model is OpenAI's GPT (short for \"Generative Pre-trained Transformer\") series (Brown et al., 2020; OpenAI, 2023), with GPT-4 being the most current iteration. Compared to existing LLMs, GPT-4 is also able to understand image inputs and perform better on logic reasoning. These models have demonstrated remarkable performance across a wide range of NLP tasks, revolutionizing the field of AI and enabling new applications in various domains. Planning Domain.A planning domain refers to a formal description of a specific problem space or environment [11]. It consists of the rules, constraints, and actions that define the structure of the problem and the ways in which it can be solved. The goal of automated planning is to find a sequence of actions that can transform the initial state of the domain into a desired goal state. A planning domain generally consists of the following components: * Objects: The entities or items that exist within the domain, such as people, locations, or resources. * States: A description of the various conditions or configurations of the objects in the domain. * Actions: The operations or steps that can be taken to modify the state of the domain. Actions usually have preconditions that must be satisfied before they can be executed and effects that describe how the state changes when the action is performed. * Initial state: The starting configuration of the domain from which the planning process begins. * Goal state: The desired configuration or set of conditions that the planning process aims to achieve. Planning Domain Definition Language (PDDL) is a formal language used to describe planning problems and domains in the field of automated planning. PDDL separates the description of a planning problem into two parts: the domain and the problem. The domain defines the general structure of the problem, including the available actions and their effects, while the problem specifies the initial state and the goal state for a particular instance of the problem. In addition to the components of general planning domains, PDDL consists of a set of predicates, which is a set of properties or relations that describe the state of the objects in the domain. Graph Search.Graph search is a type of algorithm used to explore and navigate graphs, which are mathematical structures consisting of nodes (also called vertices) connected by edges. In graph search, the algorithm starts at a given node and systematically explores the graph by visiting its neighboring nodes in a specific order until it reaches a target node or a goal state. The goal of graph search is to find the shortest or most efficient path between two nodes in a graph. There are several different types of graph search algorithms, including: * Breadth-first search (BFS): This algorithm explores all the neighbors of a node before moving on to the next level of nodes. BFS is guaranteed to find the shortest path between two nodes in an unweighted graph. * Depth-first search (DFS): This algorithm explores one branch of the graph as far as possible before backtracking and exploring another branch. DFS can be used to find all paths between two nodes in a graph, but it may not find the shortest path. * Dijkstra's algorithm: This algorithm is used to find the shortest path between two nodes in a weighted graph. It works by assigning a tentative distance to each node and updating the distance as it explores the graph. * A* search: This algorithm is similar to Dijkstra's algorithm but uses a heuristic function to guide the search toward the goal node. A* search is often used in pathfinding in video games. Graph search algorithms can be used to solve a wide range of problems, but the choice of algorithm depends on the specific problem and the characteristics of the graph being searched. Adversarial Planning.Adversarial planning is a type of planning problem where the planner is required to generate a plan that can anticipate and react to the actions of an adversarial agent. In this type of problem, the planner must take into account the actions of the adversary and try to find a plan that maximizes the chances of success while minimizing the impact of the adversary's actions. Adversarial planning is commonly used in game theory, where it is used to model the strategies and actions of two or more players engaged in a game. In this context, the planner must anticipate the actions of the opponent and develop a strategy that maximizes the chances of winning. There are several approaches to adversarial planning, including mini-max, in which the goal of the agents is to maximize their own rewards or utility while minimizing the rewards or utility of their opponents, and Monte Carlo Tree Search (MCTS), which uses a search algorithm to simulate the possible outcomes of the planner's actions and the adversary's responses. Adversarial planning is a challenging problem because it requires the planner to consider not only their own objectives but also the objectives and capabilities of the adversary agents. As a result, it often involves complex decision-making and requires sophisticated algorithms and techniques."
    },
    {
      "title": "4 Planning Domain Generation",
      "text": "In this section, we formulate an approach to generating planning domains using the large language model. To generate the planning domain, we apply the following procedure: querying a brief description of a task to GPT and transforming the responses into PDDL. If we have prior task knowledge, we can send it to GPT and ask it to generate PDDL from the knowledge. This approach enables the task designers to obtain task knowledge in a formal representation, regardless of the prior information the task designers have. Moreover, after generating the planning domains, the task designer can obtain a task plan by performing a simple path search. We also show the capability of GPT-4 on path search in the later sections. We start the experiment with a daily-life task--cross the road--to examine the planning domain generation ability. We send the following input prompt to GPT-4: ``` 1Defineaproblemandactionsforatask\"crosstheroadattrafficlight\"inPDDL. ``` Listing 1: Define a problem and actions for a task \"cross the road at traffic light\" in PDDL The PDDL outputs generated by GPT-4 is presented in Listing 1. ``` 1(define(domaincross-road) 2{:requirements:strips) 3{:typeside} 4{:predicates 5{pedestrian-at?s-side} 6{traffic-light?s-side} 7{safe-to-cross?s-side} 8} 9{:actionwait-for-green 10:parameters(?s-side) 11:precondition(and(pedestrian-at?s)(traffic-light?s)) 12:effect(safe-to-cross?s) 13} 14{:actioncross 15:parameters(?s1-side?s2-side) 16:precondition(and(pedestrian-at?s1)(safe-to-cross?s1)) 17:effect(and 18(not(pedestrian-at?s1))(pedestrian-at?s2) 19(not(safe-to-cross?s1)) 20) 21} 22} 23{define(problemcross-road-problem) 24{:domaincross-road} 25{:objectsside1side2-side} 26{:init 27{pedestrian-atside1} 28{traffic-lightside1} 29{traffic-lightside2} 30} 31{:goal(and(pedestrian-atside2))) 32} ``` Listing 2: Define a problem and actions for a task \"cross the road at traffic light\" in PDDL Then, we query GPT-4 to find a plan by searching through the planning domain: ``` 1Solvetheproblemfor\"crosstheroadatthetrafficlight\"inPDDLwiththeactionsdefined. 21.wait-for-greenside1 22.crosssidedside2The result indicates that the generated planning domain is self-contained, and we can obtain a formal representation of the plan, which solves a zero-shot planning problem. In addition to daily-life tasks, we can ask GPT-4 to generate the planning domain for some well-known games, such as Tic-Tac-Toe in Listing 2 and chess in Listing 3. However, once the complexity of the game increases, the success rate of generating self-contained planning domains from GPT-4 decreases. A failure example is the chess game in Listing 2, which defines the wrong goal state. ``` 1(define(domaintic-tac-toe) 2{:requirements:strips:typing) 3{:typesplayercell} 4{:predicates 5{cell-empty?c-cell} 6{cell-filled?c-cell?p-player} 7{current-player?p-player} 8} 9{:actionplace-mark 10{:parameters(?p-player?c-cell) 11{:preconditionand 12{cell-empty?c}(current-player?p) 13} 14{:effect(and 15{(not(cell-empty?c))(cell-filled?c?p) 16{forall(?other-player) 17{when(not(=?other?p))(current-player?other))} 18} 19} 20} 21 22{define(problemtic-tac-toe-problem) 23{:domaintic-tac-toe) 24{:objects 25x0-player 26c1c2c3c4c5c6c7c8c9-cell 27} 28{:init 29{cell-emptyc1}...(cell-emptyc9) 30{current-playerx} 31} 32{:goal(or 33{ Checkforhorizontalwins 34{and(cell-filledc1x)(cell-filledc2x)(cell-filledc3x)) 35{: Checkforverticalwins 36{and(cell-filledc1x)(cell-filledc4x)(cell-filledc7x)) 37{: Checkfordiagonalwins 38{and(cell-filledc1x)(cell-filledc5x)(cell-filledc9x)) 39{and(cell-filledc3x)(cell-filledc5x)(cell-filledc7x)) 40} } ``` Listing 2: Define a problem and a set of actions for tic-tac-toe in PDDL. ``` 1(define(problemeches-problem) 2{:objects 3{:objects 41a2a3......h6h7h8-square 56{:init 69{atwpi1a2}(atwpi2b2)(atwpi3c2)...... 70{cleara3}(cleara4)(cleara5)...... 71{:goal(and(atwpi47))) 72} ``` Listing 3: Define a problem and a set of actions for the chess game in PDDL. For more empirical results, we select 100 tasks with different complexities. The tasks are ranged from board games to daily tasks to domain-specific tasks. Then, we query GPT-4 to generate planning domains for those tasks and check the correctness of the generated domains. We show the results in Table 1. As we can see, GPT-4 can always generate self-contained planning domains but occasionally generate planning domains that do not match human knowledge. Additionally, we further query GPT-4 to solve the planning problem given those generated domains. Since all the planning domains are self-contained, we also run _fast-downward_ planner to find a plan and compare it with the plan generated from GPT-4. The results in Table 2 indicate that GPT-4 can find plans for simple tasks, but once the task requires more steps, GPT-4 may generate plans with missing disordered actions. In conclusion, large language models like GPT-4 are useful in planning domain generation. Due to the rich knowledge encoded in these models, we can use them as a knowledge source, with a notice that they are not always reliable for complex tasks. In the path search aspect, GPT-4 can solve very simple path search problems from given planning domains. However, there is no significant advantage to using GPT-4 compared to using a traditional planner."
    },
    {
      "title": "5 Graph Search",
      "text": "In this section, we examine the capability of large language models, such as GPT-4, on graph searches. The examination consists of two aspects: first, whether GPT-4 understands the well-known graph search algorithms, and second, whether GPT-4 can follow the algorithms to find the desired path. Note that we compare the outputs of GPT-4 to the outputs of the graph search algorithms. The outputs are not necessarily the optimal path. We consider GPT-4 to be accurate as long as it can generate paths following the graph search algorithms. We collect direct weighted graphs from 5 nodes to 95 nodes with a gap of 10 (5, 15, 25,..., 85, 95 nodes). For each number of nodes, we collect 20 different graphs. An example is presented in Figure 1. For each graph, we query GPT-4 to perform three graph search algorithms, depth-first search, breath-first search, and Dijkstra's algorithm, respectively, to generate paths. For the example in Figure 1, we query: \\begin{table} \\begin{tabular}{||c|c|c|c||} \\hline Total Tasks & Correct Plan & Wrong Plan & Failed \\\\ \\hline 100 & 73 & 27 & 0 \\\\ \\hline \\end{tabular} \\end{table} Table 1: Results on Planning Domain Generation using GPT-4. A correct plan means the planning domain is self-contained and matches human knowledge. A wrong plan means the planning domain is self-contained but does not match human knowledge (e.g., chess game in Listing 3). A failed plan means the planning domain is not self-contained due to the inconsistency of predicates. \\begin{table} \\begin{tabular}{||c|c|c|c|c||} \\hline Length & \\(\\leq\\) 3 & 4—6 & 6—8 & \\(\\geq\\) 8 \\\\ \\hline Number of Tasks & 68 & 10 & 7 & 15 \\\\ Number of Correct Plans & 68 & 8 & 4 & 3 \\\\ \\hline \\end{tabular} \\end{table} Table 2: Results on path search using GPT-4. Length indicates the length of the plan generated by _fast-downward_ using the planning domains from GPT-4. The number of tasks indicates how many tasks can be completed in this range of steps. A plan is considered _correct_ if the plan generated by GPT-4 is identical to the plan from _fast-downward_. Figure 1: A randomly generated direct weighted graph for examining the graph search capability of large language models. * [3]1. Start at node A. Enqueue A andmark it as visited. * [4]2. Dequeue A. Enqueue its unvisited neighbors, B and C, andmark them as visited. * [5]3. Dequeue B. Enqueue its unvisited neighbor, D, andmark it as visited. * [6]4. Dequeue C. Enqueue its unvisited neighbor, E, andmark it as visited. * [7]5. Dequeue D. There are no unvisited neighbors. * [8]6. Dequeue E. There are no unvisited neighbors. * [9]The BPS traversal visitsnodes in the following order: A -> B -> C -> D -> E. * [10]By using the predecessors, we can reconstruct the shortest path from A to E: * [11]1. Start at node E. * [13]3. The predecessor of C is A. So, we have C -+- A. * [14]Putting it all together, we get the shortest path from A to E: A -> C -> E. * [15] * [16]Run Dijkstra's algorithm to find the shortest path from A to E. * [17] * [18]Here's the DFS traversal on the directed graph: * [19]The DFS traversal visitsnodes in the following order: A -> B -> D -> C -> E. * [20]Putting it all together, we get a path from A to E: A -> C -> E. * [21]Run DFS to find the shortest path from A to E. * [22] * [23]Here's how Dijkstra's algorithm proceeds: * [24]1. Distances: A = 0, B = 999, C = 999, D = 999, E = 999. Unvisited: A, B, C, D, E * [25]27. Viit node A. Update B's distance and sets its predecessor as A. Update C's distance and set its predecessor as A. Distances: A = 0, B = 3, C = 2, D = 999, E = 999. Unvisited: B, C, D, E * [26]3. Viit node C (smallest unvisited distance). Update E's distance and set its predecessor as C. Distances: A = 0, B = 3, C = 2, D = 999, E = 8. * [27]4. Viit node B (smallest unvisited distance). Update D's distance and set its predecessor as B. Distances: A = 0, B = 3, C = 2, D = 7, E = 8. * [28]5. Viit node D (smallest unvisited distance). No updates. Unvisited: E * [29]6. Viit node E (smallest unvisited distance). No unvisited neighbors. * [30]Putting it all together, we get a path from A to E: A -> C -> E. As we indicate in this example, GPT-4 is sufficient to generate accurate paths under all three algorithms. However, as the graphs become more complicated, the accuracy of GPT-4 decreases. In Figure 2, we present how the accuracies of GPT-4 on three algorithms decrease as the number of graph nodes increases. Therefore, we conclude that GPT-4 is only capable of simple graph search. But it provides the possibility of decomposing a complex graph into simple graphs and performing graph search."
    },
    {
      "title": "6 Adversarial Planning",
      "text": "In this section, we explore the capability of the large language model, specifically GPT-4, on adversarial planning. The experiment consists of two components: defining heuristics and applying adversarial search. Figure 2: The accuracy of graph searching results generated by GPT-4 on graphs with different nodes. [MISSING_PAGE_FAIL:8] Fine-tuning LLM for Logical Reasoning Given the subpar performance of LLM on logical reasoning tasks like adversarial planning, we can fine-tune our own language model to check if we could improve its performance on logistic reasoning tasks."
    },
    {
      "title": "Dataset",
      "text": "The dataset collected comprised three parts which were planning domain generation (7 different tasks), graph search (20 different tasks), and adversarial planning (4 different tasks). For example, for planning domain generation, we queried GPT-4 using seven different problem definitions. Each problem definition generated 10-100 different goal state configurations depending on the problem, resulting in a total of 540 queries. Given each query (only those queries were selected, which we thought would give correct results when passed through LLM), we ran GPT-4 inference on them to get the soft labels for fine-tuning our own LLM. We collected around 1300 queries (appended with the name of the part, e.g., planning domain queries were appended by planning domain : and so on) and soft label pairs across all tasks."
    },
    {
      "title": "Model Selection And Fine-Tuning",
      "text": "To select the correct model to fine-tune, we chose a model small enough that could be easily fine-tuned using the resources available to us and also large enough such that it could infer logically. We chose the Flan T5 base model (Shen et al., 2023) released by Google since it meets this criterion. One of the reasons we chose this model was because this model's checkpoints were readily available at HuggingFace, and had a reasonable size of 240M parameters. Also, as shown in (Shen et al., 2023), the model shows the SOTA performance in the CoT dataset (Qingyi Si, 2023), which contains a chain of thought data points like arithmetic reasoning, explanation generation, etc., for the number of parameters it had. For fine-tuning the model, we froze the weights of the original model. We only changed the final layer's weights. Updating the weights of the entire model could have led to catastrophic forgetting, or it would have been fine-tuned properly since our dataset size was too small."
    },
    {
      "title": "Results",
      "text": "We fine-tuned our LLM model on approximately 1000 data points and evaluated it on the remaining 200 data points. We used the remaining 100 data points as the validation set and used it to stop training the model when we started to see an increase in the validation loss. Given the rapid advances in LLM models, we observed that the outputs of GPT-4 were much better than the Flan models, which were more or less incorrect for every data point we had. In Table 3, we compare the outputs of Flan, fine-tuned Flan, and GPT-4 for a specific case of graph search and planning domain generation. As for adversarial search, the flan models are unable to come up with a coherent heuristic, and hence we skip their evaluations. Also, we could not compare the output of the LLM and the ground truth values after planning since all the planning domains provided by the Flan were incorrect. In conclusion, we were able to see minor improvements due to fine-tuning because the original model might have never seen prompts like these but was unable to process the outputs of the fine-tuned models."
    },
    {
      "title": "8 Conclusion",
      "text": "Large language models can play critical roles in planning due to their large knowledge domain. The up-to-date large language models encode rich real-world knowledge and can make logical inferences to a certain extent. We provide examples to demonstrate that these models can generate self-consistent planning domains of given tasks without any prior information provided. This capability enables language models to do zero-shot planning. Moreover, the language models can perform graph searches on small-scaled graphs, indicating their great potential in searching. However, the current models have limited abilities to memorize the sequence of previous states during planning and to solve search problems in complicated environments (graphs). Both limitations lead the large language models incapable of adversarial planning. Overall, large language models can play significant roles in planning, especially few-shot planning, and their significance can be improved over time."
    },
    {
      "title": "References",
      "text": "* Brown et al. [2015] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. _Advances in Neural Information Processing Systems_, 33:1877-1901, 2020. * Chintagunta et al. [2021] Bharath Chintagunta, Namit Katariya, Xavier Amatriain, and Anitha Kannan. Medically aware gpt-3 as a data generator for medical dialogue summarization. In _Machine Learning for Healthcare Conference_, pages 354-372. PMLR, 2021. * Haslum et al. [2017] Patrik Haslum, Nir Lipovetzky, Daniele Magazzeni, and Christian Muise. An introduction to the planning domain definition language. _Synthesis Lectures on Artificial Intelligence and Machine \\begin{table} \\begin{tabular}{|p{142.3pt}|p{142.3pt}|} \\hline & Planning domain & Graph Search \\\\ \\hline Input query & Q. Define a problem and actions for the task “tic-tac-toe” in PDDL? & Answer the following yes/no question by reasoning step-by-step. Given a graph with vertices A, B, C, D, E where the connections are given as A-B, B-C, C-D, C-E. Run BFS to find the shortest path from A to E. \\\\ \\hline Flan & Tic-tac-toe is a word that means “to engage in a classic three-in-a-row game typically played on a grid by two players taking turns to place their respective marks, either X or O, in an attempt to achieve a winning combination.” \\\\ \\hline Flan-finetuned & \\multirow{4}{*}{BFS is a program that calculates the distance between A and E. Exploring A gives B. Exploring B gives C. Exploring C gives D and E. Therefore, the path is A - B - C - E.} \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\hline GPT-4 & \\multirow{4}{*}{BFS is a program that calculates the distance between A and E. Exploring A gives B. Exploring B gives C. Exploring C gives D and E. Therefore, the path is A - B - C - E.} \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\cline{2-3} & & \\\\ \\hline \\end{tabular} \\end{table} Table 3: The comparisons between the outputs of various models for planning domains and graph search. Learning_, 2019. * Huang et al. [2022a] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, _International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA_, volume 162 of _Proceedings of Machine Learning Research_, pages 9118-9147. PMLR, 2022a. URL [https://proceedings.mlr.press/v162/huang22a.html](https://proceedings.mlr.press/v162/huang22a.html). * Huang et al. [2022b] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Sermanet, Tomas Jackson, Noah Brown, Linda Luu, Sergey Levine, Karol Hausman, and Brian Ichter. Inner monologue: Embodied reasoning through planning with language models. 205:1769-1782, 2022b. * Ichter et al. [2022] Brian Ichter, Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, Dmitry Kalashnikov, Sergey Levine, Yao Lu, Carolina Parada, Kanishka Rao, Pierre Sermanet, Alexander Toshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Mengyuan Yan, Noah Brown, Michael Ahn, Omar Cortes, Nicolas Sievers, Clayton Tan, Sichun Xu, Diego Reyes, Jarek Rettinghouse, Jornell Quiambao, Peter Pastor, Linda Luu, Kuang-Huei Lee, Yuheng Kuang, Sally Jesmonth, Nikhil J. Joshi, Kyle Jeffrey, Rosario Jauregui Ruano, Jasmine Hsu, Keerthana Gopalakrishnan, Byron David, Andy Zeng, and Chuyuan Kelly Fu. Do as I can, not as I say: Grounding language in robotic affordances. In Karen Liu, Dana Kulic, and Jeffrey Ichnowski, editors, _Conference on Robot Learning, CoRL 2022, 14-18 December 2022, Auckland, New Zealand_, volume 205 of _Proceedings of Machine Learning Research_, pages 287-318. PMLR, 2022. URL [https://proceedings.mlr.press/v205/ichter23a.html](https://proceedings.mlr.press/v205/ichter23a.html). * Leippold [2023] Markus Leippold. Thus spoke gpt-3: Interviewing a large-language model on climate finance. _Finance Research Letters_, 53:103617, 2023. * Lin et al. [2023] Bill Yuchen Lin, Chengsong Huang, Qian Liu, Wenda Gu, Sam Sommerer, and Xiang Ren. On grounded planning for embodied tasks with language models. In Brian Williams, Yiling Chen, and Jennifer Neville, editors, _AAAI Conference on Artificial Intelligence_, pages 13192-13200, Washington, DC, USA, 2023. AAAI Press. * Nori et al. [2023] Harsha Nori, Nicholas King, Scott Mayer McKinney, Dean Carignan, and Eric Horvitz. Capabilities of gpt-4 on medical challenge problems. _arXiv preprint arXiv:2303.13375_, 2023. * OpenAI [2023] OpenAI. GPT-4 technical report. _CoRR_, abs/2303.08774, 2023. doi: 10.48550/arXiv.2303.08774. URL [https://doi.org/10.48550/arXiv.2303.08774](https://doi.org/10.48550/arXiv.2303.08774). * Qingyi [2023] Zheng Lin Qingyi Si. Alpaca-cot: An instruction fine-tuning platform with instruction data collection and unified large language models interface. [https://github.com/PhoebusSi/alpaca-CoT](https://github.com/PhoebusSi/alpaca-CoT), 2023. * Shah et al. [2022] Dhruv Shah, Blazej Osinski, Brian Ichter, and Sergey Levine. Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action. In Karen Liu, Dana Kulic, and Jeffrey Ichnowski, editors, _Conference on Robot Learning, CoRL 2022, 14-18 December 2022, Auckland, New Zealand_, volume 205 of _Proceedings of Machine Learning Research_, pages 492-504. PMLR, 2022. URL [https://proceedings.mlr.press/v205/shah23b.html](https://proceedings.mlr.press/v205/shah23b.html). * Shen et al. [2023] Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, Jason Wei, Hyung Won Chung, Barret Zoph, William Fedus, Xinyun Chen, Tu Vu, Yuexin Wu, Wuyang Chen, Albert Webson, Yunxuan Li, Vincent Zhao, Hongkun Yu, Kurt Keutzer, Trevor Darrell, and Denny Zhou. Flan-moe: Scaling instruction-finetuned language models with sparse mixture of experts. _CoRR_, abs/2305.14705, 2023. doi: 10.48550/arXiv.2305.14705. URL [https://doi.org/10.48550/arXiv.2305.14705](https://doi.org/10.48550/arXiv.2305.14705). * Shin et al. [2020] Hoo-Chang Shin, Yang Zhang, Evelina Bakhturina, Raul Puri, Mostofa Patwary, Mohammad Shoeybi, and Raghav Mani. Biomegatron: Larger biomedical domain language model. In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu, editors, _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020_, pages 4700-4706. Association for Computational Linguistics, 2020. doi: 10.18653/v1/2020.emnlp-main.379. URL [https://doi.org/10.18653/v1/2020.emnlp-main.379](https://doi.org/10.18653/v1/2020.emnlp-main.379). * Shin et al. [2020]Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, and Animesh Garg. Progprompt: Generating situated robot task plans using large language models. In _IEEE International Conference on Robotics and Automation, ICRA 2023, London, UK, May 29 - June 2, 2023_, pages 11523-11530. IEEE, 2023. * Song et al. [2022] Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M. Sadler, Wei-Lun Chao, and Yu Su. LImplanner: Few-shot grounded planning for embodied agents with large language models. _CoRR_, abs/2212.04088, 2022. doi: 10.48550/arXiv.2212.04088. URL [https://doi.org/10.48550/arXiv.2212.04088](https://doi.org/10.48550/arXiv.2212.04088). * Thirunavukarasu et al. [2023] Arun James Thirunavukarasu, Darren Shu Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, and Daniel Shu Wei Ting. Large language models in medicine. _Nature Medicine_, pages 1-11, 2023. * Valmeekam et al. [2022] Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati. Large language models still can't plan (a benchmark for llms on planning and reasoning about change). _arXiv preprint arXiv:2206.10498_, 2022. * Wu et al. [2023] Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David S. Rosenberg, and Gideon Mann. Bloomberggpt: A large language model for finance. _CoRR_, abs/2303.17564, 2023. doi: 10.48550/arXiv.2303.17564. URL [https://doi.org/10.48550/arXiv.2303.17564](https://doi.org/10.48550/arXiv.2303.17564). * Yang et al. [2022] Yunhao Yang, Jean-Raphael Gaglione, Cyrus Neary, and Ufuk Topcu. Automaton-based representations of task knowledge from generative language models. _CoRR_, abs/2212.01944, 2022. doi: 10.48550/arXiv.2212.01944. URL [https://doi.org/10.48550/arXiv.2212.01944](https://doi.org/10.48550/arXiv.2212.01944). [MISSING_PAGE_FAIL:13]"
    }
  ]
}
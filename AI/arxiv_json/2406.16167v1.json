{
  "title": "FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy in Large Language Models",
  "authors": [
    "Harish Tayyar Madabushi",
    "Josh Openai",
    "Steven Achiam",
    "Sandhini Adler",
    "Lama Agarwal",
    "Ilge Ahmad",
    "Florencia Akkaya",
    "Diogo Leoni",
    "Janko Almeida",
    "Sam Altenschmidt",
    "Shyamal Alt- Man",
    "Red Anadkat",
    "Igor Avila",
    "Suchir Babuschkin",
    "Valerie Balaji",
    "Paul Balcom",
    "Haim- Ing Baltescu",
    "Mohammad Bao",
    "Jeff Bavarian",
    "Ir- Wan Belgum",
    "Jake Bello",
    "Gabriel Berdine",
    "Christopher Bernadett-Shapiro",
    "Lenny Berner",
    "Oleg Bogdonoff",
    "Madelaine Boiko",
    "Anna-Luisa Boyd",
    "Greg Brakman",
    "Tim Brock- Man",
    "Miles Brooks",
    "Kevin Brundage",
    "Trevor Button",
    "Rosie Cai",
    "Andrew Campbell",
    "Brittany Cann",
    "Chelsea Carey",
    "Rory Carlson",
    "Brooke Carmichael",
    "Che Chan",
    "Fotis Chang",
    "Derek Chantzis",
    "Sully Chen",
    "Ruby Chen",
    "Jason Chen",
    "Mark Chen",
    "Ben Chen",
    "Chester Chess",
    "Casey Cho",
    "Hyung Won Chu",
    "Dave Chung",
    "Jeremiah Cummings",
    "Yunxing Currier",
    "Dai",
    "Tarun Goel",
    "Gabriel Gogineni",
    "Rapha Goh",
    "Jonathan Gontijo- Lopes",
    "Morgan Gordon",
    "Scott Grafstein",
    "Ryan Gray",
    "Joshua Greene",
    "Shixiang Shane Gross",
    "Yufei Gu",
    "Chris Guo",
    "Jesse Hallacy",
    "Jeff Han",
    "Yuchen Harris",
    "Mike He",
    "Johannes Heaton",
    "Chris Heidecke",
    "Alan Hesse",
    "Wade Hickey",
    "Peter Hickey",
    "Brandon Hoeschele",
    "Kenny Houghton",
    "Shengli Hsu",
    "Xin Hu",
    "Joost Hu",
    "Shantanu Huizinga",
    "Shawn Jain",
    "Joanne Jain",
    "Angela Jang",
    "Roger Jiang",
    "Haozhun Jiang",
    "Denny Jin",
    "Shino Jin",
    "Billie Jomoto",
    "Hee- Woo Jonn",
    "Tomer Jun",
    "Łukasz Kaftan",
    "Ali Kaiser",
    "Ingmar Ka- Mali",
    "Kanitscheider",
    "Shirish Nitish",
    "Tabarak Keskar",
    "Logan Khan",
    "Jong Wook Kilpatrick",
    "Christina Kim",
    "Yongjik Kim",
    "Jan Hendrik Kim",
    "Jamie Kirch- Ner",
    "Matt Kiros",
    "Daniel Knight",
    "Łukasz Kokotajlo",
    "Andrew Kondraciuk",
    "Aris Kondrich",
    "Kyle Kon- Stantinidis",
    "Gretchen Kosic",
    "Vishal Krueger",
    "Michael Kuo",
    "Ikai Lampe",
    "Teddy Lan",
    "Jan Lee",
    "Jade Leike",
    "Daniel Leung",
    "Chak Ming Levy",
    "Rachel Li",
    "Molly Lim",
    "Stephanie Lin",
    "Mateusz Lin",
    "Theresa Litwin",
    "Ryan Lopez",
    "Patricia Lowe",
    "Anna Lue",
    "Kim Makanju",
    "Sam Malfacini",
    "Todor Manning",
    "Yaniv Markov",
    "Bianca Markovski",
    "Katie Martin",
    "Andrew Mayer",
    "Bob Mayne",
    "Scott Mayer Mcgrew",
    "Christine Mckinney",
    "Paul Mcleavey",
    "Jake Mcmillan",
    "David Mcneil",
    "Aalok Medina",
    "Jacob Mehta",
    "Luke Menick",
    "Andrey Metz",
    "Pamela Mishchenko",
    "Vinnie Mishkin",
    "Evan Monaco",
    "Daniel Morikawa",
    "Tong Mossing",
    "Mira Mu",
    "Oleg Murati",
    "David Murk",
    "Ashvin Mély",
    "Reiichiro Nair",
    "Rajeev Nakano",
    "Arvind Nayak",
    "Richard Neelakantan",
    "Hyeonwoo Ngo",
    "Long Noh",
    "Cullen Ouyang",
    "Jakub O'keefe",
    "Alex Pachocki",
    "Joe Paino",
    "Ashley Palermo",
    "Giambat Pantuliano",
    "Carl Ross",
    "Bob Rotsted",
    "Henri Roussez",
    "Nick Ry- Der",
    "Mario Saltarelli",
    "Ted Sanders",
    "Shibani Santurkar",
    "Girish Sastry",
    "Heather Schmidt",
    "David Schnurr",
    "John Schulman",
    "Daniel Selsam",
    "Kyla Sheppard",
    "Toki Sherbakov",
    "Jessica Shieh",
    "Sarah Shoker",
    "Pranav Shyam",
    "Szymon Sidor",
    "Eric Sigler",
    "Maddie Simens",
    "Jordan Sitkin",
    "Katarina Slama",
    "Ian Sohl",
    "Benjamin Sokolowsky",
    "Yang Song",
    "Natalie Staudacher",
    "Clemens Winter",
    "Samuel Wolrich",
    "Hannah Wong",
    "Lauren Workman",
    "Sherwin Wu",
    "Jeff Wu",
    "Michael Wu",
    "Kai Xiao",
    "Tao Xu",
    "Sarah Yoo",
    "Kevin Yu",
    "Qim- Ing Yuan",
    "Wojciech Zaremba",
    "Rowan Zellers",
    "Chong Zhang",
    "Marvin Zhang",
    "Shengjia Zhao",
    "Tianhao Zheng",
    "Juntang Zhuang",
    "William Zhuk",
    "Barret 2024 Zoph"
  ],
  "abstract": "\n We present a novel extension to Retrieval Augmented Generation with the goal of mitigating factual inaccuracies in the output of large language models. Specifically, our method draws on the cognitive linguistic theory of frame semantics for the indexing and retrieval of factual information relevant to helping large language models answer queries. We conduct experiments to demonstrate the effectiveness of this method both in terms of retrieval effectiveness and in terms of the relevance of the frames and frame relations automatically generated. Our results show that this novel mechanism of Frame Semantic-based retrieval, designed to improve Retrieval Augmented Generation (FS-RAG), is effective and offers potential for providing data-driven insights into frame semantics theory. We provide open access to our program code and prompts 1 . \n",
  "references": [
    {
      "id": null,
      "title": "FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy in Large Language Models",
      "authors": [
        "Harish Tayyar Madabushi",
        "Josh Openai",
        "Steven Achiam",
        "Sandhini Adler",
        "Lama Agarwal",
        "Ilge Ahmad",
        "Florencia Akkaya",
        "Diogo Leoni",
        "Janko Almeida",
        "Sam Altenschmidt",
        "Shyamal Alt- Man",
        "Red Anadkat",
        "Igor Avila",
        "Suchir Babuschkin",
        "Valerie Balaji",
        "Paul Balcom",
        "Haim- Ing Baltescu",
        "Mohammad Bao",
        "Jeff Bavarian",
        "Ir- Wan Belgum",
        "Jake Bello",
        "Gabriel Berdine",
        "Christopher Bernadett-Shapiro",
        "Lenny Berner",
        "Oleg Bogdonoff",
        "Madelaine Boiko",
        "Anna-Luisa Boyd",
        "Greg Brakman",
        "Tim Brock- Man",
        "Miles Brooks",
        "Kevin Brundage",
        "Trevor Button",
        "Rosie Cai",
        "Andrew Campbell",
        "Brittany Cann",
        "Chelsea Carey",
        "Rory Carlson",
        "Brooke Carmichael",
        "Che Chan",
        "Fotis Chang",
        "Derek Chantzis",
        "Sully Chen",
        "Ruby Chen",
        "Jason Chen",
        "Mark Chen",
        "Ben Chen",
        "Chester Chess",
        "Casey Cho",
        "Won Chu",
        "Dave Chung",
        "Jeremiah Cummings",
        "Yunxing Currier",
        "Dai",
        "Tarun Goel",
        "Gabriel Gogineni",
        "Rapha Goh",
        "Jonathan Gontijo- Lopes",
        "Morgan Gordon",
        "Scott Grafstein",
        "Ryan Gray",
        "Joshua Greene",
        "Shane Gross",
        "Yufei Gu",
        "Chris Guo",
        "Jesse Hallacy",
        "Jeff Han",
        "Yuchen Harris",
        "Mike He",
        "Johannes Heaton",
        "Chris Heidecke",
        "Alan Hesse",
        "Wade Hickey",
        "Peter Hickey",
        "Brandon Hoeschele",
        "Kenny Houghton",
        "Shengli Hsu",
        "Xin Hu",
        "Joost Hu",
        "Shantanu Huizinga",
        "Shawn Jain",
        "Joanne Jain",
        "Angela Jang",
        "Roger Jiang",
        "Haozhun Jiang",
        "Denny Jin",
        "Shino Jin",
        "Billie Jomoto",
        "Hee- Woo Jonn",
        "Tomer Jun",
        "Łukasz Kaftan",
        "Ali Kaiser",
        "Ingmar Ka- Mali",
        "Kanitscheider",
        "Shirish Nitish",
        "Tabarak Keskar",
        "Logan Khan",
        "Jong Wook Kilpatrick",
        "Christina Kim",
        "Yongjik Kim",
        "Jan Hendrik Kim",
        "Jamie Kirch- Ner",
        "Matt Kiros",
        "Daniel Knight",
        "Łukasz Kokotajlo",
        "Andrew Kondraciuk",
        "Aris Kondrich",
        "Kyle Kon- Stantinidis",
        "Gretchen Kosic",
        "Vishal Krueger",
        "Michael Kuo",
        "Ikai Lampe",
        "Teddy Lan",
        "Jan Lee",
        "Jade Leike",
        "Daniel Leung",
        "Ming Levy",
        "Rachel Li",
        "Molly Lim",
        "Stephanie Lin",
        "Mateusz Lin",
        "Theresa Litwin",
        "Ryan Lopez",
        "Patricia Lowe",
        "Anna Lue",
        "Kim Makanju",
        "Sam Malfacini",
        "Todor Manning",
        "Yaniv Markov",
        "Bianca Markovski",
        "Katie Martin",
        "Andrew Mayer",
        "Bob Mayne",
        "Scott Mayer Mcgrew",
        "Christine Mckinney",
        "Paul Mcleavey",
        "Jake Mcmillan",
        "David Mcneil",
        "Aalok Medina",
        "Jacob Mehta",
        "Luke Menick",
        "Andrey Metz",
        "Pamela Mishchenko",
        "Vinnie Mishkin",
        "Evan Monaco",
        "Daniel Morikawa",
        "Tong Mossing",
        "Mira Mu",
        "Oleg Murati",
        "David Murk",
        "Ashvin Mély",
        "Reiichiro Nair",
        "Rajeev Nakano",
        "Arvind Nayak",
        "Richard Neelakantan",
        "Hyeonwoo Ngo",
        "Long Noh",
        "Cullen Ouyang",
        "Jakub O'keefe",
        "Alex Pachocki",
        "Joe Paino",
        "Ashley Palermo",
        "Giambat Pantuliano",
        "Carl Ross",
        "Bob Rotsted",
        "Henri Roussez",
        "Nick Ry- Der",
        "Mario Saltarelli",
        "Ted Sanders",
        "Shibani Santurkar",
        "Girish Sastry",
        "Heather Schmidt",
        "David Schnurr",
        "John Schulman",
        "Daniel Selsam",
        "Kyla Sheppard",
        "Toki Sherbakov",
        "Jessica Shieh",
        "Sarah Shoker",
        "Pranav Shyam",
        "Szymon Sidor",
        "Eric Sigler",
        "Maddie Simens",
        "Jordan Sitkin",
        "Katarina Slama",
        "Ian Sohl",
        "Benjamin Sokolowsky",
        "Yang Song",
        "Natalie Staudacher",
        "Clemens Winter",
        "Samuel Wolrich",
        "Hannah Wong",
        "Lauren Workman",
        "Sherwin Wu",
        "Jeff Wu",
        "Michael Wu",
        "Kai Xiao",
        "Tao Xu",
        "Sarah Yoo",
        "Kevin Yu",
        "Qim- Ing Yuan",
        "Wojciech Zaremba",
        "Rowan Zellers",
        "Chong Zhang",
        "Marvin Zhang",
        "Shengjia Zhao",
        "Tianhao Zheng",
        "Juntang Zhuang",
        "William Zhuk",
        "Barret 2024 Zoph"
      ],
      "year": "2024",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "The Berkeley FrameNet project",
      "authors": [
        "Collin F Baker",
        "Charles J Fillmore",
        "John B Lowe"
      ],
      "year": "1998",
      "venue": "36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics",
      "doi": "10.3115/980845.980860"
    },
    {
      "id": "b1",
      "title": "Alec Radford, Ilya Sutskever, and Dario Amodei",
      "authors": [
        "Tom Brown",
        "Benjamin Mann",
        "Nick Ryder",
        "Melanie Subbiah",
        "Jared D Kaplan",
        "Prafulla Dhariwal",
        "Arvind Neelakantan",
        "Pranav Shyam",
        "Girish Sastry",
        "Amanda Askell",
        "Sandhini Agarwal",
        "Ariel Herbert-Voss",
        "Gretchen Krueger",
        "Tom Henighan",
        "Rewon Child",
        "Aditya Ramesh",
        "Daniel Ziegler",
        "Jeffrey Wu",
        "Clemens Winter",
        "Chris Hesse",
        "Mark Chen",
        "Eric Sigler",
        "Mateusz Litwin",
        "Scott Gray",
        "Benjamin Chess",
        "Jack Clark",
        "Christopher Berner",
        "Sam Mccandlish"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "Palm: Scaling language modeling with pathways",
      "authors": [
        "Aakanksha Chowdhery",
        "Sharan Narang",
        "Jacob Devlin",
        "Maarten Bosma",
        "Gaurav Mishra",
        "Adam Roberts",
        "Paul Barham",
        "Hyung Won Chung",
        "Charles Sutton",
        "Sebastian Gehrmann",
        "Parker Schuh",
        "Kensen Shi",
        "Sasha Tsvyashchenko",
        "Joshua Maynez",
        "Abhishek Rao",
        "Parker Barnes",
        "Yi Tay",
        "Noam Shazeer",
        "Emily Vinodkumar Prabhakaran",
        "Nan Reif",
        "Ben Du",
        "Reiner Hutchinson",
        "James Pope",
        "Jacob Bradbury",
        "Michael Austin",
        "Guy Isard",
        "Pengcheng Gur-Ari",
        "Toju Yin",
        "Anselm Duke",
        "Sanjay Levskaya",
        "Sunipa Ghemawat",
        "Henryk Dev",
        "Xavier Michalewski",
        "Vedant Garcia",
        "Kevin Misra",
        "Liam Robinson",
        "Denny Fedus",
        "Daphne Zhou",
        "David Ippolito",
        "Hyeontaek Luan",
        "Barret Lim",
        "Alexander Zoph",
        "Ryan Spiridonov",
        "David Sepassi",
        "Shivani Dohan",
        "Mark Agrawal",
        "Omernick"
      ],
      "year": "2023",
      "venue": "Journal of Machine Learning Research",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Explaining answers with entailment trees",
      "authors": [
        "Bhavana Dalvi",
        "Peter Jansen",
        "Oyvind Tafjord",
        "Zhengnan Xie",
        "Hannah Smith",
        "Leighanna Pipatanangkura",
        "Peter Clark"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2021.emnlp-main.585"
    },
    {
      "id": "b4",
      "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/N19-1423"
    },
    {
      "id": "b5",
      "title": "Frame semantics. Cognitive linguistics: Basic readings",
      "authors": [
        "J Charles",
        "Fillmore"
      ],
      "year": "2006",
      "venue": "Frame semantics. Cognitive linguistics: Basic readings",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "Retrieval-augmented generation for large language models: A survey",
      "authors": [
        "Yunfan Gao",
        "Yun Xiong",
        "Xinyu Gao",
        "Kangxiang Jia",
        "Jinliu Pan",
        "Yuxi Bi",
        "Yi Dai",
        "Jiawei Sun",
        "Meng Wang",
        "Haofen Wang"
      ],
      "year": "2024",
      "venue": "Retrieval-augmented generation for large language models: A survey",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "Survey of hallucination in natural language generation",
      "authors": [
        "Ziwei Ji",
        "Nayeon Lee",
        "Rita Frieske",
        "Tiezheng Yu",
        "Dan Su",
        "Yan Xu",
        "Etsuko Ishii",
        "Ye",
        "Jin Bang",
        "Andrea Madotto",
        "Pascale Fung"
      ],
      "year": "2023",
      "venue": "ACM Comput. Surv",
      "doi": "10.1145/3571730"
    },
    {
      "id": "b8",
      "title": "Retrieval-augmented generation for knowledgeintensive nlp tasks",
      "authors": [
        "Patrick Lewis",
        "Ethan Perez",
        "Aleksandra Piktus",
        "Fabio Petroni",
        "Vladimir Karpukhin",
        "Naman Goyal",
        "Heinrich Küttler",
        "Mike Lewis",
        "Wen-Tau Yih",
        "Tim Rocktäschel",
        "Sebastian Riedel",
        "Douwe Kiela"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "Are emergent abilities in large language models just in-context learning? Pruthvi Patel, Swaroop Mishra, Mihir Parmar, and Chitta Baral. 2022. Is a question decomposition unit all we need?",
      "authors": [
        "Sheng Lu",
        "Irina Bigoulaeva",
        "Rachneet Sachdeva",
        "Harish Tayyar Madabushi",
        "Iryna Gurevych"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2022.emnlp-main.302"
    },
    {
      "id": "b10",
      "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "authors": [
        "Colin Raffel",
        "Noam Shazeer",
        "Adam Roberts",
        "Katherine Lee",
        "Sharan Narang",
        "Michael Matena",
        "Yanqi Zhou",
        "Wei Li",
        "Peter J Liu"
      ],
      "year": "2020",
      "venue": "J. Mach. Learn. Res",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Sentence-BERT: Sentence embeddings using Siamese BERTnetworks",
      "authors": [
        "Nils Reimers",
        "Iryna Gurevych"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "doi": "10.18653/v1/D19-1410"
    },
    {
      "id": "b12",
      "title": "Automatic keyword extraction from individual documents",
      "authors": [
        "Stuart Rose",
        "Dave Engel",
        "Nick Cramer",
        "Wendy Cowley"
      ],
      "year": "2010",
      "venue": "Text mining: applications and theory",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy",
      "authors": [
        "Zhihong Shao",
        "Yeyun Gong",
        "Yelong Shen",
        "Minlie Huang",
        "Nan Duan",
        "Weizhu Chen"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2023",
      "doi": "10.18653/v1/2023.findings-emnlp.620"
    },
    {
      "id": "b14",
      "title": "Retrieval augmentation reduces hallucination in conversation",
      "authors": [
        "Kurt Shuster",
        "Spencer Poff",
        "Moya Chen",
        "Douwe Kiela",
        "Jason Weston"
      ],
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021",
      "doi": "10.18653/v1/2021.findings-emnlp.320"
    },
    {
      "id": "b15",
      "title": "Finetuned language models are zero-shot learners",
      "authors": [
        "Jason Wei",
        "Maarten Bosma",
        "Vincent Zhao",
        "Kelvin Guu",
        "Adams Wei Yu",
        "Brian Lester",
        "Nan Du",
        "Andrew M Dai",
        "Quoc V Le"
      ],
      "year": "",
      "venue": "Finetuned language models are zero-shot learners",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "Emergent abilities of large language models",
      "authors": [
        "Jason Wei",
        "Yi Tay",
        "Rishi Bommasani",
        "Colin Raffel",
        "Barret Zoph",
        "Sebastian Borgeaud",
        "Dani Yogatama",
        "Maarten Bosma",
        "Denny Zhou",
        "Donald Metzler",
        "Ed H Chi",
        "Tatsunori Hashimoto",
        "Oriol Vinyals",
        "Percy Liang",
        "Jeff Dean",
        "William Fedus"
      ],
      "year": "2022",
      "venue": "Transactions on Machine Learning Research",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Chain of thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Fei Xia",
        "Ed H Chi",
        "Denny Quoc V Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Least-to-most prompting enables complex reasoning in large language models",
      "authors": [
        "Denny Zhou",
        "Nathanael Schärli",
        "Le Hou",
        "Jason Wei",
        "Nathan Scales",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Claire Cui",
        "Olivier Bousquet",
        "Ed H Quoc V Le",
        "Chi"
      ],
      "year": "2023",
      "venue": "The Eleventh International Conference on Learning Representations",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Fs-Rag: A Frame Semantics Based Approach For Improved Factual Accuracy In Large Language Models",
      "text": "Harish Tayyar Madabushi The University of Bath, Bath, UK htm43@bath.ac.uk"
    },
    {
      "title": "Abstract",
      "text": "We present a novel extension to Retrieval Augmented Generation with the goal of mitigating factual inaccuracies in the output of large language models. Specifically, our method draws on the cognitive linguistic theory of frame semantics for the indexing and retrieval of factual information relevant to helping large language models answer queries. We conduct experiments to demonstrate the effectiveness of this method both in terms of retrieval effectiveness and in terms of the relevance of the frames and frame relations automatically generated. Our results show that this novel mechanism of Frame Semantic-based retrieval, designed to improve Retrieval Augmented Generation (FS-RAG), is effective and offers potential for providing data-driven insights into frame semantics theory. We provide open access to our program code and prompts1. Footnote 1: [https://github.com/H-TayyarMadabushi/A-Frame-](https://github.com/H-TayyarMadabushi/A-Frame-) Semantics-based-approach-for-Improved-Factual-Accuracy-in-Large-Language-Models"
    },
    {
      "title": "1 Introduction, Motivation And Context",
      "text": "Large language models (LLMs), despite their significant capabilities and widespread adoption have the inherent tendency to generate plausible sounding, yet inaccurate, output. This phenomenon, referred to as \"hallucinations,\" has been a significant stumbling block in the widespread deployment of these solutions (Ji et al., 2023). Hallucinations themselves are not limited to factual inaccuracies, and include other modes of failure, including the incorrect interpretation of input prompts and errors in logical inference. However, factual hallucinations are particularly important to address as the retrieval of incorrect facts is particularly hard to recover from and can neutralise and make irrelevant all other improvements. The capabilities of LLMs typically improve with an increase in their \"size,\" which is a combination of a model's parameters and the size of the pre-training corpus. Until recently, this was seen by some as being evidence that further scaling would eventually address the shortcomings of LLMs, including hallucinations. For example, LLMs were claimed to develop \"emergent abilities\": specifically, it was believed that LLMs, when scaled to several billion parameters developed capabilities including those required to solve tasks requiring reasoning in humans, thus indicative that they were developing reasoning skills (Wei et al., 2022). More recent work, however, has shown that this is not the case and that LLMs instead develop a single capability, which they leverage to solve tasks (Lu et al., 2023). This capability, called \"in-context learning,\" is, roughly put, the ability of models to solve a particular task based on a few examples provided in the prompt (Brown et al., 2020; Chowdhery et al., 2023). (Lu et al., 2023) further suggest that the process of instructional fine-tuning LLMs to understand instructions (Wei et al., 2022), enables models to leverage the same \"in-context\" abilities even in the absence of examples. This finding indicates that further scaling, while providing improved instruction following abilities, will not grant modes the broader capacity to for general reasoning. The fact that LLMs are not likely to develop the ability to reason has profound implications to work on improving them, including to mitigating hallucinations. It implies that we must explore alternative approaches. This is especially the case when it comes to factual hallucinations as the 'parametric memory' in LLMs is orders of magnitude smaller than the pre-training data (Ji et al., 2023). As such, they must necessarily use some method of compressing their pre-training data. Without the ability to distinguish between the information that is relevant and what is not relevant in their pre-training data, their method of compression defaults to be the memorisation of frequent information and the learning of statistical patterns and trends to represent the less frequent information."
    },
    {
      "title": "Retrieval Augmented Generation",
      "text": "Given this context, it isn't surprising that Retrieval Augmented Generation, or RAG, which involves the inclusion of relevant information to the prompt has been so successful Lewis et al. (2020). It provides a viable mechanism of offloading information retrieval (IR) demands and instead focuses on using the LLM as a mechanism of analysing and processing data based on explicit instructions. It should be noted that analysing and processing data through explicit instructions is precisely what models excel at through in-context learning. Importantly, RAG also provides a solution to another of LLMs' problems, which is the outdating of knowledge. By incorporating the latest information, RAG prevents the need for further training for even minor knowledge updates to the LLM which is clearly infeasible Shuster et al. (2021). However, RAG comes with its own shortcomings. RAG transfers the problem of mitigating factual hallucinations to one of retrieving information relevant to answering a query Gao et al. (2024). While LLMs can handle some noise in the retrieved context provided, a dramatic increase in noise unsurprisingly leads to deteriorating performance of models. The retrieval of information relevant to answering a query is non-trivial as such information is not always likely to be semantically related to the query. This problem becomes even more important when the query requires reasoning over multiple facts each of which are progressively semantically further from the query. Overall, the fact that logically connected information is not always semantically similar makes existing keyword and semantic similarity based search and IR systems poorly suited for the specific IR requirements of LLMs. Existing mechanisms of dealing with this problem in information retrieval typically involve using LLMs themselves to solve this problem. Broadly, there are two ways of doing this: the first involves the use of LLMs to decompose the query into sub-queries each of which require less complex reasoning Patel et al. (2022); Zhou et al. (2023), and the second involves the use of LLMs to generate intermediary reasoning steps, called chain of thought Wei et al. (2022), to answer the query. These intermediary steps are then used to generate IR search queries and the resultant facts are fed back to an LLM to generate a response Shao et al. (2023). While these methods show some promise, the problem with them is clear: they are yet another opaque mechanism the failure of which will be hard to fix. In fact, we might be able to improve these systems be fine-tuning models to perform this task. However, such a solution is only going to further obfuscate the process."
    },
    {
      "title": "Contributions",
      "text": "_To address these concerns we propose a novel, transparent, and mutable storage and retrieval system for the mitigation of factual hallucinations in LLMs. This solution is based on theoretical insights from cognitive linguistics, specifically frame semantics._ Specifically, this work makes the following contributions: 1. We propose a novel, transparent, and mutable storage and retrieval system for the mitigation of factual hallucinations in LLMs which is based on theoretical insights from frame semantics. We call this system FS-RAG. 2. We show the effectiveness of our method by experimenting on a closed domain question answering. Specifically, our method of storage and retrieval provides a significant boost over both traditional search systems and, significantly, also outperforms an LLM based search system wherein we generate search terms using a Language Model. 3. We show that our method has the significant additional advantage of being interpretable, and thus having the potential to provide data-driven insights to the theory of frame semantics."
    },
    {
      "title": "2 Frame Semantics",
      "text": "Given the context provided earlier, it is evident that only the most frequently occurring factual information from pre-training is explicitly retained in LLMs. Less frequently occurring facts are not explicitly stored and instead the model has access to only statistical approximations. Given that the exact information stored is not explicit and also different for models of different scale and training regimes, the only way to get around hallucination is to explicitly provide LLMs with all but the most common information The effectiveness of RAG provides an easy mechanism for including such information. However, as mentioned previously, the effectiveness of this method hinges on the non-trivial task of retrieving relevant information. We propose that this mechanism can be found in the concept of Frame Semantics in cognitive linguistics, which purportedly facilitate human understanding of words by allowing us to recall pertinent information. Frame semantics Fillmore et al. (2006) is a theory of linguistic meaning that emphasises that the meanings of words are best understood by the semantic and conceptual \"frames\" or \"schemas\" within which they function. A frame is a cognitive structure that helps individuals understand and perceive the world around them, enabling them to organise knowledge based on typical situations, actions, or common experiences. In linguistics, a frame influences how the meanings of words are interpreted in different contexts. For example, the word \"sell\" invokes a commercial transaction frame involving a seller, a buyer, an item being sold, and an agreed price and helps to predict and explain the use of other related words and the roles they play within the same context. FrameNet Baker et al. (1998) is an online database based on frame semantics, with the goal to catalogue English words and their associated semantic frames, defining the various roles and relations in a frame and illustrating these with example sentences. Each \"frame\" in FrameNet captures a specific type of event, relation, or entity and the roles associated with it. For example, the commerce_sell frame in FrameNet includes roles for the seller, the buyer, the goods being sold, and is annotated to be inherited by the frame renting_out and as a \"perspective on\" the frame commerce_goods-transfer."
    },
    {
      "title": "3 Frame Semantic Rag",
      "text": "This section provides an overview of Frame Semantic RAG (FS-RAG), the proposed mechanism of storing and indexing factual information to aid effective retrieval for the mutation of hallucinations in LLMs. In evaluating our mechanism of retrieval we make use of Entailment Bank, Dalvi et al. (2021), which comprises science questions from school years 4 to 6, along with relevant facts and \"entailment trees\". Consider Table 1, which presents an example from the Entailment-Bank dataset. The original task involves building an entailment tree to answer questions and consists of three tasks at different levels of difficulty: a) Task 1 presents the model with all relevant facts and requires only the construction of the entailment tree; b) Task 2 requires the model to perform the same task, but with 15 to 25 distractors included; c) Task 3 involves first extracting the relevant facts from the entire corpus before constructing the entailment tree. The authors find that even a relatively small model, T5-11B Raffel et al. (2020), can perform relatively well on Tasks 1 and 2, when fine-tuned. Task 3, they find, is much harder highlighting the importance of efficient retrieval. We direct the reader to the results section of Dalvi et al. (2021) for details. Overall, these results reinforce our earlier points: Retrieval is non-trivial and improving retrieval has the potential to significantly boost model performance. In the example presented above, using search terms derived just from the question (e.g. \"eruption\") including more complex combinations (e.g. \"eruption and plants\") may not effectively retrieve relevant information. Additionally, if the search terms are too broad, it can cause the retrieval of a significant number of irrelevant facts. Both the lack of relevant facts and a large number of unrelated facts can hinder the model's performance. _This work is motivated by the hypothesis that \\begin{table} \\begin{tabular}{|p{28.5pt}|p{28.5pt}|} \\hline Question & How might eruptions affect plants? \\\\ \\hline \\multirow{4}{*}{Associated Facts} & F1: eruptions emit lava; F2: eruptions produce ash clouds; F3: plants have green leaves; F4: plant producers die without sunlight; F5: ash clouds block sunlight. \\\\ \\cline{2-3} & F2 + F5 implies I1: eruptions block sunlight; F4 + I1 implies I2: eruptions can cause plants to die. \\\\ \\cline{2-3} Answer & eruptions can cause plants to die. \\\\ \\hline \\end{tabular} \\end{table} Table 1: An example question from Entailment Bank and associated factoids. Language models find it significantly easier to generate the required entailment trees when presented with all relevant facts. However, the fact that the retrieval of relevant facts is non-trivial motivates a frame semantics based mechanism for indexing and search facts relevant to answering questions. we can significantly narrow the search space if we index facts-stored as plain text-according to the frames they invoke and use the frames associated with the question along with the relations between frames to retrieve relevant facts._ To test our hypothesis, we focus our experiments on the retrieval of relevant facts. In the above example, the FrameNet frames associated with the question could include: a) Surviving, which captures situations requiring endurance in a dangerous situation and includes annotations of the frame element \"Dangerous_situation\"; and b) Cause_harm, which describes a situation where an 'agent' injures a 'victim'. Our frame-based mechanism additionally allows the exploitation of the relations between frames to traverse the hierarchical interconnections between frames. This method approximates reasoning steps, enabling the retrieval of facts that are logically connected, even if they are not semantically similar. Within the limited scope of a single task, this work shows a significant improvement in retrieval (recall) using frames when compared to traditional search based baseline, and when compared to retrieval using search terms generated by LLMs, thus verifying the feasibility of this approach. Finally, we use the adaptability of state of the art LLMs to develop helper-LLMs that generate sets of frames, which we then evaluate and compare for their effectiveness in retrieving relevant information. Expanding these methods has the potential to provide, for the first time, data-driven insights that can be used to refine the theory of frame semantics."
    },
    {
      "title": "4 Experimental Settings",
      "text": "In this section, we describe the experiments we conduct to test the hypothesis that frame based indexing and search is a more effective mechanism than keyword based indexing."
    },
    {
      "title": "Task",
      "text": "Our choice of the specific task is motivated by the observation that LLMs can perform reasonably well when provided with relevant facts alongside some distractors. However, as described in the previous section, the retrieval of these relevant facts poses a significant challenge. Therefore, we focus on the task of retrieving relevant factoids for answering questions in Entailment Bank. Specifically, we focus on the information extraction subtask required in Task 3 described in Section 3. Notice that the effective retrieval of facts would simplify Task 3 to Task 2, the task of building entailment trees given the relevant facts and some distractors. Given how effective T5-11B, which, by current standards consists of relatively few parameters, is on Task 2, simplifying Task 3 to Task 2 provides a template for solving tasks based exclusively on retrieved facts, which would in turn help with the mitigation of factual hallucinations in LLMs. We slightly modify Task 3 by constructing the corpus of facts that we extract from using all the facts required by any question across the relevant data split, instead of the complete text book corpus which is harder to process. Regardless, we evaluate frame semantic retrieval and the baselines on exactly the same set of questions and facts to ensure a fair comparison."
    },
    {
      "title": "Empirical Evaluation Metrics",
      "text": "Given the nature of our task, we select Retrieval@k as our evaluation metric. The average length of entailment trees in the Entailment Bank dataset 7.6 with very few having more than 10. Given that Task 2 (described previously in Section 3) includes between 15 and 25 distractors, we test our methods using Retrieval@k for \\(k\\in 35,40,45\\). Success in this setting will demonstrate that our retrieval mechanism can effectively simplify Task 3, which requires retrieval from the entire corpus, into Task 2, which involves building entailment trees based on relevant facts and a few distractors. Recall that models perform significantly better on Task 2 than on Task 3."
    },
    {
      "title": "Baselines",
      "text": "We use two different baselines to compare the effectiveness of frame semantic indexing and retrieval against. The first, is a simple keyword match baseline and is chosen due to our emphasis on interpretability and ease of correction. Being able to understand why a system retrieves certain facts enables refinement of the system by reassigning facts to different clusters or index buckets. This level of transparency is not possible with more opaque methods, such as dense vector-based retrieval. Since frame semantic retrieval implicitly provides interpretable we choose a baseline that is similarly transparent. We first generate search terms by feeding the relevant question to RAKE (Rose et al., 2010), a tool for extracting search terms, which is known to be effective. We then perform a simple string match to extract all factoids that contain the keywords. The second baseline we use is not directly comparable as it is not interpretable. This consists of using an LLM to generate relevant search terms and is included so we might compare frame semantic retrieval to a rough analogue of question decomposition, a standard mechanism used in RAG as described above. Both baselines can be boosted using several techniques. For example, we do not generate chain of thoughts before generating the search terms using GPT-4, which is likely to improve the effectiveness of the resultant search terms. This is because the purpose of this work is not create a mechanism that outperforms existing methods, but to establish the feasibility of the frame semantic indexing and retrieval process which has the advantage of being interpretable and being based on cognitive linguistic theory."
    },
    {
      "title": "5 Frame Semantic Retrieval: Methods And Qualitative Analysis",
      "text": "In this section we detail the methods used for frame semantic indexing and retrieval. Given that one of objectives is to maintain interpretability and to to potentially provide data-driven insights to the theory of frame semantics, we perform a qualitative analysis of the outputs of each of the stages. An empirical evaluation of the effectiveness of these methods is presented next, in Section 6. The mechanism of retrieving information based on frame semantics consists of three distinct stages: The first is a pre-processing step, which involves indexing all relevant factoids based on between two and four of the most prominent frames that they invoke. The second and third steps are performed when answering a question at inference time and involve identifying the single most important frame associated with the question (the question frame), and frames associated with the question frame, which are likely to be associated with factoids relevant to answering the original question but separated by one or more logical steps. The most important parts of the prompts associated with each of these steps along with example outputs are presented in Table 2. The complete prompts, including prior versions we experimented with, are included in the supplementary data uploaded with this paper. In all cases, we prompt GPT-4 (OpenAI et al., 2024) using a temperature of 0 to ensure reproducible results."
    },
    {
      "title": "Frame Identification",
      "text": "There are two difficulties in identifying the frames associated with facts or questions. The first is the necessity to define a complete set of frames, and the second is the linking of these frames to the relevant fact or question. Our exploratory experiments of using FrameNet as a definitive source of all frames which we use to compare against facts and questions from Entailment Bank, showed that FrameNet is inadequate for this purpose. Specifically, the approximately 1,200 frames indexed on FrameNet have two significant shortcomings. The first is FrameNet's focus on 'trigger' words to identify frames is problematic. This emphasis on individual trigger words, likely influenced by the tools available at the time of FrameNet's inception, overlooks the fact that a sentence, as a whole, might invoke a frame that is difficult to identify through trigger words alone, which themselves can be challenging to extract within sentences. The second is the fact that the frames available within FrameNet cover a limited set of domains, which overlap minimally with the frames that are appropriate for the Entailment Bank dataset. To address these issues, we bootstrap the creation of frames using an LLM, specifically GPT-4. We prompt GPT-4 to generate frames relevant to the input fact or question, allowing us to organically expand our set of frames. We use in-context examples, selected from the training set, to enable the model to better output relevant frames. The complete prompts, including prior versions we experimented with, are included in the supplementary data uploaded with this paper. We start with an empty 'frame set' and iteratively generate frames associated with facts and questions. For each fact or question, the frames output by GPT-4 are compared with the existing frames previously generated (or none in the initial instances). This comparison is also done with the help of GPT-4. We first extract 5 frames, whose frame names are most semantically similar to that of the newly generated frame. This is done using sentence BERT (Reimers and Gurevych, 2019), an effective semantic similarity metric that originally relied on BERT (Devlin et al., 2019), but now makes use of custom contextual embeddings. We then prompt GPT-4 to determine if the newly generated frame must be added to the frame set. As an example, GPT-4, when prompted to generate frames related to the factoid \"the gravitational [MISSING_PAGE_EMPTY:6] pull of the sun on earth's oceans causes the tides,\" might generate gravitational influence and tidal movement. These frames are compared against the existing frames and the frame gravitational influence might be replaced by the similar frame gravitational attraction already in our frame set. If a similar frame is not found, the original frame is added to the frame set. This same process is then used to generate frames associated with questions. We find that this method is sub-optimal and that GPT-4 is a poor judge of identifying frames which are truly different form those already in the frame set. As such, we always augment the original set of frames with five frames whose names are most semantically similar to the original. See also Table 2 for more examples."
    },
    {
      "title": "Frame Relations",
      "text": "We call the overlap between the frames invoked by a question and those invoked by the facts necessary for answering that question a first-order frame overlap. This first-order overlap is not sufficient to extracting all facts that are relevant to answering a question. As such, we require a means of identifying relations between frames, so we can expand the set of relevant frames to include those which are related to the original, as a proxy for the reasoning process. This is in addition to the expansion using semantic similarity described previously. Instead of importing definitions of frame relations, for example from FrameNet, we generate these relations using a data-driven approach. Specifically, we extract questions and associated facts from the training data. We then assign frames to both the questions and the facts using the methods described previously. The frames associated with the questions and the corresponding facts are assumed to hold a latent relation, which we use to generate similar frame relations at the time of answering questions. This is done by prompting GPT-4 with the relevant question and the frame associated with the frame and requiring GPT-4 to generate frames relevant to answering the question. Row three of Table 2 presents the prompt and an example output of this step."
    },
    {
      "title": "Qualitative Analysis",
      "text": "A qualitative analysis of resultant frames and frame relations demonstrate the surprising effectiveness of this method. Table 2 presents some of the frames and frame relations automatically generated using the methods described above. The results are far from perfect, but are interesting from the perspectives of the diversity and adaptability they present. It is important to note that these results are achieved though prompting alone. Given that LLMs, such as GPT-4, are unlikely to be designed to solve tasks such as this, it is not surprising that there is much room for improvement, although the results demonstrate the feasibility of this method. Overall, we believe that bootstrapping these methods-by first manually refining a dataset generated through prompting, then iteratively training models specifically for this task, and subsequently using that model to generate more data-is an effective way to scale these methods."
    },
    {
      "title": "6 Empirical Evaluation",
      "text": "In addition to the qualitative analysis we present an empirical evaluation of the frame semantic retrieval methods described above. We compare the performance of frame semantic retrieval to the two search based baselines described in Section 4.3. We present the results in Table 3. Overall, we find that frame semantic retrieval outperforms both the simple search based baseline and the baseline where search terms are generated using GPT-4 by a significant margin. Recall that we test our methods using Retrieval@k for \\(k\\in 35,40,45\\) to take into account the fact that this allows us to demonstrate that our retrieval mechanism can effectively simplify Task 3, which requires retrieval from the entire corpus, into Task 2, which involves building entailment trees based on relevant facts and a few distractors. While our results are not perfect, frame semantic indexing and retrieval has one significant advantage. It is the fact that each stage of the process can be improved by fine-tuning LLMs for the specific purpose. In addition, the transparent nature of this process, which outputs frames at each stage, allows for the analysis and 'debugging' of each stage."
    },
    {
      "title": "7 Conclusions And Future Work",
      "text": "This work presents a novel mechanism for the indexing and retrieval of facts relevant for answering specific questions with the purpose of mitigating factual hallucinations in LLMs. This work demonstrates the feasibility and effectiveness of this method in both retrieval and the automatic generation of frames which, when scaled to multiple tasks, has the potential to provide data-driven insights to the theory of Frame Semantics. We believe that this work provides a template for effectively integrating cognitive linguistics and LLM research, benefiting both fields. In future work, we intend to first create models that are specifically fine-tuned to perform each of the tasks described above, specifically frame generation, frame identification and frame relation identification. In addition, we indent to extend this work to multiple tasks so as to establish its effectiveness."
    },
    {
      "title": "Limitations",
      "text": "This work presents a novel method of indexing and retrieval of facts specifically for the purpose of ensuring that LLMs reason over retrieved, and therefore correct facts, thereby mitigating factual hallucinations in LLMs. Our experiments are based on a single task in a specific domain. As a proof of concept of a novel method that is based on cognitive linguistic theory, these experiments are effective in showcasing the feasibility of this method. However, demonstrating the effectiveness of this method on multiple tasks is required for a more rigorous test, which we leave to future work. Additionally, our experiments, however, do not extend to testing LLMs for reduced hallucinations - prior work implies that improved retrieval will indeed lead to reduced hallucinations, but it is left to future work to rigorously test this."
    },
    {
      "title": "References",
      "text": "* S. Abadi, M. A. Abadi, and M. A. Abadi (2018)Audio-based approach to the evaluation of the performance of a novel method. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Online and Punta Cana, Dominican Republic, pp. 1-11. Cited by: SS2. * S. Abadi, M. A. Abadi, and M. A. Abadi (2018)Audio-based approach to the evaluation of the performance of a novel method. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Online and Punta Cana, Dominican Republic, pp. 1-11. Cited by: SS2. * S. Abadi, M. A. Abadi, and M. A. Abadi (2018)Audio-based approach to the evaluation of the performance of a novel method. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Online and Punta Cana, Dominican Republic, pp. 1-1. Cited by: SS2. * S. Abadi, M. A. Abadi, and M. A. Abadi (2018)Audio-based approach to the evaluation of the performance of a novel method. Charles J Fillmore et al. 2006. Frame semantics. _Cognitive linguistics: Basic readings_, 34:373-400. * Gao et al. (2024) Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen Wang. 2024. Retrieval-augmented generation for large language models: A survey. * Ji et al. (2023) Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of hallucination in natural language generation. _ACM Comput. Surv._, 55(12). * Lewis et al. (2020) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kuttler, Mike Lewis, Wen-tau Yih, Tim Rocktaschel, Sebastian Riedel, and Douwe Kiela. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. In _Advances in Neural Information Processing Systems_, volume 33, pages 9459-9474. Curran Associates, Inc. * Lu et al. (2023) Sheng Lu, Irina Bigoulaeva, Rachneet Sachdeva, Harish Tayyar Madabushi, and Iryna Gurevych. 2023. Are emergent abilities in large language models just in-context learning? * OpenAI et al. (2020) OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiai Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simon Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kafatan, Lukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Lukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosc, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Tedby Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mely, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O'Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbutte Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurur, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B. Thompson, Phil Tillet, Amin Tootouchonian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Ceron Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. 2024. Gpt-4 technical report. * Patel et al. (2022) Prutwi Patel, Swaroop Mishra, Mihir Parmar, and Chitta Baral. 2022. Is a question decomposition unit all we need? In _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 4553-4569, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. * Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. _J. Mach. Learn. Res._, 21(1). * Raffel et al. (2020)Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence embeddings using Siamese BERT-networks. In _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)_, pages 3982-3992, Hong Kong, China. Association for Computational Linguistics. * Rose et al. (2010) Stuart Rose, Dave Engel, Nick Cramer, and Wendy Cowley. 2010. Automatic keyword extraction from individual documents. _Text mining: applications and theory_, pages 1-20. * Shao et al. (2023) Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen. 2023. Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy. In _Findings of the Association for Computational Linguistics: EMNLP 2023_, pages 9248-9274, Singapore. Association for Computational Linguistics. * Shuster et al. (2021) Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021. Retrieval augmentation reduces hallucination in conversation. In _Findings of the Association for Computational Linguistics: EMNLP 2021_, pages 3784-3803, Punta Cana, Dominican Republic. Association for Computational Linguistics. * Wei et al. (2022a) Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V Le. 2022a. Finetuned language models are zero-shot learners. In _International Conference on Learning Representations_. * Wei et al. (2022b) Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022b. Emergent abilities of large language models. _Transactions on Machine Learning Research_. Survey Certification. * Wei et al. (2022c) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou. 2022c. Chain of thought prompting elicits reasoning in large language models. In _Advances in Neural Information Processing Systems_. * Zhou et al. (2023) Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, and Ed H. Chi. 2023. Least-to-most prompting enables complex reasoning in large language models. In _The Eleventh International Conference on Learning Representations_."
    }
  ]
}
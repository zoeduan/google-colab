<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TrafficSafetyGPT: Tuning a Pre-trained Large Language Model to a Domain-Specific Expert in Transportation Safety</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>PhD</roleName><forename type="first">Ou</forename><surname>Zheng</surname></persName>
							<email>ou.zheng@ucf.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Civil</orgName>
								<orgName type="department" key="dep2">Environmental &amp; Construction Engineering</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<postCode>32816</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>PhD</roleName><forename type="first">Mohamed</forename><surname>Abdel-Aty</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Civil</orgName>
								<orgName type="department" key="dep2">Environmental &amp; Construction Engineering</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<postCode>32816</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>PhD</roleName><forename type="first">Dongdong</forename><surname>Wang</surname></persName>
							<email>dongdong.wang@ucf.edu</email>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Civil</orgName>
								<orgName type="department" key="dep2">Environmental &amp; Construction Engineering</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<postCode>32816</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>PhD</roleName><forename type="first">Chenzhu</forename><surname>Wang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Civil</orgName>
								<orgName type="department" key="dep2">Environmental &amp; Construction Engineering</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<postCode>32816</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shengxuan</forename><surname>Ding</surname></persName>
							<email>shengxuan.ding@ucf.edu</email>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Civil</orgName>
								<orgName type="department" key="dep2">Environmental &amp; Construction Engineering</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<postCode>32816</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">TrafficSafetyGPT: Tuning a Pre-trained Large Language Model to a Domain-Specific Expert in Transportation Safety</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EC23E29DFD64B17A71849148E681763A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ChatGPT</term>
					<term>Natural Language Processing</term>
					<term>Deep Learning</term>
					<term>Traffic Safety</term>
					<term>Large Language Models</term>
					<term>Generative Pre-trained Transformers</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large Language Models (LLMs) have shown remarkable effectiveness in various generaldomain natural language processing (NLP) tasks. However, their performance in transportation safety domain tasks has been suboptimal, primarily attributed to the requirement for specialized transportation safety expertise in generating accurate responses <ref type="bibr" target="#b0">[1]</ref>. To address this challenge, we introduce TrafficSafetyGPT, a novel LLaMA-based model, which has undergone supervised fine-tuning using TrafficSafety-2K dataset which has human labels from government produced guiding books and ChatGPT-generated instruction-output pairs. Our proposed TrafficSafetyGPT model and TrafficSafety-2K train dataset are accessible at <ref type="url" target="https://github.com/ozheng1993/TrafficSafetyGPT">https://github.com/ozheng1993/TrafficSafetyGPT</ref> </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the realm of natural language processing (NLP) and large language models, a surge in advancements has unfolded a plethora of potential applications. This rapid development, spearheaded by pre-trained large language models like OpenAI's ChatGPT and its derivatives, has drastically augmented our capabilities in language comprehension, generation, and interactivity. The foundational strength of these models lies in their pre-training on extensive and diverse datasets, empowering them to decipher intricate language patterns and contextual interconnections.</p><p>Nevertheless, while these pre-trained models exhibit commendable proficiency across an array of tasks, their generic nature could constrain their efficacy in niche applications, such as transportation safety. The training of a Large Language Model (LLM) from scratch necessitates the ingestion of vast, heterogeneous data to master sophisticated language patterns and relationships, which in turn requires potent hardware like high-performance GPUs or TPUs to manage the colossal computational load during training. Furthermore, the training duration may extend from a few days to weeks, subject to the model's size and complexity.</p><p>This research paper aims to address this conundrum by concentrating on the fine-tuning of a pre-trained offline large language model, Meta AI's LLaMA, to cultivate a subject-matter expert in transportation safety. The process capitalizes on the pre-trained model's inherent knowledge and linguistic proficiency, amalgamating it with a comprehensive transportation safety dataset gleaned from government-produced guidelines and instruction-output pairs generated by ChatGPT. The objective is to engineer a specialized language model capable of producing precise, context-sensitive, and safety-conscious responses in traffic-related situations. The novelty of TrafficSafetyGPT is its potential to redefine how language models augment traffic safety and the broader transportation field. Instead of constructing a model from the ground up, our methodology refines the existing linguistic aptitude through fine-tuning with small dataset TrafficSafety-2k, yielding a more efficient allocation of computational resources and training time. Moreover, this tailored model assures that the output aligns with ratified traffic safety standards and guidelines, thus ensuring its practical applicability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Large Language Models</head><p>Large Language modeling (LLM) offers impressive capabilities in natural language processing and artificial intelligence. There were many models which have been proposed in the current analysis, including GPT4 <ref type="bibr" target="#b1">[2]</ref>, Palm2 <ref type="bibr" target="#b2">[3]</ref> , Claude <ref type="bibr" target="#b3">[4]</ref>, Cohere <ref type="bibr" target="#b4">[5]</ref>, Falcon <ref type="bibr" target="#b5">[6]</ref>, and Meta LLaMA <ref type="bibr" target="#b6">[7]</ref>.Some of the key roles of these large language models include natural language understanding, language generation, reasoning tasks, text processing, language tutoring and learning. The introduction of the GPT-4 model marked a significant advancement in natural language understanding and generation <ref type="bibr" target="#b7">[8]</ref>. This latest iteration showcased remarkable abilities across various domains, including complex reasoning, comprehensive comprehension, advanced coding capabilities, proficiency in diverse academic exams, and even human-level performance in numerous tasks <ref type="bibr" target="#b8">[9]</ref>. Its impressive attributes have garnered widespread attention and acclaim. For reasoning tasks, PaLm2 was an advanced language model from Google with enhanced multilingual capabilities, improved reasoning skills, and proficient coding capabilities, having been trained on a diverse dataset encompassing over 100 languages, scientific papers, web pages containing mathematical expressions, and publicly available source code datasets <ref type="bibr" target="#b2">[3]</ref>. In the aspect of text processing, Claude offers a wide range of use cases, such as summarization, search, creative and collaborative writing, Q&amp;A, coding, and much more. Just like ChatGPT, Claude boasts a user-friendly chat interface and API, which developers can access through our developer console. Its outstanding abilities in handling various conversational and text processing tasks are complemented by its exceptional reliability and predictability <ref type="bibr" target="#b9">[10]</ref>. LLM impressed many users by virtue of its exceptionally superior performance based on billions of parameters, which provides a solid foundation for the fine-tuning of models. For example, Cohere offers offer multiple models, varying in size from small to large, with as few as 6 billion parameters to the larger models trained on an extensive 52 billion parameters <ref type="bibr" target="#b10">[11]</ref>. Moreover, Falcon is open-source and released under the Apache 2.0 license <ref type="bibr" target="#b11">[12]</ref>. This permits users to utilize the model for commercial purposes without any royalties or restrictive limitations. In addition, the official release of LLaMA models comes in different sizes, ranging from 7 billion to 65 billion parameters. Numerous developers are utilizing LLaMA for fine-tuning and creating exceptional open-source models <ref type="bibr" target="#b12">[13]</ref>. However, it is important to note that LLaMA has been made available for research purposes exclusively. As an extension of LLaMA, Meta LLaMA 2 introduces pertained and fine-tuned LLMs with 7B, 13B, and 70B parameters. These models improve upon LLaMA 1 with 40% more tokens, a context length of 4,000 tokens for better language comprehension, and grouped-query attention for faster inference in the 70B model <ref type="bibr" target="#b13">[14]</ref>. Given this, the existing Large Language Models were developed to be more academic and human-level in many aspects of studies. However, in the field of traffic safety, a limited body of research efforts has been proposed to analyze trajectory prediction <ref type="bibr" target="#b14">[15]</ref>, safety planning and design <ref type="bibr" target="#b15">[16]</ref>, safety rules <ref type="bibr" target="#b16">[17]</ref>, etc. And LLaMA is proven to be effective and available in research analysis, which will be used as the base model of the TrafficSafetyGPT in the current study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pre-trained Models with Domain Knowledge Fine-tuning</head><p>Due to the swift advancements in LLM and the increasing demands for practical applications across diverse fields, researchers recognized the need to enhance the performance of LLMs by fune turning the models based on domain knowledge. For example, researchers have acknowledged the imperative to improve the performance of LLMs in medical applications, where precision is of utmost importance, primarily due to their limited domain-specific knowledge. To address this issue, they developed ChatDoctor, a specialized model tailored specifically for the biomedical field. The main objective of ChatDoctor is to enhance the understanding of LLMs in this domain. This endeavor underscores the significance of integrating domain-specific knowledge to attain superior outcomes in medical applications <ref type="bibr" target="#b17">[18]</ref>.</p><p>Another notable study focused on enhancing LLMs' performance in the specific domain through domain-specific knowledge transfer with different languages. As an illustration, researchers effectively fine-tuned the LLaMA model with Chinese medical knowledge, which contributed to improved comprehension and performance in Chinese LLM applications <ref type="bibr" target="#b18">[19]</ref>. This research emphasized the importance of domain-specific tuning to optimize LLMs for specific fields <ref type="bibr" target="#b19">[20]</ref>. Several technical approaches were explored to enhance domain knowledge transfer and fine-tuning of LLMs. Effective techniques such as soft fine-tuning <ref type="bibr" target="#b20">[21]</ref>, large-scale fine-grained categorization <ref type="bibr" target="#b20">[21]</ref>, and domain-specific transfer learning were employed to optimize LLM performance in specialized domains(). Additionally, the LLaMA-adapter method demonstrated efficient fine-tuning of language models with zero-init attention, contributing to better adaptability in domain-specific tasks <ref type="bibr" target="#b21">[22]</ref>. There are some domain knowledge datasets that support LLM fine-tuning, such as Alpaca, which contributes 52k instruction-following data points by leveraging Self-Instruct techniques to encode specific instructions within conversations <ref type="bibr" target="#b22">[23]</ref> .The HealthCareMagic-100k dataset encompasses 100k real-world patient-physician conversations, providing valuable insights into authentic medical interactions <ref type="bibr" target="#b17">[18]</ref>. On the other hand, GenMedGPT-5k enriches dataset diversity with 5k synthetic conversations between patients and physicians <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TrafficSafetyGPT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Foundation Model</head><p>We selected a lightweight version of ChatGPT-LLaMA as a foundation model. A family of models derived from LLaMA represents a cutting-edge collection of open-access large language models ranging from 7B to 70B parameters (7B, 13B, 70B) introduced by Meta AI, showcasing significant advancements in natural language processing research. However, LLaMA is made accessible under a non-commercial license, restricting its usage exclusively to academics with specific credentials. However, recent developments have been unveiled by Meta, with the announcement of LLaMA 2-a new family of AI language models that also falls under the source-available category but distinguishes itself with the inclusion of a commercial license, enabling broader usage beyond non-commercial purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Transportation Safety Knowledge</head><p>Government departments and agencies produce guiding books pertaining to specific domains, such as healthcare, education, finance, and more. This allows Large Language Models (LLMs) to grasp domain-specific language and terminologies, enhancing their ability to communicate effectively in specialized contexts. Moreover, these government guiding books encompass authoritative and accurate information on various subjects, including laws, regulations, policies, and procedures. By training LLMs on this data, they gain reliable knowledge, enabling them to deliver well-informed and precise responses. Additionally, exposure to real-world contexts and scenarios in these guiding books deepens LLMs' understanding of practical language applications, leading to more contextually relevant and useful outputs. Furthermore, the information contained in these books often involves decision-making processes, problem-solving guidelines, and strategies for complex situations. Consequently, LLMs trained on such data can offer valuable insights and recommendations in diverse governance and administrative tasks. We have manually labeled 665 rows of data from the perspective of traffic management, traffic operation, and drivers. The ground truth follows the government book as fine-tuning instruction data incorporating the NSTHA Model Minimum Uniform Crash Criteria (MMUCC) Guideline Fourth edition and FHWA's Highway Safety Manual (HSM) in the training process of LLMs contributes to creating safer, more informed, and reliable language models in the domain of traffic safety and transportation. However, books have a limited amount of labeled data, and relying solely on them for training a domain-specific language model may not be sufficient. rows of data related to transportation safety were generated by ChatGPT. Using generated conversations from ChatGPT with content from government departments and agencies guiding books as training data for a pre-trained large language model to become a domain-specific expert in transportation safety offers several benefits. The specialized nature of generated conversations ensures the model focuses solely on transportation safety topics while incorporating the comprehensive information from guiding books helps it gain an authoritative understanding of the subject. By simulating real-world scenarios, the model learns to respond appropriately to various safety concerns, enhancing its practical applicability. Moreover, using standardized information from government sources promotes consistency and accuracy in the model's responses while mitigating potential biases.</p><p>Achieving optimal performance necessitates a balanced approach, combining both generated and real data, and fine-tuning the model to ensure it provides reliable and knowledgeable insights in the transportation safety domain. We name this dataset TrafficSafety-2K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Knowledge-based Instruction Data</head><p>Table 2 Example of Knowledge-based Instruction Data Type Input Knowledge Definition What is the definition of a van in Motor Vehicle Traffic Crashes? A van is a motor vehicle consisting primarily of a transport device that has a gross vehicle weight rating (GVWR) of 10,000 pounds or less and is basically a "box on wheels" that is identifiable by its enclosed passenger and/or cargo area, step-up floor, and relatively short (or nonexistent) hood. Vans are classified by size based on frame type and overall vehicle body width. Before classification, vehicle width should be rounded to the nearest inch. Inclusions What are the inclusions of Trafficway in Motor Vehicle Traffic Crashes? Within areas with guarded entrances, such as military posts or private residential developments, land ways are trafficways if the guards customarily admit public traffic. Privately constructed and/or maintained road open to the public for moving persons or property for transportation purposes. Local road in a residential development, which is open to the public. Land way providing vehicular access and/or circulation from a trafficway to a business open to the public Exclusions What are the exclusions of a commercial motor vehicle in Motor Vehicle Traffic Crashes? Privately owned motor vehicle providing private transportation of personal property or people. Categories What is the guide to the classification of Persons by injury severity in Motor Vehicle Traffic Crashes? The injury classification applies to any person involved in road vehicle crashes while either in or out of a road vehicle. The categories are so defined that, for the most part, neither medical attention nor special tests are required for classification. Classification usually can be done by ordinary observation at the time of the crash or from information submitted on the crash report. Examples What are the Examples of transit bus in Motor Vehicle Traffic Crashes? City metro or ride-on bus.Trolley (on highway tires). Guidance How do you deal with collisions and emergencies? Personal safety and the safety of any passengers should always be your first consideration. Use your hazard warning lights and high-visibility clothing to make sure you and your vehicle can be seen by other road users. Collisions that result in injury while driving for work should be reported to the Gardai, as appropriate, and your line manager immediately. Details should be recorded on a preliminary incident report form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>We select ChatGPT as a baseline foundation model for text generation assessment. For efficient implementation, a pre-trained LLaMA-7B foundation model is chosen as a practical alternative and fine-tuned with domain knowledge. To improve domain-specific knowledge with limited data, we only tuned the last two layers. This fine-tuning strategy is developed for the reasons as follows. First, although our traffic-safety-domain specific data are adequate, the number is not comparable to the scale of a large language knowledge database, like Wikipedia. Fine-tuning all layers with limited data can easily result in overfitting. Second, the original features in the pretrained LLaMA are still helpful for language generation, like reasoning and fluency. Third, this fine-tuning on the last two layers saves lots of both space and time cost, which enables efficient training and practical implementation.</p><p>Based upon the designed strategy , we fine-tuned the LLaMA-7B model on the Lambda server with 8 RTX TITAN GPUs, 128 CPU cores, and 500GB RAM. The fine-tuning process is completed with three training epochs which costs ~70 CPU hours. The training is implemented with the hyper parameters as follows: the batch size of 16, the learning rate of 2X10-5, the epoch of 3, the maximum sequence length of 152 tokens, and the warm-up ratio of 0.03 without weight decay.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Base model</head><p>LLaMA is one of important foundational large language models created by Meta AI. Just like its counterparts in the field, LLaMA operates on the principle of accepting a word sequence as input and employing its predictive capabilities to generate subsequent words recursively, ultimately producing coherent and contextually appropriate text.</p><p>In the study, we follow the Stanford instruction-following LLaMA Model train processing: Alpaca <ref type="bibr" target="#b23">[24]</ref>. Figure <ref type="figure" target="#fig_0">1</ref> demonstrates the process for instruction-following, employing a methodology that builds upon the self-instruct approach utilized in MUCC and HSM. To initiate this process, we utilized a set of 1k instruction-output pairs that were previously humanlabeled in those specific books. Subsequently, we leveraged the In ChatGPT model, prompting it to generate additional instructions while utilizing the aforementioned human-labeled dataset as in-context examples. Figure <ref type="figure" target="#fig_1">2</ref> shows the example of human labels and ChatGPT generate instruction-output pairs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Metrics</head><p>We evaluate the proficiency of generated texts in traffic safety with domain questions of different kinds, including definition, inclusion, exclusion, category, example, and guidance. The generated answers to these questions are evaluated by several popular and reliable quantitative metrics, which examines the results from coverage, fluency, and brevity. For coverage, we selected BLEU, ROUGE, and BERTScore. For fluency, we chose BLEURT. For brevity, we count the words of the generated sentences.</p><p>Coverage. BLEU (bilingual evaluation understudy) is a popular metric for natural language generation. This algorithm is first proposed to evaluate machine translation performance. Since computer generated texts can be taken as a different language system from human language, this score can also reflect the quality of machine-generated texts. BLEU ranges from 0 to 1, which indicates the similarity between human languages and machine generated texts. However, this score is quantified heavily based upon word matching on golden labels, which can yield some bias. For example, a correctly generated machine language can still show a low BLEU score because of the paraphrase; meanwhile, just one word change may yield totally different meaning, but the BLEU score can stay similar.</p><p>ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is an algorithm to assess text summarization and machine translation. The metric can evaluate the information coverage of automatically produced texts on a reference passage which is usually a human-written summary. ROUGE relies on n-gram modeling which considers word overlapping between generated and reference texts. The common ROUGE scores include ROUGE-1 (overlap of unigrams), ROUGE-2 (overlap of bigrams), and ROUGE-L (longest common subsequence based statistics). Since ROUGE is proposed to solve a summarization problem, it is very effective and reliable to assess the information coverage. However, it can also result in the bias due to lack of semantic meaning understanding. Therefore, like BLEU, a high ROUGE score may lead to a sentence with a different meaning.</p><p>BERTScore is a recently proposed metric based upon a milestone large language model of BERT. It relies on the prediction results from BERT to evaluate candidate sentences and reference sentences by tokens. BERTScore computes the token similarity with the context embeddings, which replaces word exact match. This evaluation is more focused on comparison on a vectorized embedding space instead of a common letter system, which is more suitable for large language model evaluation. Since BERT is developed upon mask modeling, its word embeddings can reflect mask filling accuracy and help effectively assess information coverage. However, one of its important weaknesses is language model dependency, where model bias will be induced in the evaluation process.</p><p>Fluency. BLEURT (Bilingual Evaluation Understudy with Representations from Transformer) is adopted to evaluate the fluency of generated texts. This evaluation metric is developed based upon BERT, which is derived from the outputs of a robust BERT model pretrained by perturbed synthetic sentences from Wikipedia. This metric can reflect the paraphrase level and language fluency. Although it relies on a large language model and may induce model bias, its fluency assessment is more reliable due to pretraining on a large set of synthetic data.</p><p>Brevity. We adopt the Word Count to assess the brevity of the expression, which is straightforward and also popular in summarization evaluation. Fewer words indicate better brevity of the generated texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>To evaluate the efficacy of TrafficSafetyGPT, we conduct extensive experiments on various transportation safety-related tasks. We compare its performance with the state-of-the-art nonspecialized LLM of LLaMA. The results justify that TrafficSafetyGPT consistently outperforms on different specific tasks. This observation results from the success of domain-specific finetuning, especially with more structural presentation and professional expression. It is obtained that the information coverage of TrafficSafetyGPT is significantly higher than LLaMA, even on the BLEU score. The performance also shows that the enumeration tasks, like inclusions, exclusions, categories, and examples, are more challenging for language modeling because these tasks are sensitive to exact match with each single word. The performance gain of TrafficSafetyGPT on these tasks results from a larger domain specific terminology database, which helps enhance including more professional terms. For guidance, LLaMA exhibits wordy expressions with higher word count since the generalized domain does not provide technical information focus. TrafficSafetyGPT yields briefer expressions after fine-tuning on domainspecific contexts.</p><p>TABLE 3 The examples of TrafficSafetyGPT generated texts. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Data generation process for instruction-following.</figDesc><graphic coords="9,72.00,99.60,468.00,244.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2 Example of human label and ChatGPT generate instruction-following.</figDesc><graphic coords="9,72.00,371.20,468.00,228.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 TrafficSafety-2K number of data</head><label>1</label><figDesc>• NSTHA Model Minimum Uniform Crash Criteria (MMUCC) Guideline Fourth edition MMUCC was established with the aim of fostering increased uniformity and consistency. Its purpose is to offer State and Local agencies a standardized set of data variables related to motor vehicle traffic crashes, encouraging them to consider these elements for collection. The key components of MMUCC Guidelines cover various aspects of crash data collection and reporting, including 1689 rows of data. The first type is the definition. The guidelines provide standardized definitions for each data element, ensuring that different agencies interpret and record the information in the same way. In addition, MMUCC outlines the classification of crashes based on severity, collision type, and other relevant factors to enable meaningful analysis and comparison. Lastly, the guidelines offer recommendations on reporting formats and methods, encouraging efficient data exchange and sharing among agencies. • FHWA The Highway Safety Manual (HSM) The Highway Safety Manual (HSM), published by the American Association of State Highway Transportation Officials (AASHTO), is a valuable resource for evaluating traffic safety on existing or proposed roadways. It offers a science-based and technical approach that helps state and local agencies analyze safety without relying on guesswork. The HSM promotes a safety management process that involves identifying high-crash locations, analyzing contributing factors, and implementing countermeasures to mitigate risks and improve overall safety. 311 rows of data related to the safety management process are labeled in our work. It utilizes a data-driven approach and employs decisionmaking strategies to allocate resources more efficiently by focusing on locations with the greatest safety improvement potential.</figDesc><table><row><cell></cell><cell>NSTHA Model</cell><cell>FHWA The Highway</cell><cell>ChatGPT generated</cell></row><row><cell></cell><cell>Minimum Uniform</cell><cell>Safety Manual</cell><cell>Data</cell></row><row><cell></cell><cell>Crash Criteria</cell><cell>(HSM)</cell><cell></cell></row><row><cell></cell><cell>(MMUCC) Guideline</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Fourth edition</cell><cell></cell><cell></cell></row><row><cell>Number of label</cell><cell>1689</cell><cell>311</cell><cell>2000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 Comparison of TrafficSafetyGPT output Type of task ChatGPT TrafficSafetyGPT</head><label>4</label><figDesc>Nissan Leaf. A Chevy Spark, Chargé, or Volt. An Underwood Navigator. A Smart ForTwo. A Rhino. A parking lot Fuller hog. A metallic or all-plas tic bus vault. A custom made on a truck chassis. An exciting electric or hybrid road vehicle with speed postings or numbers.</figDesc><table><row><cell>Definitions</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>In this paper, we propose the TrafficSafetyGPT, a LLaMA-based model that addresses the limitations faced by Large Language Models in transportation safety domain tasks. By employing supervised fine-tuning with the TrafficSafety-2k dataset, human labels from the government produce guiding books and ChatGPT-generated instruction-output pairs. TrafficSafetyGPT demonstrates superior performance in generating responses with reliable traffic safety knowledge, allocating efficient computational resources and saving training time. Our research opens new avenues for enhancing language models' capabilities in transportation safety domains and contributes to the advancement of natural language processing applications in specialized fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">AUTHOR CONTRIBUTIONS</head><p>The authors confirm contribution to the paper as follows: study conception and design: Ou Zheng, Mohamed Abdel-Aty,Dongdong Wang,Shengxuan Ding,Chenzhu Wang; data collection and processing: Ou Zheng, Shengxuan Ding, Chenzhu Wang; analysis and interpretation of results: Chenzhu Wang, Dongdong wang; draft manuscript preparation: Ou Zheng, Mohamed Abdel-Aty,Dongdong Wang, Shengxuan Ding,Chenzhu Wang. All authors reviewed the results and approved the final version of the manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Availability</head><p>The TrafficSafetyGPT model and the curated training dataset are publicly accessible at <ref type="url" target="https://github.com/ozheng1993/TrafficSafetyGPT">https://github.com/ozheng1993/TrafficSafetyGPT</ref> for research and non-commercial purposes. It is crucial to emphasize that the accuracy of responses generated by large language models cannot be assured. The safety knowledge presented by these models should not be considered a replacement for professional engineer advice.We encourage researchers and practitioners to leverage this resource to further explore and improve language models' capabilities in transportation safety domains.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">ChatGPT is on the horizon: Could a large language model be all we need for Intelligent Transportation?</title>
		<author>
			<persName><forename type="first">O</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abdel-Aty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.05382</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">GPT-4 Technical Report</title>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<idno>abs/2303.08774</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Anil</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10403</idno>
		<title level="m">Palm 2 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Language Models Don&apos;t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Turpin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.04388</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Holistic Evaluation of Language Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Falcon: malware detection and categorization with network traffic images</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zarras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Machine Learning-ICANN 2021: 30th International Conference on Artificial Neural Networks</title>
		<meeting><address><addrLine>Bratislava, Slovakia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">September 14-17, 2021. 2021</date>
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I 30</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">LLaMA: Open and efficient foundation language models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Capabilities of gpt-4 on medical challenge problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mckinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carignan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13375</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03277</idno>
		<title level="m">Instruction tuning with gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models</title>
		<author>
			<persName><forename type="first">Y.-T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-N</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13711</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A step-by-step researcher&apos;s guide to the use of an AI-based transformer in epidemiology: an exploratory analysis of ChatGPT using the STROBE checklist for observational studies</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sanmarchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Public Health</title>
		<imprint>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">hybrid-Falcon: Hybrid Pattern Malware Detection and Categorization with Network Traffic and Program Code</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zarras</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.10035</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Meta LLaMA leak raises risk of AI-linked harms</title>
		<author>
			<persName><forename type="first">O</forename><surname>Analytica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Emerald Expert Briefings, no. oxan-es</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">LLaMA 2: Open Foundation and Fine-Tuned Chat Models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">CitySim: A drone-based vehicle trajectory dataset for safety oriented research and digital twins</title>
		<author>
			<persName><forename type="first">O</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abdel-Aty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdelraouf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mahmoud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.11036</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">AVOID: Autonomous Vehicle Operation Incident Dataset Across the Globe</title>
		<author>
			<persName><forename type="first">O</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abdel-Aty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.12889</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17788</idno>
		<title level="m">Exploratory Analysis of the Crash Severity between Vehicular Automation (SAE L2-5) with Multi-Source Data</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Chatdoctor: A medical chat model fine-tuned on LLaMA model using medical domain knowledge</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yunxiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zihan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ruilong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>You</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.14070</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Huatuo: Tuning LLaMA model with chinese medical knowledge</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.06975</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Pmc-LLaMA: Further finetuning LLaMA on medical papers</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.14454</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Effective domain knowledge transfer with soft fine-tuning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.02236</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">LLaMA-adapter: Efficient fine-tuning of language models with zero-init attention</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.16199</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Self-instruct: Aligning language model with self generated instructions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10560</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Stanford alpaca: An instruction-following LLaMA model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Taori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

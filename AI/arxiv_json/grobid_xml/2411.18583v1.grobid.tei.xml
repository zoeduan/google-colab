<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nurshat</forename><forename type="middle">Fateh</forename><surname>Ali</surname></persName>
							<email>nurshatfateh@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering Military Institute of Science and Technology Dhaka</orgName>
								<address>
									<country key="BD">Bangladesh</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shakil</forename><surname>Mosharrof</surname></persName>
							<email>shakilmrf8@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering Military Institute of Science and Technology Dhaka</orgName>
								<address>
									<country key="BD">Bangladesh</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Md</forename><forename type="middle">Mahdi</forename><surname>Mohtasim</surname></persName>
							<email>mahdimohtasim@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Engineering Military Institute of Science and Technology Dhaka</orgName>
								<address>
									<country key="BD">Bangladesh</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">T</forename><surname>Gopi</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science and Engineering Military Institute of Science and Technology Dhaka</orgName>
								<address>
									<country key="BD">Bangladesh</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2314EF7854567C9C14817A62E36DE240</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>T5</term>
					<term>SpaCy</term>
					<term>Large Language Model</term>
					<term>GPT</term>
					<term>ROUGE</term>
					<term>Literature Review</term>
					<term>Natural Language Processing</term>
					<term>Retrieval-augmented generation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This research presents and compares multiple approaches to automate the generation of literature reviews using several Natural Language Processing (NLP) techniques and retrieval-augmented generation (RAG) with a Large Language Model (LLM). The ever-increasing number of research articles provides a huge challenge for manual literature review. It has resulted in an increased demand for automation. Developing a system capable of automatically generating the literature reviews from only the PDF files as input is the primary objective of this research work. The effectiveness of several Natural Language Processing (NLP) strategies, such as the frequency-based method (spaCy), the transformer model (Simple T5), and retrievalaugmented generation (RAG) with Large Language Model (GPT-3.5-turbo), is evaluated to meet the primary objective. The SciTLDR dataset is chosen for this research experiment and three distinct techniques are utilized to implement three different systems for auto-generating the literature reviews. The ROUGE scores are used for the evaluation of all three systems. Based on the evaluation, the Large Language Model GPT-3.5-turbo achieved the highest ROUGE-1 score, 0.364. The transformer model comes in second place and spaCy is at the last position. Finally, a graphical user interface is created for the best system based on the large language model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Literature reviews have gained considerable importance for scholars. It provides researchers with a comprehensive overview of previous findings in a specific field and assists scholars in identifying gaps in past understandings. It helps to conduct future research and informs researchers of areas where they can provide significant input. However, conducting literature reviews can be incredibly cumbersome because there's so much to read. Due to the vast volume of research articles being released, reviewing all related studies and extracting relevant information can be a time-consuming, tedious, and error-prone task. Due to these difficulties, there has been an increasing interest in automating the process of literature reviews <ref type="bibr" target="#b0">[1]</ref>. Automated systems can use natural language processing techniques and machine learning algorithms to analyze extensive amounts of text, extract relevant details, and create structured summaries <ref type="bibr" target="#b1">[2]</ref>.</p><p>The primary objective of this research is to develop a system that can automatically generate the literature review segment of a research paper by using only the PDF files of the related papers as input. Several Natural Language Processing techniques such as the Frequency-based approach, Transformerbased approach, and Large Language Model-based approach are implemented and compared to find the best procedure. The SciTLDR dataset <ref type="bibr" target="#b2">[3]</ref> is selected for this research work. The first procedure uses the frequency-based approach. The library named spaCy <ref type="bibr" target="#b3">[4]</ref> is utilized here. The second procedure uses the transformer-based model. The Simple T5 model is utilized here. The last procedure is based on using the Large Language Model. The GPT-3.5-TURBO-0125 model is utilized here. The evaluation and comparison are performed using ROUGE scores <ref type="bibr" target="#b4">[5]</ref>. Then the best approach is identified and a Graphical User Interface-based tool is created.</p><p>Automating aspects of the literature review process allows academicians to save time and concentrate on the most pertinent articles for their research. It can also reduce the chance of errors or prejudice in the review process. The highlights of this article are:</p><p>• All three considered NLP approaches such as spaCy, T5, and GPT-3.5-TURBO-0125 model can produce satisfactory results in automating the literature review generation.</p><p>• The LLM-based model outperforms T5 and spaCy in generating literature reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. LITERATURE REVIEW</head><p>A framework was proposed by Silva et al.</p><p>[6] for automatically producing systematic literature reviews. They have focused on four technical steps: Searching, Screening, Mapping, and Synthesizing. In response to a specific inquiry, extensive searches are conducted to find as much relevant research as feasible, involving looking through reference lists, scouring internet databases, and reviewing published materials. Screening reduces the search scope by limiting the collection to only the papers pertinent to a particular review, aiming to highlight important findings and facts that could influence policy. Mapping is used to comprehend research activity in a particular area, involve stakeholders, and define priorities concerning the review emphasis. Synthesizing integrates data from numerous sources and provides an overview of the outcomes. The formulation of research questions, reporting phase, and peer review are some steps that are also discussed for the composition of systematic literature reviews.</p><p>Peer-reviewed publications are growing exponentially with the rapid development of science. Therefore, Yuan et al.</p><p>[7] have explored the use of machine learning techniques, natural language generation, multi-document summarization, and multi-objective optimization for automating scientific reviewing. They have discussed the generation of comprehensive reviews and noted the limitations of constructive feedback compared to human-written reviews. The models used in this research are not yet fully capable of automating Literature Reviews and they require human reviewers.</p><p>A comprehensive analysis of existing tools for systematic literature reviews was done by Karakan et al. <ref type="bibr">[8]</ref>. They have explored the potential for automation in various phases of the review process, highlighting the need for a holistic tool design to address researchers' challenges effectively. They have discussed two methodologies to accomplish their research: Rapid Review and Semi-Structured Interviews. Rapid Review emphasizes decision-making procedures for resolving issues, difficulties, and challenges that software engineers encounter in their daily work. Semi-structured interviews are used to explore researchers' experiences, challenges, strategies, strengths, weaknesses of Systematic Literature Review tools, and requirements for effective support in software engineering. Jaspers et al.</p><p>[9] focused on the use of machine learning techniques for automation of literature reviews and systematic reviews. They have outlined the pros and cons of different machine-learning techniques. The process of automating the literature review was elaborately discussed. The paper lacks practical validation across diverse domains and detailed insights.</p><p>A concise overview of automated literature reviews was presented by Tauchert et. al.</p><p>[10] They have emphasized the potential for automation in various stages of the systematic review process. The paper discusses the importance of integrating computational techniques to streamline tasks such as searching, screening, extraction, and synthesis. It also acknowledges the need for further research to address challenges and enhance the effectiveness of automated approaches.</p><p>A brief overview on the topic of automatic literature review tools was given by Tsai et. al. <ref type="bibr">[11]</ref> They discussed the existing research in the field, the challenges faced in conducting literature reviews manually, and the potential benefits of automating the process. The main focus of their contributions is the evaluation of Mistral LLM's effectiveness in the field of Academic Research.</p><p>The gaps in the intersection of systematic literature reviews (SLRs) and LLMs are discussed by Susnjak et. al. <ref type="bibr">[12]</ref>. They also emphasized the need to address challenges in the synthesis phase of research and highlighted the potential of fine-tuning LLMs with datasets to enhance knowledge synthesis accuracy. The study aims to bridge this gap by proposing a Systematic Literature Review automation framework.</p><p>Most of the related works that have been discussed are mainly focused on discussing the potential and challenges of using NLP techniques and LLMs to automate the literature review process. None of them proposes a complete system pipeline where users can directly generate the literature review only using the PDF and DOI. In contrast, this article proposes and implements three unique end-to-end pipelines and procedures for a literature review automation system. This research endeavor has also resulted in the implementation of a UI tool where users can directly upload PDFs and get a literature review segment generated automatically without any additional effort. Moreover, this paper also includes a comparative analysis of different approaches such as the frequency-based approach, transformer-based approach, and rag-based approach using ROUGE scores which contributes towards finding the effectiveness of these approaches for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SYSTEM DESIGN</head><p>The research is carried out in four stages: 1. Defining research objectives. 2. Proposing multiple procedures for automated literature review generation. 3. Evaluating multiple procedures to find the best approach. 4. The final system development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset Selection</head><p>The SciTLDR dataset from the Hugging Face is selected for this research work <ref type="bibr">[13]</ref>. It contains the summarization of scientific documents. It is a dataset with 5,400 TLDRs derived from over 3,200 papers. It contains both author-written and expert-derived TLDRs of scientific documents. Curated research articles' abstract, introduction, and conclusion (AIC) or full text of the paper are given as "source" and the summaries of the corresponding articles are given as "target". Only these two attributes are utilized in all three proposed procedures. There is no training for the spaCy approach, but the dataset is utilized for testing purposes. The T5 model is trained using the SciTLDR dataset for the transformer-based approach and later evaluated on the test dataset. For the LLMbased approach, this dataset is used as the knowledge base for the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Procedure Utilizing the Frequency-Based Approach using spaCy</head><p>The first procedure utilizes the frequency-based approach by using spaCy. The first task is to build the model pipeline. The model pipeline takes text as input and converts the text into NLP tokens using the spaCy library. Then preprocessing step is done by removing stop words and punctuation. Afterward, the word frequency is calculated for each word which later helps to calculate individual sentence weights. This sentence weight represents the importance of that sentence. Then the top 10 percent of sentences are selected as the final output. The model is later evaluated using ROUGE scores to get an overview of the performance. The overview of the spaCy Model is given in Figure <ref type="figure" target="#fig_0">1</ref>. The next step is to implement a system pipeline by using the spaCy model to generate a literature review segment automatically. The system takes the DOI and PDF files of multiple papers as input. It uses the Requests library to collect the paper titles and first author names from the DOI. Then it uses PYPDF2 and Regular Expression (RE) libraries to collect only the conclusion of each PDF. Then it uses the previously implemented spaCy model to get a summary of each paper. Later it performs post-processing and merges all summaries to produce a coherent literature review segment. The system pipeline overview of the spaCy Model is given in Figure <ref type="figure" target="#fig_1">2</ref>.  The next step is to implement a system pipeline by using the transformer-based model to generate a literature review segment automatically. The system takes the DOI and PDF of multiple papers as input. It uses the Requests library to collect the paper titles and first author names from DOIs. Then it uses PYPDF2 and Regular Expression (RE) libraries to collect each PDF's abstract, introduction, and conclusion. Then it merges 3 of these sections to get the final model input. Later it uses the previously trained and saved T5 model to get a summary of each paper. In the next step, it performs post-processing and merges all summaries to produce a coherent literature review segment. The system pipeline overview of the Transformer Model is given in Figure <ref type="figure" target="#fig_3">4</ref>. The third procedure utilizes the RAG-based approach by using the Large Language Model: GPT-3.5-TURBO-0125. The first task is to create a custom OpenAI Assistant. Firstly, the SciTLDR dataset is collected, and then the GPT-3.5-TURBO-0125 model is selected for the OpenAI assistant. The retrieval is turned on and the dataset is added for the knowledge of the LLM. Now some prompt engineering is performed to produce the required output. Then the LLM results are evaluated using ROUGE SCORE. The overview of the creation of the OpenAI assistant is given in figure <ref type="figure">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 5: Creation of Custom OpenAI Assistant</head><p>The used prompt: "The user will give you a pdf file as input, similar to the "input" field of the given "data.json" file in your knowledge base. You have to produce a summarized "output" for the given pdf based on file given to your knowledge. The output will be of max 80 words. Note: You must write in a way that can be considered a literature review of a new research paper. The user in the future might add more PDFs so try to make the literature review coherent and as per IEEE standards. Please mention the first author's name and paper title. Don't write like this "Literature Review of. . . "." Figure <ref type="figure">6</ref>: Pipeline using LLM The next step is to implement a system pipeline by using the LLM to generate a literature review segment automatically. The system takes PDFs of multiple papers as input. It uses the PYPDF2 library to extract the entire text of each PDF. Then it creates a new thread with the extracted text as a message and submits the thread to the assistant with the extracted text as a query. Then the response from the assistant is retrieved and the outputs of each paper are merged for the final literature review segment. The system pipeline overview of the LLM is given in Figure <ref type="figure">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. The Final System Tool</head><p>The final system is implemented using the Large Language Model: GPT-3.5-TURBO-0125 as the backend. An aesthetic and simple user interface is created where the user can easily upload multiple research articles or PDF files. The user has to press the "Browse files" button and then select the files to upload. Then the system loads the research papers and within a few seconds, it produces the literature review segment automatically. It individually processes each paper and produces output. The loading screen and processing file numbers indicate the progress level and the number of processed papers. At the end of the literature review, the UI shows "Done" text to indicate the completion of the task. The user interface of the system is given in Figure 7 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Evaluation of Frequency-Based spaCy</head><p>The spaCy-based model was evaluated on the test data utilizing the ROUGE scores. The results are stated in Table <ref type="table">I</ref>.</p><p>Table I: ROUGE Scores for spaCy ROUGE-1 0.257 ROUGE-2 0.055 ROUGE-L 0.144 ROUGE-L SUM 0.146 B. Evaluation of Transformer T5 The transformer-based model was evaluated on the test data utilizing the ROUGE scores. The results are stated in Table II. Table II: ROUGE Scores for T5 ROUGE-1 0.268 ROUGE-2 0.115 ROUGE-L 0.204 ROUGE-L SUM 0.204 C. Evaluation of Large Language Model: GPT-3.5-TURBO-0125 The LLM-based model was evaluated on the test data utilizing the ROUGE scores. The results are stated in Table III. Table III: ROUGE Scores for LLM ROUGE-1 0.364 ROUGE-2 0.123 ROUGE-L 0.181 ROUGE-L SUM 0.182</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparison of Multiple Approaches</head><p>The comparison between all three approaches is provided in Table <ref type="table">IV</ref>.</p><p>Table IV: Comparison of Rouge Scores T5 spaCy GPT-3.5-TURBO-0125 ROUGE-1 0.268 0.257 0.364 ROUGE-2 0.115 0.055 0.123 ROUGE-L 0.204 0.144 0.181 ROUGE-L SUM 0.204 0.146 0.182</p><p>From the ROUGE scores, it is clear that the LLM-based model outperformed both T5 and spaCy. The Transformerbased model is in the second spot based on the ROUGE-1 score. The evaluation proves that large language models are superior to older NLP approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. User Evaluation on UI</head><p>The user evaluation was performed on the LLM-based UI system. The user chose 4 research articles as input. These were:</p><p>• AI-IoT based Healthcare Prognosis Interactive System • Applying Internet of Things and Machine-Learning for Personalized Healthcare: Issues and Challenges • Improving patients health-care using IoT • IoT Based AI and its Implementations in Industries The received output from the system: "The paper by Joshua Ernest Pedi Reddy et al. presents an AI-IoT based Healthcare Prognosis Interactive System (HPIS) to provide real-time medical diagnosis and support in the absence of healthcare workers. The system includes an AI-based chatbot and Application Interface to gather information, answer medical queries, assist users, and ensure medication adherence. With a focus on improving healthcare accessibility and quality, the system integrated smart pill dispensers for monitoring and enhancing medication adherence, offering great potential in revolutionizing healthcare services. Ahamed explores the application of IoT and Machine Learning in Personalized Healthcare (PH) to enhance disease management and intervention. IoT sensor devices and wearables collect patient data, which is analyzed using AI and ML techniques for disease prediction and patient self-management. Challenges include biased data collection, outdated training datasets, and privacy concerns. The integration of IoT and ML in PH faces issues such as data transmission reliability and biased training datasets, impacting diagnostic accuracy. Addressing these challenges is crucial for improving personalized healthcare systems. Khurana implements a Smart Healthcare System using IoT sensors to enhance patient care in hospitals. The system utilizes Ultrasonic and IR Proximity Sensors connected to an Arduino Uno for automated IV fluid level monitoring and patient alarm system. The literature review highlights the importance of automated Hospital Management Systems for efficient healthcare administration. The proposed system reduces manpower, costs, and human errors while improving patient care. Future research aims to enhance system scalability and functionality for widespread hospital use. Sherif El-Gendy explores the integration of IoT and AI in industries in the paper "IoT Based AI and its Implementations in Industries." The paper delves into Industry 4.0, IIoT, IAIoT, and IoRT, showcasing the impact on automation and robotics. It discusses IoT challenges, benefits of AI in data analysis, and presents case studies like oil field production optimization and smart robotics by companies like ABB and Boeing. The future of IoT/AI integration promises transformative advancements in various sectors."</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Building spaCy Model</figDesc><graphic coords="3,74.05,231.85,199.12,103.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Pipeline using spaCy</figDesc><graphic coords="3,74.05,513.30,199.13,125.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Training of Transformer Model</figDesc><graphic coords="3,337.05,188.60,199.12,110.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Pipeline using Transformer Model</figDesc><graphic coords="3,337.05,518.75,199.14,155.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The Preview of the System UI</figDesc><graphic coords="4,343.35,298.50,187.50,173.25" type="bitmap" /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULT AND DISCUSSION</head><p>The study introduced three procedures for automated literature review generation. The research work also illustrates the performance comparison between various NLP approaches such as the frequency-based method (spaCy), transformer model (Simple T5), and retrieval-augmented generation (RAG) with LLM (GPT-3.5-turbo). All three procedures are implemented and the ROUGE-1, ROUGE-2, ROUGE-L, and ROUGE-Lsum scores are calculated based on the Test dataset. For all three approaches, the ROUGE-1 and ROUGE-2 scores are found above the acceptable mark.</p><p>From the evaluation, it is seen that the GPT-3.5-turbo model produced results with higher ROUGE-1 and ROUGE-2 scores than the SpaCy and T5. The overall ROUGE-1 score for the LLM is 0.364 while the score for T5 is 0.268 and spaCy is 0.257. It shows that the LLM-generated summaries have better unigram and bigram overlapping with human summaries. The transformer T5 is also an advanced model which comes in second place. The last position is occupied by the frequencybased spaCy model.</p><p>From the scores, it is clear that the most advanced models are LLMs which outperformed all other NLP techniques. But other approaches such as transformer models and frequencybased approaches are also capable of producing satisfactory ROUGE scores and a coherent literature review segment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION AND FUTURE SCOPES</head><p>The research focused on implementing and comparing various NLP techniques for automated literature review. All three implemented systems are successful in generating the coherent Literature Review segment of a research paper. The results of various Natural Language Processing techniques such as the Frequency-based approach, Transformer model, and Large Language Model are also successfully obtained and compared. Based on the comparisons, the LLM-based approach is proven to be the best-performing one based on ROUGE-N scores.</p><p>Thus, based on the LLM, a final system tool is also successfully developed where the user can upload multiple PDF files to automatically generate a coherent literature review segment.</p><p>Future work of this research work can be focused on enhancing the effectiveness and applicability of the developed system tool. More functionality can be added to the Graphical User Interface such as model options, output size, etc. More models such as Bert, Gemini, and LLaMA can be utilized to find better results. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Automating systematic literature review. Contemporary empirical methods in software engineering</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Felizardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Carver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="327" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Nlp based machine learning approaches for text summarization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Adhikari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020-03-11">2020 Mar 11</date>
			<biblScope unit="page" from="535" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">TLDR: Extreme summarization of scientific documents</title>
		<author>
			<persName><forename type="first">I</forename><surname>Cachola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.15011</idno>
		<imprint>
			<date type="published" when="2020-04-30">2020 Apr 30</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Extractive automatic text summarization using SpaCy in Python &amp; NLP</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jugran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Anand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 International conference on advance computing and innovative technologies in engineering (ICACITE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021-03-04">2021 Mar 4</date>
			<biblScope unit="page" from="582" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ROUGE Score Analysis and Performance Evaluation Between Google T5 and SpaCy for YouTube News Video Summarization</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">U</forename><surname>Tanvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Akhtaruzzaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 26th International Conference on Computer and Information Technology (ICCIT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023-12-13">2023 Dec 13</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

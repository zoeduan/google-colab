<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large Language Models Can Be Easily Distracted by Irrelevant Context</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-06-06">6 Jun 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Freda</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<settlement>Xinyun Chen</settlement>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<settlement>Xinyun Chen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
							<email>&lt;xinyunchen@google.com&gt;</email>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<settlement>Xinyun Chen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kanishka</forename><surname>Misra</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<settlement>Xinyun Chen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Scales</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<settlement>Xinyun Chen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<settlement>Xinyun Chen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<settlement>Xinyun Chen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nathanael</forename><surname>Sch√§rli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<settlement>Xinyun Chen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
							<email>nyzhou@google.com&gt;.</email>
							<affiliation key="aff0">
								<orgName type="institution">Toyota Technological Institute at Chicago</orgName>
								<address>
									<settlement>Xinyun Chen</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large Language Models Can Be Easily Distracted by Irrelevant Context</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-06-06">6 Jun 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">2AE8B6A794638D5A12D6F0F7ED16A574</idno>
					<idno type="arXiv">arXiv:2302.00093v3[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models have achieved impressive performance on various natural language processing tasks. However, so far they have been evaluated primarily on benchmarks where all information in the input context is relevant for solving the task. In this work, we investigate the distractibility of large language models, i.e., how the model problem-solving accuracy can be influenced by irrelevant context. In particular, we introduce Grade-School Math with Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant information in the problem description. We use this benchmark to measure the distractibility of cutting-edge prompting techniques for large language models, and find that the model performance is dramatically decreased when irrelevant information is included. We also identify several approaches for mitigating this deficiency, such as decoding with self-consistency and adding to the prompt an instruction that tells the language model to ignore the irrelevant information. 1 Work done while FS and KM are student researchers at Google DeepMind.</p><p>* Equal contribution 1 Google Deep-Mind</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Prompting large language models performs decently well in a variety of domains <ref type="bibr" target="#b1">(Brown et al., 2020;</ref><ref type="bibr">Chowdhery et al., 2022, inter alia)</ref>. However, for most of theses evaluation benchmarks, all the information provided in the problem description is relevant to the problem solution, as the problems in exams. This is different from real-world situations, where problems usually come with several pieces of contextually Original Problem Jessica is six years older than Claire. In two years, Claire will be 20 years old. How old is Jessica now? Modified Problem Jessica is six years older than Claire. In two years, Claire will be 20 years old. Twenty years ago, the age of Claire's father is 3 times of Jessica's age. How old is Jessica now? Standard Answer 24 Table <ref type="table">1</ref>. An example problem from GSM-IC. An irrelevant sentence (italic and underlined) that does not affect the standard answer is added immediately before the question. related information, which may or may not be relevant to the problems that we want to solve. We have to identify what information is actually necessary during solving those problems. Studies in psychology have shown that irrelevant information may significantly decrease some children and even adults problem-solving accuracy <ref type="bibr" target="#b14">(Hoyer et al., 1979;</ref><ref type="bibr" target="#b37">Pasolunghi et al., 1999;</ref><ref type="bibr">Marzocchi et al., 2002, inter alia)</ref>.</p><p>In this work, we study the distractibility of large language models for various prompting techniques; i.e., how is large language model prompting affected by irrelevant context, and what strategies can be used to improve performance? To measure distractibility, we construct the GSM-IC dataset, a grade-school math problem dataset derived from GSM8K <ref type="bibr" target="#b7">(Cobbe et al., 2021)</ref> and introduce two different metrics. In contrast to prior work that derives benchmark variations by substituting sentences of the base problems with variations <ref type="bibr" target="#b38">(Patel et al., 2021;</ref><ref type="bibr">Kumar et al., 2021, inter alia)</ref>, we keep the base problem description and add to it one irrelevant sentence, while making sure that it does not affect the solution of the problem (Table <ref type="table">1</ref>).</p><p>We use Codex (code-davinci-002) and  in the GPT3 model family to evaluate state-of-the-art prompting techniques on GSM-IC,<ref type="foot" target="#foot_0">foot_0</ref> including chain-of-thought prompting (COT; <ref type="bibr" target="#b55">Wei et al., 2022)</ref>, zero-shot chain-of-thought prompting (0-COT; <ref type="bibr" target="#b22">Kojima et al., 2022)</ref>, least-to-most-prompting (LTM; <ref type="bibr" target="#b57">Zhou et al., 2022)</ref>, and prompting with programs (PROGRAM; <ref type="bibr" target="#b4">Chowdhery et al., 2022)</ref>.We find that their performance on GSM-IC greatly decreases compared to the original GSM8K (without irrelevant context). We then investigate several approaches to mitigate this weakness, including self-consistency <ref type="bibr">(Wang et al., 2022c)</ref> and adding irrelevant information to the exemplars in the prompt. In addition to demonstrating how to handle irrelevant information via exemplars, we also investigate the usage of task-specific instructions <ref type="bibr" target="#b54">(Wei et al., 2021;</ref><ref type="bibr" target="#b42">Sanh et al., 2021;</ref><ref type="bibr" target="#b34">Ouyang et al., 2022;</ref><ref type="bibr" target="#b47">Suzgun et al., 2022;</ref><ref type="bibr" target="#b5">Chung et al., 2022)</ref>, where we prepend an instruction sentence "feel free to ignore irrelevant information in the problem description" to the exemplars. We summarize our key findings below:</p><p>1. All investigated prompting techniques are sensitive to irrelevant information in the problem description. In particular, among the original problems that can be solved by baseline prompts with greedy decoding, no more than 18% of them can be consistently solved for all types of irrelevant information, showing that the large language model is easily distracted and produces inconsistent predictions when adding a small amount of irrelevant information to the problem description. 2. Self-consistency improves the performance of all prompting techniques on GSM-IC. In particular, the recall rate of the correct answer for GSM-IC is as high as 99.7% with 20 samples per problem, i.e., at least one of the 20 solutions result in the correct final answer, which means that using multiple samples allows the model to almost always retrieve the correct answer. 3. Adding irrelevant information to the exemplars shown in the prompt consistently boosts the performance, and the same holds for adding an instruction to ignore irrelevant context. This suggests that language models are-to some extent-able to learn to ignore irrelevant information by following examples or instructions. 4. We identify different factors of the irrelevant information that affect the model's sensitivity to irrelevant context. Our breakdown analysis shows that varying the numbers in the irrelevant information does not notably change the model performance, while the degree of lexical overlap with the original problem description matters.</p><p>Filtering out irrelevant information is essential for handling real-world tasks. Our evaluation indicates that despite the strong performance on challenging reasoning problems, state-of-the-art language models still have fundamental weaknesses in context understanding and identifying the relevant information from the input. Our findings suggest that in order to gain a more holistic understanding of the reasoning capability of language models, future work should also consider the model sensitivity to irrelevant context, in addition to solving more challenging problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Few-shot prompting. Few-shot prompting <ref type="bibr" target="#b1">(Brown et al., 2020;</ref><ref type="bibr">Chowdhery et al., 2022, inter alia)</ref> has been significantly boosted with various techniques, including generating intermediate steps <ref type="bibr" target="#b26">(Ling et al., 2017;</ref><ref type="bibr" target="#b7">Cobbe et al., 2021;</ref><ref type="bibr" target="#b33">Nye et al., 2021;</ref><ref type="bibr" target="#b55">Wei et al., 2022;</ref><ref type="bibr" target="#b47">Suzgun et al., 2022;</ref><ref type="bibr">Shi et al., 2022b, inter alia)</ref>, problem decomposition <ref type="bibr" target="#b57">(Zhou et al., 2022;</ref><ref type="bibr" target="#b10">Drozdov et al., 2022;</ref><ref type="bibr" target="#b9">Dohan et al., 2022;</ref><ref type="bibr" target="#b20">Khot et al., 2022;</ref><ref type="bibr">Press et al., 2022, inter alia)</ref>, generating programs <ref type="bibr" target="#b0">(Austin et al., 2021;</ref><ref type="bibr" target="#b4">Chowdhery et al., 2022;</ref><ref type="bibr" target="#b12">Gao et al., 2022;</ref><ref type="bibr">Chen et al., 2022, inter alia)</ref>, marginalizing intermediate steps that share the same result <ref type="bibr">(Wang et al., 2022c;</ref><ref type="bibr">Shi et al., 2022a)</ref>, and ensemble <ref type="bibr">(Wang et al., 2022b;</ref><ref type="bibr" target="#b10">Drozdov et al., 2022)</ref>. In addition, <ref type="bibr" target="#b22">Kojima et al. (2022)</ref> demonstrate that appropriate hint in prompts also leads to decent performance, even without any exemplar. In this work, we examine these cutting-edge prompting techniques <ref type="bibr" target="#b55">(Wei et al., 2022;</ref><ref type="bibr" target="#b57">Zhou et al., 2022;</ref><ref type="bibr" target="#b22">Kojima et al., 2022;</ref><ref type="bibr">Wang et al., 2022c)</ref> on our benchmark, and demonstrate that they are sensitive to irrelevant input context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Natural language benchmarks with input perturbations.</head><p>There has been a long line of work on adding input perturbations for natural language tasks, including model-agnostic input transformations <ref type="bibr" target="#b25">(Liang et al., 2022;</ref><ref type="bibr">Ravichander et al., 2022, inter alia)</ref> and adversarial example generation against individual models <ref type="bibr" target="#b15">(Jia &amp; Liang, 2017;</ref><ref type="bibr" target="#b45">Shi et al., 2018;</ref><ref type="bibr" target="#b31">Morris et al., 2020;</ref><ref type="bibr" target="#b49">Wang et al., 2021)</ref>. In particular, prior work has constructed arithmetic reasoning benchmarks through paraphrasing or rewriting sentences in the base problems from clean datasets <ref type="bibr" target="#b38">(Patel et al., 2021;</ref><ref type="bibr" target="#b23">Kumar et al., 2021)</ref>. Meanwhile, <ref type="bibr" target="#b25">Liang et al. (2022)</ref> evaluate various large language models under several metrics, including accuracy, robustness, fairness, etc. Specifically, the input transformations in their robustness evaluation include semanticspreserving and semantics-altering perturbations, such as injecting typos and modifying sentences to change the groundtruth classification labels. In contrast the above work where the meaning of problem descriptions may be changed with perturbations, we keep all sentences in the original problem description, and introduce an irrelevant sentence that is ensured not to affect the standard answer.</p><p>Natural language benchmarks with irrelevant input context. <ref type="bibr" target="#b15">Jia &amp; Liang (2017)</ref> have shown that neural question answering systems are largely affected by adversarial distracting sentences, whereas follow up work <ref type="bibr" target="#b19">(Khashabi et al., 2017;</ref><ref type="bibr" target="#b32">Ni et al., 2019)</ref> proposes learning strategies that mitigate the problem. Similar issues have been found for general-purpose pretrained language models, on the tasks of factual reasoning <ref type="bibr" target="#b17">(Kassner &amp; Sch√ºtze, 2020;</ref><ref type="bibr" target="#b35">Pandia &amp; Ettinger, 2021;</ref><ref type="bibr" target="#b30">Misra et al., 2023;</ref><ref type="bibr" target="#b24">Li et al., 2022)</ref>, code generation <ref type="bibr" target="#b16">(Jones &amp; Steinhardt, 2022)</ref>, and syntactic generalization <ref type="bibr" target="#b2">(Chaves &amp; Richter, 2021)</ref>. In particular, Li et al.</p><p>(2022) evaluated T5 <ref type="bibr" target="#b40">(Raffel et al., 2020)</ref> and PaLM <ref type="bibr" target="#b4">(Chowdhery et al., 2022)</ref> with few-shot prompts, and proposed knowledge-aware finetuning that finetunes the model on problems with counterfactual and irrelevant context, which strengthens the model robustness to noisy context. In our evaluation, we show that without training or finetuning, adding irrelevant context into demonstrations in the prompt also mitigates the distractibility of the underlying language model and significantly improves the model performance on our GSM-IC benchmark.</p><p>There exist some logical reasoning benchmarks that contain irrelevant content in task descriptions <ref type="bibr" target="#b56">(Weston et al., 2015;</ref><ref type="bibr" target="#b46">Sinha et al., 2019;</ref><ref type="bibr" target="#b6">Clark et al., 2021;</ref><ref type="bibr" target="#b13">Han et al., 2022;</ref><ref type="bibr">Tafjord et al., 2020, inter alia)</ref>. However, previous work largely focuses on designing models that require extra training, and prompting alone still hardly achieves the same level of performance as finetuned models for these tasks <ref type="bibr" target="#b13">(Han et al., 2022;</ref><ref type="bibr" target="#b8">Creswell et al., 2022)</ref>. In our work, we focus on arithmetic reasoning, where prompting techniques have achieved the state-of-the-art results, e.g., on GSM8K, while we show that adding a single irrelevant sentence into the problem description significantly degrades the performance.</p><p>Prompting with noisy ground truth. A line of work studies the model performance with incorrect prompting exemplars, i.e., the example problems are paired with wrong answers <ref type="bibr" target="#b29">(Min et al., 2022;</ref><ref type="bibr" target="#b21">Kim et al., 2022)</ref>. In addition, prior work has investigated the model sensitivity to other parts of the prompt, such as instruction tuning with misleading and irrelevant instructions <ref type="bibr" target="#b53">(Webson &amp; Pavlick, 2021)</ref> and wrong reasoning steps in the examples <ref type="bibr" target="#b27">(Madaan &amp; Yazdanbakhsh, 2022;</ref><ref type="bibr">Wang et al., 2022a)</ref>. In particular, <ref type="bibr" target="#b27">Madaan &amp; Yazdanbakhsh (2022)</ref> conclude that the correctness of numbers and equations in chain-of-thought prompts does not play a key role in model performance, but using wrong entities and removing either equations or text explanation in the reasoning steps drastically hamper the performance. Different from this line of work, we always include correct answers to example problems in the prompt, and ensure that the irrelevant context added to the problem description does not change the ground truth answer. We show that the model performance significantly drops when presented with irrelevant context in problem descriptions, and different distributions of numbers and entities in the irrelevant context also lead to different levels of performance degradation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The GSM-IC Dataset</head><p>In this section, we introduce the creation process of the GSM-IC dataset ( ¬ß3.1) and the evaluation metrics ( ¬ß3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset Creation</head><p>We randomly choose 1,000 problems from the GSM8K training set as a development set. To construct our base dataset,</p><p>COT LTM PROGRAM 0-COT 95.0 94.0 83.0 44.0 + SC 96.0 99.0 91.0 76.0 Table 2. Accuracy (√ó100) on the base 100-example dataset using code-davinci-002. See Table 3 for results with text-davinci-003. Figure 1. Illustration of the considered factors when creating the GSM-IC dataset. Best viewed in color.</p><p>we then choose 100 problems from this development set that can be correctly solved by at least one of the prompting techniques mentioned in this paper;<ref type="foot" target="#foot_1">foot_1</ref> that is, our base dataset is an "easy" subset of GSM8K (Table <ref type="table">2</ref>). Each base problem requires two to seven reasoning steps to solve.<ref type="foot" target="#foot_2">foot_2</ref> Among the 100 base problems, 60 of them can be solved with two reasoning steps. The full dataset statistics can be found in Appendix A.</p><p>We then generate the examples of our new dataset by adding to each base problem one sentence containing irrelevant information. We use a template-based method (Figure <ref type="figure">1</ref>) to generate these sentences, which can be characterized by the following three factors:</p><p>‚Ä¢ Topic of the inserted sentence. We write templates for both in-topic and off-topic sentences. In-topic sentences are closely related to the topic of the original problem, whereas off-topic sentences are about a different topic. ‚Ä¢ Role name overlap. Most sentence templates contain some role name blanks, which can be filled with names that may or may not overlap with the role names that occur in the problem. For blank fillers that have overlap with original role names, we: (1) randomly pick a role name A from the original problem description and (2) create the blank fillers with template such as A's father and A's sister.</p><p>‚Ä¢ Range of numbers. Since we focus on arithmetic reasoning, most sentence templates also contain a number blank.</p><p>We can choose to fill in the number blank with a number of similar or different magnitude to those in the original problem description. Concretely, for a number a, if there exists a number b in the original problem description or solution such that 1 10 ‚â§ a b ‚â§ 10, we consider a as an in-range number, and otherwise an out-of-range number.</p><p>Since the standard answer to GSM8K problems are all positive integers, we only consider positive integers as the number blank fillers.</p><p>We manually verify that (1) all the generated sentences are acceptable in English and that (2) adding them does not affect the standard solution of the base problem. Because the above factors are orthogonal, we generate for each base example a set of derived examples with different factor combinations. The full GSM-IC benchmark consists of 58,052 examples. More details about the dataset creation process can be found in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Evaluation Metrics</head><p>For a problem p, we denote its standard solution by s(p), and the solution of method M by M(p). To evaluate the distractibility of M, we consider the following two metrics:</p><p>‚Ä¢ Micro accuracy Acc micro (M; P) is the average accuracy of method M over all the test problems P. </p><formula xml:id="formula_0">Acc macro (M; B) = b‚ààB 1 p‚ààP(b) [M(p) = s(p)]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>|B|</head><p>This means that the macro accuracy is the fraction of base problems that can be consistently solved no matter what irrelevant sentence is being added. ‚Ä¢ Normalized accuracy measures how a method is affected by the distractors, considering its accuracy on base problems. For a micro or macro accuracy a M achieved by method M, we calculate its corresponding normalized accuracy by</p><formula xml:id="formula_1">norm(a M ; M) = a M n M ,</formula><p>where n M denotes the base problem accuracy of method M (Table <ref type="table">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Investigated Solutions</head><p>In the following section, we review the investigated prompting techniques ( ¬ß4.1), present the formats of our prompts ( ¬ß4.2), and introduce instructed prompting ( ¬ß4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Base Techniques</head><p>Chain-of-thought prompting (COT; <ref type="bibr" target="#b55">Wei et al., 2022</ref>) is a prompting technique that guides the language models to solve a problem in a step-by-step manner. By presenting exemplars that solve the corresponding problems with intermediate reasoning steps in the prompts, COT significantly improves the reasoning performance over direct answer prediction without such intermediate reasoning steps.</p><p>Zero-shot chain-of-thought prompting (0-COT; <ref type="bibr" target="#b22">Kojima et al., 2022</ref>) is a variation of COT where the prompt does not contain any exemplar. Instead, the model is prompted directly with the problem of interest followed by the instruction "Let's think step by step:".</p><p>Least-to-most prompting (LTM; <ref type="bibr" target="#b57">Zhou et al., 2022)</ref> teaches language models to (1) break down a problem into subproblems, and (2) solve those subproblems sequentially using COT. The final answer is that to the last subproblem.</p><p>Program prompts (PROGRAM; <ref type="bibr" target="#b4">Chowdhery et al., 2022)</ref> represent the arithmetic reasoning process as a program. Following prior work on solving GSM8K problems with code <ref type="bibr" target="#b4">(Chowdhery et al., 2022;</ref><ref type="bibr" target="#b12">Gao et al., 2022;</ref><ref type="bibr" target="#b3">Chen et al., 2022)</ref>, we include a Python program as the problem solution in the prompt, and execute the generated Python code using an external Python interpreter to obtain the final answer.</p><p>Self-consistency (SC; <ref type="bibr">Wang et al., 2022c;</ref><ref type="bibr">Shi et al., 2022a)</ref> may further boost the reasoning performance by marginalizing over intermediate reasoning steps that share the same final result. In practice, SC can be implemented by (1) sampling several solutions from the large language model and (2) taking the majority vote. Note that SC is orthogonal to above techniques, and can be combined with any of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Prompt Design</head><p>We present some example prompts used in our experiments (Figure <ref type="figure" target="#fig_1">2</ref>). For few-shot prompting techniques (i.e., COT, LTM and PROGRAM), the input prompt includes exemplar problems and their solutions before the problem of interest.</p><p>In order to keep simplicity and avoid over-fitting in prompt engineering, we follow <ref type="bibr" target="#b57">Zhou et al. (2022)</ref> on exemplar creation; that is, we only use one simple exemplar for our main experiments. This exemplar is either based on the [Original Problem] or the [Problem with Irrelevant Context], which [Original Problem] = Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. How many apples do they have together? [Problem with Irrelevant Context] = Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. Liz has 4 peaches. How many apples do they have together? [COT Solution] = A: Anna has 2 more apples than Elsa, so Anna has 2 + 5 = 7 apples. Elsa and Anna have 5 + 7 = 12 apples together. The answer is 12. [LTM Solution] = A: Let's break down this problem: 1. How many apples does Anna have? 2. How many apples do Elsa and Anna have together? 1. Anna has 2 more apples than Elsa. So Anna has 2 + 5 = 7 apples. 2. Elsa and Anna have 5 + 7 = 12 apples together. [PROGRAM Solution] = A: Let's solve the problem by a Python program: Elsa_apples = 5 Anna_apples = 2 + Elsa_apples Elsa_Anna_apples = Elsa_apples + Anna_apples print(Elsa_Anna_apples) [Problem of Interest] = Q: Jeanne wants to ride the Ferris wheel, the roller coaster, and the bumper cars. The Ferris wheel costs 5 tickets, the roller coaster costs 4 tickets and the bumper cars cost 4 tickets. Jeanne has 5 tickets. Jeanne's neighbor rides 8 kilometers to the bus station every day. How many more tickets should Jeanne buy? allows us to investigate the effect of irrelevant information in the prompt exemplar. For 0-COT, we adhere to <ref type="bibr" target="#b22">Kojima et al. (2022)</ref> and directly present the problem of interest followed by "A: Let's think step by step:".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Instructed Prompting</head><p>In addition to presenting irrelevant information in the exemplars, we also investigate whether natural language instructions help language models ignore irrelevant context and become less distracted. Extending the line of work <ref type="bibr" target="#b47">(Suzgun et al., 2022;</ref><ref type="bibr" target="#b42">Sanh et al., 2021;</ref><ref type="bibr" target="#b34">Ouyang et al., 2022)</ref> that includes a general task description before exemplars, we add the sentence "Solve grade school math problems. Feel free to ignore irrelevant information given in the questions." before our exemplars in the prompt (Figure <ref type="figure" target="#fig_1">2</ref>), which explicitly instructs the language model to ignore irrelevant information in the problem description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>Being mindful of the experiment costs, we uniformly sample 4,000 examples from the GSM-IC dataset (denoted by GSM-IC-4K)<ref type="foot" target="#foot_3">foot_3</ref> for evaluation and analysis purposes throughout this paper. Unless otherwise specified, we mainly use code-davinci-002 in our experiments, and we also evaluate text-davinci-003 which is a model trained with RLHF to better follow instructions <ref type="bibr" target="#b34">(Ouyang et al., 2022)</ref>. For experiments without self-consistency decoding, we use greedy decoding (i.e., temperature œÑ = 0); for self-consistency experiments that require multiple samples for a problem, we sample 20 responses with temperature œÑ = 0.7 following <ref type="bibr">Wang et al. (2022c)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Main Results on GSM-IC</head><p>We compare the performance of different prompting techniques on GSM-IC-4K ( Table <ref type="table" target="#tab_2">3</ref>. Micro and macro accuracies (√ó100) on the GSM-IC-4K dataset. SC denotes self-consistency. Norm is the overall accuracy normalized by the fraction of solved base problems (Table <ref type="table">2</ref>), which is a measure for robustness w.r.t. irrelevant information. For text-davinci-003, the base problem accuracy with COT is 80.0, and the base problem accuracy with LTM is 81.0. The best numbers in each column for each section (i.e., whether using code-davinci-002 or text-davinci-003, whether using exemplar with irrelevant context or not, and whether using self-consistency or not) are in boldface.</p><p>and macro accuracies, as well as their corresponding normalized accuracies. Overall, we observe significant performance drop for both models with all prompting techniques. The drop on macro accuracy is especially large, showing that fewer than 30% of the base problems are consistently solved after adding distractors. Comparing the results of two models, text-davinci-003 achieves better normalized micro accuracy than code-davinci-002, though its macro accuracy is mostly worse. In Figure <ref type="figure">3</ref>, we present a GSM-IC-4K example where a single irrelevant sentence causes different types of errors in investigated prompting techniques. One common error type is wrongly using the number in the irrelevant sentence, as shown in the LTM prediction and other examples in Appendix B. Even if the model does not directly use the irrelevant number for numerical calculation, the presence of the irrelevant sentence in the reasoning steps alone can still cause a wrong prediction, as shown in the COT prediction.</p><p>LTM is generally the most robust technique to irrelevant context. In terms of micro accuracy, LTM outperforms all other prompting methods across mod-els. Using code-davinci-002, LTM achieves about double macro accuracy of COT. Interestingly, with text-davinci-003, despite that LTM outperforms COT on the micro accuracy, its macro accuracy is lower.</p><p>Specifically, text-davinci-003 is highly susceptible to irrelevant context with role overlap; e.g., such irrelevant sentences decrease the macro accuracy to 0 on problems with more than 2 reasoning steps. See Table <ref type="table">4</ref> for the breakdown performance on different types of irrelevant context.</p><p>Selecting exemplars with distractors mitigates the distractibility. For few-shot prompts, we find that using exemplars with distractors (i.e., including problems with irrelevant context) consistently outperforms using the original exemplars without distractors across prompting techniques.</p><p>While prior work has shown that training and fine-tuning with different types of problems improves model robustness <ref type="bibr" target="#b24">(Li et al., 2022)</ref>, our results show that prompting with exemplars that demonstrate how to ignore irrelevant context also results in significant robustness improvement. In Table <ref type="table" target="#tab_6">5</ref>, we further show that using exemplars with distractors does not cause a performance drop on the original GSM8K dataset,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modified Problem</head><p>Maria buys a large bar of French soap that lasts her for 2 months. She spends $8.00 per bar of soap. Every 10 months, Maria's neighbor buys a new shampoo and moisturizer for Maria's neighbor. If Maria wants to stock up for the entire year, how much will she spend on soap?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correct COT Output to the Original Problem</head><p>Maria spends $8.00 per bar of soap. She buys a bar of soap every 2 months. There are 12 months in a year. Maria will spend $8.00 x 12 / 2 = $48.00 on soap for the year. The answer is $48.00.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output to the</head><p>Modified Problem COT Maria buys a large bar of French soap that lasts her for 2 months. She spends $8.00 per bar of soap. Every 10 months, Maria's neighbor buys a new shampoo and moisturizer for Maria's neighbor. If Maria wants to stock up for the entire year, she will spend $8.00 x 12 = $96.00 on soap. The answer is $96.00. LTM Let's break down this problem: 1. How much does Maria spend on soap every 10 months? 2. How much does Maria spend on soap every year? 1. Maria spends $8.00 per bar of soap. She buys a new bar of soap every 10 months. So Maria spends $8.00 * 10 = $80.00 every 10 months. 2. Maria spends $80.00 every 10 months. So Maria spends $80.00 * 12 = $960.00 every year. The answer is $960.00. PROGRAM Soap_price = 8.00 Soap_per_year = 2 * 12 Soap_total = Soap_price * Soap_per_year print(Soap_total) Output: 192.0 Figure 3. Example problem and corresponding outputs by different prompting techniques (best viewed in color). The COT answer to the original problem is highlighted in green. The added irrelevant sentence is in italic and highlighted in red, which causes different errors (highlighted in yellow) for all prompting techniques. More examples of model predictions can be found in Appendix B.</p><p>indicating that such a prompt design can be beneficial in achieving better accuracy and robustness simultaneously.</p><p>Self-consistency significantly reduces the distractibility.</p><p>Taking the majority vote from 20 samples, 6 SC improves the overall micro accuracy by more than 11 percentage points. This means that in addition to improving model performance on clean arithmetic reasoning tasks <ref type="bibr">(Wang et al., 2022c)</ref>, SC also substantially reduces the distractibility of large language models to irrelevant context. The gain on micro accuracy is notably large on 0-COT (35.5 percentage points). Furthermore, the correct answer for 99.7% of the problems is in the 20 sampled answers for both COT and LTM. Even for 0-COT, the recall of correct solutions within 20 samples is 96.5%. Despite these improvements, the best macro accuracy among all prompting techniques is only 45%, suggesting that for more than half of the base problems, SC fails to prevent the model from being distracted by different variants of irrelevant information. These results imply that a better algorithm may be developed to further reduce the distractibility based on a few sampled solutions. 6 If there is a tie, we take a random top-tier result for evaluation, following <ref type="bibr">Wang et al. (2022c)</ref> and <ref type="bibr">Shi et al. (2022a)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Break-Down Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">FACTORS OF THE IRRELEVANT CONTEXT</head><p>We analyze the performance of COT, LTM and PROGRAM with respect to the considered factors ( ¬ß3.1) of the irrelevant sentences (Table <ref type="table">4</ref>). For both models, we find that (1) in-topic sentences with (2) role name overlap and (3) in-range numbers are generally more challenging, which is examplified by Figure <ref type="figure">3</ref>. For LTM, the latter two factors do not have a large effect on the micro accuracy. The difference is more significant for the macro accuracy and, as an anomaly, using distractors with in-range numbers turns out to be less challenging than out-of-range numbers when using irrelevant context in the exemplar. Again, with code-davinci-002, LTM outperforms COT and PRO-GRAM on all investigated sub-categories. On the other hand, using text-davinci-003, LTM outperforms COT in terms of the micro accuracy, but the macro accuracy is much lower on all sub-categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">BREAK-DOWN ACCURACIES W.R.T. # STEPS</head><p>We analyze the break-down accuracies for problems with respect to the reasoning steps (Figure <ref type="figure" target="#fig_2">4</ref>). While we see a significant drop for COT and PROGRAM on problems that require four or more steps in the reasoning process, the performance of LTM is fairly consistent across difficulty.</p><p>In addition to the advantage of LTM on clean problems for complicated reasoning <ref type="bibr" target="#b57">(Zhou et al., 2022)</ref>, our results show that LTM is also less sensitive to irrelevant context for complicated problems that require more steps to solve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Instructed Prompting Improves Robustness to Irrelevant Context</head><p>We have shown that using exemplars with distractors improves robustness to irrelevant context. We also compare the performance of instructed prompting and that of the prompts without instructions in Table 4. Breakdown accuracies (√ó100) w.r.t. the factors of the added irrelevant sentence.</p><p>Lower accuracy indicates the model is more fragile to the corresponding type of irrelevant contexts. Note that the macro average accuracies are higher than the corresponding ones reported in Table <ref type="table" target="#tab_2">3</ref>, as we only include a subset of created problems (i.e., those corresponding to the appropriate factor) here to compute the metric. The best result in each column is in boldface.</p><p>original exemplars reaches comparable or even better performance than uninstructed prompting that uses exemplars with distractors for both COT and LTM. Note that adding the instruction "Solve grade school math problems." alone does not significantly improve the performance, and it is the instruction "Feel free to ignore irrelevant information given in the questions." that makes the difference. Similar to the instruction "Let's think step by step." employed by 0-CoT, this shows that language models are-to some extent-able to follow natural language instructions in a way that dramatically changes their problem solving behavior, suggesting that such instructions may be useful for guiding the behavior of language models on more tasks.</p><p>On the original GSM8K development set <ref type="bibr" target="#b7">(Cobbe et al., 2021;</ref><ref type="bibr" target="#b57">Zhou et al., 2022)</ref>, we do not observe a drop in accuracy when using exemplars with irrelevant information, adding natural language instructions, or both (Table <ref type="table" target="#tab_6">5</ref>). The same holds for SVAMP <ref type="bibr" target="#b38">(Patel et al., 2021)</ref>, an arithmetic reasoning benchmark constructed by applying different types of variations to math problems from existing clean datasets, e.g., changing sentence structures, asking different questions with the same information, etc. This is impressive because the results on GSM-IC show that prompt exemplars with irrelevant information and instructed prompting both improve robustness. For the PROGRAM prompt, we find that using exemplars with distractors even increases performance on SVAMP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Complicated Prompts May Hurt the Robustness to Irrelevant Context</head><p>We compare our 1-exemplar COT prompt (Figure <ref type="figure" target="#fig_1">2</ref>) to a 4-exemplar prompt (Appendix D of <ref type="bibr" target="#b57">Zhou et al., 2022)</ref>, which is reported as the best-performing COT prompt on GSM8K, on GSM-IC (Table <ref type="table">6</ref>). Note that the 1-exemplar COT prompt only includes a problem with a 2-step solution, while the 4-exemplar prompt includes problems that require more reasoning steps. While the 4-exemplar prompt leads to better performance on the original GSM8K development set, the 4-exemplar prompt is surprisingly more susceptible to the distraction provided by the irrelevant context. In particular, the 4-exemplar prompt is consistently worse than the 1-exemplar prompt on problems with more than 2 intermediate steps. Even for 2-step prompts, the accuracy improvement from adding more exemplars is almost negligible when using instructions (79.0 vs 79.2). Overall, this finding indicates that adding more exemplars can make the prompt less robust as it leads to some overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Extension to DROP</head><p>In addition to GSM-IC, we extend our evaluation to the DROP dataset <ref type="bibr" target="#b11">(Dua et al., 2019)</ref>, where the task is to answer a question according to a long passage that naturally contains irrelevant context. We show an example about football games in Table <ref type="table">8</ref>.</p><p>We use the COT and LTM prompts in <ref type="bibr" target="#b57">(Zhou et al., 2022)</ref> as the baselines, and we evaluate the prompt variants with the instruction "Solve following questions. Feel free to ignore irrelevant information given in the questions." added before the exemplars. Note that by adding a problem reduction step in the exemplar solution, the least-to-most prompt implicitly leads the model to come up with relevant subproblems to solve the given problem. Again, we observe that the instruction consistently improves the performance of both COT and LTM prompting (Table <ref type="table" target="#tab_7">7</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Discussion</head><p>In this work, we introduce GSM-IC, a dataset that supports comprehensive study of the distractibility of large language models when performing arithmetic reasoning in presence of irrelevant contexts. We examine a variety of prompting techniques on GSM-IC, and demonstrate that they are all sensitive to the irrelevant information in the problems. Among the studied techniques, self-consistency <ref type="bibr">(Wang et al., 2022c)</ref> leads to a substantial improvement in robustness to irrelevant context across the board, and presenting example</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Paragraph</head><p>The Seahawks played the San Francisco 49ers. In the first quarter, the Hawks RB Julius Jones got a 27-yard TD run, along with DT Craig Terrill returning a fumble 9 yards for a touchdown. In the third quarter, the 49ers almost rallied as RB H. J. Torres made a 12-yard TD pass to Lucas Nelly, along with Mare kicking a 32-yard field goal. In the final quarter, Julius Jones got another 11-yard TD. Question How many yards do the shortest touchdown run and the longest touchdown pass combine for?</p><p>LTM solution</p><p>To answer the question "How many yards do the shortest touchdown run and the longest touchdown pass combine for?", we need to know: "How many yards was the shortest touchdown run?", "How many yards was the longest touchdown pass?". Q: How many yards was the shortest touchdown run? A: All the touchdown runs are: a 27-yard touchdown run, a 9-yard touchdown run, a 11-yard touchdown run.</p><p>The smallest number between 27, 9, 11 is 9. The shortest touchdown run was 9 yards. The answer is 9. Q: How many yards was the longest touchdown pass? A: All the touchdown passes are: a 12-yard touchdown pass. The longest touchdown pass was 12 yards. The answer is 12. Q: How many yards do the shortest touchdown run and the longest touchdown pass combine for? A: We know that the shortest touchdown run was 9-yard. We also know that the longest touchdown pass was 12yard. 9 + 12 = 21. The answer is 21.</p><p>Table 8. A DROP example about football games.</p><p>problems with irrelevant context in the prompt also consistently improves the performance. Similarly, we find that simply adding an instruction to ignore irrelevant information brings notable performance gains on our benchmark.</p><p>Despite the improvement achieved by these methods, the fundamental issue remains: a single piece of irrelevant information can distract the models and substantially degrade their performance, even on problems whose clean versions they correctly solve. We encourage researchers to also prioritize improving on this fundamental limitation when developing new training and prompting techniques. We leave further investigation on the distractibility for other tasks and different language models for future work.</p><p>Method Original GSM8K Problem Modified Problem (w/ Irrelevant Sentence) Lucy has $65 in the bank. She made a $15 deposit and then followed by a $4 withdrawal. What is Lucy's bank balance? Lucy has $65 in the bank. She made a $15 deposit and then followed by a $4 withdrawal. Lucy's mother's monthly rent is $10. What is Lucy's bank balance? COT Lucy has $65 in the bank. She made a $15 deposit, so she has $65 + $15 = $80. She then made a $4 withdrawal, so she has $80 -$4 = $76. The answer is $76. Lucy has $65 in the bank. She made a $15 deposit and then followed by a $4 withdrawal. Lucy's mother's monthly rent is $10. Lucy's bank balance is $65 + $15 -$4 -$10 = $66. The answer is $66. LTM Let's break down this problem: 1. How much money did Lucy deposit? 2. How much money did Lucy withdraw? 3. How much money does Lucy have in the bank? Let's break down this problem: 1. How much money did Lucy deposit? 2. How much money did Lucy withdraw? 3. How much money does Lucy have in the bank? 1. Lucy deposited $15. 1. Lucy deposited $15. 2. Lucy withdrew $4. 2. Lucy withdrew $4.  Table 14. All prompts with instructions. The placeholder [Problem of Interest] is substituted for each problem at the test time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>Acc micro (M; P) = p‚ààP 1 [M(p) = s(p)] |P| This means that the micro accuracy weighs all the individual test problems equally. ‚Ä¢ Macro accuracy Acc macro (M; B) is the average accuracy of method M over classes of test problems, where each class P(b) consists of the set of test examples derived from the base example b ‚àà B. We define M's prediction for a class P(b) to be correct if and only if M's prediction for all problems in this class are correct.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Prompt formats for the investigated techniques on the right, which are constructed from building blocks on the left (best viewed in color). The [Problem with Irrelevant Context] is obtained by adding an irrelevant sentence (italic and underlined) to the original problem description and it can be used as an alternative to the [Original Problem] in the prompts on the right. In these prompts, identifiers highlighted and wrapped by brackets (e.g., [Problem of Interest]) are replaced by the contents of the corresponding building blocks. The prompts for all settings can be found in Appendix C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Micro accuracies on GSM-IC-4K with respect to the number of required reasoning steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc>3. Lucy has $65 + $15 -$4 = $76 in the bank.3. Lucy has $65 + $15 -$4 -$10 = $66 in the bank. The answer is $76.The answer is $66. PROGRAM Lucy balance = 65 Lucy bank = 65 Lucy balance = Lucy balance + 15 Lucy bank = Lucy bank + 15 Lucy balance = Lucy balance -4 Lucy bank = Lucy bank -4 print(Lucy balance) Lucy bank = Lucy bank -10 print(Lucy bank)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 )</head><label>3</label><figDesc>, in terms of both micro</figDesc><table><row><cell>Method</cell><cell cols="8">Micro Accuracy 2 Steps &gt;2 Steps Overall Norm 2 Steps &gt;2 Steps Overall Norm Macro Accuracy</cell></row><row><cell cols="6">Prompting Exemplar w/o Irrelevant Context, code-davinci-002</cell><cell></cell><cell></cell><cell></cell></row><row><cell>COT</cell><cell>73.5</cell><cell>70.8</cell><cell>72.4</cell><cell>76.2</cell><cell>8.3</cell><cell>2.5</cell><cell>6.0</cell><cell>6.3</cell></row><row><cell>COT + INST.</cell><cell>79.0</cell><cell>76.0</cell><cell>77.8</cell><cell>81.8</cell><cell>20.0</cell><cell>7.0</cell><cell>15.0</cell><cell>15.8</cell></row><row><cell>0-COT</cell><cell>29.0</cell><cell>29.1</cell><cell>29.0</cell><cell>65.9</cell><cell>1.7</cell><cell>0.0</cell><cell>1.0</cell><cell>2.3</cell></row><row><cell>0-COT +INST.</cell><cell>31.6</cell><cell>28.8</cell><cell>30.5</cell><cell>69.3</cell><cell>1.7</cell><cell>0.0</cell><cell>1.0</cell><cell>2.3</cell></row><row><cell>LTM</cell><cell>74.9</cell><cell>81.5</cell><cell>77.5</cell><cell>82.4</cell><cell>16.7</cell><cell>20.0</cell><cell>18.0</cell><cell>19.1</cell></row><row><cell>LTM + INST.</cell><cell>80.1</cell><cell>81.3</cell><cell>80.6</cell><cell>85.7</cell><cell>18.3</cell><cell>35.0</cell><cell>25.0</cell><cell>26.6</cell></row><row><cell>PROGRAM</cell><cell>59.1</cell><cell>47.4</cell><cell>54.4</cell><cell>65.5</cell><cell>6.7</cell><cell>2.5</cell><cell>5.0</cell><cell>6.0</cell></row><row><cell>PROGRAM + INST.</cell><cell>60.6</cell><cell>50.9</cell><cell>56.7</cell><cell>68.3</cell><cell>6.7</cell><cell>5.0</cell><cell>6.0</cell><cell>7.2</cell></row><row><cell>COT + SC</cell><cell>87.6</cell><cell>90.1</cell><cell>88.1</cell><cell>91.8</cell><cell>29.0</cell><cell>28.3</cell><cell>30.0</cell><cell>31.3</cell></row><row><cell>0-COT + SC</cell><cell>61.6</cell><cell>68.4</cell><cell>64.3</cell><cell>84.6</cell><cell>0.0</cell><cell>2.5</cell><cell>1.0</cell><cell>1.3</cell></row><row><cell>LTM + SC</cell><cell>92.4</cell><cell>94.8</cell><cell>93.4</cell><cell>94.3</cell><cell>51.6</cell><cell>35.0</cell><cell>45.0</cell><cell>45.5</cell></row><row><cell>PROGRAM + SC</cell><cell>73.5</cell><cell>76.1</cell><cell>74.6</cell><cell>82.0</cell><cell>16.7</cell><cell>7.5</cell><cell>13.0</cell><cell>14.3</cell></row><row><cell cols="6">Prompting Exemplar w/o Irrelevant Context, text-davinci-003</cell><cell></cell><cell></cell><cell></cell></row><row><cell>COT</cell><cell>69.3</cell><cell>66.9</cell><cell>68.4</cell><cell>85.4</cell><cell>10.0</cell><cell>7.5</cell><cell>9.0</cell><cell>11.3</cell></row><row><cell>COT + INST.</cell><cell>72.0</cell><cell>70.3</cell><cell>71.3</cell><cell>89.1</cell><cell>11.7</cell><cell>12.5</cell><cell>12.0</cell><cell>15.0</cell></row><row><cell>LTM</cell><cell>78.0</cell><cell>73.6</cell><cell>76.3</cell><cell>94.2</cell><cell>5.0</cell><cell>0.0</cell><cell>5.0</cell><cell>6.2</cell></row><row><cell>LTM + INST.</cell><cell>80.5</cell><cell>70.9</cell><cell>76.7</cell><cell>94.7</cell><cell>5.0</cell><cell>0.0</cell><cell>5.0</cell><cell>6.2</cell></row><row><cell cols="6">Prompting Exemplar w/ Irrelevant Context, code-davinci-002</cell><cell></cell><cell></cell><cell></cell></row><row><cell>COT</cell><cell>79.8</cell><cell>72.4</cell><cell>76.8</cell><cell>80.8</cell><cell>16.7</cell><cell>10.0</cell><cell>14.0</cell><cell>14.7</cell></row><row><cell>COT + INST.</cell><cell>80.5</cell><cell>74.4</cell><cell>78.1</cell><cell>82.2</cell><cell>20.0</cell><cell>12.0</cell><cell>17.0</cell><cell>17.9</cell></row><row><cell>LTM</cell><cell>78.1</cell><cell>84.6</cell><cell>80.7</cell><cell>85.9</cell><cell>23.3</cell><cell>35.0</cell><cell>28.0</cell><cell>29.8</cell></row><row><cell>LTM + INST.</cell><cell>81.0</cell><cell>85.4</cell><cell>82.8</cell><cell>88.1</cell><cell>23.3</cell><cell>35.0</cell><cell>28.0</cell><cell>29.8</cell></row><row><cell>PROGRAM</cell><cell>67.0</cell><cell>55.0</cell><cell>62.2</cell><cell>74.9</cell><cell>11.7</cell><cell>5.0</cell><cell>9.0</cell><cell>10.8</cell></row><row><cell>PROGRAM + INST.</cell><cell>68.8</cell><cell>54.8</cell><cell>63.2</cell><cell>76.1</cell><cell>15.0</cell><cell>7.5</cell><cell>12.0</cell><cell>14.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Adding instructions to COT, LTM, and PROGRAM consistently improves their performance. Surprisingly, instructed prompting with</figDesc><table><row><cell></cell><cell cols="10">Large Language Models Can Be Easily Distracted by Irrelevant Context</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Micro Accuracy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Macro Accuracy</cell><cell></cell></row><row><cell>Method</cell><cell cols="2">Topic</cell><cell cols="4">Role Overlap Num. Range</cell><cell cols="2">Topic</cell><cell cols="4">Role Overlap Num. Range</cell></row><row><cell></cell><cell>In</cell><cell>Off</cell><cell>Yes</cell><cell>No</cell><cell>In</cell><cell>Out</cell><cell>In</cell><cell>Off</cell><cell>Yes</cell><cell>No</cell><cell>In</cell><cell>Out</cell></row><row><cell cols="8">Prompting Exemplar w/o Irrelevant Context (code-davinci-002)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>COT</cell><cell cols="3">63.1 80.7 68.3</cell><cell>76.6</cell><cell>70.2</cell><cell>74.6</cell><cell cols="3">10.2 33.0 10.3</cell><cell>22.2</cell><cell>11.0</cell><cell>19.0</cell></row><row><cell>LTM</cell><cell cols="3">70.8 83.4 77.0</cell><cell>78.2</cell><cell>77.2</cell><cell>77.8</cell><cell cols="3">23.5 45.0 25.8</cell><cell>35.4</cell><cell>27.0</cell><cell>29.0</cell></row><row><cell cols="4">PROGRAM 44.1 63.5 50.7</cell><cell>58.4</cell><cell>54.3</cell><cell>54.5</cell><cell>4.1</cell><cell>24.0</cell><cell>9.3</cell><cell>16.2</cell><cell>7.0</cell><cell>11.0</cell></row><row><cell cols="8">Prompting Exemplar w/o Irrelevant Context (text-davinci-003)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>COT</cell><cell cols="3">63.3 72.9 68.7</cell><cell>68.1</cell><cell>67.2</cell><cell>69.6</cell><cell cols="3">16.3 36.0 17.5</cell><cell>20.2</cell><cell>19.0</cell><cell>22.0</cell></row><row><cell>LTM</cell><cell cols="3">75.4 76.9 75.6</cell><cell>76.8</cell><cell>75.3</cell><cell>77.2</cell><cell>6.1</cell><cell>7.0</cell><cell>6.2</cell><cell>9.1</cell><cell>6.0</cell><cell>6.0</cell></row><row><cell cols="8">Prompting Exemplar w/ Irrelevant Context (code-davinci-002)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>COT</cell><cell cols="3">70.2 82.7 73.6</cell><cell>80.2</cell><cell>76.1</cell><cell>77.7</cell><cell cols="3">18.4 43.0 21.6</cell><cell>32.3</cell><cell>22.0</cell><cell>26.0</cell></row><row><cell>LTM</cell><cell cols="3">73.0 87.5 81.4</cell><cell>80.2</cell><cell>80.0</cell><cell>81.4</cell><cell cols="3">28.6 58.0 37.1</cell><cell>42.4</cell><cell>41.0</cell><cell>35.0</cell></row><row><cell cols="4">PROGRAM 52.9 70.5 60.2</cell><cell>64.5</cell><cell>61.5</cell><cell>62.8</cell><cell cols="3">10.2 37.0 14.4</cell><cell>23.2</cell><cell>15.0</cell><cell>17.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Accuracies (√ó100) on the GSM8K development set and the SVAMP test set. IRRCTX denotes irrelevant contexts, and +INST. denotes instructed prompting. The baseline results (i.e., those using the simplest exemplars without irrelevant context and without instructions) are underlined.</figDesc><table><row><cell>Method</cell><cell cols="3">Exemplar W/ IRRCTX? GSM8K Dev. SVAMP Test Accuracy</cell></row><row><cell>COT</cell><cell>‚úì</cell><cell>59.3</cell><cell>79.1</cell></row><row><cell></cell><cell>‚úó</cell><cell>60.3</cell><cell>77.6</cell></row><row><cell>COT</cell><cell>‚úì</cell><cell>59.3</cell><cell>79.1</cell></row><row><cell>+ INST.</cell><cell>‚úó</cell><cell>58.8</cell><cell>78.7</cell></row><row><cell>LTM</cell><cell>‚úì</cell><cell>61.9</cell><cell>76.9</cell></row><row><cell></cell><cell>‚úó</cell><cell>59.8</cell><cell>76.6</cell></row><row><cell>LTM</cell><cell>‚úì</cell><cell>60.9</cell><cell>76.2</cell></row><row><cell>+ INST.</cell><cell>‚úó</cell><cell>60.3</cell><cell>76.3</cell></row><row><cell>PROGRAM</cell><cell>‚úì</cell><cell>58.6</cell><cell>80.0</cell></row><row><cell></cell><cell>‚úó</cell><cell>59.8</cell><cell>77.3</cell></row><row><cell>PROGRAM</cell><cell>‚úì</cell><cell>59.2</cell><cell>77.9</cell></row><row><cell>+ INST.</cell><cell>‚úó</cell><cell>61.1</cell><cell>77.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 .</head><label>7</label><figDesc>Accuracies (√ó100) on the football split of DROP<ref type="bibr" target="#b11">(Dua et al., 2019)</ref> benchmark.</figDesc><table><row><cell>Method</cell><cell cols="2">#Prompting GSM8K Exemplars Dev.</cell><cell cols="2">GSM-IC-4K 2 Steps &gt; 2 Steps</cell></row><row><cell>COT</cell><cell>1</cell><cell>60.3</cell><cell>73.6</cell><cell>70.8</cell></row><row><cell></cell><cell>4</cell><cell>66.3</cell><cell>78.0</cell><cell>69.4</cell></row><row><cell>COT</cell><cell>1</cell><cell>58.8</cell><cell>79.0</cell><cell>76.0</cell></row><row><cell>+ INST.</cell><cell>4</cell><cell>66.5</cell><cell>79.2</cell><cell>70.6</cell></row><row><cell cols="5">Table 6. Micro accuracies (√ó100) on the GSM8K development set</cell></row><row><cell cols="5">and GSM-IC-4K. # Prompting exemplars denotes the number of</cell></row><row><cell cols="5">exemplars used in the prompt. The best number in each column is</cell></row><row><cell>in boldface.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="4">code-davinci-002 text-davinci-003</cell></row><row><cell>COT</cell><cell></cell><cell>67.4</cell><cell>68.2</cell><cell></cell></row><row><cell cols="2">COT + INST.</cell><cell>68.9</cell><cell>69.9</cell><cell></cell></row><row><cell>LTM</cell><cell></cell><cell>73.4</cell><cell>70.2</cell><cell></cell></row><row><cell cols="2">LTM + INST.</cell><cell>74.4</cell><cell>72.8</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 12 .</head><label>12</label><figDesc>Output example #2 for different prompting techniques, on a GSM8K problem and a corresponding GSM-IC problem. While all techniques give correct answers to the original problem, they output the same incorrect result for the modified GSM-IC problem.Elsa has 5 apples. Anna has 2 more apples than Elsa. Liz has 4 peaches. How many apples do they have together? A: Let's solve the problem by a Python program:</figDesc><table><row><cell>Method</cell><cell>Example</cell><cell>Prompt</cell></row><row><cell></cell><cell>w/ IrrCtx?</cell><cell></cell></row><row><cell>COT</cell><cell>‚úó</cell><cell>Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. How many apples do they</cell></row><row><cell></cell><cell></cell><cell>have together?</cell></row><row><cell></cell><cell></cell><cell>A: Anna has 2 more apples than Elsa, so Anna has 2 + 5 = 7 apples. Elsa and Anna</cell></row><row><cell></cell><cell></cell><cell>have 5 + 7 = 12 apples together. The answer is 12.</cell></row><row><cell></cell><cell></cell><cell>Q: [Problem of Interest]</cell></row><row><cell></cell><cell></cell><cell>A:</cell></row><row><cell>COT</cell><cell>‚úì</cell><cell>Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. Liz has 4 peaches. How</cell></row><row><cell></cell><cell></cell><cell>many apples do they have together?</cell></row><row><cell></cell><cell></cell><cell>A: Anna has 2 more apples than Elsa, so Anna has 2 + 5 = 7 apples. Elsa and Anna</cell></row><row><cell></cell><cell></cell><cell>have 5 + 7 = 12 apples together. The answer is 12.</cell></row><row><cell></cell><cell></cell><cell>Q: [Problem of Interest]</cell></row><row><cell></cell><cell></cell><cell>A:</cell></row><row><cell>LTM</cell><cell>‚úó</cell><cell>Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. How many apples do they</cell></row><row><cell></cell><cell></cell><cell>have together?</cell></row><row><cell></cell><cell></cell><cell>A: Let's break down this problem: 1. How many apples does Anna have? 2. How</cell></row><row><cell></cell><cell></cell><cell>many apples do Elsa and Anna have together?</cell></row><row><cell></cell><cell></cell><cell>1. Anna has 2 more apples than Elsa. So Anna has 2 + 5 = 7 apples.</cell></row><row><cell></cell><cell></cell><cell>2. Elsa and Anna have 5 + 7 = 12 apples together.</cell></row><row><cell></cell><cell></cell><cell>Q: [Problem of Interest]</cell></row><row><cell></cell><cell></cell><cell>A: Let's break down this problem:</cell></row><row><cell>LTM</cell><cell>‚úì</cell><cell>Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. Liz has 4 peaches. How</cell></row><row><cell></cell><cell></cell><cell>many apples do they have together?</cell></row><row><cell></cell><cell></cell><cell>A: Let's break down this problem: 1. How many apples does Anna have? 2. How</cell></row><row><cell></cell><cell></cell><cell>many apples do Elsa and Anna have together?</cell></row><row><cell></cell><cell></cell><cell>1. Anna has 2 more apples than Elsa. So Anna has 2 + 5 = 7 apples.</cell></row><row><cell></cell><cell></cell><cell>2. Elsa and Anna have 5 + 7 = 12 apples together.</cell></row><row><cell></cell><cell></cell><cell>Q: [Problem of Interest]</cell></row><row><cell></cell><cell></cell><cell>A: Let's break down this problem:</cell></row><row><cell>0-COT</cell><cell>N/A</cell><cell>Q: [Problem of Interest]</cell></row><row><cell></cell><cell></cell><cell>A: Let's think step by step:</cell></row><row><cell>PROGRAM</cell><cell>‚úó</cell><cell>Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. How many apples do they</cell></row><row><cell></cell><cell></cell><cell>have together?</cell></row><row><cell></cell><cell></cell><cell>A: Let's solve the problem by a Python program:</cell></row><row><cell></cell><cell></cell><cell>Elsa apples = 5</cell></row><row><cell></cell><cell></cell><cell>Anna apples = 2 + Elsa apples</cell></row><row><cell></cell><cell></cell><cell>Elsa Anna apples = Elsa apples + Anna apples</cell></row><row><cell></cell><cell></cell><cell>print(Elsa Anna apples)</cell></row><row><cell></cell><cell></cell><cell>Q: [Problem of Interest]</cell></row><row><cell></cell><cell></cell><cell>A: Let's solve the problem by a Python program:</cell></row><row><cell>PROGRAM</cell><cell>‚úì</cell><cell>Q: Elsa apples = 5</cell></row><row><cell></cell><cell></cell><cell>Anna apples = 2 + Elsa apples</cell></row><row><cell></cell><cell></cell><cell>Elsa Anna apples = Elsa apples + Anna apples</cell></row><row><cell></cell><cell></cell><cell>print(Elsa Anna apples)</cell></row><row><cell></cell><cell></cell><cell>Q: [Problem of Interest]</cell></row><row><cell></cell><cell></cell><cell>A: Let's solve the problem by a Python program:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 13 .</head><label>13</label><figDesc>Prompts used for all investigated techniques, without instruction. The placeholder [Problem of Interest] is substituted for each problem at the test time.Solve grade school math problems. Feel free to ignore irrelevant information given in the questions. Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. How many apples do they have together? A: Anna has 2 more apples than Elsa, so Anna has 2 + 5 = 7 apples. Elsa and Anna have 5 + 7 = 12 apples together. The answer is 12.Solve grade school math problems. Feel free to ignore irrelevant information given in the questions. Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. Liz has 4 peaches. How many apples do they have together? A: Anna 2 more apples than Elsa, so Anna has 2 + 5 = 7 apples. Elsa and Anna have 5 + 7 = 12 apples together. The answer is 12. Q: [Problem of Interest] A: LTM ‚úó Solve grade school math problems. Feel free to ignore irrelevant information given in the questions. Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. How many apples do they have together? A: Let's break down this problem: 1. How many apples does Anna have? 2. How many apples do Elsa and Anna have together? 1. Anna has 2 more apples than Elsa. So Anna has 2 + 5 = 7 apples. 2. Elsa and Anna have 5 + 7 = 12 apples together. Q: [Problem of Interest] A: Let's break down this problem: LTM ‚úì Solve grade school math problems. Feel free to ignore irrelevant information given in the questions. Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. Liz has 4 peaches. How many apples do they have together? A: Let's break down this problem: 1. How many apples does Anna have? 2. How many apples do Elsa and Anna have together? 1. Anna has 2 more apples than Elsa. So Anna has 2 + 5 = 7 apples. 2. Elsa and Anna have 5 + 7 = 12 apples together. Solve grade school math problems. Feel free to ignore irrelevant information given in the questions. Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. How many apples do they have together? A: Let's solve the problem by a Python program: Elsa apples = 5 Anna apples = 2 + Elsa apples Elsa Anna apples = Elsa apples + Anna apples print(Elsa Anna apples) Q: [Problem of Interest] A: Let's solve the problem by a Python program: PROGRAM ‚úì Solve grade school math problems. Feel free to ignore irrelevant information given in the questions. Q: Elsa has 5 apples. Anna has 2 more apples than Elsa. Liz has 4 peaches. How many apples do they</figDesc><table><row><cell>Method</cell><cell>Example</cell><cell>Prompt</cell></row><row><cell></cell><cell>w/ IrrCtx?</cell><cell></cell></row><row><cell>COT</cell><cell>‚úó</cell><cell></cell></row><row><cell></cell><cell>Q: [Problem of Interest]</cell><cell></cell></row><row><cell></cell><cell>A:</cell><cell></cell></row><row><cell>COT</cell><cell>‚úì</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>http://openai.com/api/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>We do not generate new examples or perform analysis on the test set to avoid potential tuning-on-test-set issues.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>The number of reasoning steps of a problem is given by the number of sentences in its standard answer<ref type="bibr" target="#b7">(Cobbe et al., 2021)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Our sampled GSM-IC-4K covers all 100 base problems.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>We would like to thank <rs type="person">Dale Schuurmans</rs>, <rs type="person">Olivier Bousquet</rs> and <rs type="person">Jack Nikodem</rs> for helpful discussion and feedback.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. GSM-IC Details</head><p>Each of the 100 base problem require two to seven steps to solve (Figure <ref type="figure">5</ref>). Starting from the base problems, we follow the protocols below to create GSM-IC ( ¬ß3.1).</p><p>1. Irrelevant sentence template.</p><p>(a) For in-topic sentences, we manually write templates within the topic that is close to the original problem description. We are particularly careful about the shareable stuff, for example, money is sometimes considered shareable between family members. In such cases, we make sure that the added do not change the amount of shareable stuff to ensure that the final standard answer is not affected. (b) For off-topic sentences, we use general templates (Table <ref type="table">9</ref>) for all problems unless some of them can be considered as in-topic sentences for some problems-for example, the sentence "The height of {role} is {number} feet." is considered as an in-topic sentence for problems about heights of people.</p><p>The shoe size of</p><p>[ROLE] bought [NUMBER] tomatoes from the grocery store.</p><p>[ROLE] has read [NUMBER] books in the past year.</p><p>Table <ref type="table">9</ref>. Off-topic sentence templates for GSM-IC.</p><p>(c) We make sure that all sentences derived by each template are grammatical English sentences. (d) We write four in-topic and choose four off-topic distractor sentence templates for each problem.</p><p>2. Blank fillers: role names.</p><p>(a) We randomly choose a role name X, and use X's father, X's mother, X's brother, X's sister and X's neighbor as the overlapped role names. (b) We choose from the name set {Ada, David, Emma, Jack, John, Mary, Max, Tom} for nonoverlapped role names. (c) We write five names that have overlap with the original character, and five names that do not have overlap for each problem.</p><p>3. Blank fillers: numbers.</p><p>(a) For in-range numbers, we randomly sample positive integers in the range of [ ‚Ñì 10 , 10r], where ‚Ñì and r denote the smallest and the largest number that appear in the problem description and standard solution, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original Problem</head><p>Kim plants 80 cherry pits. 25% of them sprout and Kim sells 6 of the saplings. How many cherry saplings does she have left?</p><p>Added Sentence Kim's mother plants 20 more potatoes.</p><p>Ambiguous Problem Kim plants 80 cherry pits. 25% of them sprout and Kim sells 6 of the saplings. Kim's mother plants 20 more potatoes. How many cherry saplings does she have left?</p><p>Fixed Problem Kim plants 80 cherry pits. 25% of them sprout and Kim sells 6 of the saplings. Kim's mother plants 20 more potatoes. How many cherry saplings does Kim have left? Table <ref type="table">10</ref>. An example that adding irrelevant contexts causes ambiguity: after adding the sentence, it is unclear whether she refers to Kim or Kim's mother. To ensure that the standard answer is unchanged, we modify the final question to make it clear and faithful to the original problem.</p><p>(b) For out-of-range numbers, we choose from the range of [2, +‚àû)\[ ‚Ñì 10 , 10r]. For very few problems that ‚Ñì is relatively large (i.e., ‚Ñì &gt; 10 5 ) where we choose out-of-range numbers from the range of [2, ‚Ñì 10 ]; for other problems we choose out-of-range numbers n = a √ó 10 b from the range [10r, ‚àû), where a and b are both non-negative integers. (c) We write four in-range numbers and four out-of-range numbers for each problem. 4. Finally, if adding the irrelevant sentence causes ambiguity (e.g., Table <ref type="table">10</ref>), we fix the question to ensure that the standard solution to the generated problem remain the same as the base problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Sample Predictions on GSM-IC</head><p>In addition to the example outputs shown in Figure <ref type="figure">3</ref>, we include more example problems and the predictions by different techniques (Tables <ref type="table">11</ref> and <ref type="table">12</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Full prompts in experiments</head><p>We list the prompts for all experiments in Tables <ref type="table">13</ref> and <ref type="table">14</ref>.</p><p>Large Language Models Can Be Easily Distracted by Irrelevant Context Method Original GSM8K Problem Modified Problem (w/ Irrelevant Sentence) Jessica is six years older than Claire. In two years, Claire will be 20 years old. How old is Jessica now? Jessica is six years older than Claire. In two years, Claire will be 20 years old. Twenty years ago, the age of Claire's father is 3 times of Jessica's age. How old is Jessica now?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COT</head><p>In two years, Claire will be 20 years old. So, Claire is 18 years old now. Jessica is six years older than Claire, so Jessica is 18 + 6 = 24 years old now. The answer is 24.</p><p>Jessica is six years older than Claire, so Jessica is 20 -6 = 14 years old. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Program synthesis with large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07732</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Look at that! BERT can be easily distracted from paying attention to morphosyntax</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Chaves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Richter</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.scil-1.3" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Society for Computation in Linguistics 2021</title>
		<meeting>the Society for Computation in Linguistics 2021</meeting>
		<imprint>
			<date type="published" when="2021-02">February 2021</date>
			<biblScope unit="page" from="28" to="38" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.12588</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<title level="m">Scaling language modeling with pathways</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Scaling instruction-finetuned language models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brahma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11416</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Transformers as soft reasoners over language</title>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence</title>
		<meeting>the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3882" to="3890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Training verifiers to solve math word problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14168</idno>
		<ptr target="https://arxiv.org/pdf/2110.14168" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.09712</idno>
		<title level="m">Selectioninference: Exploiting large language models for interpretable logical reasoning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Saurous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.10342</idno>
		<title level="m">Language model cascades</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Compositional semantic parsing with large language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Drozdov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sch√§rli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Aky√ºrek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.15003</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.10435</idno>
		<title level="m">Program-aided language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riddell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zubova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burtell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.00840</idno>
		<title level="m">Natural language reasoning with first-order logic</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Effects of varying irrelevant information on adult age differences in problem solving</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Rebok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Sved</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of gerontology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="553" to="560" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07328</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Capturing failures of large language models via human cognitive biases</title>
		<author>
			<persName><forename type="first">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.12299</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sch√ºtze</surname></persName>
		</author>
		<idno>doi: 10.18653</idno>
		<ptr target="1/2020.acl-main" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="7811" to="7818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<ptr target="https://aclanthology.org/2020.acl-main.698" />
		<title level="m">URL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning what is essential in questions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K17-1010</idno>
		<ptr target="https://aclanthology.org/K17-1010" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Conference on Computational Natural Language Learning</title>
		<meeting>the 21st Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2017-08">CoNLL 2017. August 2017</date>
			<biblScope unit="page" from="80" to="89" />
		</imprint>
	</monogr>
	<note type="report_type">Vancouver</note>
	<note>Canada</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Decomposed prompting: A modular approach for solving complex tasks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02406</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12685</idno>
		<title level="m">Ground-truth labels matter: A deeper look into input-label demonstrations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.11916</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adversarial examples for evaluating math word problem solvers</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Maheshwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2705" to="2712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05110</idno>
		<title level="m">Large language models with controllable working memory</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soylu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09110</idno>
		<title level="m">Holistic evaluation of language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Program induction by rationale generation: Learning to solve and explain algebraic word problems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1015</idno>
		<ptr target="https://aclanthology.org/P17-1015" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07">July 2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="158" to="167" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Text and patterns: For effective chain of thought, it takes two to tango</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yazdanbakhsh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.07686</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The disturbing effect of irrelevant information on arithmetic problem solving in inattentive children</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Marzocchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lucangeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>De Meo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cornoldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Developmental neuropsychology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="92" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.12837</idno>
		<title level="m">Rethinking the role of demonstrations: What makes in-context learning work? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">COMPS: Conceptual minimal pair sentences for testing robust property knowledge and its inheritance in pre-trained language models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rayz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ettinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Conference of the European Chapter</title>
		<meeting>the 17th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Textattack: A framework for adversarial attacks, data augmentation, and adversarial training in nlp</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lifland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grigsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05909</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to attend on essential terms: An enhanced retriever-reader model for open-domain question answering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1030</idno>
		<ptr target="https://aclanthology.org/N19-1030" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="335" to="344" />
		</imprint>
	</monogr>
	<note>Minnesota Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.00114</idno>
		<title level="m">Show your work: Scratchpads for intermediate computation with language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02155</idno>
		<ptr target="https://arxiv.org/abs/2203.02155" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sorting through the noise: Testing robustness of information processing in pretrained language models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pandia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ettinger</surname></persName>
		</author>
		<idno>doi: 10.18653</idno>
		<ptr target="1/2021.emnlp-main" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1583" to="1596" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<ptr target="https://aclanthology.org/2021.emnlp-main.119" />
		<title level="m">URL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Working memory and intrusions of irrelevant information in a group of specific poor problem solvers</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Pasolunghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cornoldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>De Liberto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="779" to="790" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Are nlp models really able to solve simple math word problems?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattamishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2021.naacl-main.168.pdf" />
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03350</idno>
		<title level="m">Measuring and narrowing the compositionality gap in language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified textto-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Ravichander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marasoviƒá</surname></persName>
		</author>
		<author>
			<persName><surname>Condaqa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.00295</idno>
		<title level="m">A contrastive reading comprehension dataset for reasoning about negation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raja</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.08207</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Natural language to code translation with execution</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Language models are multilingual chain-of-thought reasoners</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srivats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03057</idno>
		<ptr target="https://arxiv.org/pdf/2210.03057" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning visually-grounded semantics from contrastive adversarial samples</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3715" to="3727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">CLUTRR: A diagnostic benchmark for inductive reasoning from text</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sodhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1458</idno>
		<ptr target="https://aclanthology.org/D19-1458" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4506" to="4515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Challenging big-bench tasks and whether chain-of-thought can solve them</title>
		<author>
			<persName><forename type="first">M</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sch√§rli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.09261</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><surname>Proofwriter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.13048</idno>
		<title level="m">Generating implications, proofs, and abductive statements over natural language</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Adversarial glue: A multitask benchmark for robustness evaluation of language models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.02840</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Towards understanding chain-of-thought prompting: An empirical study of what matters</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10001</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.00747</idno>
		<title level="m">Rationale-augmented ensembles in language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Do prompt-based models really understand the meaning of their prompts</title>
		<author>
			<persName><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01247</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01652</idno>
		<title level="m">Finetuned language models are zero-shot learners</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://openreview.net/pdf?id=_VjQlMeSB_J" />
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Merri√´nboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.05698</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Leastto-most prompting enables complex reasoning in large language models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sch√§rli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2205.10625</idno>
		<ptr target="https://arxiv.org/pdf/2205.10625" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

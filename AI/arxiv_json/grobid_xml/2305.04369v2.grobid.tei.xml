<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Getting More out of Large Language Models for Proofs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-05-31">31 May 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shizhuo</forename><forename type="middle">Dylan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana-Champaign</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emily</forename><surname>First</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Talia</forename><surname>Ringer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana-Champaign</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Getting More out of Large Language Models for Proofs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-05-31">31 May 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">A29E1C234F6B63EFDB63434261935531</idno>
					<idno type="arXiv">arXiv:2305.04369v2[cs.FL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models have the potential to simplify formal theorem proving and make it more accessible. But how to get the most out of these models is still an open question.</p><p>To answer this question, we take a step back and explore the failure cases of these models using common prompting-based techniques. Our talk will discuss these failure cases and what they can teach us about how to get more out of these models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Introduction Formal theorem proving is a crucial but challenging task-and a natural fit for automation. Historically, most work on formal proof automation has relied on symbolic techniques <ref type="bibr" target="#b7">[8]</ref>, sometimes combined with neural tools <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b2">3]</ref>. Recent advances in large language models have improved their instruction-following and in-context learning capabilities, making it possible to build powerful proof automation that elides symbolic search procedures altogether, as shown by Baldur <ref type="bibr" target="#b4">[5]</ref>.</p><p>How can we get more out of these advances in large language models? To answer that, we examine the capabilities of the state-of-the-art language models GPT-3.5 Turbo and GPT-4 to prove theorems in Coq using common prompting-based techniques. In particular, we conduct a fine-grained analysis of model outputs on an example project. Our emphasis is on the failure cases-how these outputs commonly go wrong, and what that can teach us about how to get more out of these models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPT-3.5-Turbo</head><p>GPT-</p><p>4 Proverbot FS-rand FS-sim ZS FS-rand FS-sim ZS FS+Lem ZS+Lem -#Correct Proof 10 8 0 7 8 0 14 9 -#Proven Theorems 6 4 0 6 7 0 7 5 23 Table 1: Results. 'FS' stands for 'few-shot', 'ZS' stands for 'zero-shot'. '+lemma' 'denotes providing lemmas preceding the query theorem in the file in the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Recommendations</head><p>We performed fine-grained analysis of the model-generated proofs and categorized the comments of human experts in Figure <ref type="figure">1a</ref>. Details about our experimental methodology, along with examples, are in the appendix. Our recommendations:</p><p>1. Allow the model to prompt the proof assistant for more information. Model outputs sometimes ask for more information about the definitions of referenced variables when those definitions have not been provided as input as shown in Figure <ref type="figure">1c</ref> and Appendix C.1. This opens up a perfect opportunity for tool use at the model's request. By prompting the model to ask for information using standard Coq commands like Print, and executing them in real time, we can allow the model to obtain information as it generates proof in steps.</p><p>2. Give the model access to proof states. Language models are found to be weak at 'execution'. In our case, they by default lack access to proof state. This manifests in outputs as incorrect assumptions about the current proof state, like introducing too many variables</p><p>Hallucination 34.3% Dependency 20.7% Proof State 19.5% Refusal 5.4% Syntax 4.9% Circular 0.4% Incomplete Proof 1.8% Tactic Failure 0.8% QED 0.9% Unification 4.7% Complex Error 2.2% Missing Information 4.5% (a) Breakdown of 740 expertannotated GPT-4 outputs under few-shot 'theorem-proof' set-up (see Appendix A.2 for more). or overloading variables already used (see Figure <ref type="figure">1b</ref> and Appendix C.4). For human proof engineers, interactive proof is more like a conversation with the proof assistant with constant feedback on the state; emulating this is a perfect opportunity to put the chat API to good use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>Give the model access to information in file dependencies. Naively prompted models produce outputs that make incorrect assumptions about definitions and lemmas from dependencies, for example by hallucinating lemma names (see Appendix C.6), or by attempting to induct over a non-inductive hypothesis. Human proof engineers avoid this by having access to dependencies directly; models should access to those dependencies in context or in memory.</p><p>4. Give the model access to proofs preceding the current proof. Naively prompted models fail to solve proofs that would be obvious from context, since human-written proofs are often small permutations of earlier proofs. Baldur <ref type="bibr" target="#b4">[5]</ref> showed in-context learning can help with this in Isabelle/HOL; we now have evidence (see Appendix C.5) this is worth trying in Coq.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Learn from errors.</head><p>People have attempted to iteratively improve the quality of generated programs by providing the model with correctness signals as feedback <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b9">10]</ref>; the same has shown success for proofs in Isabelle/HOL <ref type="bibr" target="#b4">[5]</ref>. The error messages we observed were very informative,<ref type="foot" target="#foot_0">foot_0</ref> and suggest this may be fruitful in Coq as well.</p><p>6. Introduce diversity through prompt engineering. It has been observed that a mixture of experts can boost performance of ML-guided proof synthesis by performing diverse sequences of tactics <ref type="bibr" target="#b2">[3]</ref>. On the other hand, there is evidence of performance gain by introducing diversity in few-shot set-up for both synthesis <ref type="bibr" target="#b0">[1]</ref> and reasoning <ref type="bibr" target="#b10">[11]</ref> tasks from the language modeling research community. The diversity we have already observed (see Appendix B) is evidence this may be worth trying with different prompts for Coq proofs.</p><p>Proposed Talk In our talk, we will discuss specific examples of these failure cases, how they correspond to our recommendations, and our progress on experimentation along these recommendations in the intervening months. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Message</head><p>Theorem in Test Project To Be Proven ……   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Few-Shot Prompting</head><p>Our approach utilizes the conventional few-shot in-context learning method. We include examples in the form of theorem-proof tuples at the beginning of the target query as shown in Figure <ref type="figure" target="#fig_2">3</ref>. In addition to the description of the task in the initial system message and the query, we provide examples of query-answer pairs obtained from training set to demonstrate to the model the task we want it to perform and the expected output format. We experimented with a few variants:</p><p>Theorem-Proof In this set-up, we provide examples of pairs of theorems and proofs, as illustrated in Figure <ref type="figure" target="#fig_3">4</ref>.</p><p>Theorem with Given Lemmas In this setting, we provide the model with the names of lemmas preceding the theorem. The format is shown in Figure <ref type="figure" target="#fig_4">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Training of Retriever</head><p>We perform continued fine-tuning from the sentence-transformer model all-mpnet-base-v2 based on <ref type="bibr" target="#b8">[9]</ref>. In particular, this model has been trained on code corpus and has certain level of code-understanding capabilities. We train the model to perform similar proof search on the</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>Prove the following theorem in Coq: Let HBGGn: forall R n, incl (comp (star B) (UExp G R n)) (UExp G R (S n)). Error: "R is already used." (b) An example output that incurs an error because model lacks local proof state, and so uses variable name R that is already taken. See Appendix C.4 for full context. Prove the following theorem in Coq: Lemma G_wmon: wmonotonic TX TX G. (* Without further information on what TX and G are, I cannot generate a valid proof. Please provide more information or define the related functions and types. *) (c) An example output that recognizes the necessary definitions are not provided and asks for clarifications from the user. See Appendix C.1 for more.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2: Investigation Pipeline</figDesc><graphic coords="4,113.27,254.40,167.60,55.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Workflow of few-shot prompting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Few-shot example format of Theorem-Proof setting.</figDesc><graphic coords="4,113.27,310.43,167.60,75.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Few-shot example format of Theorem with Given Lemma setting.</figDesc><graphic coords="4,343.25,253.59,167.80,89.96" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Our annotated data with errors is available here: https://github.com/DylanZSZ/LLM4Proof.git</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Coq makes it possible to generalize all proofs in a Section by the same pre-defined parameters, and one such parameter here is named R.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Methodology</head><p>We experimented with both zero-shot and few-shot prompting methods with &amp; without preceding lemmas of the query theorem. To select few-shot samples, we experimented with two strategies: random selection and similarity based selection using a retrieval model we fine-tuned on the training set. The details are deferred to appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Zero-Shot Prompting</head><p>The notable characteristic of GPT-3.5 Turbo and GPT-4 is their robust ability to follow instructions. In a zero-shot configuration, we leverage the system's messaging to establish the task and desired output format for the entire conversation, while utilizing user messaging to provide query-specific information such as the theorem to be proven and relevant lemmas. train set by minimizing the triplet objective</p><p>where T i is the query theorem,P i is the proof of this theorem and P j is a randomly sampled proof of another theorem. During retrieval, we compute the similarity scores between test theorems and proofs in the training set, ans use those theorems whose proofs are similar to the test instance as the few-shot examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Experiment Set-up</head><p>We conducted experiments to evaluate the performance of two language models, GPT-3.5-turbo and GPT4, under both few-shot and zero-shot settings. The few-shot learning was performed with k-shots=6, meaning that the models were trained on only six examples per class. The hyperparameters used for both models were set as follows: temperature T =1,presence penalty=0.1, number of samples per prompt n=5. presence penalty is a penalty term applied to the logit values of tokens already present in the prompt to discourage the repetition of those tokens in the generated text. GPT4-random-fs GPT3.5-random-fs GPT4-sim-fs GPT3.5-sim-fs GPT4-lemma-fs GPT4-lemma-zs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Coinciding proofs solved</head><p>Proof synthesis is a special task in nature, having similarities with code-synthesis where both being generative, but still different as the criteria of whether or not the target theorem is proved is close-ended to a certain extent. Even under few-shot set-up where the model output is restricted to be in Coq format, the model insists on requesting additional information on the variables not clearly defined. It is impressive that the model has certain level of ability to understand Coq as well as the necessary information to complete the proof, e.g. the definition of variable names ans assumptions. This category constitutes 5.4% of total number of cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Example Outputs C.1 Refusing To Answer</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Not Trying Simple Tactics</head><p>This is an easy theorem which model has failed. In particular, to prove this, a simple auto. tactic will do. However, the model did not give this tactic a try.</p><p>This is a case where all of context, proof state, and dependency information may help. It is also a case where diverse prompting may be useful (for example, by adding a prompt that favors very simple proofs that do not use any lemmas).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Succeeding</head><p>There are certain cases where the model succeeded in proving the theorems. These theorems generally do not depend much on context. For example, the model-generated proof of weak_refl succeeds using only simple tactics:</p><p>Lemma weak_refl: forall x, Weak T x x. Proof. intros x. constructor. reflexivity. Qed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Lacking the Proof State</head><p>Here we provide the proof state of the example in the main text before the step in Figure <ref type="figure">1b</ref>: </p><p>Note the proof assistant renamed the R in the goal into R0 because there is another R in context from earlier in the file. 2 Coq chooses R0 so as not to shadow R. Similarly, the human proof calls this RR to avoid shadowing R: intros RR n x y H; right; apply (HBG H).</p><p>In contrast, without any access to the fact that R is already defined the local proof state, the model output attempts to introduce a new variable named R. Coq refuses and responds with an error. Another place where proof state is useful is when the model introduces more variables than can be introduced. For example, the model generates this output: The second step, intros R u v, assumes there are three variables to introduce. This would be reasonable if unfolding G and eeq introduced more foralls in the goal of the proof state after the first step. But it does not; the local proof state at that step includes only one variable R to introduce. Coq thus responds with an error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Lacking Local Context</head><p>Writing proofs is often easier with context, since proofs often mirror preceding proofs in the same file. For example, proving this lemma is easier with context:</p><p>This is because the human-written proofs preceding it in the file very much mirror the humanwritten proof of this lemma: This gives us evidence that in-context learning in the style of Baldur may be fruitful in Coq as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.6 Hallucination</head><p>Below is an example from the model where it hallucinates H which has been defined nowhere. We observe in many cases the model are directly using the commonly used variable names like H, x, y which it has seen multiple times during pre-training. Moreover, it hallucinates lemmas or definitions in the proofs, like stutter_bisim. By providing proof state, we can help the model pick more correct variables; by providing file dependencies that contain referenced definitions and auxiliary lemmas, and prompting the model to restrict itself to those, we can help the model use only the definitions and lemmas that exist already.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Program synthesis with large language models</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">HOList: An environment for machine learning of higher order logic theorem proving</title>
		<author>
			<persName><forename type="first">Kshitij</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stewart</forename><surname>Wilcox</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</editor>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Diversity-driven automated formal verification</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>First</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Brun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International Conference on Software Engineering, ICSE &apos;22</title>
		<meeting>the 44th International Conference on Software Engineering, ICSE &apos;22<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="749" to="761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Tactok: Semantics-aware proof synthesis</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>First</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Brun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Guha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Program. Lang</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2020-11">nov 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Baldur: Whole-proof generation and repair with large language models</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>First</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Talia</forename><surname>Ringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Brun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Hypertree proof search for neural theorem proving</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amaury</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Generative language modeling for automated theorem proving</title>
		<author>
			<persName><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Qed at large: A survey of engineering of formally verified software</title>
		<author>
			<persName><forename type="first">Talia</forename><surname>Ringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Palmskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sergey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milos</forename><surname>Gligoric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Tatlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Programming Languages</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="102" to="281" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Mpnet: Masked and permuted pre-training for language understanding</title>
		<author>
			<persName><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Compilable neural code generation with compiler feedback</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yitong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning to prove theorems from scratch with deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Minchao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Norrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Walder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Dezfouli</surname></persName>
		</author>
		<author>
			<persName><surname>Tacticzero</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Conversational automated program repair</title>
		<author>
			<persName><forename type="first">Chunqiu</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Lingming</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

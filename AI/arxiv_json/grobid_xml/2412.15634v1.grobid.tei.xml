<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Darkit: A User-Friendly Software Toolkit for Spiking Large Language Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-12-20">20 Dec 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xin</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shifan</forename><surname>Ye</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qian</forename><surname>Zheng</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">The State Key Lab of Brain-Machine Intelligence</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yangfan</forename><surname>Hu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">The State Key Lab of Brain-Machine Intelligence</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">The State Key Lab of Brain-Machine Intelligence</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shunyu</forename><surname>Qi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">The State Key Lab of Brain-Machine Intelligence</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuyang</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">The State Key Lab of Brain-Machine Intelligence</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huajin</forename><surname>Tang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">The State Key Lab of Brain-Machine Intelligence</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gang</forename><surname>Pan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">The State Key Lab of Brain-Machine Intelligence</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuiguang</forename><surname>Deng</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">The State Key Lab of Brain-Machine Intelligence</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Zhejiang</settlement>
									<region>China</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Darkit: A User-Friendly Software Toolkit for Spiking Large Language Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-12-20">20 Dec 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">0205DDCF88DA308607C807D96D052B09</idno>
					<idno type="arXiv">arXiv:2412.15634v1[cs.SE]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models (LLMs) have been widely applied in various practical applications, typically comprising billions of parameters, with inference processes requiring substantial energy and computational resources Brown [2020], Touvron et al. [2023]. In contrast, the human brain, employing bio-plausible spiking mechanisms, can accomplish the same tasks while significantly reducing energy consumption, even with a similar number of parameters Xing et al. [2024a]. Based on this, several pioneering researchers have proposed and implemented various large language models that leverage spiking neural networks Xing et al. [2024b], Zhu et al. [2023]. They have demonstrated the feasibility of these models, validated their performance, and open-sourced their frameworks and partial source code. To accelerate the adoption of brain-inspired large language models and facilitate secondary development for researchers, we are releasing a software toolkit named DarwinKit (Darkit). The toolkit is designed specifically for learners, researchers, and developers working on spiking large models, offering a suite of highly user-friendly features that greatly simplify the learning, deployment, and development processes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>When novices attempt to use existing open-source frameworks and tools for the study and development of spiking large language models, they often face several troubles that result in significant time consumption:</p><p>1. Configuration and Preprocessing: Configuring the development environment, preprocessing data, and preparing a suitable tokenizer according to the requirements of corresponding spiking large language model frameworks can be cumbersome and time-consuming.</p><p>2. Parameter Tuning and Testing: Tuning and testing the parameters of spiking large language models are often complex and tedious. Comparing different models and parameter configurations necessitates frequent code updates and continuous monitoring of training and inference processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Secondary Development:</head><p>Conducting secondary development based on the source code of existing spiking large language models requires an in-depth understanding of the computational graph of the original framework and the relationships between individual blocks. This results in substantial learning and analysis costs when navigating the original codebase. Darkit introduces the following ten features to address the above issues commonly faced by researchers and developers working with spiking large language models:</p><p>1. One-Click Environment Configuration: Users can configure the development environment with a single command, requiring only CUDA and Conda environments on their local machines. As shown in Figure <ref type="figure">1</ref>, the toolchain can be installed effortlessly via pip.</p><p>Figure <ref type="figure">1</ref>: The toolchain is installed using the pip command.</p><p>2. Integrated Preprocessed Datasets: Darkit includes preprocessed datasets such as Wikitext, Wikipedia, Ultrachat, and Fineweb, which are readily available via code or a graphical interface on the web (Figure <ref type="figure">2</ref>). The tool will continue to maintain and expand its dataset collection while providing interfaces for users to contribute new datasets for integration. 3. Integrated Preprocessed Tokenizers: Popular tokenizers, including GPT-2 (small, medium, and large variants), BERT-based-cased, and BERT-base-Chinese, are pre-integrated in Darkit (as shown in Figure <ref type="figure">3</ref>). Similar to datasets, tokenizers will be continuously updated and allow users to add new tokenizers through the provided interfaces. 6. Automated Extraction of Model Computational Graphs: Darkit automatically extracts the computational graph of large models, organizing nodes into a hierarchical tree structure based on module identifiers (Figure <ref type="figure">6a</ref>). This feature allows users to explore the model architecture interactively, making it easier to understand than reading the raw source code (Figure <ref type="figure">6b</ref>). When a module is selected on the web frontend, the backend extracts the relevant code segment and displays it for the user, facilitating comprehension of the module's functionality without delving into the source code.  7. Code Editing and Re-Integration: Darkit provides interfaces for users to edit extracted source code via the web frontend or backend. The modified code can be re-injected into the model for convenient architectural and computational flow adjustments (Figure <ref type="figure" target="#fig_4">7a</ref>). The tool validates user edits, offers suggestions for corrections, and supports saving, training, and executing the modified models directly (Figure <ref type="figure" target="#fig_4">7b</ref>).</p><p>8. Flowchart-Based Model Design: Darkit allows users to design spiking large language model computational graphs through a visual flowchart interface or terminal commands. The combination of graphical and coding interfaces facilitates the creation and implementation of spiking neural network models (Figure <ref type="figure">8</ref>).  10. Unified Interface for Third-Party Extensions: Darkit supports seamless integration of thirdparty contributions. New models, datasets, and modules can be incorporated through a unified plugin system, enabling easy expansion and collaboration (Figure <ref type="figure">10</ref>).  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>4.</head><figDesc>Data Monitoring and Experiment Comparison: For researchers performing secondary development, the ability to view, record, and trace model runtime data in real-time is essential. Comparing experimental results across different configurations often requires additional tools to visualize and analyze the outcomes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>Figure 2: The display of integrated preprocessed datasets.</figDesc><graphic coords="2,108.00,205.58,190.07,79.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>Figure 3: The display of integrated preprocessed tokenizers.</figDesc><graphic coords="2,108.00,392.42,190.07,79.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc>Figure 6: Automated extraction and display of model computational graphs.</figDesc><graphic coords="3,108.00,404.80,190.08,107.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Code editing, re-integration and validation process.</figDesc><graphic coords="3,108.01,578.46,190.07,107.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><figDesc>Figure 8: Illustration of flowchart-based model design process.</figDesc><graphic coords="4,108.01,191.96,190.06,107.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><figDesc>Figure 9: Illustration of logging and visualization tools.</figDesc><graphic coords="4,313.93,412.77,190.06,107.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>Darkit encapsulates and integrates mainstream large language model architectures (such asGPT Zong  and Krishnamachari [2022],BERT Jawahar et al. [2019], and Llama<ref type="bibr" target="#b1">Touvron et al. [2023]</ref>) through standardized application programming interfaces (APIs), providing a flexible, open, and efficient framework that offers comprehensive support for the learning, research, and development of spiking large language models. Darkit provides an accessible web-based version, which can be accessed via the website http://121.40.226.59:8080/. The platform's frontend is developed using the Svelte framework<ref type="bibr" target="#b7">Bhardwaz and Godha [2023]</ref>, while the backend is built on the FastAPI stackLubanovic  [2023], utilizing asynchronous non-blocking I/O to ensure high performance and stability. Users can also download the source code for local installation from https://github.com/zju-bmi-lab/ DarwinKit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><figDesc>Figure 10: Workflow for uploading and running custom models and parameters.</figDesc><graphic coords="5,108.00,72.00,190.07,107.71" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><surname>Tom B Brown</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Llama 2: Open foundation and fine-tuned chat models</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasmine</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Spikellm: Scaling up spiking neural network to large language models via saliency-based spiking</title>
		<author>
			<persName><forename type="first">Xingrun</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Clifton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shitao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.04752</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Xingrun</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyi</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shitao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Spikelm</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.03287</idno>
		<title level="m">Towards general spike-driven language modeling via elastic bi-spiking mechanisms</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Rui-Jie</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">K</forename><surname>Eshraghian</surname></persName>
		</author>
		<author>
			<persName><surname>Spikegpt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13939</idno>
		<title level="m">Generative pre-trained language model with spiking neural networks</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhaskar</forename><surname>Krishnamachari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.00857</idno>
		<title level="m">A survey on gpt-3</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">What does bert learn about the structure of language?</title>
		<author>
			<persName><forename type="first">Ganesh</forename><surname>Jawahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoît</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Djamé</forename><surname>Seddah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2019-57th Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Svelte. js: The most loved framework today</title>
		<author>
			<persName><forename type="first">Saumyamani</forename><surname>Bhardwaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Godha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 2nd International Conference for Innovation in Technology (INOCON)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Bill</forename><surname>Lubanovic</surname></persName>
		</author>
		<author>
			<persName><surname>Fastapi</surname></persName>
		</author>
		<imprint>
			<publisher>O&apos;Reilly Media, Inc</publisher>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

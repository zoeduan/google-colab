<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multilevel Large Language Models for Everyone</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-07-25">25 Jul 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Yuanhao</forename><surname>Gong</surname></persName>
							<email>gong.ai@qq.com</email>
							<affiliation key="aff0">
								<orgName type="department">College of Electronics and Information Engineering</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multilevel Large Language Models for Everyone</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-07-25">25 Jul 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">B4FB7ADF5878E9A6FE85498CBDEE7AF9</idno>
					<idno type="arXiv">arXiv:2307.13221v1[cs.CV]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>language model</term>
					<term>neural network</term>
					<term>multilevel</term>
					<term>personal LLM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models have made significant progress in the past few years. However, they are either generic or field specific, splitting the community into different groups. In this paper, we unify these large language models into a larger map, where the generic and specific models are linked together and can improve each other, based on the user personal input and information from the internet. The idea of linking several large language models together is inspired by the functionality of human brain. The specific regions on the brain cortex are specific for certain low level functionality. And these regions can jointly work together to achieve more complex high level functionality. Such behavior on human brain cortex sheds the light to design the multilevel large language models that contain global level, field level and user level models. The user level models run on local machines to achieve efficient response and protect the user's privacy. Such multilevel models reduce some redundancy and perform better than the single level models. The proposed multilevel idea can be applied in various applications, such as natural language processing, computer vision tasks, professional assistant, business and healthcare.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Large language models (LLM) are a fascinating result of recent advancements in artificial intelligence technology. These models have the potential to transform communication and writing. With the latest technological advancements, large language models have become more sophisticated in imitating human language. They are trained on enormous amounts of text data, enabling them to produce coherent and relevant text on various topics. This technology has opened up a wide range of usage in fields such as business, education, and healthcare.</p><p>In recent years, several popular large language models have emerged, each with unique qualities designed to cater to different requirements and perform different functions. For instance, GPT-3 generates highly accurate and convincing text, making it suitable for applications such as generating conversational responses or writing articles <ref type="bibr" target="#b0">[1]</ref>. On the other hand, T5 is versatile and can perform a wide range of natural language processing tasks, making it valuable in areas such as translation and question answering <ref type="bibr" target="#b1">[2]</ref>.</p><p>Apart from GPT-3 and T5, BERT is another popular large language model that has made significant contributions to the field of natural language processing <ref type="bibr" target="#b2">[3]</ref>. BERT excels at understanding the context of words and sentences, making it valuable for applications such as search engines and chatbots. By understanding the context of sentences, BERT can provide more accurate and relevant search results, and it helps chatbots to produce more natural and human-like responses.</p><p>Manuscript received April 19, 2005; revised September 17, 2014. user level: personal LLM field level: finance, IT global level: all Global LLM field LLM field LLM user LLM user LLM user1 user2 user3 user4 Fig. 1. Illustration of the proposed multilevel method. The global LLM are large and trained on a cloud. They are trained for the common intelligence. They are retrained (fine tuning) and distilled to get a smaller field specific LLM for different fields, such as medical diagnosis, mathematical education, and C++ programming. These models are further retrained and distilled to get a personal LLM that runs on a local machine to get efficient response and protect users' privacy from the internet attack.</p><p>Despite their differences, all of these models share a common goal: to advance the field of artificial intelligence and push the limits of what machines can do. With the continued development of large language models, we can expect to see even more exciting breakthroughs in artificial intelligence technology in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Why Large Models?</head><p>Large language models have transformed the field of natural language processing, allowing machines to understand and generate human-like language. These models learn from vast amounts of data and store and process more information due to their large number of parameters, enabling them to produce accurate, relevant, and contextually appropriate results. However, it is important to balance the number of parameters to prevent overfitting, which can reduce the model's overall performance. Additionally, training models with many parameters can be time-consuming, slowing down the training process.</p><p>Furthermore, large language models are versatile and can enhance various natural language processing tasks, such as language translation, sentiment analysis, and text summarization. By training on extensive data sets, these models can detect patterns and nuances in language that are difficult for humans to recognize. They are essential tools for applications such as virtual assistants, chatbots, and language understanding systems. Large language models can also generate humanlike text, which has various applications in fields such as journalism, creative writing, and content generation. In conclusion, large language models are a powerful tool that can revolutionize how we interact with machines and generate human-like language, but it is important to balance the number of parameters and the model's performance for optimal results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Limitations</head><p>Large language models have some limitations that need to be addressed. One such limitation is their potential to perpetuate biases present in their training data, which can lead to unfair and discriminatory outcomes. Additionally, these models have high computational and energy requirements, making them expensive to train and operate. Their tendency to generate unreliable or false information, particularly when dealing with complex or sensitive topics, is also problematic. Concerns have also been raised about the potential misuse of large language models for generating disinformation.</p><p>Another concern is the potential threat to privacy posed by large language models. Since these models require large amounts of data to train, they can potentially capture sensitive information. Therefore, it is important to develop privacypreserving models that can ensure users' sensitive information is not compromised.</p><p>Furthermore, the environmental impact of running these models is also a concern. These models require significant amounts of energy to train and operate, leading to a significant carbon footprint. To mitigate this, researchers and developers are actively working to address these limitations and reduce the risks associated with large language models.</p><p>To address these limitations, researchers are developing more robust and diverse datasets for training. This can help reduce bias and enable models to produce more accurate results. Ethical guidelines are being implemented for model development and use to ensure that these models are used responsibly and do not cause harm. Finally, alternative approaches to language processing are being explored, such as using smaller models or leveraging other technologies like knowledge graphs to process language more efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MULTILEVEL LARGE LANGUAGE MODELS</head><p>The development of artificial intelligence has resulted in increasingly complex neural networks with more parameters. This has led to the creation of large language models such as GPT-3 and BERT, which have significantly impacted natural language processing. However, a major challenge associated with these models is their high computational cost. Traditional large language models, like GPT-3 and BERT, require thousands of GPUs for training and deployment. This high cost is a significant obstacle for many researchers and organizations, limiting access to these powerful models.</p><p>Despite this challenge, advancements in hardware and software have made it possible to train and deploy these models on fewer GPUs. This has opened new opportunities for researchers and organizations to explore the capabilities of these models and leverage their potential in various applications.</p><p>Another problem with current LLM is that these models are static. In other words, they can not evolve to achieve higher performance with more and more user input. In fact, millions of users can help to improve the LLM in each specific field, such as poem, medical diagnosis and car design.</p><p>TABLE I SUMMARY MULTILEVEL LLM. LLM # parameters update period inference time global large long long field medium medium medium user small short real-time</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multilevel Models</head><p>To tackle these issues, we propose a multilevel strategy. We propose to decompose the system into three levels: global level, field level and user level. Each level contains different LLM for different purpose. The full map is illustrated in Fig. <ref type="figure">1</ref>. A simple comparison between these levels is shown in Table <ref type="table">I</ref>.</p><p>At the global level, the LLM are trained using all available dataset. As a result, they are good at everything but not excellent at any specific fields. Letting users directly using these models is wasting the computation resource because the performance is just good, not excellent. However, such global LLM can help in improving the field LLM.</p><p>At the field level, the LLM are designed to be excellent in a specific field, such as poem, music, medical knowledge, and finance. These models correspond to the different professional career in human society such as lawyers and doctors. These models are excellent in a specific field in general, but not for any specific person.</p><p>At the user level, the LLM are trained to be an assistant with both personal information and professional advice from some specific field LLM. These models fill the gap between each individual user and the field LLM. Moreover, these models run on local machines to protect the user's privacy.</p><p>1) Global LLM: The global LLM contain a very large parameters and are updated at low frequency. If nothing happens, they will automatically update themselves every week. However, if there are more information from the training data, they will update themselves with a shorter period.</p><p>Meanwhile, these global LLM are not designed to serve users. Instead, they are designed to update the field LLM that have specific domain knowledge and also smaller parameters. Therefore, users' response time is not affected by the long time training and inference processing from the global LLM.</p><p>2) Field LLM: The field LLM are designed to be professional in some field, such as art, music, object tracking, and education. They are automatically updated by the global LLM which receive new knowledge from the user input.</p><p>The field LLM can be considered as a buffer that exchanges information between the global LLM and the user LLM. Their parameter weights are updated by the global LLM. But they extract the information from the user LLM and feed the information into the global LLM.</p><p>3) User LLM: At the user level, user LLM have much less parameters and also the inference time. Different from the global and field LLM, user LLM run on local machine and can contain each user's personal information such as movie and music preferences. Such user LLM can be considered as an excellent assistant who helps the user in planing, shopping, and working.</p><p>More importantly, these models are stored and encrypted on the user's local machine. Ideally, they will not betray the user. The user's privacy is protected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Dynamic Large Language Models</head><p>Be aware that these models can evolve during users' usage. With more and more user input, the local LLM know more about the user's preference. Therefore, the local LLM can evolve to update themselves accordingly. They can also dynamically link themselves to several related field LLM because the user's input is also dynamically changing. Such dynamics affects the whole system, leading to dynamic LLM.</p><p>1) Learning during Using: The multilevel large language models are designed to evolve during its usage. Thus, they are highly dynamic, especially with the user input. They are life-long learning systems, keeping evolving to understand the user from his/her history recording.</p><p>2) Interaction between User and User LLM: There is a direct interaction between users and users' LLM. The user input is dynamic and the user's preference might be also changing with time and experience. Such dynamics requires the user LLM quickly adapt to such change.</p><p>To be adaptive, one way is to change the parameter or architecture in user LLM, based on the received users' input. The other way is to change the user LLM from the interaction with field LLM.</p><p>3) Interaction between User LLM and Field LLM: The user LLM and field LLM have a soft link. And such link can be changed dynamically when the user's preference is changed. For example, if the user's preference is changed from IT to finance, the user LLM will find such change and trigger a require to the field LLM. The field LLM will update the user LLM accordingly.</p><p>If the field LLM are updated, they will also update the user LLM to fresh the new knowledge into the user LLM. Such fresh frequency is medium to balance the model accuracy and the inference running time.</p><p>4) Interaction between Field LLM and Global LLM: The field LLM can be updated by the user LLM and also the global LLM. Meanwhile, the global LLM can be updated by the field LLM that receive new information from the user LLM. The global LLM can be updated if there is new data set available.</p><p>Such interaction happens in a very low frequency because the global LLM are large and should be stable (not so adaptive to an individual user). In contrast, the user LLM are quickly adaptive to each user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. ECONOMICAL ECOSYSTEM</head><p>Our multilevel large language model (MLLM) is an innovative approach to training and deploying the LLM that offers significant benefits to both users and developers. By leveraging advanced computational techniques and sophisticated algorithms, the MLLM achieves unparalleled levels of accuracy and efficiency in natural language processing tasks. This translates to significant cost savings for developers, who can now train and deploy their models more quickly and easily than ever before. Meanwhile, users can enjoy a more seamless and intuitive experience when interacting with language-based applications and services, thanks to the MLLM's ability to understand and interpret natural language in a more nuanced and sophisticated way. With its cutting-edge technology and user-focused design, the MLLM is poised to revolutionize the field of natural language processing and usher in a new era of innovation and discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Users</head><p>Users in the system have two roles. First, users are able to utilize the system's features, and as a result, they are required to pay a fee for the services rendered. The payment allows for continued access to the system and its benefits, including but not limited to increased productivity, streamlined processes, and enhanced data analysis capabilities. Additionally, regular payment ensures that the system can be maintained and further developed to meet the evolving needs of its users. Therefore, it is important to maintain a consistent payment schedule to ensure uninterrupted access to the system and its benefits.</p><p>Second, it is important to acknowledge the critical role that users play in the system. Users are valuable sources of input and integral to the system's success. Without their contributions, the system would lack quality and reliability. To encourage more high-quality contributors, incentivizing users to share their knowledge and expertise is an effective approach. One way to achieve this is by establishing a system of fair compensation for users, recognizing their efforts and contributions. This compensation can come in various forms, including monetary rewards, recognition, or exclusive access to features. By providing fair compensation, the system can attract a larger pool of motivated users who will contribute their best work, resulting in a more robust and reliable platform. Therefore, prioritizing the establishment of a fair compensation system for users is crucial, as it will ultimately benefit the system as a whole and contribute to its long-term success.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Developers</head><p>The developers can work on these three level LLM. They can develop the user LLM that can be more adaptive to each individual user. They can also develop field LLM, to make them more professional. They can work on global LLM to accelerate the model convergence and efficiency.</p><p>The developers also have two roles in this system. First, thanks to the extensive work on their LLM at these three levels, developers can earn money from their LLM. They are well-equipped to capitalize on their expertise and earn a lucrative income from their specialized model. With a deep understanding of the complexities of the field and the latest industry trends, they can confidently navigate the landscape and offer valuable services to a wide range of users.</p><p>Second, they have to pay money for the (valuable) input from users. In order to obtain valuable input from their users, developers may pay a fee. This fee is necessary to ensure that the developer can continue to provide high-quality services and products that meet the needs and expectations of their customers. By compensating users for their input, developers can gain valuable insights that can help them improve existing products or develop new ones that better meet the needs of their target market. Additionally, this feedback can be used to identify areas for improvement in the developer's operations and customer service, which can lead to increased satisfaction and loyalty among existing customers and attract new ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Dynamic Models</head><p>The models in the system are not equal. Some are more important than others and thus have higher service fees. But this is also dynamic, which means that some important models might become important in the future. Therefore, all the price in the models are dynamic, according to their service quality and market demand.</p><p>As a result, both users and developers have the potential to earn an income that is closely tied to the growth and progress of the system. As new technologies and innovations are introduced, users and developers have the opportunity to adapt and evolve LLM in order to stay competitive and continue to earn a sustainable income. This is different from the traditional economical mode for LLM, where the developers have to pay for the training and inference process first and then charge the users with their usage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Blockchains</head><p>From the hardware point of view, implementation of the proposed multilevel large language models is difficult. Each LLM requires a lot of GPUs to train. And there are many LLM in the multilevel large language models. The traditional way to train the system is unrealistic.</p><p>To tackle this issue, we propose to develop MLLM on blockchains, which have high computation performance, are decentralized and run parallel on all nodes. Interestingly, the decentralized mode in blockchains also fits the proposed local machine and server mode in the MLLM.</p><p>Each miner client in the blockchain can be considered as a user in the MLLM. Instead of only contributing the computation to the blockchain, the users also get services from the blockchain in the terms of computation and economy. Therefore the miner client and the blockchain charge each other according to their performance.</p><p>More importantly, the user's input is also considered as valuable resource that can improve the LLM at each level. Such economics is not considered in the traditional blockchains and traditional LLM. This novel idea will trigger the promotion of high quality input in the system and eventually benefit everyone in the ecosystem.</p><p>The system is still under developing and we will release the system in the future to accelerate the related research and practical applications. The economic mode behind MLLM can reduce the barrier for LLM development, making the developing easier and available for everyone.</p><p>Nowadays, the mobile phones and chips become more and more powerful. They are likely the node in the blockchains. And both the users and developers should benefit from such devices and get higher quality services.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION AND DISCUSSION</head><p>In recent times, there has been a significant rise in the usage of large language models. These models are created to comprehend and analyze human language and are becoming increasingly popular in various industries such as natural language processing, sentiment analysis, machine translation, and speech recognition. With the increasing demand for these models, we can expect to see further developments in the field of artificial intelligence and natural language processing. These advancements will undoubtedly impact the way we interact with technology and communicate in the future.</p><p>Although the large language models have made significant progress in natural language processing, there are still some limitations that need to be addressed. One of the most important limitations is the computational power needed to train and run these models. In addition, while these models can generate coherent text, they often struggle with generating text that is both relevant and accurate. Another limitation is the lack of diversity in the training data used to create these models, which can lead to bias and inaccuracies in the generated text. Therefore, it is essential to continue exploring ways to improve these models, such as incorporating more diverse and representative training data and developing more powerful computational resources to train and run these models.</p><p>In this paper, we have introduced multilevel large language models that address some of the challenges posed by previous large language models. Specifically, our models incorporate innovative strategies for handling long-term dependencies, improving computational efficiency, and enhancing the accuracy of predictions. Overall, our work represents a significant step forward in the development of large language models and lays the groundwork for future research in this area.</p><p>The multilevel approach seeks to balance accuracy and running time. It is based on the concept that complex problems can be broken down into smaller, simpler sub-problems to achieve accurate results. By solving these sub-problems, the overall accuracy of the solution can be improved. However, creating too many sub-problems can increase the running time. The multilevel approach suggests that a balance can be struck by dividing the problem into an optimal number of sub-problems. This allows for the maintenance of accuracy while keeping the running time within acceptable limits. The multilevel approach has gained popularity in various fields, such as computer science, mathematics, and engineering. It has been successfully applied to problems such as image processing, signal analysis, and optimization. Overall, the multilevel approach is a promising strategy that can improve the accuracy of complex problem solutions while keeping the running time practical.</p><p>Our approach is a novel step forward in the development of next generation large language models. The multilevel methods also show a novel economic model for developing large language models. They can be adopted in various applications such as audio, vision and machine learning tasks <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>,</p></div>		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr" target="#b39">[40]</ref><p>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Language models are fewshot learners</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2005.14165" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2005">2005.14165. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020-01">jan 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Objective comparison of particle tracking methods</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chenouard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Smal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De Chaumont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Sbalzarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cardinale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Carthel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Coraluppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Godinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rohr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kalaidzidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E G</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jalden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Blau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Paul-Gilloteaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Roudot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kervrann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Waharte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Tinevez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Shorte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Willemse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Celler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Van Wezel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-W</forename><surname>Dan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ortiz De Solorzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Olivo-Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Meijering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="U247" />
			<date type="published" when="2014-03">March 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Symmetry detection for multi-object using local polar coordinate</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">5702</biblScope>
			<biblScope unit="page">277</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BART: denoising sequence-tosequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1910.13461" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="1910">1910.13461. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A survey of large language models</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Coupled signed-distance functions for implicit surface reconstruction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Sbalzarini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intl. Symp. Biomed. Imaging (ISBI)</title>
		<imprint>
			<date type="published" when="2012-05">May 2012</date>
			<biblScope unit="page" from="1000" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Local weighted Gaussian curvature for image processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Sbalzarini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. Image Proc. (ICIP)</title>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
			<biblScope unit="page" from="534" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Single image interpolation exploiting semilocal similarity</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Orchard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="1722" to="1726" />
			<pubPlace>Brighton, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image enhancement by gradient distribution specification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Sbalzarini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop &quot;Emerging Topics in Image Enhancement and Restoration</title>
		<meeting>Workshop &quot;Emerging Topics in Image Enhancement and Restoration<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-11">Nov 2014</date>
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
	<note>12th Asian Conference on Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Side window filtering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8750" to="8758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Spectrally regularized surfaces</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<idno type="DOI">10.3929/ethz-a-010438292</idno>
		<ptr target="http://dx.doi.org/10.3929/ethz-a-010438292" />
		<imprint>
			<date type="published" when="2015">22616. 2015</date>
			<publisher>ETH Zurich</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast and highquality blind multi-spectral image pansharpening</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Boufounos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A natural-scene gradient distribution prior and its application in light-microscopy image processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sbalzarini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="114" />
			<date type="published" when="2016-02">Feb 2016</date>
		</imprint>
	</monogr>
	<note>Selected Topics in Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey on blockchain technology and its security</title>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S2096720922000070" />
	</analytic>
	<monogr>
		<title level="j">Blockchain: Research and Applications</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">100067</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Curvature filters efficiently reduce certain variational energies</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Sbalzarini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1786" to="1798" />
			<date type="published" when="2017-04">April 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Motion saliency based multi-stream multiplier resnets for action recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S0262885621000135" />
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page">104108</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bernstein filter: A new solver for mean curvature regularized models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2016-03">March 2016</date>
			<biblScope unit="page" from="1701" to="1705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Blockchain-based cross-domain authorization system for user-centric resource sharing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ezawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kakei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shiraishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Morii</surname></persName>
		</author>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S2096720923000015" />
	</analytic>
	<monogr>
		<title level="j">Blockchain: Research and Applications</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">100126</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Linear approximation of mean curvature</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="570" to="574" />
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Real-time optimizing weighted gaussian curvature for 4k videos</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 31st International Workshop on Machine Learning for Signal Processing</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sub-window box filter</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visual Communications and Image Processing</title>
		<meeting>IEEE Visual Communications and Image essing</meeting>
		<imprint>
			<date type="published" when="2018-12">Dec. 2018</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Image filtering with generic geometric prior</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">330</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Blind multi-spectral image pan-sharpening</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Boufounos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2020 -2020 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1429" to="1433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Weighted mean curvature</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Goksel</surname></persName>
		</author>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0165168419302282" />
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="page" from="329" to="339" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">What do large language models learn about scripts</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sancheti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rudinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Computing gaussian curvature in real-time for 4k video processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">944</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Structure adaptive filtering for edge-preserving image smoothing</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
		<editor>Image and Graphics, Y. Peng, S.-M. Hu, M. Gabbouj, K. Zhou, M. Elad, and K. Xu</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="265" to="276" />
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Soft tissue removal in x-ray images by half window dark channel prior</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Processing (ICIP)</title>
		<meeting>IEEE Int. Conf. Image essing (ICIP)</meeting>
		<imprint>
			<date type="published" when="2019-09">Sep. 2019</date>
			<biblScope unit="page" from="3576" to="3580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Side window guided filtering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal Process</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page" from="315" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Computing curvature, mean curvature and weighted mean curvature</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="266" to="270" />
			<pubPlace>Bordeaux, France</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fast and efficient implementation of image filtering using a side window convolutional neural network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page">107717</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Molecular surface estimation by geometric coupled distance functions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="176" to="263" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A high performance concurrency protocol for smart contracts of permissioned blockchain</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="5070" to="5083" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Quarter laplacian filter for edge aware image processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Processing</title>
		<meeting>IEEE Int. Conf. Image essing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1959" to="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Curvature-based real-time brightness adjustment for ultra hd video</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE 24th International Workshop on Multimedia Signal Processing</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A discrete scheme for computing image&apos;s weighted gaussian curvature</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1919" to="1923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A novel structure adaptive algorithm for feature-preserving 3d mesh denoising</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE 24th International Workshop on Multimedia Signal Processing</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Gc-net: An unsupervised network for gaussian curvature optimization on images</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11265-022-01800-4</idno>
		<ptr target="https://doi.org/10.1007/s11265-022-01800-4" />
	</analytic>
	<monogr>
		<title level="j">Journal of Signal Processing Systems</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="88" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Feature preserving 3d mesh denoising with a dense local graph neural network</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">233</biblScope>
			<biblScope unit="page">103710</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Regression-based camera pose estimation through multi-level local features and global features</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poslad</surname></persName>
		</author>
		<ptr target="https://www.mdpi.com/1424-8220/23/8/4063" />
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Dynamic neural networks: A survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="7436" to="7456" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Training language models with language feedback at scale</title>
		<author>
			<persName><forename type="first">J</forename><surname>Scheurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Korbak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-03">Mar. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Llama-adapter: Efficient fine-tuning of language models with zero-init attention</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<idno>abs/2303.16199</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

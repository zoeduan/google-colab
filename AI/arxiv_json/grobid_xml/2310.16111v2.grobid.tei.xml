<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Locally Differentially Private Document Generation Using Zero Shot Prompting</title>
				<funder ref="#_6xpdjje">
					<orgName type="full">Document level Pure-LDP Yes Yes DP Prompt (Ours) Document level Pure-LDP</orgName>
				</funder>
				<funder ref="#_gtNgz5V">
					<orgName type="full">Sentence level Pure-DP Yes No Paraphraser</orgName>
				</funder>
				<funder ref="#_s4QYGjM #_Wnf2xbB">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Saiteja</forename><surname>Utpala</surname></persName>
							<email>saitejautpala@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Cohere For AI</orgName>
								<orgName type="institution" key="instit2">IBM Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sara</forename><surname>Hooker</surname></persName>
							<email>sarahooker@cohere.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Cohere For AI</orgName>
								<orgName type="institution" key="instit2">IBM Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Cohere For AI</orgName>
								<orgName type="institution" key="instit2">IBM Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Locally Differentially Private Document Generation Using Zero Shot Prompting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">14C66F2A778EA6BF8026B6F294CEBAAB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Numerous studies have highlighted the privacy risks associated with pretrained large language models. In contrast, our research offers a unique perspective by demonstrating that pretrained large language models can effectively contribute to privacy preservation. We propose a locally differentially private mechanism called DP-Prompt, which leverages the power of pretrained large language models and zero-shot prompting to counter author de-anonymization attacks while minimizing the impact on downstream utility. When DP-Prompt is used with a powerful language model like ChatGPT (gpt-3.5), we observe a notable reduction in the success rate of deanonymization attacks, showing that it surpasses existing approaches by a considerable margin despite its simpler design. For instance, in the case of the IMDB dataset, DP-Prompt (with ChatGPT) perfectly recovers the clean sentiment F1 score while achieving a 46% reduction in author identification F1 score against static attackers and a 26% reduction against adaptive attackers. We conduct extensive experiments across six open-source large language models, ranging up to 7 billion parameters, to analyze various effects of the privacyutility tradeoff. Code is avaliable at <ref type="url" target="https://github.com/SaitejaUtpala/dp_prompt">https:  //github.com/SaitejaUtpala/dp_prompt</ref> Mechanism Privacy Level Requires fine-tuning Generates sanitized doc Madlib (Feyisetan et al., 2020) Word level Metric-DP No Yes Mahanolbis (Xu et al., 2020) Word level Metric-DP No Yes TEM (Carvalho et al.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The vast amount of online text data has the potential to reveal numerous user attributes, making individuals easily identifiable <ref type="bibr" target="#b54">(Rao et al., 2000;</ref><ref type="bibr" target="#b26">Hovy et al., 2015;</ref><ref type="bibr" target="#b50">Preoţiuc-Pietro et al., 2015)</ref>. While private information can be directly disclosed through specific phrases in the text, it can also be implicitly inferred. For instance, linguistic patterns embedded within the text can inadvertently facilitate authorship attribution <ref type="bibr" target="#b34">(Kešelj et al., 2003;</ref><ref type="bibr" target="#b58">Shrestha et al., 2017)</ref>, leading to unintended privacy leakage.</p><p>An illustrative real-world scenario is the AOL search data leak in August 2006 <ref type="bibr">(Pass et al.</ref>, 2006). The incident unfolded when AOL mistakenly released detailed search logs of their users, wrongly assuming that the data had been adequately anonymized through the use of random user IDs. Unfortunately, the released logs contained sufficient personally identifiable information, leading to the identification of numerous individuals <ref type="bibr" target="#b6">(Barbaro and Jr., 2006;</ref><ref type="bibr" target="#b31">Jones et al., 2007)</ref>. This breach of privacy triggered widespread public outcry and led to the initiation of class action lawsuits.</p><p>This case is just one among many that highlights the limitations of ad-hoc privacy approaches that may give the impression of providing privacy but ultimately fall short. Differential privacy (DP) provides a rigorous treatment for the notion of data privacy by providing plausible deniability by precisely quantifying the deviation in the model's output distribution under modification of a small number of data points <ref type="bibr" target="#b21">(Dwork et al., 2006</ref><ref type="bibr" target="#b22">(Dwork et al., , 2014))</ref>. The provable guarantees offered by DP, coupled with its compelling properties such as immunity to arbi- Figure <ref type="figure">2</ref>: Overview of the privacy-utility tradeoff with DP-Prompt (using ChatGPT) for the IMDB and Yelp datasets, conducted at a temperature of 1.5. The terms 'Static' and 'Adaptive' refer to the attack models defined in Definition 2. trary post-processing and graceful composability, have established it as the de facto standard for privacy. DP has witnessed widespread adoption and numerous deployments in both private <ref type="bibr" target="#b23">(Erlingsson et al., 2014;</ref><ref type="bibr" target="#b4">Apple, 2017;</ref><ref type="bibr" target="#b45">Near, 2018)</ref> and public organizations <ref type="bibr" target="#b0">(Abowd, 2018)</ref>.</p><p>To address the issue of deanonymization attacks, various approaches have been proposed within the DP framework. These approaches encompass word-level strategies <ref type="bibr">(Feyisetan et al., 2020;</ref><ref type="bibr" target="#b67">Xu et al., 2020;</ref><ref type="bibr" target="#b13">Carvalho et al., 2021)</ref> where noise is added at the word level, as well as sentence-level techniques <ref type="bibr" target="#b44">(Meehan et al., 2022)</ref> where noise is added at the sentence level. However, recent research by <ref type="bibr">(Mattern et al., 2022b)</ref> has identified limitations in word-level approaches, particularly their disregard for contextual information. To overcome these limitations, Mattern introduced a mechanism that fine-tunes the GPT-2 model <ref type="bibr" target="#b52">(Radford et al., 2019)</ref> specifically for paraphrasing tasks, resulting in the generation of sanitized versions of documents. While promising, the approach is limited by their reliance on annotated paraphrasing data, extensive computing resources for larger models, and the quality of annotations.</p><p>We propose DP-Prompt, a novel and straightforward solution to address deanonymization attacks. Our method leverages pretrained large language models by directly prompting them to generate paraphrases. These paraphrases are then released as sanitized documents in a zero-shot manner (See Figure <ref type="figure" target="#fig_0">1</ref>). Our motivation for this approach stems from two important factors. Firstly, recent research <ref type="bibr" target="#b7">(Bevendorff et al., 2019;</ref><ref type="bibr">Mattern et al., 2022b)</ref> has shown that paraphrasing is a robust defense mechanism against deanonymization attacks. Secondly, growing evidence suggests that pretrained large language models can effectively tackle complex tasks without the need for task-specific and expensive fine-tuning <ref type="bibr" target="#b10">(Brown et al., 2020;</ref><ref type="bibr" target="#b16">Chowdhery et al., 2022;</ref><ref type="bibr" target="#b16">Chung et al., 2022;</ref><ref type="bibr" target="#b35">Kojima et al., 2022;</ref><ref type="bibr" target="#b46">OpenAI, 2023)</ref>, through zero-shot prompting.</p><p>By harnessing the capabilities of pretrained large language models, DP-Prompt offers a straightforward and powerful solution to mitigate the risk of deanonymization. It provides a promising alternative that can be widely applicable, particularly in the context of on-device large language models where text completion tasks require significantly fewer resources. We summarize the contributions as follows:</p><p>• We propose DP-Prompt, a new, simple, and computationally effective differentially private (DP) mechanism designed as a defense against de-anonymization attacks. DP-Prompt takes a private document and generates a paraphrased version using zero-shot prompting.</p><p>The resulting paraphrased document is then released as a sanitized document, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>• We demonstrate that DP-Prompt, in combination with ChatGPT (gpt-3.5), surpasses all current methods in terms of utility for any level of privacy. Our approach successfully recovers clean sentiment F1 score while significantly reducing the accuracy of author deanonymization attacks. Refer to Figure <ref type="figure">2</ref> for an overview of these results.</p><p>• To demonstrate the broad applicability of DPprompt, We conduct extensive experiments with 6 open source models ranging upto 7 billion parameters to study the privacy-utiliy tradeoff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>A mechanism M : D → V achieves ϵ-PureDP if, for all inputs D, D ′ ∈ D that differ in one element, and for all <ref type="bibr">et al., 2006)</ref>.  <ref type="bibr">et al., 2013;</ref><ref type="bibr" target="#b14">Chatzikokolakis et al., 2013</ref>) is a relaxation of Pure-DP that applies to data represented in a general metric space. For a given distance metric d :</p><formula xml:id="formula_0">V ⊆ Range(M), Pr [M(D) ∈ V ] ≤ exp (ϵ)Pr [M(D ′ ) ∈ V ] (Dwork</formula><formula xml:id="formula_1">D × D → R + , a mechanism M : D → V achieves ϵd-MetricDP if, for any D, D ′ ∈ D and for all V ⊆ Range(M), Pr [M(D) ∈ V ] ≤ exp (d(D, D ′ ))Pr [M(D ′ ) ∈ V ].</formula><p>Local differential privacy (LDP) <ref type="bibr" target="#b32">(Kasiviswanathan et al., 2011;</ref><ref type="bibr" target="#b20">Duchi et al., 2013;</ref><ref type="bibr" target="#b66">Xiong et al., 2020)</ref> is a privacy framework where data is locally perturbed before transmission, considering the presence of an untrusted data collector or server. The formal definition of LDP is as follows: Definition 1 (PureLDP). A randomized mechanism M : D → V is said to be ϵ-PureLDP if for any pair of inputs D, D ′ ∈ D and for all V ⊆ Range(M)</p><formula xml:id="formula_2">Pr[M(D) ∈ V ] ≤ exp (ϵ)Pr[M(D ′ ) ∈ V ].</formula><p>There is a growing consensus that, despite the assurance of formal guarantees, it is imperative to subject differentially private mechanisms to robust privacy attacks that simulate strong and malicious adversaries <ref type="bibr" target="#b28">(Jayaraman and Evans, 2019;</ref><ref type="bibr" target="#b9">Blanco-Justicia et al., 2022)</ref>. Such evaluation allows to effectively assess the empirical privacy provided by the mechanism in real-world scenario. To this end we define four attack models depending its adaptivity and mode of access. Definition 2 (Attack Models). Consider a collection of private documents (D 1 , . . . , D n ) from distribution D with associated author identities (a 1 , . . . , a n ) and embeddings (E 1 , . . . , E n ) ∼ E.</p><p>For text-to-text sanitization using mechanism M text , the sanitized documents are represented as (P 1 , .</p><p>. . , P n ) ∼ P Mtext . For text-to-embedding sanitization via mechanism M embedding , the sanitized embeddings are denoted as (N 1 , . . . , N n ) ∼ N M embedding • Static Attacker with Embedding Access: Has access to clean documents (D 1 , . . . , D n ) but lacks access to sanitized versions (P 1 , . . . , P n ). • Static Attacker with Text Access : Doesn't have access to sanitized embeddings (N 1 , . . . , N n ) but only to the clean embeddings (E 1 , . . . , E n ). • Adaptive Attacker with Embedding Access : Has access to sanitized embeddings (N 1 , . . . , N n ). Hence, trains a deanonymization model to adapt to the DP mechanism M embedding . • Adaptive Attacker with Text Access: Has access to sanitized text (P 1 , . . . , P n ). Consequently, trains a de-anonymization model to adapt to the DP mechanism M text .</p><p>It is important to note that the adaptive attacker is a more formidable adversary since it adapts to the characteristics of the mechanism M, whereas the static attacker only has access to clean documents/clean embeddings without any added noise. The mode of access-either raw text or abstracted embeddings-offers further nuances, determining the exact nature of the data an attacker can exploit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DP Prompt</head><p>Language models use a decoder network to generate sequential text output. Given a context or prompt represented by a sequence of tokens C = (c 1 , . . . , c m ), the language model generates text by sampling tokens from a conditional distribution Pr |C (x 1 , . . . , x n ) = n i=1 Pr |C (x i |x 1 , . . . , x i-1 ). In this distribution, the logits u ∈ R |V| are transformed using the softmax function with a temperature T , where</p><formula xml:id="formula_3">p ij = exp( u ij T ) |V| j=1 exp( u ij T )</formula><p>, and V represents the vocabulary. This process of sequentially generating text can be regarded as a problem of selecting tokens at each step. Hence, to make the generation step differentially private, one must replace it with a differentially private version of the selection process. One commonly used and well-known differentially private mechanism is the exponential mechanism <ref type="bibr" target="#b43">(McSherry and Talwar, 2007)</ref>, which is defined as follows:</p><formula xml:id="formula_4">Definition 3 (Exponential Mechanism). Given an utility function u : D × V → V. The ex- ponential mechanism M Exp : D → V is a randomized algorithm with output distribution P M Exp (D) = v ∝ exp ϵu(D,v) 2∆u , where ∆u = max D,D ′ ,v |u(D, v) -u(D ′ , v)| is sensitivity.</formula><p>In our case, the utility of token v j ∈ V at each step i is simply the logit u ij ∈ R. Hence, one can make text generation differentially private using the exponential mechanism.</p><p>Extensive research has shown that paraphrasing documents helps conceal author identity <ref type="bibr" target="#b54">(Rao et al., 2000;</ref><ref type="bibr" target="#b7">Bevendorff et al., 2019;</ref><ref type="bibr">Mattern et al., 2022b)</ref>. Considering recent advancements where tasks are formulated as prompts and language models are tasked to complete them <ref type="bibr" target="#b53">(Raffel et al., 2020;</ref><ref type="bibr" target="#b10">Brown et al., 2020;</ref><ref type="bibr" target="#b63">Wei et al., 2022)</ref>, we directly prompt the language model to generate paraphrases. Therefore, given a private document D and a specific prompt template instructing the language model to generate a paraphrase, such as T := "Paraphrase of the document:" we combine D and T to create a context C. By utilizing this context, we execute the text generation procedure in a differentially private manner to produce a paraphrase. We refer to this procedure as DP-Prompt. Algorithm 1 outlines the specific steps of our pro- </p><formula xml:id="formula_5">1 P ← [], C ← GeneratePrompt(D, T) 2 Ctokens ← Tokenize(C) 3 for i ← 1 to n do 4 u ← LM(Ctokens) 5 u ′ ← ClipAndScale(u, b, T ) 6 p ← ConvertToProbabilities(u ′ ) 7 v ← SampleToken(p) 8 P ← P ∪ [v], Ctokens ← Ctokens ∪ [v]</formula><p>9 end 10 P ← Detokenize(P) return P posed DP-Prompt, and the code for implementing DP-Prompt in HuggingFace <ref type="bibr" target="#b65">(Wolf et al., 2019)</ref> is provided in Appendix B. The formal guarantee of achieving ϵ-PureLDP is provided by the following theorem:</p><p>Theorem 1. Suppose the language model has not been pretrained on the private documents distribution D. If the final logits u ∈ R |V| satisfy the condition b 1 ≤ u i ≤ b 2 , ∀i, and the DP-Prompt run with a temperature T for generating n tokens, then it can be proven that the generated output satisfies (2n(b 2 -b 1 )/T )-LDP.</p><p>See the Appendix A for the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setup</head><p>Evaluation: Note that we are comparing DPmechanisms with different levels of differential privacy. Therefore, in our experiments, we focus on evaluating the empirical privacy rather than the theoretical privacy(ϵ) for effective and realistic as-</p><p>0.0 0.2 0.4 0.6 0.8 Author Identification F1 Score (Privacy) 0.3 0.4 0.5 0.6 0.7 0.8 Sentiment F1 Score (Utility) 46% Reduction Clean Random Madlib Mahalanobis TEM Truncated-Laplace Deep-Candidate Paraphraser(gpt2-xl) DP-Prompt(ChatGPT) (a) IMDB (static) 0.2 0.4 0.6 0.8 Author Identification F1 Score (Privacy) 0.50 0.55 0.60 0.65 0.70 0.75 0.80 Sentiment F1 Score (Utility) 25% Reduction Clean Random Madlib Mahalanobis TEM Truncated-Laplace Deep-Candidate Paraphraser(gpt2-xl) DP-Prompt(ChatGPT) (b) IMDB (adaptive) 0.0 0.2 0.4 0.6 0.8 Author Identification F1 Score (Privacy) 0.50 0.55 0.60 0.65 0.70 0.75 0.80 Sentiment F1 Score (Utility) 53% Reduction Clean Random Madlib Mahalanobis TEM Truncated-Laplace Deep-Candidate Paraphraser(gpt2-xl) DP-Prompt(ChatGPT) (c) Yelp (static) 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Author Identification F1 Score (Privacy) 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 Sentiment F1 Score (Utility) 29% Reduction Clean Random Madlib Mahalanobis TEM Truncated-Laplace Deep-Candidate Paraphraser(gpt2-xl) DP-Prompt(ChatGPT) (d) Yelp (adaptive) 0.0 0.2 0.4 0.6 0.8 1.0 Author Identification F1 Score (Privacy) 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 Sentiment F1 Score (Utility) 54% Reduction Clean Random Madlib Mahalanobis TEM Paraphraser(gpt2-xl) DP-Prompt(ChatGPT) (e) IMDB (static) 0.2 0.4 0.6 0.8 1.0 Author Identification F1 Score (Privacy) 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 Sentiment F1 Score (Utility) 10% Reduction Clean Random Madlib Mahalanobis TEM Paraphraser(gpt2-xl) DP-Prompt(ChatGPT) (f) IMDB (adaptive) 0.0 0.2 0.4 0.6 0.8 1.0 Author Identification F1 Score (Privacy) 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 Sentiment F1 Score (Utility) 73% Reduction Clean Random Madlib Mahalanobis TEM Paraphraser(gpt2-xl) DP-Prompt(ChatGPT) (g) Yelp (static) 0.0 0.2 0.4 0.6 0.8 1.0 Author Identification F1 Score (Privacy) 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 Sentiment F1 Score (Utility) 24% Reduction Clean Random Madlib Mahalanobis TEM Paraphraser(gpt2-xl) DP-Prompt(ChatGPT) (h) Yelp (adaptive) Figure 4: Comparison of DP-Prompt (with ChatGPT) with various baselines. The top row shows results for an attacker with embedding access, while the row below presents results for an attacker with text access. Notably, it is evident that regardless of the chosen privacy level, DP-Prompt, when utilized with ChatGPT (GPT-3.5), exhibits significantly better utility compared to all baseline mechanisms.</p><p>sessment. As a result, we plot the author identification F1 score, which is calculated by conducting de-anonymization attacks on the sanitized documents. This score indicates the potential for privacy breaches. On the other hand, the y-axis represents the sentiment F1 score, which measures the utility of the sanitized documents. Datasets: We conduct experiments using IMDB movie reviews and Yelp business reviews, both of which contain author and sentiment labels. The IMDB dataset has a size of 15,000, while the Yelp dataset has 17,336 samples. For both datasets, sentiment analysis is a 2-class classification task, and the author identification task is a 10-class classification task. Implementation Details: For the embedding-level attacker, we utilize 3-Layer MLPs with ReLU activation functions and train them on sentence embeddings <ref type="bibr" target="#b55">(Reimers and Gurevych, 2019)</ref>. For the textlevel attacker, we fine-tune BERT <ref type="bibr" target="#b19">(Devlin et al., 2018)</ref>. More details can be found in Appendix C. Regarding the static attacker, the clean set of documents is used for training and validation, while the sanitized documents serve as the test set. On the other hand, for the adaptive attacker, all three sets (training, validation, and testing) consist of sanitized documents.</p><p>• For each of word level mechanisms, <ref type="bibr">(Madlib (Feyisetan et al., 2020)</ref>, Mahalanobis <ref type="bibr" target="#b67">(Xu et al., 2020)</ref> For DP-Prompt we run ChatGPT at temperatures {1.0, 1.25, 1.5, 1.75, 2.0}.</p><p>Further we also consider F1 scores on Clean (without noise added) embeddings/documents and performance of uniformly random classifier (for more details, refer to Appendix C.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">DP-prompt with ChatGPT (gpt-3.5)</head><p>In this section we compare 6 baselines (Madlib, Mahalanobis, Tem, Truncated-laplace, Deepcandidate, Paraphraser) run with configurations above (for more details also refer to Appendix C) with DP-Prompt with ChatGPT. Except for DP-Prompt, we run each mechanism to 3 times to produce 3 different sanitized documents and plot mean author F1 identification score on x-axis and show 2σ band around mean sentiment F1 score. Results are show in Figure <ref type="figure">4</ref> The results clearly demonstrate the superior performance of DP-Prompt with ChatGPT (GPT-3.5).</p><p>0.2 0.4 0.6 0.8 Author Identification F1 Score (Privacy) 0.3 0.4 0.5 0.6 0.7 0.8 Sentiment F1 Score (Utility) Clean Random T5(3b) Flan-T5(3b) Stablelm-Base(7b) Stablelm-Base(3b) Stablelm-Tuned(3b) Stablelm-Tuned(7b) ChatGPT(gpt.3.5) (a) IMDB (static) 0.2 0.4 0.6 0.8 Author Identification F1 Score (Privacy) 0.50 0.55 0.60 0.65 0.70 0.75 0.80 Sentiment F1 Score (Utility) Clean Random T5(3b) Flan-T5(3b) Stablelm-Base(7b) Stablelm-Base(3b) Stablelm-Tuned(3b) Stablelm-Tuned(7b) ChatGPT(gpt.3.5) (b) IMDB (adaptive) 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Author Identification F1 Score (Privacy) 0.50 0.55 0.60 0.65 0.70 0.75 0.80 Sentiment F1 Score (Utility) Clean Random T5(3b) Flan-T5(3b) Stablelm-Base(7b) Stablelm-Base(3b) Stablelm-Tuned(3b) Stablelm-Tuned(7b) ChatGPT(gpt.3.5) (c) Yelp (static) 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Author Identification F1 Score (Privacy) 0.50 0.55 0.60 0.65 0.70 0.75 0.80 Sentiment F1 Score (Utility) Clean Random T5(3b) Flan-T5(3b) Stablelm-Base(7b) Stablelm-Base(3b) Stablelm-Tuned(3b) Stablelm-Tuned(7b) ChatGPT(gpt.3.5) (d) Yelp (adaptive) 0.0 0.2 0.4 0.6 0.8 1.0 Author Identification F1 Score (Privacy) 0.5 0.6 0.7 0.8 Sentiment F1 Score (Utility) Clean Random T5(3b) Flan-T5(3b) Stablelm-Base(7b) Stablelm-Base(3b) Stablelm-Tuned(3b) Stablelm-Tuned(7b) ChatGPT(gpt.3.5) (e) IMDB (static) 0.0 0.2 0.4 0.6 0.8 1.0 Author Identification F1 Score (Privacy) 0.5 0.6 0.7 0.8 Sentiment F1 Score (Utility) Clean Random T5(3b) Flan-T5(3b) Stablelm-Base(7b) Stablelm-Base(3b) Stablelm-Tuned(3b) Stablelm-Tuned(7b) ChatGPT(gpt.3.5) (f) IMDB (adaptive) 0.2 0.4 0.6 0.8 1.0 Author Identification F1 Score (Privacy) 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 Sentiment F1 Score (Utility) Clean Random T5(3b) Flan-T5(3b) Stablelm-Base(7b) Stablelm-Base(3b) Stablelm-Tuned(3b) Stablelm-Tuned(7b) ChatGPT(gpt.3.5) (g) Yelp (static) 0.0 0.2 0.4 0.6 0.8 1.0 Author Identification F1 Score (Privacy) 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 Sentiment F1 Score (Utility) Clean Random T5(3b) Flan-T5(3b) Stablelm-Base(7b) Stablelm-Base(3b) Stablelm-Tuned(3b) Stablelm-Tuned(7b) ChatGPT(gpt.3.5) (h) Yelp (adaptive) Notably, DP-Prompt exhibits significantly higher utility on the y-axis for a chosen empirical privacy value on the x-axis. All word-level mechanisms show a similar privacy-utility tradeoff. Regarding sentence-level mechanisms, the truncated Laplace mechanism performs decently, while in the static attack experiments, Deep-candidate is reduced to a random classifier due to the distribution shift caused by sentence recoding. Furthermore, in the case of clean reviews (i.e., without any noise), the embedding-level attacker can accurately identify the author among 10 different options with a high F1 score of 0.93 in IMDB and 0.86 in Yelp. However, when DP-Prompt is employed, the sentiment F1 scores remain unchanged, while the author identification scores decrease by 46% and 25% in the case of IMDB, and 53% and 29% in the case of Yelp.</p><p>The text-level models are more accurate than the embedding-level models, with author identification scores of 0.99 (as opposed to 0.93) and 0.97 (as opposed to 0.86) in IMDB and Yelp, respectively, for clean reviews. When DP-Prompt is employed, the sentiment F1 scores remain unchanged, while the author identification scores decrease by 54% and 10% in the case of IMDB, and 73% and 24% in the case of Yelp. This illustrates that text-level attackers are more powerful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">DP-Prompt with open source models</head><p>It is important to note that models such as ChatGPT (gpt-3.5) are proprietary and can only be accessed through APIs, necessitating the uploading of user documents to the language model provider. Although DP-Prompt with such proprietary models provide LDP guarantee, this defeats the fundamental motivation of LDP, which is to achieve privacy guarantees without relying on a trusted data curator. The objective of the experiments presented in the preceding section aim to demonstrate that DP-Prompt, when combined with a powerful language model like ChatGPT, can outperform existing methods by a significant margin.</p><p>Considering the increasing interest in building high-quality open-source large language models <ref type="bibr" target="#b56">(Scao et al., 2022;</ref><ref type="bibr" target="#b8">Black et al., 2022;</ref><ref type="bibr">Touvron et al., 2023;</ref><ref type="bibr" target="#b39">Li et al., 2023;</ref><ref type="bibr" target="#b29">Jiang et al., 2023)</ref>, we expand our evaluation of DP-Prompt to include six opensource models, ranging in size up to seven billion parameters. Our evaluation takes into account two factors: (i) architecture, where we consider both encoder-decoder and decoder-only models, and (ii) the level of fine-tuning, including models that are fine-tuned using instructions and/or Reinforcement Learning with Human Feedback (RLHF). Specifically 6 models are as follows, Base: T5 (3b), Stable lm base (3b, 7b),Instruction finetuned/RLHF tuned: Flan T5 (3b), Stable lm tuned (3b,7b). While T5, Flan T5 are encoder-decoder models, rest of the models are decoder-only. In contrast to DP-Prompt with ChatGPT, we perform DP-Prompt using the aforementioned open source language models three times for each dataset and temperature, resulting in three sanitized documents. Fur-</p><p>Data IMDB Yelp Metric Sentiment F1 score Author Identification F1 Score Sentiment F1 score Author Identification F1 Score clipping 0.75 1.0 1.25 1.5 1.75 0.75 1.0 1.25 1.5 1.75 0.75 1.0 1.25 1.5 1.75 0.75 1.0 1.25 1.5 1.75 Flan-t5 (3b) Static Attacker Yes 0.74 0.67 0.56 0.45 0.38 0.26 0.21 0.13 0.07 0.05 0.69 0.62 0.58 0.54 0.48 0.21 0.17 0.12 0.09 0.07 No 0.75 (+0.01) 0.69 (+0.02) 0.58 (+0.02) 0.46 (+0.01) 0.40 (+0.02) 0.31 (+0.05) 0.24 (+0.03) 0.14 (+0.01) 0.08 (+0.01) 0.05 (+0.00) 0.69 (+0.00) 0.64 (+0.02) 0.58 (+0.00) 0.54 (+0.00) 0.49 (+0.01) 0.25 (+0.04) 0.20 (+0.03) 0.13 (+0.01) 0.09 (+0.00) 0.07 (+0.00) Adaptive Attacker Yes 0.72 0.66 0.58 0.52 0.51 0.34 0.25 0.16 0.13 0.11 0.67 0.59 0.54 0.52 0.49 0.25 0.20 0.14 0.11 0.10 No 0.73 (+0.01) 0.67 (+0.01) 0.58 (+0.00) 0.53 (+0.01) 0.52 (+0.01) 0.38 (+0.04) 0.28 (+0.03) 0.19 (+0.03) 0.13 (+0.00) 0.11 (+0.00) 0.67 (0.00) 0.60 (+0.01) 0.55 (+0.01) 0.52 (+0.00) 0.49 +0.00) 0.29 (+0.04) 0.22 (+0.02) 0.15 (+0.01) 0.11 (+0.01) 0.10 Stablelm Tuned (7b) Static Attacker Yes 0.67 0.63 0.53 0.38 0.34 0.33 0.29 0.12 0.05 0.03 0.66 0.62 0.55 0.49 0.48 0.28 0.22 0.10 0.08 0.07 No 0.68 (+0.01) 0.66 (+0.03) 0.59 (+0.06) 0.45 (+0.07) 0.36 (+0.02) 0.37 (+0.04) 0.31 (+0.02) 0.18 (+0.06) 0.07 (+0.02) 0.05 (+0.02) 0.68 (+0.02) 0.65 (+0.03) 0.59 (+0.04) 0.50 (+0.01) 0.49 (+0.01) 0.26 (-0.02) 0.21 (-0.01) 0.13 (+0.03) 0.08 (+0.00) 0.07 (+0.00) Adaptive Attacker Yes 0.65 0.60 0.54 0.51 0.50 0.45 0.37 0.22 0.14 0.12 0.63 0.57 0.50 0.49 0.48 0.36 0.28 0.17 0.13 0.10 No 0.71 (+0.06) 0.67 (+0.07) 0.59 (+0.05) 0.53 (+0.02) 0.51 (0.01) 0.53 (+0.08) 0.46 (+0.09) 0.30 (+0.02) 0.17 (+0.03) 0.14 (+0.02) 0.66 (+0.03) 0.64 (+0.07) 0.55 (+0.05) 0.51 (+0.02) 0.49 (0.01) 0.41 (+0.05) 0.35 (+0.07) 0.22 (+0.05) 0.14 (+0.01) 0.12 (+0.02)</p><p>Table 2: Effect of clipping (shown as Yes) and without clipping (shown as No) on privacy-utility tradeoff.</p><p>ther we all run these open source models at half precision (torch.float16) and with max number of tokens in paraphrase to 150. The obtained results are presented in Figure <ref type="figure" target="#fig_5">5</ref>.</p><p>Now we compare open source models along various factors Base vs Instruction/RLHF tuned: It is evident that the base models perform poorly in comparison to the models that underwent instruction finetuning/RLHF tuning. One important point to mention is that both StableLM-Based (3b, 7b) perform significantly worse against adaptive attackers. Scale: We observe that scale plays a key role, as StableLM-tuned (7b) demonstrates better utility than StableLM-Tuned (3b) across all levels of empirical privacy, with ChatGPT outperforming both. Variance: It is worth noting that we did not obtain variance for DP-Prompt with ChatGPT in Figure <ref type="figure">4</ref> through multiple runs. However, our analysis in Figure <ref type="figure" target="#fig_5">5</ref> suggests that there is no significant variance in the Sentiment F1 score, at least for open source models. Encoder-Decoder / Decoder only: Flan-T5(3b), an encoder-decoder model, outperforms the larger Stablelm-Tuned (7b) model. Notably, Flan-T5(3b) is fine-tuned exclusively on academic datasets, resulting in shorter paraphrases compared to Stablelm-Tuned (7b). ChatGPT vs Rest: While the open-source models we considered demonstrate competitiveness with ChatGPT, a notable gap remains. The key finding is that even at a higher temperature of 1.5, Chat-GPT is capable of recovering a clean sentiment F1 score, while none of the open-source models can achieve a matching clean sentiment F1 score, even at a significantly lower temperature of 0.75. See Figure <ref type="figure">7</ref>, which presents the paraphrases output by ChatGPT and Stablelm-Tuned (7B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Effect of clipping logits</head><p>In both sections (Section 4.2 and Section 4.3) DP-Prompt is run without logit clipping. This is primar-ily because ChatGPT doesn't expose logits, and for a fair comparison with ChatGPT, we didn't clip logits for open-source models in Section 4.3. However, the LDP guarantee still holds because, in practice, logits are always bounded within a certain precision, even though they may have large values.</p><p>In this section, we examine the impact of logit clipping on the tradeoff between privacy and utility using FlanT5(3b) and Stablelm Tuned(7b) models against embedding-level attacks. We adopt the approach of <ref type="bibr" target="#b37">(Li and Clifton, 2021)</ref> by learning the clipping boundaries on additional data (more details can be found in Appendix C). The results of this analysis are presented in Table <ref type="table">2</ref>. The maximum difference observed with and without clipping occurs for Stablelm-Tuned(7b) on the IMDB dataset at a temperature of 0.75. In this case, the sentiment F1 score drops from 0.71 to 0.65, and the author identification F1 score drops from 0.53 to 0.45. Based on these findings, we recommend using logit clipping when higher privacy is required and not using clipping when higher utility is desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Effect of Top-K sampling</head><p>For the differential privacy guarantee to hold, sampling from probabilities must be done over the entire vocabulary according to score probabilities. While it is common to use top-k sampling in practice to improve generation (the default value in Hugging Face <ref type="bibr" target="#b65">(Wolf et al., 2019</ref>) is 40). It is important to note that the ChatGPT chat completion API does not include a top-k parameter. In this section, using open-source models, we examine the impact of top-k sampling on utility and investigate whether it provides any empirical privacy, even in the absence of the differential privacy guarantee. In addition, we aim to assess whether top-k sampling can effectively help open source models to recover the clean sentiment F1-score and narrow the gap compared to DP-Prompt when used with ChatGPT.</p><p>We consider Flan-T5(3b) and Stablelm-</p><p>Data IMDB Yelp Metric Sentiment F1 score Author Identification F1 Score Sentiment F1 score Author Identification F1 Score top_k 0.75 1.0 1.25 1.5 1.75 0.75 1.0 1.25 1.5 1.75 0.75 1.0 1.25 1.5 1.75 0.75 1.0 1.25 1.5 1.75 Flan-t5 Static Attacker all 0.75 0.69 0.58 0.46 0.40 0.31 0.24 0.14 0.08 0.05 0.69 0.64 0.58 0.51 0.49 0.25 0.20 0.13 0.09 0.07 80 0.75 (+0.0) 0.72 (+0.03) 0.70 (+0.12) 0.69 (+0.23) 0.66 (+0.26) 0.31 (+0.0) 0.27 (+0.03) 0.23 (+0.09) 0.22 (+0.14) 0.21 (+0.16) 0.71 (+0.02) 0.69 (+0.05) 0.68 (+0.10) 0.64 (+0.13) 0.64 (+0.15) 0.25 (+0.00) 0.20 (+0.00) 0.19 (+0.06) 0.19 (+0.10) 0.17 (+0.10) 40 0.75 (+0.00) 0.74 (+0.05) 0.72 (+0.24) 0.69 (+0.23) 0.67 (+0.27) 0.32 (+0.0) 0.29 (+0.05) 0.26 (+0.12) 0.25 (+0.17) 0.23 (+0.18) 0.71 (+0.02) 0.69 (+0.05) 0.68 (+0.10) 0.64 (+0.13) 0.64 (+0.15) 0.25 (+0.00) 0.22 (+0.02) 0.20 (+0.07) 0.19 (+0.10) 0.17 (+0.10) Adaptive Attacker all 0.73 0.67 0.58 0.53 0.52 0.38 0.28 0.19 0.12 0.11 0.66 0.60 0.55 0.52 0.49 0.29 0.22 0.15 0.11 0.10 80 0.76 (+0.03) 0.70 (+0.03) 0.69 (+0.11) 0.66 (+0.13) 0.65 (+0.13) 0.39 (+0.01) 0.33 (+0.05) 0.29 (+0.10) 0.27 (+0.15) 0.26 (+0.15) 0.67 (+0.01) 0.66 (+0.06) 0.62 (+0.07) 0.60 (+0.08) 0.60 (+0.11) 0.31 (+0.02) 0.24 (+0.02) 0.23 (+0.08) 0.20 (+0.09) 0.20 (+0.10) 40 0.75 (+0.02) 0.72 (+0.05) 0.70 (+0.12) 0.67 (+0.14) 0.67 (+0.15) 0.41 (+0.02) 0.36 (+0.08) 0.33 (+0.14) 0.31 (+0.19) 0.29 (+0.18) 0.69 (+0.02) 0.66 (+0.06) 0.65 (+0.10) 0.63 (+0.11) 0.61 (+0.12) 0.31 (+0.02) 0.26 (+0.04) 0.24 (+0.09) 0.23 (+0.12) 0.23 (+0.13) Stablelm Tuned (7b) Static Attacker all 0.68 0.66 0.59 0.45 0.36 0.37 0.31 0.18 0.07 0.05 0.68 0.65 0.59 0.50 0.49 0.24 0.20 0.13 0.08 0.07 80 0.69 (+0.01) 0.67 (+0.01) 0.66 (+0.07) 0.62 (+0.17) 0.62 (+0.26) 0.37 (+0.00) 0.34 (+0.03) 0.28 (+0.10) 0.27 (+0.20) 0.24 (+0.l9) 0.69 (+0.01) 0.66 (+0.01) 0.65 (+0.06) 0.62 (+0.12) 0.59 (+0.10) 0.24 (+0.00) 0.22 (+0.02) 0.19 (+0.06) 0.16 (+0.08) 0.16 (+0.09) 40 0.69 (+0.01) 0.67 (+0.01) 0.66 (+0.07) 0.64 (+0.19) 0.64 (+0.28) 0.38 (+0.01) 0.34 (+0.03) 0.30 (+0.12) 0.27 (+0.20) 0.27 (+0.22) 0.69 (+0.01) 0.69 (+0.04) 0.61 (+0.02) 0.65 (+0.15) 0.65 (+0.16) 0.25 (+0.01) 0.22 (+0.02) 0.20 (+0.07) 0.19 (+0.11) 0.18 (+0.11) Adaptive Attacker all 0.70 0.67 0.59 0.53 0.51 0.53 0.46 0.30 0.17 0.14 0.66 0.64 0.55 0.51 0.49 0.41 0.35 0.22 0.14 0.12 80 0.70 (+0.00) 0.68 (+0.01) 0.67 (+0.08) 0.64 (+0.11) 0.63 (+0.12) 0.53 (+0.00) 0.49 (+0.03) 0.44 (+0.14) 0.40 (+0.23) 0.35 (+0.21) 0.69 (+0.03) 0.66 (+0.02) 0.64 (+0.09) 0.59 (+0.08) 0.60 (+0.11) 0.41 (+0.00) 0.38 (+0.03) 0.32 (+0.10) 0.29 (+0.15) 0.27 (+0.15) 40 0.70 (+0.00) 0.69 (+0.02) 0.67 (+0.08) 0.64 (+0.11) 0.63 (+0.12) 0.53 (+0.00) 0.49 (+0.03) 0.45 (+0.15) 0.42 (+0.25) 0.39 (+0.25) 0.69 (+0.03) 0.67 (+0.03) 0.64 (+0.09) 0.60 (+0.09) 0.62 (+0.13) 0.42 (+0.01) 0.37 (+0.02) 0.34 (+0.12) 0.32 (+0.18) 0.29 (+0.17)</p><p>Table <ref type="table">3</ref>: The effect of top-k sampling on privacy-utility tradeoff on Flan-T5(3b) and Stablelm-Tuned(7B) models Tuned(7B) models and perform decoding with top-k sampling for k = {40, 80}. The results against embedding level attacks, including no top-k sampling, are shown in Table <ref type="table">3</ref>. The maximum difference observed with and without clipping occurs for Stablelm-Tuned(0.75) on the IMDB dataset at a temperature of 0.7 for k = 40. In this case, the sentiment F1 score increases from 0.32 to 0.64, and the author identification F1 score increases from 0.05 to 0.27. Additionally, top-k sampling does not improve utility at a temperature of 0.75, indicating that DP-Prompt with opensource models, even with top-k sampling, does not match DP-Prompt with ChatGPT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Issue of Data Memorization</head><p>It is important to acknowledge the possibility that ChatGPT and other open-source language models (LLMs) may have been exposed to online review datasets such as IMDB and Yelp. This exposure is not unique to our approach. Similar questions can be raised for word-level approaches <ref type="bibr">(Feyisetan et al., 2020;</ref><ref type="bibr" target="#b67">Xu et al., 2020;</ref><ref type="bibr" target="#b13">Carvalho et al., 2021)</ref> and sentence-level approaches <ref type="bibr" target="#b44">(Meehan et al., 2022)</ref> since GloVe embeddings <ref type="bibr" target="#b48">(Pennington et al., 2014)</ref> and Sentence Transformers (BERT) <ref type="bibr" target="#b55">(Reimers and Gurevych, 2019)</ref> are pretrained on the Common Crawl dataset. Hence assumption in Theorem 1 may not hold. We argue that this exposure does not pose a major concern for DP-Prompt due to the following reasons. No availability of paraphrases of IMDB, Yelp: DP-Prompt essentially evaluates the performance of LLMs in the task of zero-shot paraphrasing at higher temperatures. Although the language models may have been fine-tuned using open annotated paraphrase datasets <ref type="bibr" target="#b69">(Zhang et al., 2019)</ref>, it's important to note that there is no specific annotated paraphrasing data available for the IMDB and Yelp datasets. Therefore, the language models used in DP-Prompt are not explicitly fine-tuned for paraphrasing tasks related to these datasets. Consequently, the results obtained in Section 4 are likely to generalize to a large extent. Robustness of Evaluation Setup: Our evaluation methodology goes beyond relying solely on the Sentiment F1 score (Utility) or even comparing sentiment F1 score (Utility) with ϵ (theoretical privacy) as presented in <ref type="bibr" target="#b44">(Meehan et al., 2022)</ref>. Instead, we adopt a comprehensive approach that considers the merit of our proposed approach based on the sentiment F1 score in conjunction with empirical privacy demonstration against de-anonymization attacks. Simply copying reviews verbatim would yield a high author identification F1 score, failing to provide empirical privacy. Additionally, we consider not only static attack models but also stronger ones like adaptive attackers. Superficially altering reviews may deceive static attackers but would likely fail against adaptive attackers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>The previous work on releasing private documents can be categorized into three approaches based on the level at which noise is added (See Table <ref type="table" target="#tab_0">1</ref> for concise summary). These approaches are: Word-level Approaches: MadLib (Feyisetan et al., 2020) is a word-level mechanism that applies Laplace noise to word embeddings and maps them to the nearest word in the vocabulary, demonstrating the differential privacy (DP) guarantee of MadLib under the Euclidean metric. An extension of this approach involves using a regularized Mahalanobis metric instead <ref type="bibr" target="#b67">(Xu et al., 2020)</ref>. In contrast, the TEM mechanism utilizes the exponential mechanism to transform the privatization step into a selection problem <ref type="bibr" target="#b13">(Carvalho et al., 2021)</ref>. Furthermore, there is a recent development known as Cus-Text <ref type="bibr" target="#b15">(Chen et al., 2023)</ref>, which focuses on developing customized mapping mechanisms for each individual word in the vocabulary <ref type="bibr" target="#b15">(Chen et al., 2023)</ref>. All of these approaches are word-level mechanisms and have been shown to have significant limitations, such as their disregard for contextual information <ref type="bibr">(Mattern et al., 2022b)</ref>. Sentence-level Approaches: Sentence-level mechanisms based on Sentence Transformer <ref type="bibr" target="#b55">(Reimers and Gurevych, 2019)</ref> were introduced in <ref type="bibr" target="#b44">(Meehan et al., 2022)</ref>. They proposed two approaches: one approach where noise is added to sentence embeddings, and another more complicated approach based on maximizing Tukey depth <ref type="bibr" target="#b61">(Tukey, 1975;</ref><ref type="bibr" target="#b25">Gilad-Bachrach and Burges, 2012)</ref>. Document-level Approaches: A document-level Local Differential Privacy (LDP) mechanism was introduced, where GPT-2 is fine-tuned for a paraphrasing task <ref type="bibr">(Mattern et al., 2022b)</ref>. Our approach, DP-Prompt, draws inspiration from their work, but instead of resource-intensive fine-tuning, we use a zero-shot approach with pretrained models for efficient and effective generation of sanitized documents. Furthermore, the recently proposed DP-BART <ref type="bibr" target="#b27">(Igamberdiev and Habernal, 2023)</ref> employs BART <ref type="bibr" target="#b36">(Lewis et al., 2020)</ref>, an encoder-decoder model. In DP-BART, noise is added to the encoder's output, and the decoder is fine-tuned to adapt to this noisy encoder output. Adversarial Methods: Parallel to differentially private approaches, other techniques have been proposed that utilize Adversarial Learning <ref type="bibr" target="#b57">(Shetty et al., 2018;</ref><ref type="bibr" target="#b51">Quiring et al., 2019)</ref> and Data Poisoning <ref type="bibr" target="#b62">(Wang et al., 2022;</ref><ref type="bibr" target="#b30">Jin et al., 2020)</ref>. However, these methods typically require access to a surrogate classifier. In contrast, our method is zero-shot, requiring neither fine-tuning nor access to a classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Differentially Private Training/Fine Tuning:</head><p>There is extensive research on differentially private training or fine-tuning of language models <ref type="bibr" target="#b33">(Kerrigan et al., 2020;</ref><ref type="bibr">Li et al., 2021;</ref><ref type="bibr" target="#b68">Yu et al., 2021;</ref><ref type="bibr" target="#b3">Anil et al., 2022;</ref><ref type="bibr">Mattern et al., 2022a)</ref>. They aim to make language models resistant to various kinds of data leakage attacks <ref type="bibr" target="#b11">(Carlini et al., 2019</ref><ref type="bibr" target="#b12">(Carlini et al., , 2021;;</ref><ref type="bibr" target="#b18">Deng et al., 2021;</ref><ref type="bibr" target="#b5">Balunovic et al., 2022)</ref>. It is important to emphasize that this line of work is completely distinct from our own, as it focuses on training language models on private data, while our goal is to generate sanitized documents from private documents using pretrained language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper introduces DP-Prompt, a locally differentially mechanism called DP-Prompt that generates sanitized versions of private documents by prompting large language models to generate paraphrases. Notably, our method offers a simpler approach compared to existing methods. Through extensive experiments, we show that our approach achieves significantly improved utility compared to current methods for any required level of privacy. As the demand for on-device large language models (LLMs) continues to grow, our method emerges as a reliable safeguard for users' privacy and provides robust defense against de-anonymization attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Limitations</head><p>In our study, we explored the initial step of harnessing large language models and zero-shot prompting to generate sanitized documents. While this approach effectively conceals the specific writing style of authors, there is still a potential risk of revealing explicit personal information, such as zip codes, bank details, or gender, especially when naively prompting a language model. This risk is particularly relevant in alternative text formats like messages or emails compared to online reviews.</p><p>For future work, an important direction would be to define a set of sensitive attributes and directly prompt the language model to replace these attributes with the identifier "X" while generating paraphrases. This approach would help improve the safeguarding of personal information. Additionally, it would be worthwhile to investigate the potential side effects of hallucination and the impact of different prompt templates on the generation of paraphrases, specifically within the context of the privacy-utility tradeoff. Additionally, more robust attacks that measure privacy leakage at the text level should be explored.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of the proposed DP-Prompt mechanism. Given a private document (D), DP-Prompt generates a sanitized document (P) while ensuring local differential privacy. The level of privacy guarantee is controlled by adjusting the sampling temperature (T) during the decoding process.</figDesc><graphic coords="1,306.14,212.60,218.25,173.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>of DP-Prompt (with ChatGPT) (d) Yelp (text acccess)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Sample illustration of clean and sanitized documents for various mechanisms. For ChatGPT, prompt is "Review:[review]Paraphrase of the Review:" where review is the clean review.</figDesc><graphic coords="4,123.02,70.87,349.22,140.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 1 :</head><label>1</label><figDesc>DP-PromptInput: language model (LM), private document (D), prompt template (T), clipping vector b ∈ R |V| , temperature T ∈ R+, paraphrase tokens n. Output: Sanitized Doc (P)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>, TEM<ref type="bibr" target="#b13">(Carvalho et al., 2021)</ref>) we run the mechanisms for 8 ϵ's given ϵ ={2, 5, 8, 11, 14, 17, 20, 25} • For each of sentence level mechanisms (Truncated-Laplace (Meehan et al., 2022), Deep-Candidate (Meehan et al., 2022)): we run the mechanisms for 11 ϵ's given by ϵ ={5, 10, 20, 30, 40, 50, 75, 100, 150, 200}.• For Paraphraser(Mattern et al., 2022b)   and DP-Prompt with open source models we run decoding at 5 temperatures {0.75, 1.0, 1.25, 1.5, 1.75}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Illustration of privacy-utility tradeoff in DP-Prompt with open source models and ChatGPT(gpt-3.5). The top row shows results for an attacker with embedding access, while the row below presents results for an attacker with text access.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>We compare our proposed method, DP-Prompt, with related work on various factors. The "Privacy level" indicates the privacy guarantee provided by each mechanism. "Fine-tuning" denotes whether the mechanism involves fine-tuning a model as an intermediate step. The last column, "Generates sanitized doc," indicates whether the mechanism can output a fully sanitized document instead of just sanitized embeddings.</figDesc><table><row><cell>Metric Differential Privacy (Metric-DP) (Andrés</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>, <rs type="grantNumber">2021</rs>)</p><p>Word level Metric-DP No Yes Truncated Laplace <ref type="bibr" target="#b44">(Meehan et al., 2022)</ref> Sentence level <rs type="projectName">Pure-DP No No Deep Candidate (Meehan et al</rs>., 2022) <rs type="funder">Sentence level Pure-DP Yes No Paraphraser</rs> (<rs type="projectName">Mattern et al</rs>., 2022b) <rs type="funder">Document level Pure-LDP Yes Yes DP Prompt (Ours) Document level Pure-LDP</rs> No Yes</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_s4QYGjM">
					<idno type="grant-number">2021</idno>
				</org>
				<org type="funded-project" xml:id="_Wnf2xbB">
					<orgName type="project" subtype="full">Metric-DP No Yes Truncated Laplace (Meehan et al</orgName>
				</org>
				<org type="funded-project" xml:id="_gtNgz5V">
					<orgName type="project" subtype="full">Pure-DP No No Deep Candidate (Meehan et al</orgName>
				</org>
				<org type="funded-project" xml:id="_6xpdjje">
					<orgName type="project" subtype="full">Mattern et al</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proof of Privacy</head><p>Theorem 2. Suppose the language model has not been pretrained on the private documents distribution D. If the logits u ∈ R |V| before the final softmax layer satisfy the condition b 1 ≤ u i ≤ b 2 , ∀i ∈</p><p>[|V|], and the DP-Prompt run with a temperature T for generating n tokens, then it can be proven that the generated output satisfies (n(b 2 -b 1 )/T )-LDP.</p><p>Proof. Let D and D ′ be any two documents, and u and u ′ ∈ R |V| be their corresponding logits. Let v ∈ V, and k be its index, with u k being its corresponding logit. We then have that,</p><p>Now by using sequential composition law of DP <ref type="bibr" target="#b21">(Dwork et al., 2006)</ref>, we can set ϵ = (2n(b 2 -b 1 )/T ) to conclude the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Code</head><p>In this section, we showcase the code for DP-Prompt implemented using the Hugging Face library <ref type="bibr" target="#b65">(Wolf et al., 2019)</ref>. The code can be found in Listing 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Implementation Details and Additional Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Word-Level Mechanisms</head><p>For all word-level mechanisms, we utilize 50dimensional glove embeddings <ref type="bibr" target="#b48">(Pennington et al., 2014)</ref>, following the approach of Mattern et al. <ref type="bibr">(Mattern et al., 2022b)</ref>. The projection step, which requires approximate nearest neighbor search, is performed using an Annoy indexer with 500 trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Sentence-Level Mechanisms</head><p>Both the Truncated-Laplace and Deep-Candidate mechanisms require additional publicly available data. In the case of Truncated-Laplace, this data is used to determine truncated boundaries, while for Deep-Candidate, it is used to train the sentence recoder and obtain the output. We randomly sample 5,000 documents from both the IMDB and Yelp reviews, which are not part of the data used for privacy-utility experiments.</p><p>The sentence recoder architecture is trained with three layers of MLP, incorporating dropout and selecting the best model. We choose 50 clusters for sentence recoding and employ 100 random projections to estimate the approximate Tukey depth.</p><p>Sentence embeddings <ref type="bibr" target="#b55">(Reimers and Gurevych, 2019)</ref> of dimension 768 are obtained from <ref type="bibr" target="#b59">(Song et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Document-Level Mechanisms</head><p>For the paraphrasing mechanism, we fine-tune the gpt2-xl(1.5b) parameter model on the PAWS dataset <ref type="bibr" target="#b69">(Zhang et al., 2019)</ref>. The training set is constructed by combining the train and val sets, and the test set is used for validation to save the best model. The training set consists of 25,368 examples, and the validation set consists of 3,536 examples. We follow the procedure outlined in <ref type="bibr">(Mattern et al., 2022b)</ref>, which builds upon (Witteveen and Andrews, 2019).</p><p>To set clip thresholds in Section 4.4, we employ a process similar to Truncated-Laplace <ref type="bibr" target="#b44">(Meehan et al., 2022)</ref> with a slight difference. While <ref type="bibr" target="#b44">(Meehan et al., 2022)</ref> calculates the 75% quantile and utilizes it as the clipping threshold, we calculate the minimum and maximum values.Both Truncated-Laplace and Dp-Prompt employ the exact same additional data. The resulting min and max clip threshold vector is then used to clip the logits before scaling them by temperature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Static and Adaptive Attacker Architecture</head><p>Word level and document level output documents, to simulate embedding-level attacker we employ sentence transformer all-mpnet-base-v2 <ref type="bibr" target="#b55">(Reimers and Gurevych, 2019;</ref><ref type="bibr" target="#b59">Song et al., 2020)</ref> to convert sanitized document to sanitized embedding. For sentence level, directly sanitized embeddings are used. The embedding-level attackers employ a three-layer MLP with a hidden dimension of 768. We use the ReLU activation function and incorporate dropout of 0.5. The models are trained for 50 epochs with a batch size of 32, using the Adam optimizer with a StepLR learning scheduler. The initial learning rate is set to 10 -3 , and the gamma value is 0.95. The text-level attackers use bert-base-cased and fine-tune it for 3 epochs with a batch size of 16, using the AdamW optimizer with a linear scheduler and a starting learning rate of 5 × 10 -5 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Code and Reproducibility</head><p>The code will be publicly released. Considering the reproducibility challenges associated with closed APIs <ref type="bibr" target="#b49">(Pozzobon et al., 2023)</ref>, we also plan to release the paraphrased documents that were generated using ChatGPT.</p><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.6 Expected F1 score of random classifier</head><p>Let p i represent the fraction of documents with label y i , where i ranges from 0 to ℓ -1. A uniformly random classifier predicts class y i with a probability of 1/ℓ. Based on this setup, we can derive the following metrics:</p><p>From these metrics, we can calculate the F1 Score for sentiment analysis, which is a binary classification task, as follows:</p><p>For author identification, which is a multi-class classification task, we utilize the F1 Score with a macro average. In the case of a random classifier, the expected F1 score can be calculated as:</p><p>BERT Score IMDB Yelp t=1.0 t=1.25 t=1.5 t=1.75 t=2.0 t=1.0 t=1.25 t=1.5 t=1.75 t=2.0 Chat GPT 0.882 0.879 0.863 0.805 0.765 0.89 0.887 0.876 0.83 0.777 </p><p>By employing this approach, we can effectively evaluate the performance of a random classifier for author identification in terms of the F1 Score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Comparing 50 and 300-Dimensional</head><p>Glove Embeddings for Word-Level Mechanism</p><p>Note that in Section 4.2, we used 50-dimensional Glove embeddings (glove-wiki-gigaword-50) <ref type="bibr" target="#b48">(Pennington et al., 2014)</ref> for Madlib, Mahalanobis, and TEM mechanisms. In this section, we demonstrate that there is no significant benefit to using 300-dimensional glove embeddings (glove-wiki-gigaword-300). We show this for IMDB dataset against embedding-level attackers. Results are show in Figure <ref type="figure">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 BERT score for paraphrasing models</head><p>We use BERTScore, which has been demonstrated to correlate with human judgments, in conjunction with the RoBerta model <ref type="bibr" target="#b40">(Liu et al., 2019)</ref> (roberta-large) to assess the similarity between a review and its paraphrase. The results for Chat-GPT are presented in Table <ref type="table">4</ref>, while those for the open-source model can be found in Table <ref type="table">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Sample Illustration of paraphrases</head><p>In this section, we present a comparison of paraphrases generated from ChatGPT and Stablelm at various temperatures, as illustrated in Figure <ref type="figure">7</ref>. It is evident from the results that ChatGPT produces higher-quality paraphrases compared to Stablelm-Tuned (7B). </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The US census bureau adopts differential privacy</title>
		<author>
			<persName><surname>John M Abowd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2867" to="2867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Nicolás</forename><forename type="middle">E</forename><surname>Miguel E Andrés</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Bordenabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catuscia</forename><surname>Chatzikokolakis</surname></persName>
		</author>
		<author>
			<persName><surname>Palamidessi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Differential privacy for location-based systems</title>
		<author>
			<persName><forename type="first">Geo-Indistinguishability</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM SIGSAC conference on Computer &amp; communications security</title>
		<meeting>the 2013 ACM SIGSAC conference on Computer &amp; communications security</meeting>
		<imprint>
			<biblScope unit="page" from="901" to="914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Large-scale differentially private bert</title>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Badih</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pasin</forename><surname>Manurangsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6481" to="6491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning with privacy at scale</title>
		<author>
			<persName><surname>Apple</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Apple Machine Learning Journal</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Lamp: Extracting text from gradients with language model priors</title>
		<author>
			<persName><forename type="first">Mislav</forename><surname>Balunovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitar</forename><surname>Iliev Dimitrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikola</forename><surname>Jovanović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Vechev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A face is exposed for aol searcher no. 4417749</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Barbaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Zeller</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New York Times</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Heuristic authorship obfuscation</title>
		<author>
			<persName><forename type="first">Janek</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1098" to="1108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hallahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connor</forename><surname>Leahy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.06745</idno>
		<title level="m">Gpt-neox-20b: An open-source autoregressive language model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A critical review on the use (and misuse) of differential privacy in machine learning</title>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Blanco-Justicia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Domingo-Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnamurty</forename><surname>Muralidhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The secret sharer: Evaluating and testing unintended memorization in neural networks</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Úlfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jernej</forename><surname>Kos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">267</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Extracting training data from large language models</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Silva Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodore</forename><surname>Vasiloudis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oluwaseyi</forename><surname>Feyisetan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.07928</idno>
		<title level="m">Tem: high utility metric differential privacy on text</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Broadening the scope of differential privacy using metrics</title>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Chatzikokolakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><forename type="middle">E</forename><surname>Andrés</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolás</forename><surname>Emilio Bordenabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catuscia</forename><surname>Palamidessi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Privacy Enhancing Technologies: 13th International Symposium</title>
		<meeting><address><addrLine>Bloomington, IN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013-07-10">2013. July 10-12, 2013</date>
			<biblScope unit="volume">2013</biblScope>
			<biblScope unit="page" from="82" to="102" />
		</imprint>
	</monogr>
	<note>PETS</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A customized text sanitization mechanism with differential privacy</title>
		<author>
			<persName><forename type="first">Sai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengran</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="5747" to="5758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<title level="m">Palm: Scaling language modeling with pathways</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Chung</forename><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11416</idno>
		<title level="m">Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tag: Gradient attack on transformerbased language models</title>
		<author>
			<persName><forename type="first">Jieren</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanguthevar</forename><surname>Rajasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiwen</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3600" to="3610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Local privacy and statistical minimax rates</title>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>John C Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">J</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE 54th Annual Symposium on Foundations of Computer Science</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="429" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kobbi</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006-03-04">2006. March 4-7, 2006</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="265" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The algorithmic foundations of differential privacy</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="211" to="407" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rappor: Randomized aggregatable privacypreserving ordinal response</title>
		<author>
			<persName><forename type="first">Úlfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasyl</forename><surname>Pihur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Korolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2014 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1054" to="1067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Privacy-and utility-preserving textual analysis via calibrated multivariate perturbations</title>
		<author>
			<persName><forename type="first">Borja</forename><surname>Oluwaseyi Feyisetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Drake</surname></persName>
		</author>
		<author>
			<persName><surname>Diethe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The median hypothesis</title>
		<author>
			<persName><forename type="first">Ran</forename><surname>Gilad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<idno>MSR-TR- 2012-56</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">User review sites as a resource for large-scale sociolinguistic studies</title>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Johannsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on World Wide Web</title>
		<meeting>the 24th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">DP-BART for privatized text rewriting under local differential privacy</title>
		<author>
			<persName><forename type="first">Timour</forename><surname>Igamberdiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Habernal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<meeting><address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="13914" to="13934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Evaluating differentially private machine learning in practice</title>
		<author>
			<persName><forename type="first">Bargav</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Albert Q Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianna</forename><surname>Bressand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><surname>Saulnier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.06825</idno>
		<title level="m">Mistral 7b</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Is bert really robust? a strong baseline for natural language attack on text classification and entailment</title>
		<author>
			<persName><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8018" to="8025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">I know what you did last summer: query logs and user privacy</title>
		<author>
			<persName><forename type="first">Rosie</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixteenth ACM conference on Conference on information and knowledge management</title>
		<meeting>the sixteenth ACM conference on Conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="909" to="914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Shiva</forename><surname>Prasad Kasiviswanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Homin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kobbi</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sofya</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Raskhodnikova</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
		<title level="m">What can we learn privately? SIAM Journal on Computing</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="793" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Differentially private language models benefit from public pre-training</title>
		<author>
			<persName><forename type="first">Gavin</forename><surname>Kerrigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Slack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Tuyls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Privacy in NLP</title>
		<meeting>the Second Workshop on Privacy in NLP</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="39" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">N-gram-based author profiles for authorship attribution</title>
		<author>
			<persName><forename type="first">Vlado</forename><surname>Kešelj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuchun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Cercone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference pacific association for computational linguistics</title>
		<meeting>the conference pacific association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="255" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Bart</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Differentially private imaging via latent space manipulation</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Clifton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.05472</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Large language models can be strong differentially private learners</title>
		<author>
			<persName><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Allie Del Giorno, Suriya Gunasekar, and Yin Tat Lee</title>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronen</forename><surname>Eldan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.05463</idno>
	</analytic>
	<monogr>
		<title level="m">Textbooks are all you need ii: phi-1.5 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">2022a. Differentially private language models for secure data sharing</title>
		<author>
			<persName><forename type="first">Zhijing</forename><surname>Justus Mattern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Weggenmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mrinmaya</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><surname>Sachan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="4860" to="4873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">2022b. The limits of word level differential privacy</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Justus Mattern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Weggenmann</surname></persName>
		</author>
		<author>
			<persName><surname>Kerschbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: NAACL 2022</title>
		<imprint>
			<biblScope unit="page" from="867" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Mechanism design via differential privacy</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">48th Annual IEEE Symposium on Foundations of Computer Science (FOCS&apos;07)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="94" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sentence-level privacy for document embeddings</title>
		<author>
			<persName><forename type="first">Casey</forename><surname>Meehan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalil</forename><surname>Mrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3367" to="3380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Differential privacy at scale: Uber and Berkeley collaboration</title>
		<author>
			<persName><forename type="first">Joe</forename><surname>Near</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Enigma 2018</title>
		<meeting><address><addrLine>Enigma</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<title level="m">Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A picture of search</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Pass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdur</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cayley</forename><surname>Torgeson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st international conference on Scalable information systems</title>
		<meeting>the 1st international conference on Scalable information systems</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">On the challenges of using blackbox apis for toxicity evaluation in research</title>
		<author>
			<persName><forename type="first">Luiza</forename><surname>Pozzobon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beyza</forename><surname>Ermis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Hooker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.12397</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An analysis of the user occupational class through twitter content</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Preoţiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasileios</forename><surname>Lampos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1754" to="1764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Misleading authorship attribution of source code using adversarial learning</title>
		<author>
			<persName><forename type="first">Erwin</forename><surname>Quiring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alwin</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konrad</forename><surname>Rieck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th USENIX Security Symposium (USENIX Security 19)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="479" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Exploring limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5485" to="5551" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Can pseudonymity really guarantee privacy?</title>
		<author>
			<persName><forename type="first">Pankaj</forename><surname>Josyula R Rao</surname></persName>
		</author>
		<author>
			<persName><surname>Rohatgi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="85" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzana</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ilić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Castagné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><surname>Gallé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05100</idno>
		<title level="m">Bloom: A 176bparameter open-access multilingual language model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">{A4NT}: Author attribute anonymity by adversarial training of neural machine translation</title>
		<author>
			<persName><forename type="first">Rakshith</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th USENIX Security Symposium (USENIX Security 18)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1633" to="1650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for authorship attribution of short texts</title>
		<author>
			<persName><forename type="first">Prasha</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Sierra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><forename type="middle">A</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thamar</forename><surname>Solorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th conference of the European chapter of the association for computational linguistics</title>
		<meeting>the 15th conference of the European chapter of the association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="669" to="674" />
		</imprint>
	</monogr>
	<note>short papers</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Mpnet: Masked and permuted pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="16857" to="16867" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971</idno>
		<title level="m">Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Mathematics and the picturing of data</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Congress of Mathematicians</title>
		<meeting>the International Congress of Mathematicians<address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1975">1975. 1975</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="523" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">Ziyao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thai</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongwon</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09717</idno>
		<title level="m">Upton: Unattributable authorship text via data poisoning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Paraphrasing with large language models</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Witteveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Andrews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Neural Generation and Translation</title>
		<meeting>the 3rd Workshop on Neural Generation and Translation</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="215" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Huggingface&apos;s transformers: State-ofthe-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">Xingxing</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohui</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoguang</forename><surname>Niu</surname></persName>
		</author>
		<title level="m">A comprehensive survey on local differential privacy. Security and Communication Networks</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="1" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A differentially private text perturbation method using regularized mahalanobis metric</title>
		<author>
			<persName><forename type="first">Zekun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oluwaseyi</forename><surname>Feyisetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Teissier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Privacy in NLP</title>
		<meeting>the Second Workshop on Privacy in NLP</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Differentially private fine-tuning of language models</title>
		<author>
			<persName><forename type="first">Da</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arturs</forename><surname>Backurs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sivakanth</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautam</forename><surname>Huseyin A Inan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janardhan</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin Tat</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Manoel</surname></persName>
		</author>
		<author>
			<persName><surname>Wutschitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Paws: Paraphrase adversaries from word scrambling</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1298" to="1308" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Can Large Language Models Predict Antimicrobial Resistance Gene?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-03-06">6 Mar 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Hyunwoo</forename><surname>Yoo</surname></persName>
							<email>hty23@drexel.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Drexel University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Can Large Language Models Predict Antimicrobial Resistance Gene?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-03-06">6 Mar 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">431F5788BCC037C9DE8BEE466A1B3466</idno>
					<idno type="arXiv">arXiv:2503.04413v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This study demonstrates that generative large language models can be utilized in a more flexible manner for DNA sequence analysis and classification tasks compared to traditional transformer encoder-based models. While recent encoder-based models such as DNABERT and Nucleotide Transformer have shown significant performance in DNA sequence classification, transformer decoder-based generative models have not yet been extensively explored in this field. This study evaluates how effectively generative Large Language Models handle DNA sequences with various labels and analyzes performance changes when additional textual information is provided. Experiments were conducted on antimicrobial resistance genes, and the results show that generative Large Language Models can offer comparable or potentially better predictions, demonstrating flexibility and accuracy when incorporating both sequence and textual information. The code and data used in this work are available at the following GitHub repository: <ref type="url" target="https://github.com/biocomgit/llm4dna">https://github.com/biocomgit/llm4dna</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Language Models have shown notable performance in various tasks in Natural Language Processing and have recently been applied to bioinformatics tasks such as DNA sequence analysis. Encoderbased transformer models trained on nucleotide sequences, such as DNABERT <ref type="bibr" target="#b10">(Ji et al., 2021;</ref><ref type="bibr" target="#b17">Zhou et al., 2023)</ref> and Nucleotide Transformer <ref type="bibr" target="#b6">(Dalla-Torre et al., 2023)</ref>, have demonstrated excellent performance in DNA sequence classification and are widely used for various gene sequence analyses. Additionally, encoder-based models trained on amino acid sequences have also shown good performance in protein sequence classification <ref type="bibr" target="#b3">(Brandes et al., 2022)</ref>. However, generative Large Language Models, such as GPT based models <ref type="bibr" target="#b4">(Brown et al., 2020)</ref>, have not yet been actively utilized for DNA analysis. While models like BioGPT <ref type="bibr" target="#b14">(Luo et al., 2022)</ref>, which are primarily trained on medical and pharmaceutical text, have emerged, models focused specifically on DNA analysis are still relatively rare.</p><p>Generative large language Models possess the flexibility to make predictions through appropriate prompts, even when incorporating additional textual information, which can significantly enhance performance. This ability to directly utilize supplementary text in the training process sets them apart from encoder-based models, which often struggle with handling complex textual data. Furthermore, generative models can also adapt to situations where the same DNA sequence may have multiple labels, offering a level of versatility not typically seen in models relying on fixed labels.</p><p>This study primarily investigates how the performance of generative large language models improves when supplementary textual information is provided alongside DNA sequences. Additionally, it explores how these models handle cases where a single DNA sequence may be associated with different labels. Through this, the study aims to demonstrate the potential applications of generative language models in DNA analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>This study is connected to existing research on various DNA sequence analyses and the classification of antibiotic resistance genes.</p><p>AMR++ introduces an updated database of antimicrobial resistance determinants along with a classification pipeline, which classifies genes based on large-scale sequencing data <ref type="bibr" target="#b2">(Bonin et al., 2023)</ref>. This study designs experimental datasets for DNA sequence analysis using this data.</p><p>AMR-meta presents a method for analyzing high-speed single-read metagenomic data using k-mers and meta-features <ref type="bibr" target="#b15">(Marini et al., 2022)</ref>, con-tributing to the classification of antibiotic resistance genes. This study builds on this by conducting analyses using various types of metadata.</p><p>Meta-MARC proposes a method for detecting antibiotic resistance gene sequences using hierarchical hidden Markov models, which serves as an important reference for DNA sequence analysis dealing with diverse sequences <ref type="bibr" target="#b12">(Lakin et al., 2019)</ref>.</p><p>DeepARG introduces a deep learning method for predicting antibiotic resistance genes, effectively classifying these genes using metagenomic data <ref type="bibr" target="#b1">(Arango-Argoty et al., 2018)</ref>. This study extends such foundational deep learning-based DNA sequence analysis methods to explore how generative language models can be applied to gene analysis.</p><p>Blastn is a tool that compares the similarity between DNA sequences, performing local sequence alignments between query sequences and target sequences stored in databases. Since the database contains sequences already annotated with gene functions, Blastn can predict genetic functions by finding sequences similar to the query sequence. It divides the query sequence into small fragments (words), finds matching sequences, extends them, and evaluates the similarity by providing results with an E-value. It is widely used in bioinformatics for gene function prediction, evolutionary relationship analysis, and sequence variation detection <ref type="bibr" target="#b13">(Lobo, 2008)</ref>.</p><p>DNABERT is one of the first models to apply BERT to DNA sequence analysis. Based on the BERT architecture, which is primarily used in Natural Language Processing, DNABERT tokenizes DNA sequences and learns the meaning of each nucleotide sequence <ref type="bibr" target="#b10">(Ji et al., 2021)</ref>. The main technique of DNABERT1 is the use of k-mer tokenization, where DNA nucleotide sequences are divided into 3-mers or 6-mers to process them like words in natural language. This helps better understand the relationships between sequences and extract patterns within genes. DNABERT maintains BERT's pre-training and fine-tuning techniques while performing pre-training on large-scale DNA sequence data, resulting in high performance in tasks such as promoter prediction, splicing site detection, and DNA sequence classification. The self-attention mechanism of the transformer model allows DNABERT to effectively learn long-term dependencies within DNA sequences, performing similarly or slightly better than traditional rulebased models or simple sequence alignment algo-rithms.</p><p>DNABERT2, while maintaining the BERTbased transformer architecture, includes more biological data in its pre-training, enabling the model to learn complex genetic interactions and fine DNA patterns <ref type="bibr" target="#b17">(Zhou et al., 2023)</ref>. DNABERT2 overcomes the inefficiencies of traditional k-mer tokenization by introducing the Byte Pair Encoding method for DNA sequence analysis. While the kmer method used fixed-length sequence fragments as tokens, leading to inefficiencies in processing, DNABERT2 implements BPE to merge frequently occurring sequences, enabling more efficient nonoverlapping tokenization. This allows the model to overcome input length limitations, reduce time and memory usage, and improve performance.</p><p>Nucleotide Transformer is a transformer-based model pre-trained on various human and nonhuman genomic data, showing excellent performance in predicting molecular phenotypes from DNA sequences. The model is trained on 3,202 human genomes and 850 genomes from various species, generating context-specific representations <ref type="bibr" target="#b6">(Dalla-Torre et al., 2023)</ref>. These representations allow for high-accuracy predictions even with small amounts of data, matching or surpassing existing specialized methods in 11 of 18 prediction tasks. After fine-tuning, the performance improved in 15 tasks. Nucleotide Transformer focuses on learning important genetic elements, such as enhancers, that regulate gene expression, and it has shown the ability to identify such elements without supervised learning. Additionally, it has been demonstrated that utilizing the model's representations can improve the prioritization of functional genetic variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collection</head><p>The data used in this study consists of antibiotic resistance gene data collected from the MEGARes <ref type="bibr" target="#b7">(Doster et al., 2020)</ref> and CARD databases <ref type="bibr" target="#b11">(Jia et al., 2017)</ref>. The different labels from MEGARes and CARD were integrated using the Antibiotic Resistance Ontology from the European Bioinformatics Institute, as described in previous research methods <ref type="bibr" target="#b16">(Yoo et al., 2024)</ref>  <ref type="bibr" target="#b5">(Cook et al., 2016)</ref>. These databases contain DNA sequences of various antibiotic resistance genes, and each sequence is classified with one or more labels. Additionally, the BLASTn algorithm was used to search for antibi-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unclassified Rate</head><p>LLama3.1 8B-4bit (Base Model) 97%</p><p>LLama3.1 8B-4bit (Blastn) 73%</p><p>LLama3.1 8B-4bit (Finetuning) 0%</p><p>Claude3.5sonet (Base Model) 39%</p><p>Claude3.5sonet (Blastn) 11%</p><p>Chatgpt4o-mini (Base Model) 100%</p><p>Chatgpt4o-mini (Blastn) 14%</p><p>Chatgpt4o-mini (Finetuning) 0%</p><p>Table 1: Model unclassified rates with long names displayed in two lines.</p><p>otic resistance sequences similar to each DNA sequence, and the top 5 search results were selected based on the e-value criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Preprocessing</head><p>The collected DNA sequences underwent preprocessing for analysis. First, all DNA sequences were converted to uppercase, and invalid sequences were removed from the BLASTn results. The final dataset was constructed by including only antibiotic resistance gene sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fine-tuning</head><p>In this study, we applied the Low-Rank Adaptation (LoRa) technique to fine-tune the LLaMA model and the ChatGPT4-mini model for DNA sequence classification tasks. LoRa is an efficient method that converts only a portion of the parameters of large models into low-rank matrices for additional training, thereby reducing memory and computational costs while maintaining model performance <ref type="bibr" target="#b9">(Hu et al., 2021)</ref>. Additional experiments were conducted using the Claude 3.5 sonet API, and the performance of various generative language models was compared and analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>In this study, we used the 8B version of the LLaMA 3.1 model(AI, 2024) with 4-bit quantization from the unsloth model <ref type="bibr" target="#b8">(Han and Han, 2023)</ref> as the foundation model for our experiments. Additionally, the LLaMA 405B model provided through the Amazon Bedrock API was utilized. Separate experiments were conducted with ChatGPT4-mini and the Claude 3.5 sonet API to evaluate the performance of these diverse language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Metric</head><p>The performance of the model was evaluated based on the accurate classification of antibiotic resistance genes in the DNA sequences. For fine-tuned models, this criterion was used since they mostly returned the correct class labels in the output. However, for non-fine-tuned models, they rarely returned just the label names. Therefore, we implemented a model that maps class labels from rather lengthy and verbose explanations, and using this model, we extracted the class labels again. The classification performance of the large language models was then evaluated based on these labels.</p><p>In addition to classification accuracy, the models were also evaluated using precision, recall, and F1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>The experimental results showed that generative large language models performed just as well as traditional encoder-based models in handling multiple labels for DNA sequences. Furthermore, when additional gene information from the Blastn DB search results was provided, performance improved even without additional training on this data. As seen in Table <ref type="table">1</ref>, the Unclassified Rate decreased across all models. For the LLaMA 3.1 8B-4bit quantized model, the rate dropped from 97% to 73% when using Blastn. For Claude 3.5 sonet, it decreased from 39% to 11%. ChatGPT 4-mini showed a sharp improvement, going from classifying nothing to only leaving 14% unclassified. When fine-tuning was applied, both the LLaMA 3.1 8B 4bit quantized model and ChatGPT 4-mini reduced their unclassified rates to 0%. As shown in Table <ref type="table" target="#tab_1">2</ref>, overall classification performance also improved when using additional Blastn information or fine-tuning. For example, the accuracy of the LLaMA 3.1 8B-4bit model increased from 0.0037 to 0.0744 when using Blastn, and to 0.5521 with fine-tuning. The F1 Score followed a similar trend. Claude 3.5 sonet and ChatGPT 4mini also showed improvements in accuracy, preci- sion, recall, and F1 score when using the additional Blastn information. With fine-tuning, the accuracy of the ChatGPT 4-mini model rose to 0.9318, comparable to language models trained solely on DNA data. Without additional information or fine-tuning, all metrics for the ChatGPT 4-mini model were zero, indicating that the model made no predictions. The model's responses suggested that it could not make a judgment due to insufficient evidence.</p><p>Table <ref type="table">3</ref> shows the classification accuracy on test data based on the CARD labels without any additional information or training. The test was conducted using models fine-tuned on the integrated MEGARes-based label data, and the accuracy was 0.2307 for the LLaMA 3.1 8B-4bit model and 0.5037 for the ChatGPT 4-mini model. This demonstrates that large language models can still handle different labeling environments to some extent.</p><p>Large language models not only flexibly incorporate additional textual information but also improve their performance with this data. Moreover, they can handle previously unseen labels to some extent, and fine-tuning further enhances their performance. This shows that generative language models are advantageous in solving more complex problems, such as classifying DNA AMR drug classes, by integrating diverse information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This study confirmed that generative large language models can be applied more flexibly to DNA sequence analysis and classification tasks compared to traditional encoder-based models. In particular, we found that model performance improved when additional textual information was provided, offering important implications for future DNA analysis and antibiotic resistance gene classification tasks. Additionally, experiments showed that generative models are more flexible and accurate in handling cases where different labels exist for the same sequence, even if these labels differ from those in the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>This study highlighted the flexibility of generative large language models and their ability to utilize additional textual information, showing that they can play an important role in DNA sequence analysis. Generative models have the potential to handle unseen labels effectively and integrate supplementary information to solve more complex problems. However, this study used a limited dataset, and future research should expand the scope of analysis by including a wider range of DNA sequences and antibiotic resistance gene data.</p><p>Extracting specific class labels from long texts was not a straightforward task. Initially, the final prediction was based on the antibiotic name most frequently mentioned in the model's output. In cases where multiple antibiotics were predicted equally, they were excluded from evaluation, but this method was not very accurate. To address this, a model was implemented to extract class labels from lengthy texts for evaluation. However, the evaluation may vary depending on the accuracy of this extraction model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Accuracy LLama 3.1 8B-4bit (Fine-tuning) 0.2307 Chatgpt 4o-mini (Fine-tuning) 0.5037</p><p>Table 3: Model accuracy results with different label dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance metrics for various large language models.</figDesc><table><row><cell>Model</cell><cell cols="4">Accuracy Precision Recall F1 Score</cell></row><row><cell>LLama3.1 8B-4bit</cell><cell>0.0037</cell><cell>0.0011</cell><cell>0.0002</cell><cell>0.0003</cell></row><row><cell>LLama3.1 8B-4bit + Blastn</cell><cell>0.0744</cell><cell>0.0530</cell><cell>0.0129</cell><cell>0.0207</cell></row><row><cell>LLama3.1 8B-4bit + Finetuing</cell><cell>0.5521</cell><cell>0.4760</cell><cell>0.5521</cell><cell>0.5080</cell></row><row><cell>Claude3.5sonet</cell><cell>0.1488</cell><cell>0.1770</cell><cell>0.0966</cell><cell>0.0735</cell></row><row><cell>Claude3.5sonet + Blastn</cell><cell>0.8042</cell><cell>0.6287</cell><cell>0.5421</cell><cell>0.5794</cell></row><row><cell>Chatgpt4o-mini</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>Chatgpt4o-mini + Blastn</cell><cell>0.7804</cell><cell>0.9090</cell><cell>0.7804</cell><cell>0.8398</cell></row><row><cell>Chatgpt4o-mini + Finetuning</cell><cell>0.9318</cell><cell>0.9337</cell><cell>0.9318</cell><cell>0.9319</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>A.1 Example Prompt Explanation including DNA Sequence</p><p>In this example prompt, a DNA sequence is provided along with several drug class labels, such as Sulfonamides, Aminoglycosides, Betalactams, Glycopeptides, Tetracyclines, Phenicol, Fluoroquinolones, MLS (Macrolide-Lincosamide-Streptogramin), and Multi-drug resistance. This prompt is used to assess the DNA sequence for antibiotic resistance and classify the sequence into one of the specified drug resistance categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Example Prompt Explanation including Blastn information</head><p>In this prompt, a DNA sequence and the top 5 Blastn search results are provided. The task is to predict the drug class that the DNA sequence is resistant to, based on the alignment information and matching sequences. The drug class labels included in the prompt are Sulfonamides, Aminoglycosides, Betalactams, Glycopeptides, Tetracyclines, Phenicol, Fluoroquinolones, MLS (Macrolide-Lincosamide-Streptogramin), and Multi-drug resistance.</p><p>The BLASTn results contain gene information such as sequence titles, alignment length, e-values, and detailed sequence alignments (query, match, and subject sequences). This allows the model to analyze the DNA sequence's pattern and classify it into the appropriate drug resistance category.</p><p>The prompt follows this format: This prompt aims to predict the antibiotic resistance drug by using DNA sequence data from the Blastn search results and identifying the relevant drug resistance class.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Introducing llama 3.1: Our most capable models to date</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Meta</surname></persName>
		</author>
		<ptr target="https://ai.meta.com/blog/meta-llama-3-1/" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="2024" to="2029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deeparg: A deep learning approach for predicting antibiotic resistance genes from metagenomic data</title>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Arango-Argoty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Pruden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lenwood</forename><forename type="middle">S</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Vikesland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqing</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1186/s40168-018-0401-z</idno>
	</analytic>
	<monogr>
		<title level="j">Microbiome</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Megares and amr++, v3.0: an updated comprehensive database of antimicrobial resistance determinants and an improved software pipeline for classification using highthroughput sequencing</title>
		<author>
			<persName><forename type="first">Nathalie</forename><surname>Bonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Doster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Worley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><forename type="middle">J</forename><surname>Pinnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">E</forename><surname>Bravo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Ferm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><surname>Marini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mattia</forename><surname>Prosperi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noelle</forename><surname>Noyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Morley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Boucher</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/gkac1047</idno>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="744" to="D752" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Proteinbert: a universal deep-learning model of protein sequence and function</title>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Brandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Ofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yam</forename><surname>Peleg</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btac020</idno>
	</analytic>
	<monogr>
		<title level="m">Nadav Rappoport, and Michal Linial</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2102" to="2110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2005.14165</idno>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">Todd</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Cochrane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ewan</forename><surname>Birney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rolf</forename><surname>Apweiler</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/gkv1352</idno>
	</analytic>
	<monogr>
		<title level="m">The european bioinformatics institute in 2016: Data growth and integration</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="20" to="D26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Dalla-Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Mendoza-Revilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><forename type="middle">Lopez</forename><surname>Carranza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Henryk Grzywaczewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Oteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Dallago</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.01.11.523679</idno>
	</analytic>
	<monogr>
		<title level="m">The nucleotide transformer: Building and evaluating robust foundation models for human genomics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Megares 2.0: a database for classification of antimicrobial drug, biocide and metal resistance determinants in metagenomic sequence data</title>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Doster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Steven M Lakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cory</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">G</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">E</forename><surname>Boucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noelle</forename><forename type="middle">R</forename><surname>Belk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Noyes</surname></persName>
		</author>
		<author>
			<persName><surname>Morley</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/gkz1010</idno>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="561" to="D569" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Han</surname></persName>
		</author>
		<ptr target="https://github.com/unslothai/unsloth" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyuan</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shean</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno>arXiv. ArXiv:2106.09685v2</idno>
		<title level="m">Lora: Low-rank adaptation of large language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dnabert: pre-trained bidirectional encoder representations from transformers model for dnalanguage in genome</title>
		<author>
			<persName><forename type="first">Yanrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramana</forename><forename type="middle">V</forename><surname>Davuluri</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btab083</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="2112" to="2120" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">expansion and model-centric curation of the comprehensive antibiotic resistance database</title>
		<author>
			<persName><forename type="first">Baofeng</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amogelang</forename><forename type="middle">R</forename><surname>Raphenya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Alcock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Waglechner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiyao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kara</forename><forename type="middle">K</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Briony</forename><forename type="middle">A</forename><surname>Lago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biren</forename><forename type="middle">M</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheldon</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><forename type="middle">N</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mélanie</forename><surname>Courtot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">G</forename><surname>Frye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tariq</forename><surname>Elsayegh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daim</forename><surname>Sardar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erin</forename><forename type="middle">L</forename><surname>Westman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">C</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fiona</forename><forename type="middle">S L</forename><surname>Brinkman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerard</forename><forename type="middle">D</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Mcarthur</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/gkw1004</idno>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="566" to="D573" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Hierarchical hidden markov models enable accurate and diverse detection of antimicrobial resistance sequences</title>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">M</forename><surname>Lakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Kuhnle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bahar</forename><surname>Alipanahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noelle</forename><forename type="middle">R</forename><surname>Noyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Muggli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Raymond</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42003-019-0545-9</idno>
	</analytic>
	<monogr>
		<title level="j">Communications Biology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">294</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Basic local alignment search tool (blast)</title>
		<author>
			<persName><forename type="first">Ingrid</forename><surname>Lobo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Education</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">215</biblScope>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
	<note>Nature Education</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Biogpt: Generative pre-trained transformer for biomedical text generation and mining</title>
		<author>
			<persName><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1093/bib/bbac409</idno>
	</analytic>
	<monogr>
		<title level="j">Briefings in Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">409</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Amr-meta: A k -mer and metafeature approach to classify antimicrobial resistance from highthroughput short-read metagenomics data</title>
		<author>
			<persName><forename type="first">Simone</forename><surname>Marini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishabh</forename><forename type="middle">A</forename><surname>Slizovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noelle</forename><forename type="middle">Robertson</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamer</forename><surname>Noyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Kahveci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mattia</forename><surname>Boucher</surname></persName>
		</author>
		<author>
			<persName><surname>Prosperi</surname></persName>
		</author>
		<idno type="DOI">10.1093/gigascience/giac029</idno>
	</analytic>
	<monogr>
		<title level="j">Giga-Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Giac029</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Predicting anti-microbial resistance using large language models</title>
		<author>
			<persName><forename type="first">Hyunwoo</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bahrad</forename><surname>Sokhansanj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gail</forename><surname>Rosen</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2401.00642</idno>
		<idno type="arXiv">arXiv:2401.00642</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2401.00642" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Dnabert-2: Efficient foundation model and benchmark for multispecies genome</title>
		<author>
			<persName><forename type="first">Zhihan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratik</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramana</forename><surname>Davuluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Liu</surname></persName>
		</author>
		<idno>ArXiv:2306</idno>
		<imprint>
			<date type="published" when="2023">2023. 15006v1</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

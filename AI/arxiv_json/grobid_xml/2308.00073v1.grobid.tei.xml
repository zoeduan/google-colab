<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Trustworthiness of Children Stories Generated by Large Language Models</title>
				<funder ref="#_AENPRWY #_ahH4YGA">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Office of Research Computing, George Mason University</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Prabin</forename><surname>Bhandari</surname></persName>
							<email>pbhanda2@gmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of English</orgName>
								<orgName type="department" key="dep3">Linguistics Program</orgName>
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hannah</forename><forename type="middle">Marie</forename><surname>Brennan</surname></persName>
							<email>hbrennan@gmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of English</orgName>
								<orgName type="department" key="dep3">Linguistics Program</orgName>
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Trustworthiness of Children Stories Generated by Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">70B8E68CDFB3975DC48C5117675A6FB2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories. 1  </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Advancements in pretrained large language models (LLMs) like GPT-3 <ref type="bibr" target="#b0">(Brown et al., 2020)</ref> and LLaMA <ref type="bibr">(Touvron et al., 2023)</ref>, have made it easier to generate natural language text for a variety of downstream tasks, including generating narrative text like children's stories. The ability to generate natural text using LLMs has seen substantial improvement with the innovation of instructionfollowing models like InstructGPT <ref type="bibr" target="#b12">(Ouyang et al., 2022)</ref> and Alpaca <ref type="bibr" target="#b19">(Taori et al., 2023)</ref>, resulting in a better alignment with user intentions.</p><p>These systems are being used as a generalpurpose chat-bots by the general public. As these models are integrated more into everyday applications, it is crucial to continuously evaluate LLMs' performance to ensure that they are indeed trustworthy and accurate.</p><p>Trustworthiness in the case of LLMs is a broad term that refers to reliability and confidence in the generated text outputs along with their suitability for a specific downstream task. A trustworthy LLM minimizes errors, biases, and potentially harmful 1 Code and dataset are publicly available: <ref type="url" target="https://github.com/prabin525/trustworthiness-of-children-stories-generated-by-LLMs">https://github.com/prabin525/trustworthiness-of-children- stories-generated-by-LLMs</ref> content while consistently producing clear and contextually suitable text. With the advancing capabilities of LLMs, concerns regarding their trustworthiness have arisen. Notably, they are being used more frequently to support creative writing <ref type="bibr" target="#b2">(Clark et al., 2018)</ref>, raising concerns about the generation of inappropriate or offensive text (Price, 2016) and biased content <ref type="bibr">(Lucy and Bamman, 2021a)</ref>. One domain in which trustworthiness is of particular importance is text generation intended for children. This paper seeks to evaluate the trustworthiness of children's stories generated by LLMs including generative LLMs and instruction following models. In the case of text generation geared towards children, LLMs' ability to generate age-appropriate materials to target audiences also becomes a vital aspect of overall trustworthiness.</p><p>To assess the trustworthiness of LLMs in generating children's stories, we use two open-source foundation language models, OPT <ref type="bibr">(Zhang et al., 2022)</ref> and LLaMA <ref type="bibr">(Touvron et al., 2023)</ref>, along with an instruction-following model Alpaca <ref type="bibr" target="#b19">(Taori et al., 2023)</ref> to generate children's stories. Then, we compare these generated stories against actual children's stories, old and modern. Our assessment takes into account a number of aspects, including statistics derived from the text like the Flesch reading ease score <ref type="bibr" target="#b4">(Flesch, 1948)</ref>, toxicity present in the text, the most influential topics present in the text, and the sentence structure of these texts.</p><p>Our findings reveal that LLMs lack a high level of trustworthiness when tasked with generating children's stories. While the generated children's stories do share similarities in topics and patterns with the actual stories (mostly modern ones), they are also susceptible to generating toxic content. Moreover, LLMs struggle to capture the intricacies and nuances of children's literature, evident from the disparity in sentence structure between the generated and actual stories.</p><p>arXiv:2308.00073v1 [cs.CL] 25 Jul 2023 2 Related Work 2.1 Story Generation</p><p>Recently, LLMs have been increasingly used to supplement creative writing efforts for entertainment and social media. Applications include work related to narrative generations <ref type="bibr" target="#b17">(Sun et al., 2023;</ref><ref type="bibr" target="#b16">Simon and Muise, 2022;</ref><ref type="bibr" target="#b14">Razumovskaia et al., 2022;</ref><ref type="bibr" target="#b25">Xiang et al., 2018)</ref>. <ref type="bibr" target="#b27">Yuan et al. (2022)</ref> tested Wordcraft, a tool created to assist writers with story generation using LLMs. In their study, writers who were tasked with working with the AI agent noted that Wordcraft lacked content awareness and would create grammatical stories with nonsensical topics or plots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Children and AI</head><p>AI and LLMs have also been applied to contexts involving children. Researchers at MIT had children work with social robots to evaluate how much the children could learn through activities involving robots <ref type="bibr" target="#b24">(Williams, 2019)</ref>. There is much discussion on how to integrate AI into early childhood education <ref type="bibr" target="#b26">(Yang, 2022;</ref><ref type="bibr" target="#b9">Kasneci et al., 2023)</ref>. With the increasing use of AI by and around children, there is an urgent need for more thorough evaluations of LLMs and the appropriateness of generated content for vulnerable audiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Trustworthiness Testing</head><p>Chiang and Lee (2023) investigated whether LLMs can replace humans in evaluating texts. Specifically, they looked at open-ended story generation and adversarial attacks. They found that there were similar ratings between LLMs and human evaluators. <ref type="bibr" target="#b22">Venkit et al. (2023)</ref> found that unbalanced sources of training data result in biased generations in GPT-2, and proposed strategies to reduce bias using adversarial triggers. <ref type="bibr" target="#b18">Tang et al. (2022)</ref> presented EtriCA, a neural generation model which aims to remedy issues of relevance and coherence of generated texts. <ref type="bibr">Lucy and Bamman (2021b)</ref> studied the bias existing in GPT-3's generated stories. <ref type="bibr" target="#b6">Guo et al. (2023)</ref> have proposed a similar study specifically testing how similar text generated by ChatGPT is to text produced by human writers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>To investigate the trustworthiness of children's stories generated by LLMs, we compare them with actual old and modern children's stories. We collect a diverse set of stories from different sources, including both older stories such as folktales, and more recent children's stories. We use both LLMs and instruction-following models to generate stories with different prompt lengths and instruction templates. As story generation is an open-ended problem with no reference text, we rely on other metrics instead of any automatic measure of evaluation like BARTScore <ref type="bibr" target="#b28">(Yuan et al., 2021)</ref> or BERTScore <ref type="bibr" target="#b30">(Zhang et al., 2019)</ref>. We use various metrics to compare the generated stories with actual stories, including in-text statistics such as sentence length and a measure of toxicity in the text, as well as an evaluation of topics covered in these stories. Furthermore, we analyze and compare the grammatical structures of the stories using dependency structures extracted from both the original and the artificially generated stories.</p><p>In the following section, we describe the experimental setup, including details on the collected data, the story generation process, and the evaluation metrics used for comparison. Subsequently, we present the results obtained from our experimentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>Our data consists of 132 original children's stories collected from various online sources and categorized into two categories: old and modern. The old stories generally include traditional children's stories like folktales and fairy tales, whereas the modern stories include more recent children's literature published after the year 2000. Both sets of original children's stories are comprised of English texts aimed at children between the ages of three and thirteen, with both data sets representing the full range of these target ages. Overall, 122 are classified as old stories, and the remaining 10 as modern stories. Specifically, the older stories were obtained via Project Gutenberg,<ref type="foot" target="#foot_0">foot_0</ref> and the modern stories from various online platforms. <ref type="foot" target="#foot_1">3</ref> We use the old stories as a reference for the story generation task and compare the generated stories against both old and modern stories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Story generation</head><p>We generate stories using language models and an instruction-following model. Language Models Our story generation task using LLMs uses two foundational language models: OPT <ref type="bibr">(Zhang et al., 2022)</ref> and LLaMA <ref type="bibr">(Touvron et al., 2023)</ref>, with model sizes of 6.7 billion and 7 billion parameters, respectively. To generate stories, we provide a portion of each old story as context for the LLMs. Specifically, we use the first sentence, the first 256 tokens, and the first 512 tokens of each old story as a prompt. We use top-k sampling-based decoding with k set to 100 and generate five samples for each prompt, resulting in a total of 3660 generated stories. The breakdown of the generated stories along with the length of the prompt is given in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Instruction-following Models For instructionfollowing story generation, we use Alpaca <ref type="bibr" target="#b19">(Taori et al., 2023)</ref>, which is an instruction-following model that is based on the LLaMA architecture and is fine-tuned using self-instruct <ref type="bibr" target="#b23">(Wang et al., 2022)</ref>. We use the Alpaca model based on the 7B variant of the LLaMA model. We use four different instruction templates to generate stories, two of which require a story title as input and two of which do not. For the templates that require a story title, we use the title of old stories as input. The templates are provided in Table <ref type="table">2</ref>. To generate stories, we use top-k sampling-based decoding with k set to 100 and generate five samples for each template, resulting in a total of 2440 generated stories with 610 stories per template.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">In-text statistics</head><p>We compare various statistics derived from the text of the generated stories against those of actual stories. Specifically, we use two metrics: sentence length and Flesch reading ease score <ref type="bibr" target="#b4">(Flesch, 1948)</ref>.</p><p>Flesch Reading Ease Score The Flesch reading ease score (FRES) measures the readability of a text and is based on two factors: average sentence length and the average number of syllables per word. It provides a score between 0 and 100, with higher scores indicating easier readability. A Flesch reading ease score above 60 for a text indicates that it can easily be read by children up to the age of 15. The formula for calculating the FRES of a text is shown in Equation <ref type="formula">1</ref>.</p><formula xml:id="formula_0">F RES =</formula><p>206.835 -1.015 total words total sentence -84.6 total syllables total words (1) 4.4 Toxicity of text Gehman et al. 2020 found that the LLMs can generate 'toxic' text from a very innocuous prompt and attribute this to a significant amount of offensive, factually unreliable, and otherwise toxic content in the training data of these models. We want to investigate the level of toxicity in our generated children's stories. Ideally, generated children's stories should be free of any toxic text.</p><p>We use Detoxify (Hanu and Unitary team, 2020), a BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> based toxic text detector, to identify the presence of toxic text in the generated children's stories. Detoxify generates score labels in the range of 0 to 1, assessing the toxicity of the text based on categories such as toxic, severely toxic, obscene, threat, insult, and identity hate. Specifically, we use detoxify for each sentence of our actual and generated stories to get toxicity measures across the six categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Topic Modeling</head><p>We also analyze the data for topic modeling using pyLDAvis <ref type="bibr" target="#b21">(Tran, 2022)</ref>. We compare the topics found in the data set of older stories with the LLMgenerated stories. The older stories and the modern stories are also compared to assess whether there has been a shift in topics over time that would potentially influence topic properties in the LLMgenerated stories. A probable diachronic shift in topics of stories geared towards young audiences also highlights the need to test the toxicity of generated stories, as seen in the previous section.</p><p>To avoid uninformative topics, the data is preprocessed to remove stopwords and names. All texts are categorized for specific topics using word clustering for a set of documents. Modeling is performed automatically without a predefined list of</p><p>S.N. Template T1 Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: Write a short children's story given the title. ### Input: TITLE ### Response: T2 Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: Write a short children's story. ### Response: T3 Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: Write a children's story given the title. ### Input: TITLE ### Response: T4 Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: Write a children's story. ### Response:</p><p>Table 2: Templates used by Alpaca for story generation.</p><p>labels. The visualizations using pyLDAvis break down the topics based on the 122 older stories, the 10 modern stories, and the generated stories from OPT, LLaMA, and Alpaca.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Sentence structure</head><p>The structure of the sentences within a text can reveal the type or genre of the text. To analyze sentence structures, we construct a dependency tree for each sentence in both the original and generated children's stories. The dependency tree depicts the syntactic dependencies between the words in a sentence, effectively capturing the grammatical structure of the sentence. We then convert these dependencies into unlabeled directed graphs, preserving sentence structure while removing specific words. We then generate the Weisfeiler Lehman graph hash <ref type="bibr" target="#b15">(Shervashidze et al., 2011)</ref> for each graph. The Weisfeiler Lehman hashes are identical for isomorphic graphs and strongly guarantee that non-isomorphic graphs will get different hashes.</p><p>We compare the frequency of hashes to evaluate the similarity between the sentence structure of the generated stories and the actual stories.</p><p>5 Generated stories follow modern trends but struggle with nuances</p><p>Figure <ref type="figure" target="#fig_1">1</ref> shows the box plot of sentence lengths for old and modern original stories, as well as for the generated stories. Being literary texts, children's stories do not strictly confine to formal English conventions and many contain sentences with higher word counts; so for clarity, we removed all the outliers from the plot. One interesting observation is that modern children's stories generally have shorter sentence lengths than older children's stories, which adheres to previous research that shows a trend of decreasing sentence length in print <ref type="bibr" target="#b8">(Haussamen, 1994)</ref>. The generated stories from OPT and LLaMA show an increase in sentence length as the prompt length increases. We hypothesize that these models learn the pattern of larger sentence length from the older stories used as context, which is then reflected in the generated text. However, stories generated using the instruction-following model Alpaca, have sentence lengths similar to modern actual stories, indicating that language models may have been trained mostly on the newer text, and tend to generalize modern trends when instructed to generate text of a specific type. The Flesch reading ease score is a statistical measure of the readability of a text and was optimized to be general enough at the time of its formulation, as can be seen with the constant values in equation 1. That is why, we may find FRES values not within the range of 0 to 100 as seen in Figure <ref type="figure" target="#fig_3">2a</ref>. We also removed the outliers from the box plot in Figure <ref type="figure" target="#fig_3">2a</ref>. Since we are not interested in exact values but in the general trend these values represent, we use the FRES values in the range of 0-100 and show their box plot in Figure <ref type="figure" target="#fig_3">2b</ref>.</p><p>Our results from the Flesch reading ease score reveal several interesting observations. Firstly, we see that modern children's stories have a higher FRES than older stories, meaning that the modern ones are easier to read. This can be attributed to the fact that sentences are getting shorter and might have to do with simpler word selection. Secondly, we see that LLMs prompted with older stories tend to follow the pattern of the context and generate stories that are more difficult to read, as the context length increases. Finally, we see that the instruction-following model Alpaca generates stories that are easier to read compared to older original children's stories but are not as readable as  The generated children's stories are easier to read compared to older actual stories but are not as easy as modern original stories. Language models prompted with older stories tend to generate text that is more difficult to read, likely because they follow the patterns in the prompts. modern children's stories. We posit that this observation can be attributed to the fact that LLMs used in our study are generic models, and the instruction following model is also only fine-tuned for general instructions rather than instructions specific to children's story generation.</p><p>Overall, we see that modern children's stories are easier to read than older children's stories. As most of the training data for LLMs comes from newer text, the model tends to follow the trend of modern children's stories in their generated text for sentence length and word selection. However, it should be noted that these models are not fine-tuned for children's stories generation, and therefore may not capture the nuances of children's stories resulting in stories that might be difficult to read for intended readers. 6 Generated stories may contain toxic text</p><p>Our analysis of toxicity in actual and generated stories reveals several noteworthy findings. We present the toxicity measures for both actual and generated stories in Figure <ref type="figure" target="#fig_4">3</ref>. Notably, we find that older stories tend to be more toxic than modern stories across all toxicity measures. This trend is not solely due to the smaller sample size of modern actual stories, as we have normalized the toxicity ratings to ensure an accurate comparison. Rather, it suggests that writers are becoming more mindful of the language they use in children's literature.</p><p>Although modern stories are less toxic compared to older stories, we still observe some level of toxicity in them. This toxicity in modern actual stories is often related to the narrative of the story. For example, threats and insults might be needed for some stories, but identity hate is not appropriate for children's stories. It is noteworthy that modern stories do not have toxic text related to identity hate but older stories do. Similar to our previous observation, we see that LLMs tend to learn patterns from the context they are provided with. As evident from the stories generated by OPT and LLaMA, we see that the toxicity aligns with older stories and gradually increases with an increase in the length of the context. The stories generated using the instruction-following model Alpaca tend to be less toxic and mostly resemble modern stories. However, stories generated using the T1 and T3 templates have a lot of obscene text compared to stories generated using T2 and T4, which have none. As shown in Table <ref type="table">2</ref>, T1 and T3 take the title as input whereas T2 and T4 do not. It is possible that the model remembered the story title and generalized the patterns of the story or generalized to some other text in the template, leading to the generation of obscene text. This finding is consistent with Gehman et al. 2020, who suggest that children's stories generated by LLMs can contain highly toxic text despite an innocuous prompt.</p><p>Our analysis of toxicity in original and generated stories reveals that older stories tend to be more toxic than modern ones, that LLMs can learn toxic patterns from context leading to the generation of toxic text, and that LLMs can even generate toxic text from a very innocuous prompt. These findings suggest that further work is needed to make LLMs useful as tools for generating age-appropriate children's literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>with original stories</head><p>After preprocessing the data, the original stories were found to have four major topics. All of the topics tended to share the existence of some small character. The first topic mentions elements such as time, goodness, and greatness, and the presence of words like head, round, night, and water likely indicate specific scenes or settings within the narrative. The second topic contained new elements like a prince, the color white, a girl, and eyes. These additional keywords suggest different perspectives within the overarching narrative. The third topic introduces elements like a house and a heart. Like the previous topics, it shares mentions of a little character, time, goodness, and a prince. The difference between 'house' and 'heart' could indicate a change in the setting or moral of the narrative. The last topic introduces new elements of wolf, people, eyes, and a mother. These keywords might suggest narratives that introduce new characters and themes. Overall, these topics provide insight into the underlying themes present in the older 122 stories in the data set. The topics revolve around narratives involving a small character, time, goodness, and various other elements such as princes, nights, water, girls, and wolves.</p><p>Comparatively, the topics of the generated stories obtained from OPT, LLaMA, and Alpaca show minor differences. The first topic suggests a narrative that involves characters like kings, mothers, princes, and princesses. It also mentions elements of time, goodness, greatness, and shadow. The prince, princess, and shadow hint at the fairy tale or fantasy theme. The second topic shares similarities with the previous topic, with a focus on little, prince, time, goodness, and greatness, but it also introduces new elements like eyes, houses, heads, and the color white. These additions suggest different scenes, perhaps removed from the monarchy or castle theme, and suggest a different narrative. The third topic seems to center around family dynamics, with mentions of mothers, fathers, and children. It also includes keywords relating to time, goodness, night, and poverty. This suggests a change in the narrative away from the fantasy-focused topic. The last topic includes keywords like little, time, and goodness. It includes elements of fathers, eyes, and houses. The presence of 'long' and 'night' suggests a different tone or atmosphere within the narrative. These general results show remarkable similarity  <ref type="bibr">'world', 'great', 'water', 'black', 'house', 'little', 'king', 'called', and 'good'</ref>. The least shared topics (x:1, y:1) include 'heart <ref type="bibr">', 'head', 'poor', 'house', 'looking', 'children', 'good', 'young', 'lady', and 'night'.</ref> with the data set on which the LLMs were trained. The topics revolve around narratives involving characters such as kings, princes, mothers, fathers, and children. The topics also touched upon topics of time, goodness, greatness, poverty, and setting elements of houses, nights, and the color white.</p><p>As with toxic content testing, we ran topic modeling for a small number (10) of modern stories in order to compare the general topics that are currently aimed at children. The first topic includes keywords related to spatial orientation <ref type="bibr">(right, inside, door, left)</ref>, objects (ream, head, frog), time, and actions (started). The keyword 'eyes' may suggest a focus on visual perception or observation. The second topic emphasizes time, objects (ream, door), spacial orientation (right, inside), a frog, a head, fairies, and 'need'. The presence of fairies introduces a fantastical or imaginative element to the topic. The third topic revolves around time, spacial orientation (right, inside, door), physical attributes (head, eyes, long, hand), and a frog. The inclusion of 'long' might suggest a temporal or duration-related aspect. The last topic highlights time, spatial orientation (right, inside, door), objects (ream, frog), physical attributes (head, eyes, small), and the action of starting something. The modern stories' topic modeling results suggest a re-curring theme involving concepts such as time, spatial orientation, objects, and actions. Each topic emphasizes different aspects and introduces additional elements like fairies or physical attributes. Figure <ref type="figure" target="#fig_5">4</ref> represents the level of similarity and difference between the real stories and the LLM-generated stories. There are greater similarities between these stories than there appear to be differences in the main topics.</p><p>As expected, the results of the topic modeling showed similarities between the original 122 stories in the training corpus and the stories generated by the LLMs. These stories shared fairy tale and fantasy elements as well as topics of goodness, greatness, time, and setting elements of night, houses, and the color white. Once we compare this with the modern stories, we see that the focus of the small data set we have is similarly focused on time and fairies, but has more topics relating to spatial orientation. We are likely seeing a change in the content of stories written for children. With only ten modern stories, we cannot reliably generalize over all stories, but we noticed tendencies such as that the modern story set did tend to involve more overtly educational elements aimed at younger age groups when compared to the older stories.</p><p>8 Generated stories do not have similar sentence structure to original stories</p><p>Table <ref type="table" target="#tab_4">3</ref> shows the percentage of overlapping Weisfeiler Lehman hashes between the dependency tree graphs of sentences generated by various models and those actual children's stories, both old and modern. We also got an overlap of 35.57 percentage between old and modern actual stories, which is greater than all the values in Table <ref type="table" target="#tab_4">3</ref>. This shows that the structure of sentences in children's literature has changed over time, which supports our earlier findings that children's literature has undergone noticeable changes over time. Additionally, we observe a higher percentage of overlap between old original stories and the stories generated by OPT and LLaMA, which again aligns with our earlier findings that LLMs learn from their context. Furthermore, for the stories generated by OPT and LLaMA, we see an average overlap of 30% with modern stories, which can be attributed to the fact that these models were trained on a dataset consisting of recent text.</p><p>The stories generated by Alpaca have a slightly higher overlap with modern stories compared to old stories, but the percentage overlap in sentence structures is still relatively low ( ≤ 20%). Given that the old and modern actual stories share around 35% of the same sentence structures, we expected Alpaca's generated stories to overlap more with modern stories. But since Alpaca is a generic model fine-tuned for instruction-following and not solely trained or fine-tuned on children's literature, it seems plausible that it would not be capable of fully generalizing over sentence or grammatical structures observable in children's literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion and Future Work</head><p>Our study examines the trustworthiness of children's stories generated by large language models. While these generated stories may share similar topics and patterns with actual stories, they fail to capture all the nuances present in children's literature, and may even contain toxic material that is inappropriate for children. Based on our findings, we conclude that LLMs are not yet appropriate for generating high-quality children's literature.</p><p>Moving forward, we plan to extend our work by implementing reinforcement learning with both automatic and human feedback to improve the quality of LLM-generated children's stories.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison of sentence length in generated children's stories and actual children's stories. The generated children's stories exhibit shorter sentence lengths compared to the older original stories but are similar in sentence length to modern stories. Language models prompted with older stories tend to generate longer sentences following the patterns of the context that had been provided.</figDesc><graphic coords="5,72.00,62.81,218.27,163.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>(a) FRES on all data (over 100 is undefined).(b) FRES limited to well-defined 0-100 range.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of FRES in generated children's stories and actual children's stories : (a) FRES with all data and (b) FRES only in the range of 0 and 100. The generated children's stories are easier to read compared to older actual stories but are not as easy as modern original stories. Language models prompted with older stories tend to generate text that is more difficult to read, likely because they follow the patterns in the prompts.</figDesc><graphic coords="5,314.36,232.81,204.10,153.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Various toxicity measures for the actual and generated stories. Each cell in a subplot represents the percentage of sentences rated on a toxicity scale, with x-axis values indicating the toxicity level. Values for ratings in the range of 0-0.1 have been omitted from the plots for clarity.</figDesc><graphic coords="6,78.34,188.60,145.14,108.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparison of topics in generated children's stories and actual children's stories.The plot shows that the most shared topics (x:2, y:2) include 'white', 'world', 'great', 'water', 'black', 'house', 'little', 'king', 'called', and 'good'. The least shared topics (x:1, y:1) include 'heart', 'head', 'poor', 'house', 'looking', 'children', 'good', 'young', 'lady', and 'night'.    </figDesc><graphic coords="7,307.28,62.81,218.26,218.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Breakdown of the stories generated using LLMs.</figDesc><table><row><cell>Model</cell><cell>Prompt Length</cell><cell>Count</cell></row><row><cell>OPT</cell><cell>First Sentence (OPT-Line)</cell><cell>610</cell></row><row><cell></cell><cell>First 256-tokens (OPT-256)</cell><cell>610</cell></row><row><cell></cell><cell>First 512-tokens (OPT-512)</cell><cell>610</cell></row><row><cell cols="2">LLaMA First Sentence (LLaMA-Line)</cell><cell>610</cell></row><row><cell></cell><cell>First 256-tokens (LLaMA-256)</cell><cell>610</cell></row><row><cell></cell><cell>First 512-tokens (LLaMA-512)</cell><cell>610</cell></row><row><cell></cell><cell>Total</cell><cell>3660</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Overlap of the hashes of the dependency tree graph of the sentences in generated stories against old and modern actual stories.</figDesc><table><row><cell>Model</cell><cell cols="2">Percentage overlap with Old stories Modern stories</cell></row><row><cell>OPT-Line</cell><cell>34.82</cell><cell>34.21</cell></row><row><cell>OPT-256</cell><cell>31.37</cell><cell>28.88</cell></row><row><cell>OPT-512</cell><cell>32.49</cell><cell>29.89</cell></row><row><cell>LLaMA-Line</cell><cell>34.23</cell><cell>33.64</cell></row><row><cell>LLaMA-256</cell><cell>32.14</cell><cell>29.82</cell></row><row><cell>LLaMA-512</cell><cell>32.27</cell><cell>30.73</cell></row><row><cell>Alpaca: T-1</cell><cell>17.31</cell><cell>20.37</cell></row><row><cell>Alpaca: T-2</cell><cell>14.67</cell><cell>17.52</cell></row><row><cell>Alpaca: T-3</cell><cell>15.20</cell><cell>16.92</cell></row><row><cell>Alpaca: T-4</cell><cell>15.41</cell><cell>17.84</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://www.gutenberg.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://www.freechildrenstories.com/, https://monkeypen.com/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by resources provided by the <rs type="funder">Office of Research Computing, George Mason University</rs> (URL: <ref type="url" target="https://orc.gmu.edu">https://orc.gmu.edu</ref>) and by the <rs type="funder">National Science Foundation</rs> (Awards Number <rs type="grantNumber">1625039</rs> and <rs type="grantNumber">2018631</rs>). Additionally, <rs type="person">Prabin Bhandari</rs> has been partially supported by the <rs type="funder">National Science Foundation</rs> Grant No. IIS-2127901. Our sincere appreciation goes to <rs type="person">Antonios Anastasopoulos</rs> and <rs type="person">Géraldine Walther</rs> for their valuable suggestions and unwavering support throughout the course of this research.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_AENPRWY">
					<idno type="grant-number">1625039</idno>
				</org>
				<org type="funding" xml:id="_ahH4YGA">
					<idno type="grant-number">2018631</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Can Large Language Models Be an Alternative to Human Evaluations?</title>
		<author>
			<persName><forename type="first">Cheng-Han</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung-Yi</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.01937</idno>
		<idno>ArXiv:2305.01937</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Creative Writing with a Machine in the Loop: Case Studies on Slogans and Stories</title>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><surname>Spencer Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1145/3172944.3172983</idno>
	</analytic>
	<monogr>
		<title level="m">23rd International Conference on Intelligent User Interfaces</title>
		<meeting><address><addrLine>Tokyo Japan</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="329" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A new readability yardstick</title>
		<author>
			<persName><forename type="first">Rudolph</forename><surname>Flesch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of applied psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">221</biblScope>
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">RealToxi-cityPrompts: Evaluating neural toxic degeneration in language models</title>
		<author>
			<persName><forename type="first">Suchin</forename><surname>Samuel Gehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.301</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3356" to="3369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Biyang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minqi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinran</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Wu</surname></persName>
		</author>
		<idno>arXiv.org</idno>
		<title level="m">How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection. arXiv.org. Place: Ithaca Publisher: Cornell University Library</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Laura Hanu and Unitary team</title>
		<ptr target="https://github.com/unitaryai/detoxify" />
	</analytic>
	<monogr>
		<title level="j">Detoxify. Github</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The future of the english sentence. Visible language</title>
		<author>
			<persName><forename type="first">Brock</forename><surname>Haussamen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ChatGPT for good? On opportunities and challenges of large language models for education</title>
		<author>
			<persName><forename type="first">Enkelejda</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathrin</forename><surname>Sessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Küchemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Bannert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daryna</forename><surname>Dementieva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urs</forename><surname>Gasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Groh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eyke</forename><surname>Hüllermeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stepha</forename><surname>Krusche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gitta</forename><surname>Kutyniok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tilman</forename><surname>Michaeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Nerdel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Pfeffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandra</forename><surname>Poquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Sailer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albrecht</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tina</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jochen</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jochen</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.lindif.2023.102274</idno>
	</analytic>
	<monogr>
		<title level="j">Learning and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page">102274</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">2021a. Gender and representation bias in GPT-3 generated stories</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Lucy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.nuse-1.5</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Narrative Understanding</title>
		<meeting>the Third Workshop on Narrative Understanding</meeting>
		<imprint>
			<publisher>Virtual. Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">2021b. Gender and Representation Bias in GPT-3 Generated Stories</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Lucy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.nuse-1.5</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Narrative Understanding</title>
		<meeting>the Third Workshop on Narrative Understanding</meeting>
		<imprint>
			<publisher>Virtual. Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m">Microsoft deletes racist, genocidal tweets from AI chatbot Tay -Business Insider</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Little red riding hood goes around the globe:crosslingual story planning and generation with large language models</title>
		<author>
			<persName><forename type="first">Evgeniia</forename><surname>Razumovskaia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Weisfeiler-lehman graph kernels</title>
		<author>
			<persName><forename type="first">Nino</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">TattleTale -Storytelling with Planning and Large Language Models</title>
		<author>
			<persName><forename type="first">Nisha</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Muise</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Explore the future earth with wander 2.0: Ai chatbot driven by knowledge-base story generation and text-to-image model</title>
		<author>
			<persName><forename type="first">Yuqian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Hee</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Asadipour</surname></persName>
		</author>
		<idno type="DOI">10.1145/3544549.3583931</idno>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems, CHI EA &apos;23</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">EtriCA: Event-Triggered Context-Aware Story Generation Augmented by Cross Attention</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henglin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Guerin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihao</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2210.12463</idno>
		<idno>ArXiv:2210.12463</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<ptr target="https://github.com/tatsu-lab/stanford_alpaca" />
		<title level="m">Stanford alpaca: An instruction-following llama model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<title level="m">Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Khuyen</forename><surname>Tran</surname></persName>
		</author>
		<title level="m">Topic Modelling Exploration Tool That Every NLP Data Scientist Should Know</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Narayanan Venkit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjana</forename><surname>Gautam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruchi</forename><surname>Panchanadikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shomir</forename><surname>Ting-Hao 'kenneth' Huang</surname></persName>
		</author>
		<author>
			<persName><surname>Wilson</surname></persName>
		</author>
		<title level="m">Nationality bias in text generation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Self-instruct: Aligning language model with self generated instructions</title>
		<author>
			<persName><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeganeh</forename><surname>Kordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alisa</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Neural lexicons for slot tagging in spoken language understanding</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-2011</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="83" to="89" />
		</imprint>
	</monogr>
	<note>Industry Papers)</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Jingwen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mackie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megan</forename><surname>Mckenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Kilayko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><forename type="middle">C</forename><surname>Macbeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smith</forename><surname>Edu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smith</forename><surname>Edu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smith</forename><surname>Edu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smith</forename><surname>Edu</surname></persName>
		</author>
		<title level="m">Interleaving a Symbolic Story Generator with a Neural Network-Based Large Language Model</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Smith Edu, and Smith Edu</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Artificial Intelligence education for young children: Why, what, and how in curriculum design and implementation</title>
		<author>
			<persName><forename type="first">Weipeng</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.caeai.2022.100061</idno>
	</analytic>
	<monogr>
		<title level="j">Computers and Education: Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">100061</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Wordcraft: Story Writing With Large Language Models</title>
		<author>
			<persName><forename type="first">Ann</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Coenen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
		</author>
		<idno type="DOI">10.1145/3490099.3511105</idno>
	</analytic>
	<monogr>
		<title level="m">27th International Conference on Intelligent User Interfaces, IUI &apos;22</title>
		<meeting><address><addrLine>New York, NY, USA; Finland</addrLine></address></meeting>
		<imprint>
			<publisher>Helsinki</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="841" to="852" />
		</imprint>
	</monogr>
	<note>Event-place</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Bartscore: Evaluating generated text as text generation</title>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="27263" to="27277" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Susan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dewan</surname></persName>
		</author>
		<imprint>
			<pubPlace>Mona Diab, Xian Li, Xi Victoria Lin</pubPlace>
		</imprint>
	</monogr>
	<note>et al. 2022. Opt: Open pre-trained transformer language models</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<title level="m">Bertscore: Evaluating text generation with bert</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

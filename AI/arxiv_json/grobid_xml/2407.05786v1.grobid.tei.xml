<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large Language Models for Judicial Entity Extraction: A Comparative Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-07-08">8 Jul 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Atin</forename><forename type="middle">S</forename><surname>Hussain</surname></persName>
							<email>atin.s@u.nus.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anu</forename><surname>Thomas</surname></persName>
							<email>anu_t@sgcaruvithura.ac.in</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Applications</orgName>
								<address>
									<settlement>St.George&apos;s College Aruvithura</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large Language Models for Judicial Entity Extraction: A Comparative Study</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-07-08">8 Jul 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">E423747035A34F59AAE22394D8844EBE</idno>
					<idno type="arXiv">arXiv:2407.05786v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Large language Models</term>
					<term>Natural Language Processing</term>
					<term>Judicial Domain</term>
					<term>Judicial Entity Recognition</term>
					<term>Information Extraction</term>
					<term>Court Judgments</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Domain-specific Entity Recognition holds significant importance in legal contexts, serving as a fundamental task that supports various applications such as question-answering systems, text summarization, machine translation, sentiment analysis, and information retrieval specifically within case law documents. Recent advancements have highlighted the efficacy of Large Language Models in natural language processing tasks, demonstrating their capability to accurately detect and classify domainspecific facts (entities) from specialized texts like clinical and financial documents. This research investigates the application of Large Language Models in identifying domain specific entities (e.g., courts, petitioner, judge, lawyer, respondents, FIR nos.) within case law documents, with a specific focus on their aptitude for handling domain-specific language complexity and contextual variations. The study evaluates the performance of state-of-the-art Large Language Model architectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in the context of extracting judicial facts tailored to Indian judicial texts. Mistral and Gemma emerged as the top-performing models, showcasing balanced precision and recall crucial for accurate entity identification. These findings confirm the value of Large Language Models in judicial documents and demonstrate how they can facilitate and quicken scientific research by producing precise, organised data outputs that are appropriate for in-depth examination.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Domain-specific entity recognition is a pivotal component in the realm of natural language processing, especially within specialized domains such as the legal field. The task involves identifying and classifying judicial entities such as petitioner, respondents, and judges, attorneys etc. which are foundational for a variety of applications. These applications include relation extraction, , machine translation, sentiment analysis at the entity level, faceted search, knowledge base construction, and information retrieval <ref type="bibr" target="#b8">Thomas and Sangeetha (2019)</ref> . Finding domain-specific entities and their relationships helps improve the indexing and retrieval of legal texts and is helpful as a first step in feature selection for text clustering, classification, as well as information selection for text summarization. Furthermore, a well-tuned entity recognition(ER) system forms a basis for various applications in the legal domain as follows.</p><p>Legal Question-answering system: Judicial facts are essential in determining the responses to factoid queries. For instance, if the query is, "Who is the appellant in a particular judge-ment?" The answer will be predicted by the question processing module to be some judicial entity. In the event that "Mr. X" is the response and the data set has judicial entities assigned to it, the question-answering system would recognise that "Mr. X" is an entity and that it may be the response.</p><p>Creation of a knowledge graph: We can present the textual data in graphical form, such as entityrelationship graphs, if we could identify the NEs in the judicial text and the relationships among those entities. These graphs can be used to answer complicated relationship inquiries. Moreover, text summary is facilitated by the detection and annotation of the most pertinent information associated with a NE. <ref type="bibr" target="#b9">Thomas and Sangeetha (2022)</ref> Case-Based Reasoning: The foundation of casebased reasoning is the knowledge input that may be obtained from extracted information found in court language. This information can be fed into a variety of expert systems, including business intelligence tools and predictive analytics software. <ref type="bibr" target="#b7">Thomas (2024)</ref> Relation Extraction (RE): Entity Recognition plays a pivotal role in relation extraction from judicial text by identifying key entities such as names of judges, plaintiffs, defendants, legal entities, and locations mentioned within the text. Once these entities are identified, RE identifies the relationships between them, aiding in the extraction of pertinent legal relations, such as "defendant accused of crime," "plaintiff filed a lawsuit against defendant," or "court ruled in favor of plaintiff." <ref type="bibr" target="#b10">Thomas and Sivanesan (2022)</ref>. Moreover, relation triplets can be utilized as features for other machine learning applications, such text categorization, document summarization, paraphrase detection, and so on.</p><p>The capabilities of ER systems have significantly advanced with the introduction of Large Language Models (LLMs). Equipped with advanced natural language processing methods, LLMs have shown to be extraordinarily adept in identifying and classifying objects in a wide range of complex texts. They excel at understanding and processing natural language, which makes them well-suited to handle the complexities of legal documents, which frequently include complex context and specialized terminologies.</p><p>Through this exploration, we aim to shed light on the potential of LLMs to revolutionize ER in legal texts with zero-shot learning, paving the way for more efficient and accurate information retrieval and management within the judicial system.</p><p>The key contribution of this paper is:</p><p>â€¢ Evaluating the effectiveness of cutting-edge LLMs (like LLaMA 3 (Large Language Model Meta AI 3), Mistral, and Gemma) for domain-specific ER tasks within Indian legal texts.</p><p>The paper is structured as follows. Section 2 explores the related works. Section 3 explains the state-of-the-art LLMs. Section 4 discusses the proposed methodology followed by results and discussions in section 5. Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>The field of generic Named Entity Recognition (NER) has seen substantial advancements, particularly with the integration of machine learning and deep learning techniques. Early approaches relied on rule-based and statistical methods, such as Hidden Markov Models (HMMs) and Conditional Random Fields (CRFs), which, while effective to some extent, often struggled with domainspecific language and lacked generalization capabilities.</p><p>The introduction of neural network-based models marked a significant leap in NER performance. Recurrent Neural Networks (RNNs), and more specifically Long Short-Term Memory networks (LSTMs), improved the ability to capture sequential dependencies in text. The advent of attention mechanisms and Transformers further revolutionized the field, leading to the development of pre-trained language models such as BERT (Bidirectional Encoder Representations from Transformers). BERT's contextual understanding and fine-tuning abilities demonstrated remarkable improvements in NER tasks across various domains.</p><p>In the legal domain, specialized ER systems have been developed to address the unique challenges posed by legal texts, including the use of complex terminology and context-specific references. Models like Legal-BERT <ref type="bibr" target="#b2">[Chalkidis et al. (2020)</ref>] and CaseLaw-BERT <ref type="bibr" target="#b5">[Paul et al. (2023)</ref>], which are pre-trained on legal corpora, have shown promise in enhancing entity recognition within legal documents. However, these models often require extensive domain-specific training data to achieve optimal performance.</p><p>Recent advancements in LLMs have further pushed the boundaries of NER capabilities. Models such as GPT-3 and its successors have exhibited exceptional proficiency in understanding and generating human-like text, which translates into improved accuracy in entity recognition tasks. The emergence of models such as LLaMA 3 and Gemma represents the latest frontier in this evolution, promising even greater performance through enhanced architectural innovations and larger training datasets. LLMs hold the added advantage of not having to be trained on legal datasets for domain-specific ER tasks.</p><p>This study builds on these advancements by evaluating the effectiveness of LLMs including LLaMA 3 [AI@Meta (2024)], Gemma <ref type="bibr">[Team et al. (2024)</ref>], Phi3 <ref type="bibr" target="#b0">[Abdin et al. (2024)</ref>] and Mistral <ref type="bibr">[Jiang et al. (2023)</ref>] in performing domain specific ER tasks within the context of Indian judicial texts with system prompting. By focusing on these state-of-the-art models, we aim to contribute to the growing body of research that seeks to harness the power of LLMs for specialized applications in the legal domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Large Language Models</head><p>This paper compares the following 4 different state-of-the-art Large Language Models in the task of domain specific Entity Recognition for legal documents:</p><p>â€¢ LLaMA 3 [AI@Meta (2024)] : The latest generation of Meta's open-source large language model, represents a significant advancement in natural language processing capabilities, making it highly suitable for complex tasks such as Entity Recognition (ER) in legal documents. Featuring models with up to 70 billion parameters, LLaMA 3 excels in understanding and generating human-like text, demonstrating state-of-the-art performance across various benchmarks. Its enhanced architecture, including a more efficient tokenizer and grouped query attention, ensures superior inference efficiency and accuracy. These improvements make LLaMA 3 particularly effective in handling the specialized terminology and nuanced context typical of legal texts, thereby facilitating precise entity identification and categorization critical for legal information retrieval and document management.</p><p>â€¢ Gemma <ref type="bibr">[Team et al. (2024)</ref>] : Developed by Google DeepMind and other teams across Google, represents a family of lightweight, state-of-the-art open models designed for high performance and broad accessibility. Available in two sizes, Gemma 2B and Gemma 7B, these models are optimized for diverse AI applications, including Entity Recognition (ER) in legal documents.</p><p>Gemma models are pre-trained and instruction-tuned, allowing them to efficiently handle the complex and domainspecific language found in case law texts. They surpass significantly larger models on key benchmarks, making them suitable for deployment on various platforms, from laptops to cloud infrastructures like Google Cloud. The incorporation of advanced finetuning techniques and robust evaluation processes ensures Gemma models produce safe and reliable outputs, crucial for maintaining the integrity of legal document processing. By leveraging these capabilities, the Gemma model holds promise for enhancing the accuracy and efficiency of ER tasks in the legal domain.</p><p>â€¢ Phi 3 <ref type="bibr" target="#b0">[Abdin et al. (2024)</ref>] : The model, developed by Microsoft, represents a significant advancement in small language models (SLMs), offering exceptional performance and cost-effectiveness. Particularly relevant to Entity Recognition tasks in legal documents, Phi-3 models, such as the Phi-3-mini, excel due to their ability to handle long context windows up to 128K tokens. This capacity is crucial for processing extensive legal texts, ensuring comprehensive entity recognition across large document spans. Phi-3's instruction-tuned design and optimized performance across various hardware platforms, including on-device use, facilitate efficient and accurate ER in resource-constrained environments. The model's strong reasoning and logic capabilities further enhance its suitability for the analytical demands of legal document processing, providing a powerful tool for improving the efficiency and accuracy of legal information retrieval.</p><p>â€¢ Mistral <ref type="bibr">[Jiang et al. (2023)</ref>] : A powerful 7.3 billion parameter language model, demonstrates remarkable capabilities in natural language processing tasks, outperforming larger models like Llama 2 13B across various benchmarks. Utilizing advanced techniques such as Grouped-query attention (GQA) and Sliding Window Attention (SWA), Mistral 7B achieves faster inference and handles longer sequences more efficiently. These features make it particularly suitable for ER tasks in legal documents, which often involve processing extensive texts with complex domain-specific language. The model's ability to be fine-tuned easily for specific tasks further enhances its applicability in the legal domain, where precision and context understanding are crucial. Given its superior performance and efficiency, Mistral 7B is well-equipped to improve the accuracy and effectiveness of ER systems in legal document analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head><p>In this study, we employ few-shot prompt engineering to leverage the capabilities of large language models for judicial ER in legal documents. This technique involves crafting a single, carefully designed prompt that instructs the LLM to generate responses in a specified JSON format. The JSON response includes both the extracted text and the corresponding entity labels from the input document. This approach is particularly advantageous as it eliminates the necessity for extensive task-specific training. By directly utilizing the pre-trained LLM's advanced natural language understanding, we can efficiently identify and label entities within legal texts, streamlining the process and reducing the overhead typically associated with model training and fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Setup</head><p>We evaluate the model on the InLegalNER dataset <ref type="bibr" target="#b4">[Kalamkar et al. (2022)</ref>] to rigorously assess the performance of Large Language Models on domain-specific Entity Recognition tasks. The InLegalNER dataset is specifically designed to encompass a comprehensive range of entities pertinent to the legal domain, thereby providing a robust benchmark for evaluating the capability of LLMs in recognizing and categorizing legal entities accurately. Table <ref type="table" target="#tab_0">1</ref> presents a detailed breakdown of the various entities included in the dataset, offering insights into the diversity and complexity of the entity types that the models are required to identify. This evaluation aims to highlight the effectiveness of LLMs in handling the specialized terminology and context inherent in legal documents, thereby contributing to the advancement of ER methodologies in this critical domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Model Evaluation</head><p>In our study, we evaluated the performance of several state-of-the-art large language models for the Entity Recognition task within legal documents. The models evaluated include LLaMA 3,  The LLaMA model demonstrated a precision of 0.7366, a recall of 0.6286, and an F1 score of 0.5917. While the model shows high precision, indicating a strong ability to correctly identify relevant entities, its recall is relatively lower, suggesting some missed entities within the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">Gemma Evaluation</head><p>The Gemma model yielded a precision of 0.7131, a recall of 0.6534, and an F1 score of 0.6353. Gemma's balanced precision and recall indicate a more consistent performance in identifying entities correctly and ensuring fewer missed entities, resulting in a higher F1 score compared to LLaMA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.">Mistral Evaluation</head><p>The Mistral model achieved a precision of 0.7097, a recall of 0.6628, and an F1 score of 0.6376. Mis-tral's performance is similar to Gemma, with a slightly lower precision but higher recall, which translates to a marginally better F1 score. This suggests that Mistral is effective in identifying a comprehensive set of entities while maintaining a reasonable level of accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4.">Phi 3 Evaluation</head><p>The PHI3 model showed a precision of 0.5975, a recall of 0.5617, and an F1 score of 0.5440. PHI3's lower precision and recall indicate challenges in both correctly identifying and not missing entities, resulting in the lowest F1 score among the evaluated models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Comparative Analysis</head><p>Overall, Mistral emerged as the best-performing model with the highest F1 score of 0.6376, closely followed by Gemma with an F1 score of 0.6353. Both models demonstrated a good balance between precision and recall, making them suitable for the NER task in legal documents. LLaMA 3, despite its higher precision, lagged in recall, indicating potential gaps in entity recognition. Phi 3 showed the least favorable performance across all metrics, suggesting it is less suited for this specific task compared to the other models evaluated.</p><p>These evaluations underscore the importance of considering both precision and recall in ER tasks, particularly in the legal domain where the accurate and comprehensive identification of entities is crucial. The results highlight Mistral and Gemma as robust options for further exploration and deployment in legal ER applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In conclusion, our study evaluated several state-of-the-art LLMs for legal entity recognition from Case Law Documents, focusing on their performance in handling domain-specific language within Indian judicial texts. Mistral and Gemma emerged as the top-performing models, showcasing balanced precision and recall crucial for accurate entity identification. These findings underscore the potential of LLMs to revolutionize ER in legal documents, offering efficient and precise entity recognition capabilities that benefit legal information management and analysis. Continued advancements in LLM architectures hold promise for further enhancing ER systems in the legal domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Funding</head><p>This study received no external funding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Competing interests</head><p>The authors declare that they have no competing interests</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Availability of data and materials</head><p>The used and/or during the current study (the bibliography of included studies) are available from the corresponding author upon request.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>InLegalNER Dataset Entity Information</figDesc><table><row><cell>Named Entity</cell><cell>Description</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Evaluation of the LLM Models</figDesc><table><row><cell>Model</cell><cell>Precision</cell><cell>Recall</cell><cell>F1 Score</cell></row><row><cell>LLaMA 3</cell><cell>0.7366</cell><cell>0.6286</cell><cell>0.5917</cell></row><row><cell>Gemma</cell><cell>0.7131</cell><cell>0.6534</cell><cell>0.6353</cell></row><row><cell>Mistral</cell><cell>0.7097</cell><cell>0.6628</cell><cell>0.6376</cell></row><row><cell>Phi 3</cell><cell>0.5975</cell><cell>0.5617</cell><cell>0.5440</cell></row><row><cell cols="3">5.2.1. LLaMA 3 Evaluation</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p><ref type="bibr" target="#b0">July 9, 2024</ref> </p></note>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Not applicable.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Abdin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Awan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aneja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Awadalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bahree</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bakhtiari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Behl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Benhaim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bilenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bjorck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C T</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Giorno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Fragoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Haider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hewett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Javaheripi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kauffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Karampatziakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khademi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kurilenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazzola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Modi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Norick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perez-Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Portet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Radmilac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ruwase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Saarikivi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saied</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Santacroce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tupini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Witte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wyatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-07-09">2024. July 9, 2024</date>
		</imprint>
	</monogr>
	<note>Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><surname>Ai@meta</surname></persName>
		</author>
		<title level="m">Llama 3 Model Card</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LEGAL-BERT: The Muppets straight out of Law School</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fergadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Aletras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2898" to="2904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bressand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Lavaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lacroix</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Sayed, W.E., 2023. Mistral 7B</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Named Entity Recognition in Indian court judgments</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kalamkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Raghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Natural Legal Language Processing Workshop 2022, Association for Computational Linguistics</title>
		<meeting>the Natural Legal Language Processing Workshop 2022, Association for Computational Linguistics<address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>United Arab Emirates (Hybrid)</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="184" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pretrained Language Models for the Legal Domain: A Case Study on Indian Law</title>
		<author>
			<persName><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law</title>
		<meeting>the Nineteenth International Conference on Artificial Intelligence and Law<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="187" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">G</forename><surname>Team</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mesnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dadashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhupatiraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>RiviÃ¨re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Love</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tafti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hussenot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Sessa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Botev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Castro-Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Slone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>HÃ©liou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bulanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Paterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shahriari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Choquette-Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Crepy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Muraru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rozhdestvenskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tenney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Grishchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Labanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stanway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mao-Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Sjoesund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>MikuÅ‚a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chinaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wahltinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yotov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chaabouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Comanescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcilroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mullins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Girgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pandya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shakeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Klimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Stokowiec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hui Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Warkentin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Giang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Collins</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Joulin, A., Fiedel, N., Senter, E., Andreev, A., Kenealy, K., 2024. Gemma: Open Models Based on Gemini Research and Technology</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Exploring the Power of AI-Driven Decision Making in the Judicial Domain</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>Case Studies, Benefits, Challenges, and Solutions</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An innovative hybrid approach for extracting named entities from unstructured text data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sangeetha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="799" to="826" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Knowledge graph based question-answering system for effective case law analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sangeetha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolution in Computational Intelligence: Proceedings of the 9th International Conference on Frontiers in Intelligent Computing: Theory and Applications (FICTA 2021)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="291" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An adaptable, highperformance relation extraction system for complex sentences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sivanesan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">251</biblScope>
			<biblScope unit="page">108956</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

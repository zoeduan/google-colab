<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multilingual Large Language Model: A Survey of Resources, Taxonomy and Frontiers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-04-07">7 Apr 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
							<email>lbqin@csu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Central South University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qiguang</forename><surname>Chen</surname></persName>
							<email>qgchen@ir.hit.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Harbin Institute of Technology ♢ Shanghai AI Laboratory ♮ Tsinghua University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuhang</forename><surname>Zhou</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Harbin Institute of Technology ♢ Shanghai AI Laboratory ♮ Tsinghua University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhi</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yinghui</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">♮</forename><forename type="middle">Lizi</forename><surname>Liao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Min</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Central South University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">♣</forename><surname>Wanxiang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Harbin Institute of Technology ♢ Shanghai AI Laboratory ♮ Tsinghua University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Che</forename><forename type="middle">♠</forename><surname>Philip</surname></persName>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Yu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">InstructGPT Tk-Instruct GPTNeoX</orgName>
								<orgName type="institution" key="instit1">Management University</orgName>
								<orgName type="institution" key="instit2">University of Illinons at Chicago</orgName>
								<orgName type="institution" key="instit3">CREA-ICL 2020</orgName>
								<address>
									<addrLine>2021 2022 2023 2024 GPT3 mT5 GShard M2M nmT5 ByT5 CPM-2 HyperCLOVA OPT PaLM ChatGPT Luminous GLM FlanPaLM GPT4 Sabia LLaMA BLOOM WeLM ParroT ChatGLM umT5 mLongT5 PolyLM Baichuan Bayling Phoenix EcomGPT CrossAlpaca m-LLaMA BLOOMz InternLM Jurassic-2 Qwen Huozi Moss Tim LLaMA PaLM2</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multilingual Large Language Model: A Survey of Resources, Taxonomy and Frontiers</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-04-07">7 Apr 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">2FF93840CECBE23F8049EC4C06ED9A72</idno>
					<idno type="arXiv">arXiv:2404.04925v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multilingual Large Language Models are capable of using powerful Large Language Models to handle and respond to queries in multiple languages, which achieves remarkable success in multilingual natural language processing tasks. Despite these breakthroughs, there still remains a lack of a comprehensive survey to summarize existing approaches and recent developments in this field. To this end, in this paper, we present a thorough review and provide a unified perspective to summarize the recent progress as well as emerging trends in multilingual large language models (MLLMs) literature. The contributions of this paper can be summarized: (1) First survey: to our knowledge, we take the first step and present a thorough review in MLLMs research field according to multi-lingual alignment; (2) New taxonomy: we offer a new and unified perspective to summarize the current progress of MLLMs; (3) New frontiers: we highlight several emerging frontiers and discuss the corresponding challenges; (4) Abundant resources: we collect abundant open-source resources, including relevant papers, data corpora, and leaderboards. We hope our work can provide the community with quick access and spur breakthrough research in MLLMs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, remarkable progress has been witnessed in large language models (LLMs) <ref type="bibr" target="#b28">(Brown et al., 2020;</ref><ref type="bibr">Touvron et al., 2023a;</ref><ref type="bibr" target="#b343">Bang et al., 2023;</ref><ref type="bibr">Zhao et al., 2023b)</ref>, which have achieved excellent performance on various natural language processing tasks <ref type="bibr" target="#b218">(Pan et al., 2023;</ref><ref type="bibr">Nguyen et al., 2023a;</ref><ref type="bibr" target="#b301">Trivedi et al., 2023)</ref>. In addition, LLMs raise surprising emergent capabilities, including in-context learning <ref type="bibr" target="#b196">(Min et al., 2022;</ref><ref type="bibr" target="#b73">Dong et al., 2022)</ref>, chain-of-thought reasoning <ref type="bibr" target="#b326">(Wei et al., 2022;</ref><ref type="bibr">Huang et al., 2023a;</ref><ref type="bibr">Qin et al., 2023a)</ref>, and even planning <ref type="bibr" target="#b75">(Driess et al., 2023;</ref><ref type="bibr">Hu et al., 2023b)</ref>. Nevertheless, the majority of LLMs are Englishcentric, primarily focusing on English tasks <ref type="bibr" target="#b106">(Held et al., 2023;</ref><ref type="bibr">Zhang et al., 2023i)</ref>, which makes them somewhat weak for multilingual settings, especially in low-resource scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>* Equal Contribution</head><p>Actually, there are over 7,000 languages in the world. With the acceleration of globalization, the success of large language models should be considered to serve diverse countries and languages. To this end, multilingual large language models (MLLMs) possess the advantage of comprehensively handling multiple languages, gaining increasing attention. Specifically, the existing MLLMs can be broadly divided into two groups based on different stages. The first series of works <ref type="bibr">(Xue et al., 2020;</ref><ref type="bibr" target="#b338">Workshop et al., 2022;</ref><ref type="bibr">Zhang et al., 2023g;</ref><ref type="bibr" target="#b201">Muennighoff et al., 2022)</ref>  data to tuning the parameters to boost the overall multilingual performance. The second series of work <ref type="bibr">(Shi et al., 2022a;</ref><ref type="bibr">Qin et al., 2023b;</ref><ref type="bibr">Huang et al., 2023a</ref>) also adapt the advanced prompting strategies to unlock deeper multilingual potential of MLLMs during parameter-frozen inference stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>leverage multilingual</head><p>While remarkable success has been achieved in the MLLMs, there still remains a lack of a comprehensive review and analysis of recent efforts in the literature, which hinders the development of MLLMs. To bridge this gap, we make the first attempt to conduct a comprehensive and detailed analysis of MLLMs. Concretely, we first introduce the widely used data resource ( §3). Furthermore, due to the key challenge of alignment across languages, we introduce a novel taxonomy according to alignment strategies ( §4), aiming to provide a unified perspective in the literature, which includes: parameter-tuning alignment and parameter-frozen alignment (as shown in Figure <ref type="figure" target="#fig_0">1</ref>). Specifically, parameter-tuning alignment requires the fine-tuning of model parameters to enhance alignment between English and target languages during pre-training, supervised fine-tuning, reinforcement learning from human feedback and downstream fine-tuning. parameter-frozen alignment refers to the alignment achieved by prompting across languages that can be achieved without the need for parameter tuning. Finally, we point out some potential frontier areas as well as the corresponding challenges for MLLMs, hoping to inspire the follow-up research ( §5). We hope that this work can serve as a valuable resource for researchers and inspire more breakthroughs in future research<ref type="foot" target="#foot_0">foot_0</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminary</head><p>In this section, we will formally describe the definitions of monolingual large language model ( §2.1) and multilingual large language model ( §2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Monolingual Large Language Model</head><p>Monolingual large language models (LLM) can only process one language at a time. For example, as illustrated in Figure <ref type="figure" target="#fig_3">3</ref> (a), English and Chinese LLM can separately handle English and Chinese language, respectively. Formally, considering a set of languages L = {L i } |L| i=0 , given input utterance X i ∈ L i in languages L i , the process of monolingual LLM (M mono ) generating the output Y i can be defined as:</p><formula xml:id="formula_0">Y i = M mono (X i , L i ), mono = L i ; Unexpect, mono ̸ = L i ,<label>(1)</label></formula><p>where Unexpect indicates that the LLM generates output in an unintended language; mono denotes the single language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multilingual Large Language Model</head><p>As shown in Figure <ref type="figure" target="#fig_3">3</ref> (b), unlike monolingual LLM, a multilingual LLM is capable of handling and producing content in various languages simultaneously, like English and Chinese. Formally, for MLLM M multi , where multi ⊆ L and |multi| ≥ 2, the model's response is given by:</p><formula xml:id="formula_1">Y = M multi (X ),<label>(2)</label></formula><p>where X and Y belong to multiple languages, multi.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data Resource</head><p>In this section, we describe the widely used data resources in pre-training ( §3.1), supervised finetuning (SFT) ( §3.2) and reinforcement learning from human feedback (RLHF) ( §3.3) stage <ref type="bibr">(Zhao et al., 2023b)</ref> for multilingual large language model. Detailed statistics can be found in Table <ref type="table">1</ref> and Table 2 in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multilingual Pretraining Data</head><p>The widely used multilingual corpora for pretraining in MLLMs can be divided into 3 categories:</p><p>(1) Manual Creation: obtains high-quality pretraining corpora through manual creation and proofreading, which consists of the Bible Corpus <ref type="bibr" target="#b192">(Mayer and Cysouw, 2014)</ref> and MultiUN <ref type="bibr" target="#b401">(Ziemski et al., 2016)</ref>. ( <ref type="formula" target="#formula_1">2</ref>) Web Crawling: involves crawling extensive multilingual data from the internet, which includes OSCAR <ref type="bibr" target="#b282">(Suárez et al., 2019)</ref>, CC-100 <ref type="bibr" target="#b57">(Conneau et al., 2020)</ref>, mC4 <ref type="bibr">(Xue et al., 2021)</ref> and <ref type="bibr">Redpajama-v2 (Computer, 2023)</ref>. Another series of data are extracted from Wikipedia to enhance the knowledge of MLLMs. Common datasets include Wikipedia (Foundation) , WikiMatrix <ref type="bibr" target="#b264">(Schwenk et al., 2021)</ref> and WikiExpl <ref type="bibr" target="#b102">(Han et al., 2023)</ref>. ( <ref type="formula">3</ref>) Benchmark Adaptation: means re-cleaning or integrating existing benchmarks to enhance data quality which includes OPUS-100 <ref type="bibr">(Zhang et al., 2020)</ref>, Culturax <ref type="bibr">(Nguyen et al., 2023c)</ref>, OPUS (Tiedemann, 2012), WMT <ref type="bibr" target="#b141">(Kocmi et al., 2023)</ref> and <ref type="bibr">ROOTS (Laurençon et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multilingual SFT Data</head><p>Similarly, we categorize the existing multilingual SFT data into 4 classes: (1) Manual Creation: acquires SFT corpora through manual creation and proofreading, which includes Sup-NatInst <ref type="bibr">(Wang et al., 2022b)</ref>, OpenAssist <ref type="bibr" target="#b145">(Köpf et al., 2023)</ref> and COIG-PC lite <ref type="bibr">(Team, 2023a)</ref>.</p><p>(2) Machine Translation: translates the existing monolingual datasets into multilingual instruction datasets, which comprises xP3-MT <ref type="bibr" target="#b201">(Muennighoff et al., 2022)</ref>, MGSM8K Instruct <ref type="bibr">(Chen et al., 2023b)</ref>, CrossAlpaca <ref type="bibr">(Ranaldi et al., 2023b;</ref><ref type="bibr" target="#b62">Cui et al., 2023)</ref>, MultilingualSIFT <ref type="bibr">(Chen et al., 2023i)</ref> and Bactrain-X <ref type="bibr">(Li et al., 2023b)</ref>. (3) Benchmark Adaptation: involves transformation from existing benchmarks to instruction format. Widely used datasets include xP3 <ref type="bibr" target="#b201">(Muennighoff et al., 2022)</ref>, PolyglotPrompt <ref type="bibr" target="#b83">(Fu et al., 2022), and</ref><ref type="bibr">BUF-FET (Asai et al., 2023)</ref>. ( <ref type="formula">4</ref>) MLLMs Aided Generation: means that the data are automatically synthesized by the MLLMs, containing Vicuna <ref type="bibr" target="#b48">(Chiang et al., 2023)</ref>, OverMiss <ref type="bibr">(Chen et al., 2023g)</ref>, <ref type="bibr" target="#b269">ShareGPT (ShareGPT, 2023)</ref>, BELLE (Yunjie Ji, 2023), MultiAlpaca <ref type="bibr">(Wei et al., 2023c)</ref>, Guanaco <ref type="bibr" target="#b70">(Dettmers et al., 2023)</ref> and Alpaca-4 <ref type="bibr" target="#b224">(Peng et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Taxonomy ( §4)</head><p>Parameter-Tuning Alignment ( §4.1)</p><p>Pretraining Alignment ( §4.1.1)</p><p>From-scratch Pretraining Alignment e.g., GPT3 <ref type="bibr" target="#b28">(Brown et al., 2020)</ref>, mT5 <ref type="bibr">(Xue et al., 2020)</ref>, ERNIE3.0 <ref type="bibr" target="#b285">(Sun et al., 2021)</ref>, HyperCLOVA <ref type="bibr" target="#b138">(Kim et al., 2021)</ref>, nmT5 <ref type="bibr">(Kale et al., 2021)</ref>, WeLM <ref type="bibr" target="#b281">(Su et al., 2022)</ref>, BLOOM <ref type="bibr" target="#b338">(Workshop et al., 2022)</ref>, OPT <ref type="bibr" target="#b382">(Zhang et al., 2022)</ref>, GPT-NeoX <ref type="bibr" target="#b22">(Black et al., 2022)</ref>, PaLM <ref type="bibr" target="#b50">(Chowdhery et al., 2022)</ref>, GLM <ref type="bibr" target="#b370">(Zeng et al., 2022)</ref>, XGLM <ref type="bibr">(Lin et al., 2022a)</ref>, ByT5 <ref type="bibr" target="#b348">(Xue et al., 2022)</ref>, mGPT <ref type="bibr" target="#b274">(Shliazhko et al., 2022</ref><ref type="bibr">), umT5(Chung et al., 2022a)</ref>, <ref type="bibr" target="#b24">Blevins and Zettlemoyer (2022)</ref>, mLongT5 <ref type="bibr" target="#b308">(Uthus et al., 2023)</ref>, LLaMA <ref type="bibr">(Touvron et al., 2023a,b)</ref>, <ref type="bibr" target="#b169">Liang et al. (2023)</ref>, Skywork <ref type="bibr">(Wei et al., 2023a)</ref>, VCT <ref type="bibr" target="#b205">(Muraoka et al., 2023)</ref>, <ref type="bibr" target="#b27">Briakou et al. (2023)</ref>,CLS <ref type="bibr" target="#b261">(Schioppa et al., 2023)</ref>,Jasmine <ref type="bibr" target="#b1">(Abdul-Mageed et al., 2023</ref><ref type="bibr">), Mistral Holmström et al. (2023)</ref>, <ref type="bibr" target="#b129">(Jiang et al., 2023</ref><ref type="bibr" target="#b126">(Jiang et al., , 2024))</ref>, Turna <ref type="bibr" target="#b305">(Uludogan et al., 2024)</ref>, <ref type="bibr" target="#b23">Blevins et al. (2024)</ref> Continual Pretraining Alignment e.g., CPM-2 <ref type="bibr" target="#b388">(Zhang et al., 2021)</ref>, X-Gen <ref type="bibr" target="#b312">(Vu et al., 2022</ref><ref type="bibr">), FinGPT(Luukkonen et al., 2023)</ref>, Cabrita <ref type="bibr" target="#b153">(Larcher et al., 2023</ref><ref type="bibr">),LLaMAntino(Basile et al., 2023)</ref>,AFP <ref type="bibr">(Li et al., 2023a)</ref>, Sabia <ref type="bibr" target="#b230">(Pires et al., 2023)</ref>, ChineseLLaMA <ref type="bibr" target="#b62">(Cui et al., 2023)</ref>, ChineseMixtral (HIT-SCIR, 2024)</p><p>SFT Alignment ( §4.1.2) e.g., <ref type="bibr">Flan-PaLM (Chung et al., 2022b)</ref>, Tk-Instruct <ref type="bibr">(Wang et al., 2022b)</ref>, mT0, BLOOMz <ref type="bibr" target="#b201">(Muennighoff et al., 2022)</ref>, PolyLM <ref type="bibr">(Wei et al., 2023c)</ref>, PULI-GPT <ref type="bibr">(Yang et al., 2023f)</ref>, Chinese-Alpaca <ref type="bibr" target="#b62">(Cui et al., 2023)</ref>, YuLan <ref type="bibr">(Team, 2023d)</ref>, mAlpaca <ref type="bibr">(Chen et al., 2023c)</ref>, Bayling <ref type="bibr">(Zhang et al., 2023g)</ref>, Phoenix <ref type="bibr">(Chen et al., 2023h)</ref>, OverMiss <ref type="bibr">(Chen et al., 2023g)</ref>, CrossAlpaca <ref type="bibr">(Ranaldi et al., 2023a)</ref>, EcomGPT <ref type="bibr">(Li et al., 2023h)</ref>, SWIE <ref type="bibr">(Chen et al., 2023g)</ref>, Camoscio <ref type="bibr" target="#b260">(Santilli and Rodolà, 2023)</ref>, <ref type="bibr">Bao et al. (2023</ref><ref type="bibr" target="#b143">), Kohli et al. (2023)</ref>, <ref type="bibr" target="#b112">Holmström and Doostmohammadi (2023)</ref>, m-LLaMA <ref type="bibr" target="#b400">(Zhu et al., 2023)</ref>, InstructAlign <ref type="bibr">(Cahyawijaya et al., 2023b)</ref>,mFTI <ref type="bibr">(Li et al., 2023c)</ref>,PaLM2 <ref type="bibr" target="#b20">(Anil et al., 2023)</ref>, <ref type="bibr" target="#b87">Gao et al. (2024)</ref>, <ref type="bibr" target="#b306">Upadhayay and Behzadan (2023)</ref>, ParroT <ref type="bibr" target="#b130">(Jiao et al., 2023)</ref>, <ref type="bibr" target="#b32">Chai et al. (2024)</ref>, <ref type="bibr" target="#b399">Zhu et al. (2024)</ref>, Bode <ref type="bibr" target="#b88">(Garcia et al., 2024)</ref> RLHF Alignment ( §4.1.3) e.g., GPT3.5 (OpenAI, 2022), ChatGLM <ref type="bibr" target="#b370">(Zeng et al., 2022)</ref>, GPT4 (OpenAI, 2023), Okapi <ref type="bibr">(Lai et al., 2023b)</ref>, LLaMA2-Chat <ref type="bibr">(Touvron et al., 2023b)</ref>, MOSS <ref type="bibr">(Sun et al., 2023b)</ref>, Baichuan <ref type="bibr">(Yang et al., 2023a)</ref>, Huozi <ref type="bibr">(Team, 2023b)</ref>, <ref type="bibr">Qwen (Bai et al., 2023)</ref>, InternLM <ref type="bibr">(Team, 2023c)</ref>, TigerBot <ref type="bibr">(Chen et al., 2023f)</ref>, YAYI-2 <ref type="bibr">(Luo et al., 2023b)</ref>,TIM <ref type="bibr">(Zeng et al., 2023b)</ref>, <ref type="bibr">Yang et al. (2023c)</ref>, SteerLM <ref type="bibr" target="#b74">(Dong et al., 2023)</ref>,Salmon <ref type="bibr">(Sun et al., 2023c)</ref>,Moura <ref type="bibr" target="#b245">Ramos et al. (2023)</ref>,MAPO <ref type="bibr" target="#b270">(She et al., 2024)</ref>, Orion <ref type="bibr" target="#b35">(Chen et al., 2024)</ref> Downstream Finetuning Alignment ( §4.1.4)</p><p>Full-Parameter Finetuning Alignment e.g.,GShard <ref type="bibr" target="#b157">(Lepikhin et al., 2020)</ref>,M2M <ref type="bibr" target="#b78">(Fan et al., 2021)</ref>,Linguist <ref type="bibr">(Rosenbaum et al., 2022b)</ref>,AlexTM (Soltan et al., 2022),NLLB(Costa-jussà et al., 2022a),LLM-T(Awasthi et al., 2022),Bapna et al. ( <ref type="formula">2022</ref>), <ref type="bibr">(Winata et al., 2022a)</ref>, <ref type="bibr" target="#b302">Tseng and Lin (2022)</ref>, BigTrans <ref type="bibr">(Yang et al., 2023d)</ref>, ALMA <ref type="bibr">(Xu et al., 2023a)</ref>, µPLAN <ref type="bibr" target="#b333">(Huot et al., 2023)</ref>, MMNMT <ref type="bibr">(Li et al., 2023e)</ref>, LegoMT <ref type="bibr" target="#b367">(Yuan et al., 2023)</ref>, SWIM-X <ref type="bibr">(Thakur et al., 2023b)</ref>,Gen-X <ref type="bibr">(Whitehouse et al., 2023a)</ref>,CAD <ref type="bibr" target="#b67">(De Raedt et al., 2023)</ref>, <ref type="bibr">Xu et al. (2023c)</ref>, <ref type="bibr" target="#b125">Iyer et al. (2023)</ref>, Bansal and Sharma (2023), <ref type="bibr" target="#b252">Reinauer et al. (2023)</ref> Parameter-Effient Finetuning Alignment e.g., BLOOM+ <ref type="bibr" target="#b363">(Yong et al., 2022)</ref>, XSGD <ref type="bibr" target="#b303">(Tu et al., 2023)</ref>, QAmeleon <ref type="bibr">(Agrawal et al., 2022a)</ref>, HyperLoRA <ref type="bibr" target="#b169">(Xiao et al., 2023)</ref>, <ref type="bibr" target="#b203">(Mujadia et al., 2023)</ref>, <ref type="bibr">(Moslem et al., 2023b)</ref>, <ref type="bibr" target="#b222">Park et al. (2023)</ref>, <ref type="bibr">Whitehouse et al. (2023b)</ref>, LangBridge <ref type="bibr">(Yoon et al., 2024)</ref>, MAPLE <ref type="bibr" target="#b7">(Aggarwal et al., 2024)</ref>, <ref type="bibr">LAMPAT (Le et al., 2024)</ref> Parameter-Frozen Alignment ( §4.2)</p><p>Direct Prompting e.g., CLCTS <ref type="bibr">(Zhang et al., 2023e)</ref>, Native-CoT <ref type="bibr">(Shi et al., 2022a)</ref>, CB <ref type="bibr" target="#b206">(Nambi et al., 2023)</ref>, Bansal and Sharma ( <ref type="formula">2023</ref> Translation Alignment Prompting e.g., Trans-En <ref type="bibr">(Lin et al., 2021b;</ref><ref type="bibr">Shi et al., 2022a)</ref>, Chain-of-Dict <ref type="bibr" target="#b181">(Lu et al., 2023)</ref>, Self-Translate <ref type="bibr" target="#b77">(Etxaniz et al., 2023)</ref>, XLT <ref type="bibr">(Huang et al., 2023a)</ref>, CLP, CLSP <ref type="bibr">(Qin et al., 2023b)</ref>, DecoMT <ref type="bibr">(Puduppully et al., 2023b)</ref>, X-InSTA <ref type="bibr" target="#b287">(Tanwar et al., 2023)</ref>, CoDec <ref type="bibr">(Zeng et al., 2023a)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Taxonomy</head><p>As shown in Figure <ref type="figure" target="#fig_5">4</ref>, we introduce a novel taxonomy including parameter-tuning alignment ( §4.1) and parameter-frozen alignment ( §4.2), which aims to provide a unified view for researchers to understand the MLLMs literature. Specifically, parameter tuning alignment (PTA) comprises a series of progressively advanced training and alignment strategies, including Pretraining Alignment, Super-vised Fine-Tuning (SFT) Alignment, Reinforcement Learning from Human Feedback (RLHF) Alignment, and, ultimately, Downstream Fine-Tuning Alignment. These stages collectively aim to refine model parameters to align the multilingual performance systematically. Conversely, the parameter frozen alignment (PFA) focuses on four prompting strategies based on PTA: Direct Prompting, Code-Switching Prompting, Translation Alignment Prompting, and Retrieval-Augmented Alignment. This method maintains the original model parameters to achieve desired outcomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Parameter-Tuning Alignment</head><p>Parameter-tuning alignment indicates that MLLMs should tune their parameters for better cross-lingual alignment <ref type="bibr" target="#b331">(Wen-Yi and Mimno, 2023)</ref>. As shown in Figure <ref type="figure" target="#fig_6">5</ref>, we discuss the four categories of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">PTA in Pretraining Stage</head><p>From-scratch Pretraining Alignment. A series of approaches have achieved to alignment across languages by tuning the initially random parameters of MLLMs during pretraining (see Figure <ref type="figure" target="#fig_6">5</ref> (a)). Specifically, <ref type="bibr" target="#b24">Blevins and Zettlemoyer (2022)</ref>; <ref type="bibr" target="#b27">Briakou et al. (2023)</ref>; <ref type="bibr">Holmström et al. (2023)</ref> observed that adding a few multilingual data during the from-scratch pretraining alignment, even unintentionally, can significantly boost the multilingual performance. Inspired by this, <ref type="bibr" target="#b370">Zeng et al. (2022)</ref>; <ref type="bibr" target="#b281">Su et al. (2022)</ref> used bilingual data in their fromscratch pretraining for alignment. mT5 <ref type="bibr">(Xue et al., 2020)</ref>, Ernie3.0 <ref type="bibr" target="#b285">(Sun et al., 2021)</ref>, ByT5 <ref type="bibr" target="#b348">(Xue et al., 2022)</ref>, BLOOM <ref type="bibr" target="#b338">(Workshop et al., 2022)</ref>, LLaMA <ref type="bibr">(Touvron et al., 2023b,a)</ref>, PaLM <ref type="bibr" target="#b50">(Chowdhery et al., 2022)</ref>, Mistral <ref type="bibr" target="#b129">(Jiang et al., 2023)</ref>, Mixtral <ref type="bibr" target="#b126">(Jiang et al., 2024)</ref>, PolyLM <ref type="bibr">(Wei et al., 2023c)</ref>  Continual Pretraining Alignment. To address the high computational cost of from-scratch pretraining, continual pretraining alignment builds the pretraining process upon pretrained MLLMs (as shown in Figure <ref type="figure" target="#fig_6">5</ref> (a)). Specifically, CPM-2 <ref type="bibr" target="#b388">(Zhang et al., 2021)</ref>, Sabia <ref type="bibr" target="#b230">(Pires et al., 2023)</ref>, <ref type="bibr">FinGPT (Luukkonen et al., 2023)</ref>, X-Gen <ref type="bibr" target="#b312">(Vu et al., 2022)</ref>, AFP <ref type="bibr">(Li et al., 2023a)</ref>, Cabrita <ref type="bibr" target="#b153">(Larcher et al., 2023)</ref>, <ref type="bibr">LLaMAntino (Basile et al., 2023)</ref> focused on adding more target language data during continual pretraining for general performance. Further, <ref type="bibr" target="#b62">Cui et al. (2023)</ref>; HIT-SCIR (2024) emphasized extending the MLLMs' vocabularies to adapt to new languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">PTA in SFT Stage</head><p>As illustrated in Figure <ref type="figure" target="#fig_6">5</ref> (b), PTA in SFT stage means leveraging multiple multilingual task data with instruction format for tuning parameters <ref type="bibr" target="#b83">(Fu et al., 2022;</ref><ref type="bibr">Yang et al., 2023f;</ref><ref type="bibr">Team, 2023d;</ref><ref type="bibr">Chen et al., 2023c,g;</ref><ref type="bibr">Ranaldi et al., 2023a;</ref><ref type="bibr">Li et al., 2023h;</ref><ref type="bibr">Chen et al., 2023g;</ref><ref type="bibr" target="#b260">Santilli and Rodolà, 2023;</ref><ref type="bibr">Bao et al., 2023;</ref><ref type="bibr" target="#b143">Kohli et al., 2023;</ref><ref type="bibr" target="#b112">Holmström and Doostmohammadi, 2023;</ref><ref type="bibr" target="#b88">Garcia et al., 2024)</ref>. In particular, models like Flan-PaLM (Chung et al., 2022b), mT0, BLOOMz <ref type="bibr" target="#b201">(Muennighoff et al., 2022)</ref>, PolyLM <ref type="bibr">(Wei et al., 2023c)</ref>, Tk-Instruct <ref type="bibr">(Wang et al., 2022b)</ref>, Chinese-Alpaca <ref type="bibr" target="#b62">(Cui et al., 2023)</ref>, Bayling <ref type="bibr">(Zhang et al., 2023g)</ref> and Phoenix <ref type="bibr">(Chen et al., 2023h)</ref>, directly incorporated multilingual data in the SFT stage to achieve implicit multilingual alignment across languages. Besides, to solve the scarcity of multilingual SFT task data, PaLM2 <ref type="bibr" target="#b20">(Anil et al., 2023)</ref>  <ref type="formula">2024</ref>) began to consider using a more effective SFT alignment strategy to optimize the reasoning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">PTA in RLHF Stage</head><p>As shown in Figure <ref type="figure" target="#fig_6">5</ref> (c), to achieve alignment in reinforcement learning from human feedback (RLHF) stage, Okapi (Lai et al., 2023b), LLaMA2-Chat <ref type="bibr">(Touvron et al., 2023b)</ref>, Chat-GLM <ref type="bibr" target="#b370">(Zeng et al., 2022)</ref>, MOSS <ref type="bibr">(Sun et al., 2023b)</ref>, Baichuan <ref type="bibr">(Yang et al., 2023a)</ref>, Huozi <ref type="bibr">(Team, 2023b)</ref>, <ref type="bibr">Qwen (Bai et al., 2023)</ref>, InternLM <ref type="bibr">(Team, 2023c)</ref>, ParroT <ref type="bibr" target="#b130">(Jiao et al., 2023)</ref>, TigerBot <ref type="bibr">(Chen et al., 2023f)</ref>, MOSS <ref type="bibr">(Sun et al., 2023b)</ref>, YAYI-2 <ref type="bibr">(Luo et al., 2023b)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">PTA in Downstream Finetuning Stage</head><p>Full-Parameter Finetuning Alignment Fullparameter finetuning in MLLMs means tuning all parameters in downstream tasks (see Figure <ref type="figure" target="#fig_6">5 (d)</ref>). Specifically, GShard <ref type="bibr" target="#b157">(Lepikhin et al., 2020)</ref>, Linguist <ref type="bibr">(Rosenbaum et al., 2022b)</ref> Parameter-Efficient Finetuning Alignment A series of studies employ Parameter-Efficient Finetuning (PEFT) alignment approaches for reducing full-parameter fine-tuning costs <ref type="bibr" target="#b363">(Yong et al., 2022;</ref><ref type="bibr" target="#b203">Mujadia et al., 2023;</ref><ref type="bibr">Moslem et al., 2023b)</ref>, which is shown in Figure <ref type="figure" target="#fig_6">5</ref>  Takeaways (1) PTA in pretraining stage brings the essential multilingual capabilities of the MLLMs. (2) The effectiveness of alignment in MLLMs is greatly influenced by previous alignment stage, (e.g. Pretraining will significantly influence SFT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parameter-Frozen Alignment</head><p>In contrast to the traditional parameter-tuning approaches <ref type="bibr" target="#b363">(Zheng et al., 2022)</ref>, parameter-frozen alignment methods aim to perform alignment without any parameter tuning. The most popular approaches employ prompting strategies to elicit the alignment potential of MLLMs. As shown in Figure <ref type="figure" target="#fig_13">6</ref>, this section discusses four prompting strategies for alignment without parameter tuning, which include (1) Direct Prompting, (2) Code-Switching Prompting, (3) Translation Alignment Prompting and (4) Retrieval Augmented Alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Direct Prompting</head><p>As shown in Figure <ref type="figure" target="#fig_13">6</ref> (a), Direct Prompting means directly outputting the request without any additional instruction for implicit alignment through MLLM itself <ref type="bibr" target="#b0">(Abdelali et al., 2023;</ref><ref type="bibr">Zhang et al., 2023e;</ref><ref type="bibr">Wang et al., 2023b,d;</ref><ref type="bibr">Lin et al., 2022b;</ref><ref type="bibr">Bansal and Sharma, 2023;</ref><ref type="bibr">Wei et al., 2023b;</ref><ref type="bibr" target="#b233">Pourkamali and Sharifi, 2024)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Code-Switching Prompting</head><p>As shown in Figure <ref type="figure" target="#fig_13">6</ref> (b), it integrates multilingual words into a single-language utterance, which is a typical language phenomenon <ref type="bibr">(Winata et al., 2022b;</ref><ref type="bibr">Dogruöz et al., 2023a,b)</ref> for effective language alignment <ref type="bibr" target="#b241">(Qin et al., 2020</ref><ref type="bibr" target="#b240">(Qin et al., , 2022))</ref>. Specifically, <ref type="bibr" target="#b364">Yong et al. (2023)</ref>; <ref type="bibr" target="#b19">Amin et al. (2023)</ref> showed the effectiveness of MLLMs in cross-Based on the conditions in the question, Jessa is 20 years old... If Jessa is 20 years old, then Mary's age is 20 -2 = 18 years old... Therefore, the total age of these three girls is 68 years. English Request: Mary is two years younger than Joan, and Joan is five years older than Jessica. Assuming Jessica is currently 20 years old, what is the total age of these three girls? lingual alignment through model-generated codeswitching texts. Furthermore, <ref type="bibr">Zhang et al. (2023f)</ref> suggested the need for fairer and more detailed code-switching optimization for further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Translation Alignment Prompting</head><p>Translation alignment prompting approaches mean that translating the query into other languages for better alignment (see Figure <ref type="figure" target="#fig_13">6 (c</ref>)), which can be divided into the following classes: (1) Key Information Translation: This approach focuses on extracting key information and executing translation for word-level cross-lingual alignment <ref type="bibr" target="#b181">(Lu et al., 2023;</ref><ref type="bibr">Li et al., 2023i)</ref>. (2) Direct Translation: the model directly translates the whole input, enhancing alignment performance <ref type="bibr" target="#b77">(Etxaniz et al., 2023;</ref><ref type="bibr">Zhang et al., 2023a;</ref><ref type="bibr">Cheng et al., 2023a;</ref><ref type="bibr" target="#b225">Petrick et al., 2023;</ref><ref type="bibr" target="#b111">Hoang et al., 2023;</ref><ref type="bibr">Zeng et al., 2023a;</ref><ref type="bibr" target="#b206">Nambi et al., 2023;</ref><ref type="bibr">Lin et al., 2021b)</ref>. (3) Stepby-step Translation: Instead of direct translation, this method prompts MLLMs to translate whole input step-by-step <ref type="bibr">(Puduppully et al., 2023a;</ref><ref type="bibr">Moslem et al., 2023a;</ref><ref type="bibr" target="#b249">Raunak et al., 2023;</ref><ref type="bibr" target="#b340">Wu and Hu, 2023;</ref><ref type="bibr">Puduppully et al., 2023b;</ref><ref type="bibr" target="#b229">Pilault et al., 2023)</ref>. ( <ref type="formula">4</ref>) Restatement: Beyond preserving original semantics, some studies focus on prompting MLLM to restate multilingual inputs to enhance cross-lingual effectiveness <ref type="bibr">(Shi et al., 2022a;</ref><ref type="bibr" target="#b223">Patel et al., 2022;</ref><ref type="bibr">Rosenbaum et al., 2022a;</ref><ref type="bibr">Asai et al., 2023;</ref><ref type="bibr">Qin et al., 2023b;</ref><ref type="bibr">Huang et al., 2023a;</ref><ref type="bibr" target="#b287">Tanwar et al., 2023)</ref>. Further, considering the differences in multiple languages <ref type="bibr" target="#b215">(Ohmer et al., 2023)</ref>, <ref type="bibr">Qin et al. (2023b)</ref>; <ref type="bibr">Ranaldi et al. (2023a)</ref> integrated knowledge and translation strategy across different languages by cross-lingual prompting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Retrieval Augmented Alignment</head><p>Retrieval Augmented Alignment incorporates external retrieval during prompting to inject more knowledge in MLLMs (see Figure <ref type="figure" target="#fig_13">6 (d)</ref>). Specifically, <ref type="bibr">He et al. (2023b)</ref>; <ref type="bibr">Zhang et al. (2023d)</ref>; <ref type="bibr" target="#b56">Conia et al. (2023)</ref>; <ref type="bibr">Xu et al. (2023d)</ref>; Ahmad (2024) focus on retrieving cultural or professional knowledge to enrich prompts. Another series of work focused on retrieval for high-quality alignment demonstrations, yielding significant improvements <ref type="bibr">(Shi et al., 2022b;</ref><ref type="bibr">Agrawal et al., 2022b;</ref><ref type="bibr">Li et al., 2023g;</ref><ref type="bibr">Winata et al., 2023b;</ref><ref type="bibr" target="#b89">Garcia et al., 2023;</ref><ref type="bibr">Li et al., 2023f;</ref><ref type="bibr" target="#b245">Ramos et al., 2023;</ref><ref type="bibr">Kim et al., 2023a;</ref><ref type="bibr">Thakur et al., 2023a)</ref>.</p><p>Takeaways (1) Translation alignment prompting is more effective for crosslingual alignment. (2) Retrieval augmented alignment mitigates knowledge gaps in LLM.</p><p>5 Future work and New Froniter</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Hallucination in MLLMs</head><p>While remarkable progress has been achieved in MLLMs, the current approaches still face hallucination issues <ref type="bibr" target="#b248">(Raunak et al., 2021)</ref>. Specifically, Guerreiro et al. (2023a); <ref type="bibr" target="#b11">Aharoni et al. (2023)</ref>; <ref type="bibr" target="#b64">Dale et al. (2023)</ref>; <ref type="bibr" target="#b242">Qiu et al. (2023)</ref> have previously pointed out the hallucination phenomenon on current MLLM. Further, a series of works provide corresponding solutions in the pre-training <ref type="bibr" target="#b227">(Pfeiffer et al., 2023)</ref>, SFT <ref type="bibr">(Chen et al., 2023g)</ref> and decoding <ref type="bibr" target="#b15">(Ahuja et al., 2022;</ref><ref type="bibr">Yang et al., 2023e;</ref><ref type="bibr" target="#b275">Sia et al., 2023;</ref><ref type="bibr">Zeng et al., 2023a)</ref> stages.</p><p>The key challenges in this direction include: (1) Multilingual Hallucination Detection: How to effectively detect the hallucination phenomenon of MLLM across different languages is the primary problem to be solved in this field. (2) Multilingual Hallucination Alleviation: Current strategies for hallucination alleviation still focus on incorporating extensive factual data or utilizing external systems, which pose significant challenges for multiple languages, especially low-resource languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Knowledge Editing in MLLMs</head><p>The current MLLMs still face challenges with inaccurate, inconsistent, and outdated knowledge across different languages, which limits their performance. To solve this issue, <ref type="bibr">Wu et al. (2023)</ref>; <ref type="bibr">Wang et al. (2023c)</ref> introduce a multilingual knowledge editing approach and propose a new benchmark for knowledge editing in MLLM. In addition, <ref type="bibr" target="#b237">Qi et al. (2023)</ref> introduce the cross-lingual consistency metric to ensure factual consistency across languages. Additionally, <ref type="bibr">Wang et al. (2023e)</ref> incorporate a multilingual knowledge base into MLLMs with retrieval methods to facilitate knowledge editing.</p><p>The key challenges of this research include: (1) Continuous Knowledge Editing: How to continuously integrate new knowledge while preserving the accuracy of existing knowledge is a core challenge to explore. (2) Balancing Universal and Language-Specific Knowledge: Current work often neglects language-specific details like culture and slang, impacting user experience and causing cultural conflicts <ref type="bibr" target="#b106">(Held et al., 2023;</ref><ref type="bibr">Beniwal et al., 2024)</ref>. How to balance universal knowledge, while preserving language-specific knowledge presents a fascinating question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Safety in MLLMs</head><p>With the development and application of MLLMs, researchers have found that MLLMs often suffer some serious moral <ref type="bibr">(Costa-jussà et al., 2022b;</ref><ref type="bibr" target="#b259">Sánchez et al., 2023)</ref> and privacy <ref type="bibr" target="#b187">(Macko et al., 2023)</ref> risks, hindering the development of MLLMs <ref type="bibr">(Wang et al., 2023f;</ref><ref type="bibr">Ye et al., 2023b;</ref><ref type="bibr" target="#b101">Hämmerl et al., 2022;</ref><ref type="bibr" target="#b271">Shen et al., 2024)</ref>. Therefore, how to improve the safety of MLLMs is a promising research question.</p><p>The main challenges for safe MLLM are as follows: (1) Lack of Safety Benchmark: The lack of safe data in current literature hampers the relevant research. Consequently, acquiring a large-scale safety dataset to facilitate future research has become a hot topic. (2) Removal of Unsafe Data: The multilingual data generated by MLLMs poses potential unsafe risks during training <ref type="bibr">(Wang et al., 2023h)</ref>. Therefore, identifying and filtering out unsafe multilingual content is a crucial issue <ref type="bibr" target="#b38">(Bogoychev et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Fairness in MLLMs</head><p>Multilingual fairness refers to equal treatment and performance across languages and cultures <ref type="bibr" target="#b94">(Yu et al., 2022;</ref><ref type="bibr" target="#b274">Shliazhko et al., 2022)</ref>. But there is a significant performance gap between languages, especially on low-resource languages <ref type="bibr" target="#b190">(Malkin et al., 2022;</ref><ref type="bibr">Sengupta et al., 2023;</ref><ref type="bibr">Ye et al., 2023a)</ref>. Additionally, token consumption also varies by language in MLLMs, leading to unequal computational costs <ref type="bibr" target="#b144">(Koishekenov et al., 2022;</ref><ref type="bibr" target="#b119">Hua et al., 2023;</ref><ref type="bibr">Nicosia and Piccinno, 2022;</ref><ref type="bibr" target="#b348">Xue et al., 2022;</ref><ref type="bibr">Sun et al., 2023a;</ref><ref type="bibr" target="#b257">Rust et al., 2022)</ref>.</p><p>The main concerns regarding fairness in MLLM are as follows: (1) Low-resource language performance improvement: It is essential to improve the performance of low-resource languages with limited data <ref type="bibr">(Lin et al., 2023;</ref><ref type="bibr">Ansell et al., 2023;</ref><ref type="bibr" target="#b5">Adeyemi et al., 2023)</ref>. ( <ref type="formula" target="#formula_1">2</ref>) Multilingual Token Cost Improvement: Current tokenizer exhibits biases in segmenting different languages, leading to varying token costs <ref type="bibr" target="#b226">(Petrov et al., 2023;</ref><ref type="bibr" target="#b12">Ahia et al., 2023;</ref><ref type="bibr" target="#b18">Ali et al., 2023)</ref>. Addressing this challenge is essential for ensuring fairer tokenization across languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Language Extension in MLLMs</head><p>Due to the limited languages supported by current work, integrating new languages into existing MLLM is a promising direction to explore <ref type="bibr" target="#b135">(Kew et al., 2023;</ref><ref type="bibr" target="#b268">Shaham et al., 2024)</ref>. To this end, Cui et al. ( <ref type="formula">2023</ref> This challenge encompasses two main aspects: (1) Multiple Languages Extension: How to dynamically and effectively extend the languages for MLLMs is an interesting research question. (2) Original Languages Preserving: Since the expansion of the model in other languages will harm the original language performance, how to prevent the language extension in MLLM from forgetting the previously learned language is a major challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Multi-Modality Extension in MLLMs</head><p>Since the improvement in the usability of MLLM, a large amount of work has begun to further extend MLLM into visual modality <ref type="bibr" target="#b90">(Geigle et al., 2023;</ref><ref type="bibr" target="#b41">Chen et al., 2022</ref><ref type="bibr">Chen et al., , 2023d,e;,e;</ref><ref type="bibr" target="#b245">Ramos et al., 2023;</ref><ref type="bibr">Bai et al., 2023;</ref><ref type="bibr">Zhou et al., 2023;</ref><ref type="bibr">Hu et al., 2023a;</ref><ref type="bibr" target="#b398">Zhou, 2023;</ref><ref type="bibr">He et al., 2023a;</ref><ref type="bibr" target="#b99">Guo et al., 2023)</ref>, speech modality <ref type="bibr">(Huang et al., 2023b</ref><ref type="bibr" target="#b121">(Huang et al., , 2024;;</ref><ref type="bibr">Cheng et al., 2023b</ref>), video modality <ref type="bibr" target="#b289">(Team et al., 2023)</ref> and even other modalities.</p><p>This field faces two main challenges: (1) Complex Reasoning Exploration: Current multi-modal MLLMs are limited to simple cross-modal crosslingual tasks, with a need for more exploration in complex reasoning. (2) Comprehensive Benchmark: The current literature lacks comprehensive benchmarks, which hinders progress and evaluation in this evolving field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we present a comprehensive survey of the advancements in multilingual large language models (MLLMs). Specifically, we provide a new taxonomy for MLLMs from alignment perspectives, which can offer a unified view for researchers to understand the progress of MLLMs. In addition, we highlight some emerging trends and frontiers as well as their corresponding challenges in MLLMs. We hope this work can facilitate the research and inspire more breakthroughs in MLLMs literature.</p><p>Alan Ansell, Marinela Parović, Ivan Vulić, Anna Korhonen, and Edoardo Ponti. 2023. Unifying crosslingual transfer across scenarios of resource scarcity. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 3980-3995. Mikel Artetxe, Vedanuj Goswami, Shruti Bhosale, Angela Fan, and Luke Zettlemoyer. 2023. Revisiting machine translation for cross-lingual classification. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 6489-6499, Singapore. Association for Computational Linguistics. Mikel Artetxe, Sebastian Ruder, and Dani Yogatama. 2020. On the cross-lingual transferability of monolingual representations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4623-4637, Online. Association for Computational Linguistics. Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu, Terra Blevins, Hila Gonen, Machel Reid, Yulia Tsvetkov, Sebastian Ruder, and Hannaneh Hajishirzi. 2023. Buffet: Benchmarking large language models for few-shot cross-lingual transfer. arXiv preprint arXiv:2305.14857. Abhijeet Awasthi, Nitish Gupta, Bidisha Samanta, Shachi Dave, Sunita Sarawagi, and Partha Talukdar. 2022. Bootstrapping multilingual semantic parsers using large language models. arXiv preprint arXiv:2210.07313. Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. 2023. Qwen technical report. arXiv preprint arXiv:2309.16609. Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. 2023. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023. Parikshit Bansal and Amit Sharma. 2023. Large language models as annotators: Enhancing generalization of nlp models at minimal cost. arXiv preprint arXiv:2306.15766. Eliseo Bao, Anxo Pérez, and Javier Parapar. 2023. Conversations in galician: a large language model for an underrepresented language. arXiv preprint arXiv:2311.03812. Ankur Bapna, Isaac Caswell, Julia Kreutzer, Orhan Firat, Daan van Esch, Aditya Siddhant, Mengmeng Niu, Pallavi Baljekar, Xavier Garcia, Wolfgang Macherey, et al. 2022. Building machine translation systems for the next thousand languages. arXiv preprint arXiv:2205.03983. Pierpaolo Basile, Elio Musacchio, Marco Polignano, Lucia Siciliani, Giuseppe Fiameni, and Giovanni Semeraro. 2023. Llamantino: Llama 2 models for effective text generation in italian language. arXiv preprint arXiv:2312.09993. Rachel Bawden, Eric Bilinski, Thomas Lavergne, and Sophie Rosset. 2021. Diabla: a corpus of bilingual spontaneous written dialogues for machine translation. Language Resources and Evaluation, 55:635-660. Marco Bellagente, Manuel Brack, Hannah Teufel, Felix Friedrich, Björn Deiseroth, Constantin Eichenberg, Andrew Dai, Robert Baldock, Souradeep Nanda, Koen Oostermeijer, et al. 2023. Multifusion: Fusing pre-trained models for multi-lingual, multi-modal image generation. arXiv preprint arXiv:2305.15296. Himanshu Beniwal, Mayank Singh, et al. 2024. Crosslingual editing in multilingual language models. arXiv preprint arXiv:2401.10521. Aleksandrs Berdičevskis, Gerlof Bouma, Robin Kurtz, Felix Morger, Joey Öhman, Yvonne Adesam, Lars Borin, Dana Dannélls, Markus Forsberg, Tim Isbister, et al. 2023. Superlim: A swedish language understanding evaluation benchmark. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 8137-8153.</p><p>To facilitate the comparison of LLMs, extensive efforts have been invested in exploring enhanced evaluation methods for multilingual scenarios. This discussion will elaborate on MLLM evaluation, covering both (1) Evaluation Metrics and (2) Evaluation Benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Evaluation Metrics</head><p>Traditional Automatic Metric means that we assess predicted output using probabilities or pretrained language model logits <ref type="bibr">(Liu et al., 2023c;</ref><ref type="bibr" target="#b402">Zouhar and Bojar, 2024)</ref>. Generally speaking, researchers use BLEU <ref type="bibr" target="#b221">(Papineni et al., 2002)</ref>, BLEURT <ref type="bibr" target="#b266">(Sellam et al., 2020)</ref>, chrF++ <ref type="bibr" target="#b232">(Popović, 2017)</ref> and COMET <ref type="bibr" target="#b251">(Rei et al., 2020)</ref> for translation evaluation, and use ROUGE <ref type="bibr" target="#b172">(Lin, 2004)</ref> for summary evaluation. Further, <ref type="bibr">Guerreiro et al. (2023b)</ref> proposed xCOMET for better translation evaluation through fine-grained error detection. In assessing the general quality of generated text, the commonly employed approach is the utilization of multi-lingual BERTScore <ref type="bibr">(Zhang* et al., 2020)</ref> as an evaluation metric. <ref type="bibr">Qin et al. (2023b)</ref> extended Roscoe <ref type="bibr" target="#b94">(Golovneva et al., 2022)</ref> to multilanguage for quality assessment of multi-lingual CoT. Further, <ref type="bibr" target="#b110">Hlavnova and Ruder (2023)</ref> developed a comprehensive and robust multi-lingual checklist system to thoroughly assess the MLLMs' performance.</p><p>MLLM-based Automatic Metric employs robust MLLMs to score or compare generated outputs for evaluation purposes <ref type="bibr">(Li et al., 2023b;</ref><ref type="bibr">Zhang et al., 2023g;</ref><ref type="bibr" target="#b310">Vernikos and Popescu-Belis, 2024)</ref>. Specifically, <ref type="bibr" target="#b364">Zheng et al. (2023)</ref> introduced LLMas-a-Judge, where GPT4 is prompted to assess the performance of other LLMs by comparing its output to the predicted one. However, this method discussed remains unreliable in multilingual settings <ref type="bibr" target="#b100">(Hada et al., 2023)</ref>. And caution should be exercised, particularly in languages where it is known that the MLLM has performed poorly. Furthermore, <ref type="bibr">Kim et al. (2023b)</ref>; <ref type="bibr" target="#b204">Muller et al. (2023)</ref> conducted attribution evaluation to deeply evaluate the robustness of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human Evaluation involves manually assessing</head><p>MLLMs through detailed evaluation <ref type="bibr">(Zhang et al., 2023g;</ref><ref type="bibr">Li et al., 2023b;</ref><ref type="bibr" target="#b1">Khondaker et al., 2023;</ref><ref type="bibr">Zhang et al., 2023a)</ref>. <ref type="bibr" target="#b185">Lyu et al. (2023)</ref> initially explored the multilingual challenges of ChatGPT through manually annotated cases. Furthermore, <ref type="bibr" target="#b117">Hu et al. (2024)</ref> introduced a new platform for more convenient manual assessments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Evaluation Benchmarks</head><p>Current MLLMs tend to pay more attention to the alignment effect of non-English languages. Based on the different angles of alignment, we divide it into two categories: (1) Natural Language Understanding;</p><p>(2) Natural Language Generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1 Natural Language Understanding</head><p>Linguistics Analysis For multilingual models, the most basic thing is to understand the linguistic differences between different languages <ref type="bibr">(Xu et al., 2023c)</ref>. The most common multilingual linguistics assessment includes Part-of-Speech (POS) <ref type="bibr" target="#b170">(Liang et al., 2020;</ref><ref type="bibr" target="#b369">Zeman et al., 2022)</ref>, grammar analysis <ref type="bibr">(Kwon et al., 2023b;</ref><ref type="bibr" target="#b17">Alhafni et al., 2023;</ref><ref type="bibr" target="#b195">Michaelov et al., 2023;</ref><ref type="bibr">Kwon et al., 2023a)</ref> and morphology <ref type="bibr" target="#b330">(Weissweiler et al., 2023</ref>). Furthermore, Zhang et al. (2023l); Song et al. (2022) conducted a comprehensive evaluation the linguistic acceptability of MLLM across languages. Semantic Understanding Researchers take more care of should be able to analyze and understand the specific semantics of multiple languages ( <ref type="bibr">Lai et al., 2023a;</ref><ref type="bibr" target="#b262">Schott et al., 2023;</ref><ref type="bibr" target="#b220">Panchendrarajan and Zubiaga, 2024)</ref>. The most basic is to perform local semantic understanding, and the most typical one is the information extraction task <ref type="bibr">(Wei et al., 2023b</ref><ref type="bibr">), including: masakhaNER (Adelani et al., 2021)</ref>, <ref type="bibr">MASSIVE (FitzGerald et al., 2022)</ref>, Multi-CoNER <ref type="bibr" target="#b191">(Malmasi et al., 2022;</ref><ref type="bibr" target="#b80">Fetahu et al., 2023)</ref>, WikiAnn <ref type="bibr" target="#b219">(Pan et al., 2019)</ref> and SMiLER <ref type="bibr" target="#b265">(Seganti et al., 2021)</ref> The second is the semantic understanding of complete sentences, including: XNLI <ref type="bibr" target="#b58">(Conneau et al., 2018)</ref>, Paws-X <ref type="bibr">(Yang et al., 2019b)</ref>, MixATIS++ <ref type="bibr" target="#b346">(Xu et al., 2020)</ref>, MTOP <ref type="bibr" target="#b161">(Li et al., 2020)</ref>, MultiNLU <ref type="bibr" target="#b263">(Schuster et al., 2018)</ref>, and PRESTO <ref type="bibr" target="#b92">(Goel et al., 2023)</ref>. Finally, there is the semantic understanding of the paragraph, like question-answering tasks with context: MLQA <ref type="bibr" target="#b158">(Lewis et al., 2019</ref><ref type="bibr">), XQuAD(Artetxe et al., 2020)</ref>, TyDiQA <ref type="bibr" target="#b54">(Clark et al., 2020)</ref> and X-PARADE <ref type="bibr" target="#b253">(Rodriguez et al., 2023)</ref>, X-CLAIM <ref type="bibr" target="#b197">(Mittal et al., 2023)</ref>, Readme++ <ref type="bibr">(Naous et al., 2023a)</ref>, XKaggle-DBQA <ref type="bibr">(Shi et al., 2022b)</ref> and <ref type="bibr" target="#b68">de Varda and Marelli (2023)</ref>. Due to the for practical scenario.</p><p>Reasoning Currently, the most commonly used reasoning ability assessments of MLLMs tend to focus on commonsense and mathematical reasoning <ref type="bibr">(Huang et al., 2023a;</ref><ref type="bibr">Qin et al., 2023b)</ref>. Specifically, commonsense reasoning includes XCOPA <ref type="bibr" target="#b231">(Ponti et al., 2020)</ref>, MARC <ref type="bibr" target="#b134">(Keung et al., 2020)</ref>, XWinograd <ref type="bibr" target="#b298">(Tikhonov and Ryabinin, 2021)</ref>, <ref type="bibr">GEOMLAMA (Yin et al., 2022)</ref>, X-CSQA <ref type="bibr">(Lin et al., 2021a)</ref>, XStoryCloze <ref type="bibr">(Lin et al., 2022a)</ref>, ASPEN <ref type="bibr" target="#b250">(Razumovskaia et al., 2022)</ref> and <ref type="bibr">Masakhanews (Adelani et al., 2023)</ref> . Additionally, mathematical reasoning includes MGSM <ref type="bibr">(Shi et al., 2022a)</ref> and WizardMath <ref type="bibr">(Luo et al., 2023a)</ref>. Due to the expensive annotations for multilingual reasoning, <ref type="bibr">Zhang et al. (2023i)</ref> propose a complex translation and filter process to construct a multilingual reasoning benchmark.</p><p>Coding Generation Coding generation requires that MLLMs can generate structured, executable code programs. The common-used benchmarks include XSPIDER <ref type="bibr">(Shi et al., 2022b)</ref>, XSEM-PLR <ref type="bibr">(Zhang et al., 2023k)</ref>, ODEX <ref type="bibr">(Wang et al., 2022d)</ref> and Mconala <ref type="bibr">(Wang et al., 2022c)</ref>.</p><p>Summarization To test the summarization ability of the model, the model is required to be able to summarize key information based on long texts. The simplest one, Ryan et al. ( <ref type="formula">2023</ref>) proposed a multi-lingual text reduction benchmark for the evaluation of MLLM. Secondly, a lot of work focuses on cross-lingual summarization. Typical data sets include: XSUM <ref type="bibr" target="#b209">(Narayan et al., 2018)</ref>, and Cross-Sum <ref type="bibr" target="#b21">(Bhattacharjee et al., 2021)</ref>. On this basis, <ref type="bibr">Wang et al. (2022a)</ref> introduced multilingual conversation summarization, and <ref type="bibr" target="#b380">Zhang and Eickhoff (2023)</ref> proposed the concept of code-switch in the evaluation, making it more practical. <ref type="bibr" target="#b307">Urlana et al. (2023)</ref> further proposed headline summarization for languages in India. SEAHORSE <ref type="bibr" target="#b53">(Clark et al., 2023)</ref> further extended them to the multifaceted multilingual summarization. In addition <ref type="bibr">Nguyen et al. (2023b)</ref>; <ref type="bibr" target="#b309">Verma et al. (2023)</ref> developed summarization benchmarks for multi-modal scenarios.</p><p>Dialogue The communication between models and humans is often interactive, so a lot of work pays attention to MLLMs' dialogue ability <ref type="bibr" target="#b26">(Boughorbel and Hawasly, 2023)</ref>. The current evaluation set includes xDial-Eval <ref type="bibr">(Zhang et al., 2023b)</ref>, Multi 3 WOZ <ref type="bibr">(Hu et al., 2023c)</ref>, DIA-LIGHT <ref type="bibr" target="#b117">(Hu et al., 2024)</ref>, HPD <ref type="bibr">(Chen et al., 2023a)</ref> and X-RiSAWOZ <ref type="bibr" target="#b198">(Moradshahi et al., 2023)</ref>. Since multiple rounds of dialogue are not controllable, traditional indicators cannot be used. Currently, we tend to use PLM for evaluation <ref type="bibr">(Mendonça et al., 2023a)</ref>. Furthermore, <ref type="bibr">Mendonça et al. (2023b)</ref> proposed a new benchmark, which can achieve more robust evaluation by coordinating with pretrained language models. <ref type="bibr" target="#b79">Ferron et al. (2023)</ref> proposed the MEEP benchmark to further evaluate the dialogue participation of MLLMs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Parameter-Tuning Alignment ( §4.1) v.s. Parameter-Frozen Alignment ( §4.2). The former requires the model to fine-tune the MLLM parameters for cross-lingual alignment, while the latter directly uses prompts for alignment without parameter tuning.</figDesc><graphic coords="1,371.15,352.50,146.72,162.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Evolution of selected MLLMs over the past five years, where colored branches indicate different alignment stages. For models with multiple alignment stages, the final stage is represented.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>The contributions of this work can be summarized as follows: (1) First survey: To the best of our knowledge, we are the first to present a comprehensive survey in the MLLMs literature according to multi-lingual alignment; (2) New taxonomy: We introduce a novel taxonomy categorizing MLLMs into two alignment types: parameter-frozen and parameter-tuning, offering a unified view for understanding the MLLMs literature; (3) New frontiers: We discuss some emerging frontiers and highlight their challenges as well as opportunities, hoping to pave the way for future research developments; (4) Exhaustive resources: We make the first attempt to organize MLLMs resources including open-source software, diverse corpora, and a curated list of relevant publications, accessible at https://multilingual-llm.net.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Monolingual Large Language Model v.s. Multilingual Large Language Model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>),<ref type="bibr" target="#b0">Abdelali et al. (2023)</ref>,Wang et al. (2023b,d),Wei et al. (2023b),<ref type="bibr" target="#b233">Pourkamali and Sharifi (2024)</ref> Code-Switching Prompting e.g.,<ref type="bibr" target="#b364">Yong et al. (2023)</ref>,<ref type="bibr" target="#b19">Amin et al. (2023)</ref>,Zhang et al. (2023f)    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Taxonomy of MLLMs which includes Parameter-Tuning Alignment Methodology and Parameter-Frozen Alignment Methodology.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Overview of Parameter-Tuning Alignment ( § 4.1) Methods, which including PTA in Pretraining Stage ( § 4.1.1), PTA in SFT stage ( § 4.1.2), PTA in RLHF stage ( § 4.1.3) and PTA in Downstream Finetuning stage ( § 4.1.4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>, Kale et al. (2021); Kim et al. (2021); Shliazhko et al. (2022); Chai et al. (2022); Schioppa et al. (2023); Abdul-Mageed et al. (2023); Uthus et al. (2023); Wei et al. (2023a); Uludogan et al.(2024)  incorporated multilingual data in pretraining stage for better alignment.<ref type="bibr" target="#b23">Blevins et al. (2024)</ref> utilizes Mixture-of-Experts (MoE) to independently train language models on subsets of multilingual corpora to alleviate the problem of multilingual parameter competition. Furthermore, to enhance the performance of low-resource languages, umT5(Chung et al., 2022a)  and XGLM(Lin et al.,  2022a)  adopted equitable data sampling methods during from-scratch pretraining.Muraoka et al.    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><figDesc>(2023) introduced VCT to leverage vision for indirect cross-lingual alignment in from-scratch pretraining.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><figDesc>, Zhu et al. (2023); Cahyawijaya et al. (2023b); Li et al. (2023c); Gao et al. (2024) added translation task during the SFT alignment stage to improve alignment. Further, Upadhayay and Behzadan (2023); Chai et al. (2024); Zhu et al. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><figDesc>,Yang et al. (2023c); Moura<ref type="bibr" target="#b245">Ramos et al. (2023)</ref> and Orion<ref type="bibr" target="#b35">(Chen et al., 2024)</ref> directly integrated multilingual RLHF data for training multilingual reward models. Additionally, Zeng et al. (2023b); Dong et al. (2023); She et al. (2024) introduced a multilingual reward model to compare translation outputs across different granularity. Sun et al. (2023c) proposed a Salmon framework, to enhance multilingual RLHF by self-generating rewards for better alignment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><figDesc>,<ref type="bibr" target="#b78">Fan et al. (2021)</ref>;Bapna et al. (2022);<ref type="bibr" target="#b302">Tseng and Lin (2022)</ref>;<ref type="bibr" target="#b125">Iyer et al. (2023)</ref>, NLLB(Costa-jussà et al., 2022a)   AlexTM(Soltan et al., 2022), and BigTrans(Yang  et al., 2023d)  focused on directly fine-tuning the full parameters across various downstream tasks (e.g., information extraction, machine translation). Xu et al. (2023c); Huot et al. (2023); Yuan et al. (2023); Li et al. (2023e) proposed multi-step or finegrained alignment strategies during full-parameter tuning. Furthermore, to enhance the efficiency, Awasthi et al. (2022); De Raedt et al. (2023); Thakur et al. (2023b); Whitehouse et al. (2023a); Bansal and Sharma (2023); Xu et al. (2023a); Reinauer et al. (2023) focused on knowledge distillation from larger to smaller MLLMs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><figDesc>(d). Agrawal et al. (2022a); Tu et al. (2023); Park et al. (2023) proposed minimal soft prompt prefix fine-tuning for better alignment. Furthermore, Whitehouse et al. (2023b); Xiao et al. (2023); Aggarwal et al. (2024); Le et al. (2024) proposed methods based on Low-Rank Adaptation (LoRA) to achieve PEFT alignment. Further, Yoon et al. (2024) introduced a LangBridge model to bridge multilingual encoder to single-lingual LLM to effectively achieve promising performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Overview of Parameter-Frozen Alignment ( § 4.2) methods, where prompts in sub-figures sourced from Qin et al. (2023b) and Zhang et al. (2023f).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><figDesc>);Yang et al. (2023d)  suggest adding languages through two-stage pre-training. Yong et al. (2022) observe that adapter-based methods are more effective than continuous pre-training.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Figure</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>illustrates the evolution of selected MLLMs over the past five years.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>emergence of a large number of multilingual benchmarks in recent years, a series of work has begun to combine the various existing semantic understanding tasks together for unified evaluation, including: XTREME <ref type="bibr" target="#b115">(Hu et al., 2020)</ref>, XTREME-R <ref type="bibr" target="#b256">(Ruder et al., 2021)</ref>, XGLUE <ref type="bibr" target="#b170">(Liang et al., 2020)</ref>, MEGA <ref type="bibr">(Ahuja et al., 2023a)</ref>, MEGA-Verse <ref type="bibr">(Ahuja et al., 2023b)</ref>, AGIEval <ref type="bibr">(Zhong et al., 2023b), and</ref><ref type="bibr">Superlim (Berdičevskis et al., 2023)</ref> Cultural Understanding Limited by cultural differences, the understanding between different languages is not completely parallel <ref type="bibr" target="#b159">(Li and Callison-Burch, 2023;</ref><ref type="bibr" target="#b189">Maity et al., 2023;</ref><ref type="bibr">Cahyawijaya et al., 2023a)</ref>, so researchers began to explore how to evaluate multi-cultural scenes <ref type="bibr">(Naous et al., 2023b;</ref><ref type="bibr">Hershcovich et al., 2022)</ref>. The most typical one is multi-cultural sentiment analysis. Sentiment Analysis <ref type="bibr" target="#b66">(Davidson et al., 2017;</ref><ref type="bibr" target="#b279">Srinivasan and Choi, 2022;</ref><ref type="bibr">Li et al., 2023b;</ref><ref type="bibr" target="#b1">Muhammad et al., 2023;</ref><ref type="bibr">Winata et al., 2023a;</ref><ref type="bibr" target="#b351">Yadav et al., 2023</ref>  <ref type="bibr" target="#b145">(Köpf et al., 2023)</ref> --35 -EcomInstruct <ref type="bibr">(Li et al., 2023h)</ref> 2.5M Yes 2 12 COIG-PC-lite <ref type="bibr">(Team, 2023a)</ref> 650k  <ref type="bibr" target="#b296">Thulke et al. (2024)</ref> proposed benchmarks to evaluate the multilingual scientific and applied professional domain knowledge for current MLLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Natural Language Generation</head><p>Translation In the process of multi-lingual alignment, in addition to testing whether the multiple languages are aligned in terms of understanding capabilities, researchers often also need to consider whether the two can be aligned in terms of out-</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Abdelali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamdy</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Absar</forename><surname>Shammur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maram</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Basel</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabri</forename><surname>Mousi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yassine</forename><forename type="middle">El</forename><surname>Boughorbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kheir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fahim</forename><surname>Izham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Majd</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><surname>Hawasly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14982</idno>
		<title level="m">Benchmarking arabic ai with large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Jasmine: Arabic gpt models for few-shot learning</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Abdul-Mageed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdelrahim</forename><surname>Elmadany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alcides</forename><surname>Inciarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Tawkat Islam</surname></persName>
		</author>
		<author>
			<persName><surname>Khondaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="16721" to="16744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Masakhaner: Named entity recognition for african languages</title>
		<author>
			<persName><forename type="first">David</forename><surname>Ifeoluwa Adelani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jade</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Constantine</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chester</forename><surname>Lignos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Happy</forename><surname>Palen-Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Buzaaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Rijhwani</surname></persName>
		</author>
		<author>
			<persName><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1116" to="1131" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Ifeoluwa Adelani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesujoba</forename><surname>Oluwadara Alabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Ruiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dietrich</forename><surname>Klakow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Nabende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ernie</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.02022</idno>
		<title level="m">A few thousand translations go a long way! leveraging pre-trained models for african news translation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Ifeoluwa Adelani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marek</forename><surname>Masiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesujoba</forename><surname>Israel Abebe Azime</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atnafu</forename><surname>Oluwadara Alabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Lambebo Tonja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Odunayo</forename><surname>Mwase</surname></persName>
		</author>
		<author>
			<persName><surname>Ogundepo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Bonaventure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akintunde</forename><surname>Dossou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doreen</forename><surname>Oladipo</surname></persName>
		</author>
		<author>
			<persName><surname>Nixdorf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.09972</idno>
		<title level="m">Masakhanews: News topic classification for african languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Zero-shot cross-lingual reranking with large language models for low-resource languages</title>
		<author>
			<persName><forename type="first">Mofetoluwa</forename><surname>Adeyemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akintunde</forename><surname>Oladipo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronak</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.16159</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Milind</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sweta</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roldano</forename><surname>Cattoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Findings of the iwslt 2023 evaluation campaign</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Maple: Multilingual evaluation of parameter efficient finetuning of large language models</title>
		<author>
			<persName><forename type="first">Divyanshu</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashutosh</forename><surname>Sathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunayana</forename><surname>Sitaram</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.07598</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Jw300: A widecoverage parallel corpus for low-resource languages</title>
		<author>
			<persName><forename type="first">Željko</forename><surname>Agic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vulic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Priyanka</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fantine</forename><surname>Huot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.08264</idno>
		<title level="m">Multilingual qa with only 5 examples</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">2022b. Incontext examples selection for machine translation</title>
		<author>
			<persName><forename type="first">Sweta</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunting</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.02437</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multilingual summarization with factual consistency evaluation</title>
		<author>
			<persName><forename type="first">Roee</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="3562" to="3591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Do all languages cost the same? tokenization in the era of commercial language models</title>
		<author>
			<persName><forename type="first">Orevaoghene</forename><surname>Ahia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hila</forename><surname>Gonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungo</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>David R Mortensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><surname>Tsvetkov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13707</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Syed Rameel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.01511</idno>
		<title level="m">Enhancing multilingual information retrieval in mixed human resources environments: A rag model implementation for multicultural enterprise</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Kabir</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishav</forename><surname>Hada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Millicent</forename><surname>Ochieng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prachi</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harshita</forename><surname>Diddee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Maina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanuja</forename><surname>Ganu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxamed</forename><surname>Axmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.12528</idno>
		<title level="m">Mega: Multilingual evaluation of generative ai</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>et al. 2023a</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">On the calibration of massively multilingual language models</title>
		<author>
			<persName><forename type="first">Kabir</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunayana</forename><surname>Sitaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandipan</forename><surname>Dandapat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monojit</forename><surname>Choudhury</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.12265</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Sanchit</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divyanshu</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Gumma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashutosh</forename><surname>Sathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Millicent</forename><surname>Ochieng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishav</forename><surname>Hada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prachi</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxamed</forename><surname>Axmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.07463</idno>
		<title level="m">Megaverse: Benchmarking large language models across languages, modalities, models and tasks</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Advancements in Arabic grammatical error detection and correction: An empirical investigation</title>
		<author>
			<persName><forename type="first">Bashar</forename><surname>Alhafni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Go</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Khairallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="6430" to="6448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Fromm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaudia</forename><surname>Thellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Rutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Lübbering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Klug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niclas</forename><surname>Doll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasper</forename><surname>Schulze Buschhoff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.08754</idno>
		<title level="m">Tokenizer choice for llm training: Negligible or crucial? arXiv preprint</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Dhiraj</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharvari</forename><surname>Govilkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yash</forename><surname>Shashikant Lalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arshi</forename><surname>Ajaz Khwaja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daries</forename><surname>Xavier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sahil Girijashankar</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.16202</idno>
		<title level="m">Marathi-english code-mixed text generation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siamak</forename><surname>Shakeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuel</forename><surname>Taropa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paige</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10403</idno>
		<title level="m">Palm 2 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Abhik</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tahmid</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uddin</forename><surname>Wasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan-Fang</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong-Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rifat</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><surname>Shahriyar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.08804</idno>
		<title level="m">Crosssum: Beyond englishcentric cross-lingual abstractive text summarization for 1500+ language pairs</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hallahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connor</forename><surname>Leahy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<title level="m">Gpt-neox-20b: An open-source autoregressive language model. Challenges &amp; Perspectives in Creating Large Language Models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">95</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Breaking the curse of multilinguality with cross-lingual expert language models</title>
		<author>
			<persName><forename type="first">Terra</forename><surname>Blevins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomasz</forename><surname>Limisiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suchin</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hila</forename><surname>Gonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.10440</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Language contamination helps explain the cross-lingual capabilities of english pretrained models</title>
		<author>
			<persName><forename type="first">Terra</forename><surname>Blevins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.08110</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Tudor Nicolae Mateiu, Jindřich Helcl, and Mikko Aulamo. 2023. Opuscleaner and opustrainer, open source toolkits for training machine translation and large language models</title>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bogoychev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jelmer</forename><surname>Van Der Linde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graeme</forename><surname>Nail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaume</forename><surname>Zaragoza-Bernabeu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gema</forename><surname>Ramírez-Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Weymann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.14838</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Analyzing multilingual competency of llms in multi-turn instruction following: A case study of arabic</title>
		<author>
			<persName><forename type="first">Sabri</forename><surname>Boughorbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Majd</forename><surname>Hawasly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.14819</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Searching for needles in a haystack: On the role of incidental bilingualism in palm&apos;s translation capability</title>
		<author>
			<persName><forename type="first">Eleftheria</forename><surname>Briakou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10266</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">2023a. Nusacrowd: Open source initiative for indonesian nlp resources</title>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holy</forename><surname>Lovenia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Genta</forename><surname>Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Wilie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fajri</forename><surname>Koto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahmad</forename><surname>Mahendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Wibisono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ade</forename><surname>Romadhony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karissa</forename><surname>Vincentio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<imprint>
			<biblScope unit="page" from="13745" to="13818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holy</forename><surname>Lovenia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiezheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willy</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13627</idno>
		<title level="m">Teaching novel languages with to llms through alignment-based cross-lingual instruction</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Trista</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieyu</forename><surname>Sotnikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hal</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename><surname>Daume</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.07141</idno>
		<title level="m">Multilingual large language models leak human stereotypes across language boundaries</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Linzheng</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongcheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiannian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiyao</forename><surname>Peng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.07037</idno>
		<title level="m">xcot: Crosslingual instruction tuning for cross-lingual chain-ofthought reasoning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Ernie-code: Beyond english-centric cross-lingual pretraining for programming languages</title>
		<author>
			<persName><forename type="first">Yekun</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Hao Tian</surname></persName>
		</author>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.06742</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Soravit</forename><surname>Changpinyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linting</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><forename type="middle">V</forename><surname>Thapliyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Amelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.05401</idno>
		<title level="m">Towards multi-lingual visual question answering</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Du</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaopu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongqiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haihui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leichao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.12246</idno>
		<title level="m">Orion-14b: Open-source multilingual large language models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">2023a. Large language models meet harry potter: A dataset for aligning dialogue agents with characters</title>
		<author>
			<persName><forename type="first">Nuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiyun</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<biblScope unit="page" from="8506" to="8520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Nuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zinan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.20246</idno>
		<title level="m">Breaking language barriers in multilingual mathematical reasoning: Insights and observations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Pinzhen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoxiong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bogoychev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.08958</idno>
		<title level="m">Monolingual or multilingual instruction tuning: Which makes a better alpaca</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josip</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Padlewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Basil</forename><surname>Mustafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soravit</forename><surname>Changpinyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><forename type="middle">Riquelme</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.18565</idno>
		<title level="m">On scaling up a multilingual vision and language model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Voigtlaender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Basil</forename><surname>Mustafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.09199</idno>
	</analytic>
	<monogr>
		<title level="m">Piotr Padlewski, et al. 2023e. Pali-3 vision language models: Smaller, faster, stronger</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soravit</forename><surname>Changpinyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Piergiovanni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Padlewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Salz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Basil</forename><surname>Grycner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Mustafa</surname></persName>
		</author>
		<author>
			<persName><surname>Beyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.06794</idno>
		<title level="m">Pali: A jointly-scaled multilingual language-image model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Ye</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liangmin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanxuan</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Fu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.08688</idno>
		<title level="m">Tigerbot: An open multilingual multitask llm</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Improving translation faithfulness of large language models via augmenting instructions</title>
		<author>
			<persName><forename type="first">Yijie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.12674</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Zhihong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guiming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongbo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juhao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyi</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.10453</idno>
		<title level="m">Phoenix: Democratizing chatgpt across languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Zhihong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juhao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangbo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guiming</forename><surname>Hardy Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongbo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Jianquan</surname></persName>
		</author>
		<title level="m">Wan Xiang, and Benyou Wang. 2023i. MultilingualSIFT: Multilingual Supervised Instruction Fine-tuning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">2023a. Scale: Synergized collaboration of asymmetric language translation engines</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Si-Qing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.17061</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">2023b. Mu 2 slam: Multitask, multilingual speech and language models</title>
		<author>
			<persName><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Bapna</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="5504" to="5520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Vicuna: An opensource chatbot impressing gpt-4</title>
		<author>
			<persName><forename type="first">Wei-Lin</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghao</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>with 90%* chatgpt quality</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Ask me in english instead: Cross-lingual evaluation of large language models for healthcare queries</title>
		<author>
			<persName><forename type="first">De</forename><surname>Choudhury</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.13132</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<title level="m">Palm: Scaling language modeling with pathways</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Sharan Narang, and Noah Constant. 2022a. Unimax: Fairer and more effective language sampling for large-scale multilingual pretraining</title>
		<author>
			<persName><forename type="first">Chung</forename><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">Chung</forename><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunxuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11416</idno>
		<title level="m">Siddhartha Brahma, et al. 2022b. Scaling instruction-finetuned language models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Rijhwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roee</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Nikolaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Sellam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur P</forename><surname>Parikh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13194</idno>
		<title level="m">Seahorse: A multilingual, multifaceted dataset for summarization evaluation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Tydi qa: A benchmark for information-seeking question answering in ty pologically di verse languages</title>
		<author>
			<persName><forename type="first">Jonathan H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Nikolaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="454" to="470" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Redpajama: an open dataset for training large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Increasing coverage and precision of textual information in multilingual knowledge graphs</title>
		<author>
			<persName><forename type="first">Simone</forename><surname>Conia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Umar</forename><surname>Minhas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ihab</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunyao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1612" to="1634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartikay</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Édouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05053</idno>
		<title level="m">Xnli: Evaluating crosslingual sentence representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Multilingual holistic bias: Extending descriptors and patterns to unveil demographic biases in languages at scale</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Marta R Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prangthip</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Hansanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elahe</forename><surname>Ropers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Kalbassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carleigh</forename><surname>Licht</surname></persName>
		</author>
		<author>
			<persName><surname>Wood</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13198</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">James</forename><surname>Marta R Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maha</forename><surname>Çelebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Elbayad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elahe</forename><surname>Heffernan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janice</forename><surname>Kalbassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Licht</surname></persName>
		</author>
		<author>
			<persName><surname>Maillard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.04672</idno>
		<title level="m">No language left behind: Scaling human-centered machine translation</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>et al. 2022a</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">Eric</forename><surname>Marta R Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ropers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Licht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Ferrando</surname></persName>
		</author>
		<author>
			<persName><surname>Escolano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03070</idno>
		<title level="m">Toxicity in multilingual machine translation at scale</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziqing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Yao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.08177</idno>
		<title level="m">Efficient and effective text encoding for chinese llama and alpaca</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A survey of multilingual neural machine translation</title>
		<author>
			<persName><forename type="first">Raj</forename><surname>Dabre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhui</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Kunchukuttan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Halomi: A manually annotated benchmark for multilingual hallucination and omission detection in machine translation</title>
		<author>
			<persName><forename type="first">David</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Voita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janice</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prangthip</forename><surname>Hansanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Ropers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elahe</forename><surname>Kalbassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loïc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><forename type="middle">R</forename><surname>Costa-Jussà</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11746</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Mildsum: A novel benchmark dataset for multilingual summarization of indian legal case judgments</title>
		<author>
			<persName><forename type="first">Debtanu</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Soni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajdeep</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saptarshi</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="5291" to="5302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Automated hate speech detection and the problem of offensive language</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international AAAI conference on web and social media</title>
		<meeting>the international AAAI conference on web and social media</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="512" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Zeroshot cross-lingual sentiment classification under distribution shift: an exploratory study</title>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Raedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Semere</forename><forename type="middle">Kiros</forename><surname>Bitew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fréderic</forename><surname>Godin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Develder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.06549</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Scaling in cognitive modelling: a multilingual approach to human reading times</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varda</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Marelli</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.acl-short.14</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="139" to="149" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Knowledge extraction in low-resource scenarios: survey and perspective</title>
		<author>
			<persName><forename type="first">Shumin</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ningyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feiyu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><forename type="middle">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huajun</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.08063</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artidoro</forename><surname>Pagnoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14314</idno>
		<title level="m">Qlora: Efficient finetuning of quantized llms</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">Sunayana</forename><surname>Seza Dogruöz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><forename type="middle">E</forename><surname>Sitaram</surname></persName>
		</author>
		<author>
			<persName><surname>Bullock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacqueline</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><surname>Toribio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.01967</idno>
		<title level="m">A survey of code-switching: Linguistic and social perspectives for language technologies</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Representativeness as a forgotten lesson for multilingual and code-switched data collection and preparation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Seza</forename><surname>Dogruöz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunayana</forename><surname>Sitaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.findings-emnlp.382</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="5751" to="5767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<author>
			<persName><forename type="first">Qingxiu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.00234</idno>
		<title level="m">A survey for in-context learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Steerlm: Attribute conditioned sft as an (user-steerable) alternative to rlhf</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Makesh</forename><surname>Sreedhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianchao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="11275" to="11288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<author>
			<persName><forename type="first">Danny</forename><surname>Driess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mehdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corey</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayzaan</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Wahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianhe</forename><surname>Vuong</surname></persName>
		</author>
		<author>
			<persName><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.03378</idno>
		<title level="m">Palm-e: An embodied multimodal language model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Multilingual coarse political stance classification of media. the editorial line of a chatgpt and bard newspaper</title>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<publisher>Cristina España-Bonet</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="11757" to="11777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<author>
			<persName><forename type="first">Julen</forename><surname>Etxaniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gorka</forename><surname>Azkune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Soroa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oier</forename><surname>Lopez De Lacalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.01223</idno>
		<title level="m">Do multilingual language models think better in english? arXiv preprint</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Beyond english-centric multilingual machine translation</title>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>El-Kishky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandeep</forename><surname>Baines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4839" to="4886" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Meep: Is this engaging? prompting large language models for dialogue evaluation in multilingual settings</title>
		<author>
			<persName><forename type="first">Amila</forename><surname>Ferron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amber</forename><surname>Shore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekata</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ameeta</forename><surname>Agrawal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2078" to="2100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Multiconer v2: a large multilingual dataset for fine-grained and noisy named entity recognition</title>
		<author>
			<persName><forename type="first">Besnik</forename><surname>Fetahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudipta</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleg</forename><surname>Rokhlenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.13213</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Massive: A 1m-example multilingual natural language understanding dataset with 51 typologically-diverse languages</title>
		<author>
			<persName><forename type="first">Jack</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hench</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charith</forename><surname>Peris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Mackie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kay</forename><surname>Rottmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Nash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Urbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishesh</forename><surname>Kakarala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richa</forename><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.08582</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m">Wikimedia Foundation. Wikimedia downloads</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Polyglot prompt: Multilingual multitask promptraining</title>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">See-Kiong</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.14264</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Terufumi Morishita, and Yasuhiro Sogawa. 2023. How do different tokenizers perform on downstream tasks in scriptio continua languages?</title>
		<author>
			<persName><forename type="first">Takuro</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koki</forename><surname>Shibata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atsuki</forename><surname>Yamaguchi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.09572</idno>
	</analytic>
	<monogr>
		<title level="m">A case study in japanese</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">A multi-modal multilingual benchmark for document image classification</title>
		<author>
			<persName><forename type="first">Yoshinari</forename><surname>Fujinuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Varia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nishant</forename><surname>Sankaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srikar</forename><surname>Appalaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yogarshi</forename><surname>Vyas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="14361" to="14376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Normsage: Multi-lingual multi-cultural norm discovery from conversations on-the-fly</title>
		<author>
			<persName><forename type="first">Tuhin</forename><surname>Yi R Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Owen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smaranda</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.08604</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Towards boosting many-to-many multilingual machine translation with large language models</title>
		<author>
			<persName><forename type="first">Pengzhi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.05861</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<author>
			<persName><forename type="first">Lino</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Henrique</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Paiola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Morelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovani</forename><surname>Candido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cândido</forename><surname>Arnaldo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Júnior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Samuel Jodas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Afonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><forename type="middle">Elias</forename><surname>Rizzo Guilherme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João</forename><surname>Penteado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Papa</forename><surname>Paulo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.02909</idno>
		<title level="m">Introducing bode: A finetuned large language model for portuguese promptbased task</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of fewshot learning for machine translation</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yamini</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="10867" to="10878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Geigle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Goran</forename><surname>Glavaš</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.06930</idno>
		<title level="m">mblip: Efficient bootstrapping of multilingual vision-llms</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<author>
			<persName><forename type="first">Zorik</forename><surname>Gekhman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roee</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Elkind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11171</idno>
		<title level="m">Trueteacher: Learning factual consistency evaluation with large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Vashishtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Motoki</forename><surname>Sano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faiz</forename><surname>Surani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunjeong</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08954</idno>
		<title level="m">Presto: A multilingual dataset for parsing realistic task-oriented dialogs</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Explanatory argument extraction of correct answers in resident medical exams</title>
		<author>
			<persName><forename type="first">Iakes</forename><surname>Goenaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitziber</forename><surname>Atutxa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koldo</forename><surname>Gojenola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maite</forename><surname>Oronoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Agerri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.00567</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Roscoe: A suite of metrics for scoring step-by-step reasoning</title>
		<author>
			<persName><forename type="first">O</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Golovneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spencer</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Poff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Corredor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maryam</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asli</forename><surname>Fazel-Zarandi</surname></persName>
		</author>
		<author>
			<persName><surname>Celikyilmaz</surname></persName>
		</author>
		<idno>ArXiv, abs/2212.07919</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">The flores-101 evaluation benchmark for low-resource and multilingual machine translation</title>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng-Jen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjana</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc'aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="522" to="538" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<author>
			<persName><forename type="first">Duarte</forename><surname>Nuno M Guerreiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Alves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Waldendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">André Ft</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><surname>Martins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.16104</idno>
		<title level="m">Hallucinations in large multilingual translation models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Pierre Colombo, and André FT Martins. 2023b. xcomet: Transparent machine translation evaluation through fine-grained error detection</title>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Nuno M Guerreiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Van Stigt</surname></persName>
		</author>
		<author>
			<persName><surname>Coheur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.10482</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Jwsign: A highly multilingual corpus of bible translations for more diversity in sign language processing</title>
		<author>
			<persName><forename type="first">Shester</forename><surname>Gueuwou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophie</forename><surname>Siake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="9907" to="9927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Bridging the gap between synthetic and authentic images for multimodal machine translation</title>
		<author>
			<persName><forename type="first">Wenyu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingkai</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2863" to="2874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Are large language model-based evaluators the solution to scaling up multilingual evaluation</title>
		<author>
			<persName><forename type="first">Rishav</forename><surname>Hada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Gumma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>De Wynter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harshita</forename><surname>Diddee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monojit</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunayana</forename><surname>Sitaram</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.07462</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<author>
			<persName><forename type="first">Katharina</forename><surname>Hämmerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Björn</forename><surname>Deiseroth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Schramowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jindřich</forename><surname>Libovickỳ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.09904</idno>
		<title level="m">Do multilingual language models capture differing moral norms? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Bridging background knowledge gaps in translation with automatic explicitation</title>
		<author>
			<persName><forename type="first">Hyojung</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="9718" to="9735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Exams: A multi-subject high school examinations dataset for cross-lingual and multilingual question answering</title>
		<author>
			<persName><forename type="first">Momchil</forename><surname>Hardalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitrina</forename><surname>Zlatkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoan</forename><surname>Dinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Koychev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.03080</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<author>
			<persName><forename type="first">Conghui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenjiang</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiantao</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.10755</idno>
		<title level="m">Wanjuan: A comprehensive multimodal dataset for advancing english and chinese large models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxiang</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujiu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.04118</idno>
		<title level="m">Shuming Shi, and Xing Wang. 2023b. Exploring humanlike translation strategy with large language models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<author>
			<persName><forename type="first">William</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Camille</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.08391</idno>
		<title level="m">A material lens on coloniality in nlp</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heather</forename><surname>Lent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Miryam De Lhoneux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Abdou</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Brandl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><forename type="middle">Cabello</forename><surname>Bugliarello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Piqueras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruixiang</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><surname>Cui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.10020</idno>
		<title level="m">Challenges and strategies in cross-cultural nlp</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Chinese-mixtral-8x7b: An opensource mixture-of-experts llm</title>
		<author>
			<persName><surname>Hit-Scir</surname></persName>
		</author>
		<ptr target="https://github.com/HIT-SCIR/Chinese-Mixtral-8x7B" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Empowering cross-lingual behavioral testing of nlp models with typological features</title>
		<author>
			<persName><forename type="first">Ester</forename><surname>Hlavnova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7181" to="7198" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main">On-the-fly fusion of large language models and machine translation</title>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.08306</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Making instruction finetuning accessible to nonenglish languages: A case study on swedish models</title>
		<author>
			<persName><forename type="first">Oskar</forename><surname>Holmström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Doostmohammadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)</title>
		<meeting>the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="634" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Bridging the resource gap: Exploring the efficacy of english and multilingual llms for swedish</title>
		<author>
			<persName><forename type="first">Oskar</forename><surname>Holmström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>Kunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Resources and Representations for Under-Resourced Languages and Domains (RESOURCEFUL-2023)</title>
		<meeting>the Second Workshop on Resources and Representations for Under-Resourced Languages and Domains (RESOURCEFUL-2023)</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="92" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title level="m" type="main">2023a. Large multilingual models pivot zero-shot multimodal learning across languages</title>
		<author>
			<persName><forename type="first">Jinyi</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinxu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoye</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.12038</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generalisation</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4411" to="4421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<author>
			<persName><forename type="first">Mengkang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinmiao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiguang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenqi</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.08582</idno>
		<title level="m">Yu Qiao, and Ping Luo. 2023b. Tree-planner: Efficient close-loop task planning with large language models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title level="m" type="main">Dialight: Lightweight multilingual development and evaluation of taskoriented dialogue systems with large language models</title>
		<author>
			<persName><forename type="first">Songbo</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangdie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vulić</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.02208</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Multi 3 woz: A multilingual, multi-domain, multi-parallel dataset for training and evaluating culturally adapted task-oriented dialog systems</title>
		<author>
			<persName><forename type="first">Songbo</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mete</forename><surname>Hergul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milan</forename><surname>Gritta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guchun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignacio</forename><surname>Iacobacci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vulić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1396" to="1415" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<author>
			<persName><forename type="first">Wen-Yu</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davood</forename><surname>Shamsi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.06404</idno>
		<title level="m">Lacos-bloom: Low-rank adaptation with contrastive objective on 8 bits siamese-bloom</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title level="m" type="main">2023a. Not all languages are created equal in llms: Improving multilingual capability by cross-lingual-thought prompting</title>
		<author>
			<persName><forename type="first">Haoyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.07004</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<author>
			<persName><forename type="first">Ronny</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyril</forename><surname>Allauzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongzhou</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilol</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo-Yiin</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tara</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.12789</idno>
		<title level="m">Multilingual and fully non-autoregressive asr with large language model fusion: A comprehensive study</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianqian</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanbo</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.13585</idno>
		<title level="m">Speech translation with large language models: An industrial practice</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<author>
			<persName><forename type="first">Fantine</forename><surname>Huot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reinald</forename><surname>Kim Amplayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priyanka</forename><surname>Agrawal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14205</idno>
		<title level="m">Constanza Fierro, Shashi Narayan, and Mirella Lapata. 2023. µplan: Summarizing using a content plan as cross-lingual bridge</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<author>
			<persName><forename type="first">Ayyoob</forename><surname>Imanigooghari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiqin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hossein Kargaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvia</forename><surname>Severini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jalili</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nora</forename><surname>Sabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunlan</forename><surname>Kassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helmut</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><surname>Yvon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.12182</idno>
	</analytic>
	<monogr>
		<title level="m">Scaling multilingual corpora and language models to 500 languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">500</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Towards effective disambiguation for machine translation with large language models</title>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pinzhen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Conference on Machine Translation</title>
		<meeting>the Eighth Conference on Machine Translation</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="482" to="495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Cross-lingual offensive language detection: A systematic review of datasets, transfer approaches and challenges</title>
		<author>
			<persName><forename type="first">Aiqi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.09244</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Albert Q Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianna</forename><surname>Bressand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><surname>Saulnier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.06825</idno>
		<title level="m">Mistral 7b</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Albert Q Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blanche</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Savary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><forename type="middle">Bou</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><surname>Bressand</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.04088</idno>
		<title level="m">Mixtral of experts</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<author>
			<persName><forename type="first">Ming</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mansi</forename><surname>Joshi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.07897</idno>
		<title level="m">Cpopqa: Ranking cultural concept popularity by llms</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Parrot: Translating during chat using large language models tuned with human translation and feedback</title>
		<author>
			<persName><forename type="first">Wenxiang</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jen-Tse</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="15009" to="15020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><surname>Kazanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keziah</forename><surname>Reina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vishnesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byron</forename><forename type="middle">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi Jessy</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.12532</idno>
		<title level="m">Multilingual simplification of medical texts</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title level="m" type="main">Alham Fikri Aji, Genta Indra Winata, Samuel Cahyawijaya, Anuoluwapo Aremu, Perez Ogayo, and Graham Neubig. 2023. Multi-lingual and multi-cultural figurative language understanding</title>
		<author>
			<persName><forename type="first">Anubha</forename><surname>Kabra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmy</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simran</forename><surname>Khanuja</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.16171</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<author>
			<persName><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linting</forename><surname>Xue</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.02171</idno>
		<title level="m">2021. nmt5-is parallel data still relevant for pre-training massively multilingual language models? arXiv preprint</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">The multilingual amazon reviews corpus</title>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Keung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">György</forename><surname>Szarvas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4563" to="4568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Turning english-centric llms into polyglots: How much multilinguality is needed</title>
		<author>
			<persName><forename type="first">Tannon</forename><surname>Kew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schottmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.12683</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">A study of multilingual versus meta-learning for language model pre-training for adaptation to unseen low resource languages</title>
		<author>
			<persName><forename type="first">Jyotsana</forename><surname>Khatri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rudra</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amar</forename><surname>Prakash Azad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Translation Summit XIX</title>
		<meeting>Machine Translation Summit XIX</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="26" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<idno type="arXiv">arXiv:2305.14976</idno>
		<title level="m">Gptaraeval: A comprehensive evaluation of chatgpt on arabic nlp</title>
		<editor>
			<persName><forename type="first">Md</forename><surname>Tawkat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Islam</forename><surname>Khondaker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Abdul</forename><surname>Waheed</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">El</forename><surname>Moatez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Billah</forename><surname>Nagoudi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Muhammad</forename><surname>Abdul-Mageed</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">What changes can large-scale language models bring? intensive study on hyperclova: Billions-scale korean generative pretrained transformers</title>
		<author>
			<persName><forename type="first">Boseop</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyoungseok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang-Woo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gichang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghyun</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeon</forename><surname>Dong Hyeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunghyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungju</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seonhoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongpil</forename><surname>Seo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3405" to="3424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<title level="m" type="main">Boosting cross-lingual transferability in multilingual models via in-context learning</title>
		<author>
			<persName><forename type="first">Sunkyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dayeon</forename><surname>Ki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yireun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinsik</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.15233</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">2023b. Pr-mcs: Perturbation robust metric for multilingual image captioning</title>
		<author>
			<persName><forename type="first">Yongil</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yerin</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeongu</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seunghyun</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trung</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyomin</forename><surname>Jung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08389</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Findings of the 2023 conference on machine translation (wmt23): Llms are here but not quite there yet</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kocmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleftherios</forename><surname>Avramidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Bawden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Dvorkovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Fishel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thamme</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Conference on Machine Translation</title>
		<meeting>the Eighth Conference on Machine Translation</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of machine translation summit x: papers</title>
		<meeting>machine translation summit x: papers</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<monogr>
		<title level="m" type="main">Building a llama2-finetuned llm for odia language utilizing domain knowledge instruction set</title>
		<author>
			<persName><forename type="first">Guneet</forename><surname>Singh Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shantipriya</forename><surname>Parida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sambit</forename><surname>Sekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samirit</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nipun</forename><forename type="middle">B</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parul</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonal</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kusumlata</forename><surname>Patiyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debasish</forename><surname>Dhal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.12624</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<title level="m" type="main">Memory-efficient nllb-200: Language-specific expert pruning of a massively multilingual machine translation model</title>
		<author>
			<persName><forename type="first">Yeskendir</forename><surname>Koishekenov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vassilina</forename><surname>Nikoulina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Berard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09811</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Köpf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannic</forename><surname>Kilcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sotiris</forename><surname>Dimitri Von Rütte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi-Rui</forename><surname>Anagnostidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdullah</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><surname>Barhoum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Duc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richárd</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><surname>Nagyfi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.07327</idno>
		<title level="m">Openassistant conversations-democratizing large language model alignment</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Madlad-400: A multilingual and document-level large audited dataset</title>
		<author>
			<persName><forename type="first">Sneha</forename><surname>Kudugunta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><forename type="middle">Rayburn</forename><surname>Caswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derrick</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Kusupati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Romi</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">The IIT Bombay English-Hindi parallel corpus</title>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Kunchukuttan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratik</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Dialect-to-standard normalization: A largescale multilingual evaluation</title>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Olli Kuparinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yves</forename><surname>Miletić</surname></persName>
		</author>
		<author>
			<persName><surname>Scherrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="13814" to="13828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">2023a. Beyond english: Evaluating llms for arabic grammatical error correction</title>
		<author>
			<persName><forename type="first">Sang</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gagan</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Abdul-Mageed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ArabicNLP 2023</title>
		<meeting>ArabicNLP 2023</meeting>
		<imprint>
			<biblScope unit="page" from="101" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<author>
			<persName><forename type="first">Sang</forename><surname>Yun Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gagan</forename><surname>Bhatia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.04492</idno>
		<title level="m">El Moatez Billah Nagoud, and Muhammad Abdul-Mageed. 2023b. Chatgpt for arabic grammatical error correction</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<author>
			<persName><forename type="first">Dac</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nghia Trung</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Pouran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Veyseh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trung</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien Huu</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05613</idno>
		<title level="m">Chatgpt beyond english: Towards a comprehensive evaluation of large language models in multilingual learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<author>
			<persName><forename type="first">Dac</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chien</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nghia Trung</forename><surname>Van Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thuat</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien Huu</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.16039</idno>
		<title level="m">Okapi: Instructiontuned large language models in multiple languages with reinforcement learning from human feedback</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b153">
	<monogr>
		<author>
			<persName><forename type="first">Celio</forename><surname>Larcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Piau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Finardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Gengo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piero</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinicius</forename><surname>Caridá</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.11878</idno>
		<title level="m">Cabrita: closing the gap for foreign languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">The bigscience roots corpus: A 1.6 tb composite multilingual dataset</title>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Hugo Laurençon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Villanova Del Moral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Von Werra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduardo</forename><forename type="middle">González</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huu</forename><surname>Ponferrada</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="31809" to="31826" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<monogr>
		<title level="m" type="main">Lampat: Low-rank adaption for multilingual paraphrasing using adversarial training</title>
		<author>
			<persName><forename type="first">Trinh</forename><surname>Khoi M Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tho</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anh</forename><forename type="middle">Tuan</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><surname>Luu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.04348</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b156">
	<monogr>
		<title level="m" type="main">Target-agnostic gender-aware contrastive learning for mitigating bias in multilingual machine translation</title>
		<author>
			<persName><forename type="first">Minwoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyukhun</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang-Il</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minsung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyomin</forename><surname>Jung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14016</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyoukjoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16668</idno>
		<title level="m">Gshard: Scaling giant models with conditional computation and automatic sharding</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b158">
	<monogr>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.07475</idno>
		<title level="m">Mlqa: Evaluating cross-lingual extractive question answering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">This land is {Your</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14610</idno>
	</analytic>
	<monogr>
		<title level="m">My} land: Evaluating geopolitical biases in language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b160">
	<monogr>
		<title level="m" type="main">2023a. Align after pre-train: Improving multilingual generative models with cross-lingual alignment</title>
		<author>
			<persName><forename type="first">Chong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaonan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.08089</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b161">
	<monogr>
		<author>
			<persName><forename type="first">Haonan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fajri</forename><surname>Koto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.15011</idno>
		<idno>arXiv:2008.09335</idno>
		<title level="m">Bactrian-x: A multilingual replicable instruction-following model with lowrank adaptation</title>
		<editor>
			<persName><forename type="first">Haoran</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Abhinav</forename><surname>Arora</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anchit</forename><surname>Gupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2023. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Mtop: A comprehensive multilingual task-oriented semantic parsing benchmark</note>
</biblStruct>

<biblStruct xml:id="b162">
	<monogr>
		<title level="m" type="main">Eliciting the translation ability of large language models via multilingual finetuning with translation instructions</title>
		<author>
			<persName><forename type="first">Jiahuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.15083</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">2023d. Normdial: A comparable bilingual synthetic dialog dataset for modeling social norm adherence and violation</title>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mallika</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arkadiy</forename><surname>Saakyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ch-Wang</forename><surname>Sky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="15732" to="15744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">2023e. Mmnmt: Modularizing multilingual neural machine translation with flexibly assembled moe and dense blocks</title>
		<author>
			<persName><forename type="first">Shangjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangpeng</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaolin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baosong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="4978" to="4990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Crosslingual retrieval augmented in-context learning for bangla</title>
		<author>
			<persName><forename type="first">Xiaoqian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ercong</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Bangla Language Processing (BLP-2023)</title>
		<meeting>the First Workshop on Bangla Language Processing (BLP-2023)</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="136" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<monogr>
		<title level="m" type="main">From classification to generation: Insights into crosslingual retrieval augmented icl</title>
		<author>
			<persName><forename type="first">Xiaoqian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ercong</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.06595</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<author>
			<persName><forename type="first">Yangning</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengyue</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai-Tao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjun</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.06966</idno>
		<title level="m">Ecomgpt: Instruction-tuning large language model with chainof-task tasks for e-commerce</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b168">
	<monogr>
		<author>
			<persName><forename type="first">Yaoyiran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vulić</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.13995</idno>
		<title level="m">On bilingual lexicon induction with large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Multilingual sentence alignment with gpt models</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yen-Min Jasmina</forename><surname>Khaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soung-Yue</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien-Ping</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghong</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 4th International Conference on Artificial Intelligence and Data Sciences (AiDAS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="218" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<monogr>
		<title level="m" type="main">Xglue: A new benchmark dataset for cross-lingual pretraining, understanding and generation</title>
		<author>
			<persName><forename type="first">Yaobo</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeyun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fenfei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhen</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.01401</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Xiaoyang Qiao, and Xiang Ren. 2021a. Common sense beyond English: Evaluating and improving multilingual language models for commonsense reasoning</title>
		<author>
			<persName><forename type="first">Seyeon</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.102</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1274" to="1287" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<monogr>
		<title level="m" type="main">André FT Martins, and Hinrich Schütze. 2023. mplm-sim: Unveiling better cross-lingual similarity and transfer in multilingual pretrained language models</title>
		<author>
			<persName><forename type="first">Peiqin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengzhi</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheyu</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13684</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Veselin Stoyanov, and Xian Li. 2022a. Few-shot learning with multilingual generative language models</title>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Simig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakanth</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punit</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian O'</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Horo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zornitsa</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><surname>Kozareva</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.emnlp-main.616</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Mona Diab; Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="9019" to="9052" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<monogr>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Simig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><surname>Bhosale</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.10668</idno>
		<title level="m">Jingfei Du, et al. 2021b. Few-shot learning with multilingual language models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">2022b. Few-shot learning with multilingual generative language models</title>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Simig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="9019" to="9052" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<author>
			<persName><forename type="first">Cecilia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fajri</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Koto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.08591</idno>
		<title level="m">Are multilingual llms culturally-diverse reasoners? an investigation into multicultural proverbs and sayings</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b178">
	<monogr>
		<author>
			<persName><forename type="first">Peng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lemei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terje</forename><surname>Nissen Farup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Even</forename><forename type="middle">W</forename><surname>Lauvrak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Espen Ingvaldsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simen</forename><surname>Eide</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.01314</idno>
		<title level="m">Jon Atle Gulla, and Zhirong Yang. 2023b. Nlebench+ norglm: A comprehensive empirical analysis and benchmark dataset for generative language models in norwegian</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">2023c. Revisiting commonsense reasoning in machine translation: Training, evaluation and challenge</title>
		<author>
			<persName><forename type="first">Xuebo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runzhe</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liangxuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="15536" to="15550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Cceval: A representative evaluation benchmark for the chinese-centric multilingual machine translation</title>
		<author>
			<persName><forename type="first">Lianzhang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="10176" to="10184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
		<title level="m" type="main">Chainof-dictionary prompting elicits translation in large language models</title>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.06575</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b182">
	<monogr>
		<author>
			<persName><forename type="first">Haipeng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingfeng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianguang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiubo</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingwei</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.09583</idno>
		<title level="m">Shifeng Chen, and Dongmei Zhang. 2023a. Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b183">
	<monogr>
		<title level="m" type="main">2023b. Yayi 2: Multilingual open-source large language models</title>
		<author>
			<persName><forename type="first">Yin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingchao</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bao</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baoyu</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donglei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.14862</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b184">
	<monogr>
		<author>
			<persName><forename type="first">Ville</forename><surname>Risto Luukkonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jouni</forename><surname>Komulainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anni</forename><surname>Luoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenna</forename><surname>Eskelinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanna-Mari</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Kupari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veronika</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Laippala</surname></persName>
		</author>
		<author>
			<persName><surname>Muennighoff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.05640</idno>
		<title level="m">Aleksandra Piktus, et al. 2023. Fingpt: Large generative models for a small language</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b185">
	<monogr>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longyue</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.01181</idno>
		<title level="m">New trends in machine translation using large language models: Case examples with chatgpt</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b186">
	<monogr>
		<author>
			<persName><forename type="first">Chunlan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayyoob</forename><surname>Imanigooghari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haotian</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsaneddin</forename><surname>Asgari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08487</idno>
		<title level="m">Taxi1500: A multilingual dataset for text classification in 1500 languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Multitude: Large-scale multilingual machinegenerated text detection benchmark</title>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Macko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adaku</forename><surname>Uchendu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michiharu</forename><surname>Yamashita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matúš</forename><surname>Pikuliak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Srba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thai</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Simko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="9960" to="9987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Macko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adaku</forename><surname>Uchendu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Srba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Samuel Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michiharu</forename><surname>Yamashita</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.07867</idno>
	</analytic>
	<monogr>
		<title level="m">Dongwon Lee, Jakub Simko, and Maria Bielikova. 2024. Authorship obfuscation in multilingual machine-generated text detection</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b189">
	<monogr>
		<author>
			<persName><forename type="first">Ankita</forename><surname>Maity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anubhav</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rudra</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Abhishek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.15181</idno>
		<title level="m">Multilingual bias detection and mitigation for indian languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b190">
	<monogr>
		<title level="m" type="main">A balanced data approach for evaluating cross-lingual transfer: Mapping the linguistic blood bank</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Malkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomasz</forename><surname>Limisiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.04086</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b191">
	<monogr>
		<title level="m" type="main">Multiconer: a largescale multilingual dataset for complex named entity recognition</title>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anjie</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Besnik</forename><surname>Fetahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudipta</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleg</forename><surname>Rokhlenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.14536</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">Creating a massively parallel Bible corpus</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cysouw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3158" to="3163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Alon Lavie, and Isabel Trancoso. 2023a. Towards multilingual automatic open-domain dialogue evaluation</title>
		<author>
			<persName><forename type="first">John</forename><surname>Mendonça</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 24th Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<biblScope unit="page" from="130" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Simple llm prompting is state-of-the-art for robust and multilingual dialogue evaluation</title>
		<author>
			<persName><forename type="first">John</forename><surname>Mendonça</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrícia</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><surname>Moniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joao</forename><forename type="middle">Paulo</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><forename type="middle">M</forename><surname>Trancoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Eleventh Dialog System Technology Challenge</title>
		<meeting>The Eleventh Dialog System Technology Challenge</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="133" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Structural priming demonstrates abstract grammatical representations in multilingual language models</title>
		<author>
			<persName><forename type="first">James</forename><surname>Michaelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Arnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Bergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="3703" to="3720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<monogr>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinxi</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.12837</idno>
		<title level="m">Rethinking the role of demonstrations: What makes in-context learning work? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">Lost in translation, found in spans: Identifying claims in multilingual social media</title>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megha</forename><surname>Sundriyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Singapore. Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="3887" to="3902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">X-RiSAWOZ: High-quality end-to-end multilingual dialogue datasets and fewshot agents</title>
		<author>
			<persName><forename type="first">Mehrad</forename><surname>Moradshahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianhao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monojit</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gael</forename><surname>De Chalendar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anmol</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungkyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prashant</forename><surname>Kodali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ponnurangam</forename><surname>Kumaraguru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasredine</forename><surname>Semmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sina</forename><surname>Semnani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiwon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Yadavalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaobin</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monica</forename><surname>Lam</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.findings-acl.174</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<meeting><address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2773" to="2794" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b199">
	<analytic>
		<title level="a" type="main">2023a. Adaptive machine translation with large language models</title>
		<author>
			<persName><forename type="first">Yasmin</forename><surname>Moslem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rejwanul</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.13294</idno>
		<idno>arXiv:2312.12740</idno>
	</analytic>
	<monogr>
		<title level="m">Yasmin Moslem, Rejwanul Haque, and Andy Way. 2023b. Fine-tuning large language models for adaptive machine translation</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b200">
	<monogr>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Moura Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Fernandes</surname></persName>
		</author>
		<title level="m">António Farinhas, and André FT Martins. 2023. Aligning neural machine translation models: Human feedback in training and inference</title>
		<imprint>
			<biblScope unit="page">2311</biblScope>
		</imprint>
	</monogr>
	<note>arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b201">
	<monogr>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Xin</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.01786</idno>
		<title level="m">Crosslingual generalization through multitask finetuning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b202">
	<monogr>
		<author>
			<persName><forename type="first">Shamsuddeen</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2302.08956</idno>
		<title level="m">Sebastian Ruder, et al. 2023. Afrisenti: A twitter sentiment analysis benchmark for african languages</title>
		<editor>
			<persName><forename type="first">Abinew</forename><surname>Idris Abdulmumin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nedjma</forename><surname>Ali Ayele</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">David</forename><surname>Ousidhoum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Seid</forename><surname>Ifeoluwa Adelani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ibrahim</forename><surname>Muhie Yimam</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Meriem</forename><surname>Sa'id Ahmad</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Saif</forename><surname>Beloucif</surname></persName>
		</editor>
		<editor>
			<persName><surname>Mohammad</surname></persName>
		</editor>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b203">
	<monogr>
		<author>
			<persName><forename type="first">Vandan</forename><surname>Mujadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashok</forename><surname>Urlana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yash</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Penumalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kukkapalli</forename><surname>Pavani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parameswari</forename><surname>Shravya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipti</forename><forename type="middle">Misra</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><surname>Sharma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.09216</idno>
		<title level="m">Assessing translation capabilities of large language models involving english and indian languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b204">
	<monogr>
		<title level="m" type="main">Evaluating and modeling attribution for cross-lingual question answering</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baldini</forename><surname>Livio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roee</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14332</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">Cross-lingual transfer of large language model by visually-derived supervision toward low-resource languages</title>
		<author>
			<persName><forename type="first">Masayasu</forename><surname>Muraoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bishwaranjan</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Merler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graeme</forename><surname>Blackwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st ACM International Conference on Multimedia</title>
		<meeting>the 31st ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="3637" to="3646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<monogr>
		<author>
			<persName><forename type="first">Akshay</forename><surname>Nambi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaibhav</forename><surname>Balloli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mercy</forename><surname>Ranjit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanuja</forename><surname>Ganu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kabir</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunayana</forename><surname>Sitaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.17740</idno>
		<title level="m">Breaking language barriers with a leap: Learning strategies for polyglot llms</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b207">
	<monogr>
		<author>
			<persName><forename type="first">Tarek</forename><surname>Naous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Michael J Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14463</idno>
		<title level="m">Towards massively multi-domain multilingual readability assessment</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b208">
	<monogr>
		<author>
			<persName><forename type="first">Tarek</forename><surname>Naous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Michael J Ryan</surname></persName>
		</author>
		<author>
			<persName><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14456</idno>
		<title level="m">Having beer after prayer? measuring cultural bias in large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b209">
	<monogr>
		<title level="m" type="main">Don&apos;t give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization</title>
		<author>
			<persName><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.08745</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">2023a. CoF-CoT: Enhancing large language models with coarse-to-fine chain-of-thought prompting for multi-domain NLU tasks</title>
		<author>
			<persName><forename type="first">Hoang</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.emnlp-main.743</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="12109" to="12119" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b211">
	<monogr>
		<author>
			<persName><forename type="first">Laura</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Scialom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.11312</idno>
		<title level="m">Benjamin Piwowarski, and Jacopo Staiano. 2023b. Loralay: A multilingual and multimodal dataset for long range and layout-aware summarization</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b212">
	<monogr>
		<author>
			<persName><forename type="first">Thuat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chien</forename><surname>Van Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dac</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trung</forename><surname>Nghia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien Huu</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.09400</idno>
		<title level="m">Culturax: A cleaned, enormous, and multilingual dataset for large language models in 167 languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b213">
	<monogr>
		<title level="m" type="main">Evaluating byte and wordpiece level models for massively multilingual semantic parsing</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Nicosia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2212.07223</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">Small data? no problem! exploring the viability of pretrained multilingual language models for lowresourced languages</title>
		<author>
			<persName><forename type="first">Kelechi</forename><surname>Ogueji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Multilingual Representation Learning</title>
		<meeting>the 1st Workshop on Multilingual Representation Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="116" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<monogr>
		<author>
			<persName><forename type="first">Xenia</forename><surname>Ohmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dieuwke</forename><surname>Hupkes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11662</idno>
		<title level="m">Evaluating task understanding through multilingual consistency: A chatgpt case study</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b216">
	<monogr>
		<title/>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Chatgpt</note>
</biblStruct>

<biblStruct xml:id="b217">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<title level="m">Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<monogr>
		<title level="m" type="main">A preliminary evaluation of chatgpt for zero-shot dialogue understanding</title>
		<author>
			<persName><forename type="first">Wenbo</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.04256</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">Cross-lingual joint entity and word embedding to improve entity linking and parallel sentence mining</title>
		<author>
			<persName><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thamme</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-6107</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP</title>
		<meeting>the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="56" to="66" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b220">
	<monogr>
		<title level="m" type="main">Claim detection for automated fact-checking: A survey on monolingual, multilingual and cross-lingual research</title>
		<author>
			<persName><forename type="first">Rrubaa</forename><surname>Panchendrarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.11969</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<monogr>
		<title level="m" type="main">On the analysis of cross-lingual prompt tuning for decoder-based multilingual model</title>
		<author>
			<persName><forename type="first">Nohil</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joonsuk</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungroh</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><surname>Yoon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.07820</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Bidirectional language models are also few-shot learners</title>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Sadegh Rasooli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<monogr>
		<author>
			<persName><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03277</idno>
		<title level="m">Instruction tuning with gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b225">
	<monogr>
		<author>
			<persName><forename type="first">Frithjof</forename><surname>Petrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Herold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Petrushkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahram</forename><surname>Khadivi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.12303</idno>
		<title level="m">Document-level language models for machine translation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b226">
	<monogr>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">La</forename><surname>Emanuele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Malfa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adel</forename><surname>Hs Torr</surname></persName>
		</author>
		<author>
			<persName><surname>Bibi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.15425</idno>
		<title level="m">Language model tokenizers introduce unfairness between languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b227">
	<monogr>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Piccinno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Nicosia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14224</idno>
		<title level="m">mmt5: Modular multilingual pre-training solves source language hallucinations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b228">
	<monogr>
		<title level="m" type="main">Towards a common understanding of contributing factors for cross-lingual transfer in multilingual language models: A review</title>
		<author>
			<persName><forename type="first">Fred</forename><surname>Philippy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siwen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shohreh</forename><surname>Haddadan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.16768</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b229">
	<monogr>
		<title level="m" type="main">Interactive-chainprompting: Ambiguity resolution for crosslingual conditional generation with interaction</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Pilault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Garcia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.10309</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Arthur Bražinskas, and Orhan Firat</note>
</biblStruct>

<biblStruct xml:id="b230">
	<analytic>
		<title level="a" type="main">Thales Rogério, and Rodrigo Nogueira</title>
		<author>
			<persName><forename type="first">Ramon</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Abonizio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.07880</idno>
	</analytic>
	<monogr>
		<title level="m">Sabi\&apos;a: Portuguese large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b231">
	<monogr>
		<author>
			<persName><forename type="first">Maria</forename><surname>Edoardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Goran</forename><surname>Ponti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Glavaš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianchu</forename><surname>Majewska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Vulić</surname></persName>
		</author>
		<author>
			<persName><surname>Korhonen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00333</idno>
		<title level="m">Xcopa: A multilingual dataset for causal commonsense reasoning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b232">
	<analytic>
		<title level="a" type="main">chrF++: words helping character n-grams</title>
		<author>
			<persName><forename type="first">Maja</forename><surname>Popović</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-4770</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Machine Translation</title>
		<meeting>the Second Conference on Machine Translation<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="612" to="618" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b233">
	<monogr>
		<author>
			<persName><forename type="first">Nooshin</forename><surname>Pourkamali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shler</forename><surname>Ebrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharifi</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2401.08429</idno>
		<title level="m">Machine translation with large language models: Prompt engineering for persian, english, and russian directions</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b234">
	<monogr>
		<title level="m" type="main">2023a. Decomposed prompting for machine translation between related languages using large language models</title>
		<author>
			<persName><forename type="first">Ratish</forename><surname>Puduppully</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raj</forename><surname>Dabre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ai</forename><surname>Ti Aw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13085</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b235">
	<analytic>
		<title level="a" type="main">2023b. Decomt: Decomposed prompting for machine translation between related languages using large language models</title>
		<author>
			<persName><forename type="first">Ratish</forename><surname>Puduppully</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raj</forename><surname>Anoop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aiti</forename><surname>Dabre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Aw</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="4586" to="4602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<monogr>
		<author>
			<persName><forename type="first">Poorna</forename><surname>Chander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reddy</forename><surname>Puttaparthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soham</forename><surname>Sanjay Deo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hakan</forename><surname>Gul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiyi</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.10524</idno>
		<title level="m">Comprehensive evaluation of chatgpt reliability through multilingual inquiries</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b237">
	<monogr>
		<title level="m" type="main">Cross-lingual consistency of factual knowledge in multilingual language models</title>
		<author>
			<persName><forename type="first">Jirui</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arianna</forename><surname>Bisazza</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.10378</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b238">
	<monogr>
		<title level="m" type="main">2023a. Cross-lingual prompting: Improving zero-shot chain-of-thought reasoning across languages</title>
		<author>
			<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuxuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.14799</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b239">
	<monogr>
		<title level="m" type="main">2023b. Cross-lingual prompting: Improving zero-shot chain-of-thought reasoning across languages</title>
		<author>
			<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuxuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<monogr>
		<title level="m" type="main">Gl-clef: A global-local contrastive learning framework for cross-lingual spoken language understanding</title>
		<author>
			<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qixin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.08325</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b241">
	<monogr>
		<title level="m" type="main">Cosda-ml: Multi-lingual code-switching data augmentation for zero-shot cross-lingual nlp</title>
		<author>
			<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minheng</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06402</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b242">
	<monogr>
		<author>
			<persName><forename type="first">Yifu</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yftah</forename><surname>Ziser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Edoardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Ponti</surname></persName>
		</author>
		<author>
			<persName><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13632</idno>
		<title level="m">Detecting and mitigating hallucinations in multilingual summarisation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b243">
	<analytic>
		<title level="a" type="main">The task of post-editing machine translation for the low-resource language</title>
		<author>
			<persName><forename type="first">Diana</forename><surname>Rakhimova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidana</forename><surname>Karibayeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Assem</forename><surname>Turarbek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">486</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b244">
	<monogr>
		<author>
			<persName><forename type="first">Krithika</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunayana</forename><surname>Sitaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monojit</forename><surname>Choudhury</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.12578</idno>
		<title level="m">Fairness in language models beyond english: Gaps and challenges</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b245">
	<monogr>
		<author>
			<persName><forename type="first">Rita</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.19821</idno>
		<title level="m">Lmcap: Few-shot multilingual image captioning by retrieval augmented language model prompting</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b246">
	<monogr>
		<title level="m" type="main">Empowering cross-lingual abilities of instruction-tuned large language models by translation-following demonstrations</title>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Ranaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giulia</forename><surname>Pucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Freitas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.14186</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b247">
	<monogr>
		<title level="m" type="main">Empowering cross-lingual abilities of instruction-tuned large language models by translation-following demonstrations</title>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Ranaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giulia</forename><surname>Pucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Freitas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.14186</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b248">
	<monogr>
		<title level="m" type="main">The curious case of hallucinations in neural machine translation</title>
		<author>
			<persName><forename type="first">Arul</forename><surname>Vikas Raunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.06683</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b249">
	<monogr>
		<author>
			<persName><forename type="first">Amr</forename><surname>Vikas Raunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hany</forename><surname>Sharaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arul</forename><surname>Hassan Awadallah</surname></persName>
		</author>
		<author>
			<persName><surname>Menezes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14878</idno>
		<title level="m">Leveraging gpt-4 for automatic translation post-editing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b250">
	<monogr>
		<title level="m" type="main">Little red riding hood goes around the globe: Crosslingual story planning and generation with large language models</title>
		<author>
			<persName><forename type="first">Evgeniia</forename><surname>Razumovskaia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10471</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b251">
	<analytic>
		<title level="a" type="main">Comet: A neural framework for mt evaluation</title>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><forename type="middle">C</forename><surname>Farinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2685" to="2702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b252">
	<monogr>
		<title level="m" type="main">Neural machine translation models can learn to be few-shot learners</title>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Reinauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Simianer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaden</forename><surname>Uhlig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><forename type="middle">Em</forename><surname>Mosig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joern</forename><surname>Wuebker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.08590</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b253">
	<monogr>
		<title level="m" type="main">X-parade: Cross-lingual textual entailment and information divergence across paragraphs</title>
		<author>
			<persName><forename type="first">Diego</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName><surname>Durrett</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.08873</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b254">
	<monogr>
		<title level="m" type="main">2022a. Clasp: Few-shot cross-lingual data augmentation for semantic parsing</title>
		<author>
			<persName><forename type="first">Andy</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saleh</forename><surname>Soltan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wael</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Saffari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Damonte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Groves</surname></persName>
		</author>
		<idno>AACL-IJCNLP 2022</idno>
		<imprint>
			<biblScope unit="page">444</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b255">
	<monogr>
		<title level="m" type="main">Linguist: Language model instruction tuning to generate annotated utterances for intent classification and slot tagging</title>
		<author>
			<persName><forename type="first">Andy</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saleh</forename><surname>Soltan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wael</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Boese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.09900</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b256">
	<monogr>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.07412</idno>
		<title level="m">Xtreme-r: Towards more challenging and nuanced multilingual evaluation</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b257">
	<monogr>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><forename type="middle">F</forename><surname>Lotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Bugliarello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Salesky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miryam</forename><surname>De Lhoneux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.06991</idno>
		<title level="m">Language modelling with pixels</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b258">
	<monogr>
		<title level="m" type="main">Revisiting non-english text simplification: A unified multilingual benchmark</title>
		<author>
			<persName><forename type="first">Tarek</forename><surname>Michael J Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Naous</surname></persName>
		</author>
		<author>
			<persName><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.15678</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b259">
	<monogr>
		<author>
			<persName><forename type="first">Eduardo</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><forename type="middle">R</forename><surname>Costa-Jussà</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.03175</idno>
		<title level="m">Gender-specific machine translation with large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b260">
	<monogr>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Santilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Rodolà</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.16456</idno>
		<title level="m">Camoscio: An italian instruction-tuned llama</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b261">
	<monogr>
		<title level="m" type="main">Cross-lingual supervision improves large language models pre-training</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Schioppa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11778</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b262">
	<analytic>
		<title level="a" type="main">Polyglot or not? measuring multilingual encyclopedic knowledge in foundation models</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Schott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Furman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shreshta</forename><surname>Bhat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="11238" to="11253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b263">
	<monogr>
		<title level="m" type="main">Cross-lingual transfer learning for multilingual task oriented dialog</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rushin</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.13327</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b264">
	<analytic>
		<title level="a" type="main">Wiki-Matrix: Mining 135M parallel sentences in 1620 language pairs from Wikipedia</title>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.115</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1351" to="1361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b265">
	<analytic>
		<title level="a" type="main">Multilingual entity and relation extraction dataset and model</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Seganti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaudia</forename><surname>Firl Ąg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><surname>Skowronska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michał</forename><surname>Satława</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Andruszkiewicz</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.166</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1946" to="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b266">
	<monogr>
		<title level="m" type="main">Bleurt: Learning robust metrics for text generation</title>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Sellam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur P</forename><surname>Parikh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04696</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b267">
	<monogr>
		<title level="m" type="main">Rahul Pal, et al. 2023. Jais and jais-chat: Arabic-centric foundation and instruction-tuned open generative large language models</title>
		<author>
			<persName><forename type="first">Neha</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunil</forename><surname>Kumar Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bokang</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satheesh</forename><surname>Katipomu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haonan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fajri</forename><surname>Koto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Osama</forename><surname>Mohammed Afzal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samta</forename><surname>Kamboj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onkar</forename><surname>Pandit</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.16149</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b268">
	<monogr>
		<title level="m" type="main">Multilingual instruction tuning with just a pinch of multilinguality</title>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roee</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matan</forename><surname>Eyal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.01854</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b269">
	<monogr>
		<title/>
		<author>
			<persName><surname>Sharegpt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Sharegpt</note>
</biblStruct>

<biblStruct xml:id="b270">
	<monogr>
		<author>
			<persName><forename type="first">Shuaijie</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.06838</idno>
		<title level="m">Mapo: Advancing multilingual reasoning through multilingual alignment-as-preference optimization</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b271">
	<monogr>
		<author>
			<persName><forename type="first">Lingfeng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiting</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sihao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunmo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyuan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.13136</idno>
		<title level="m">The language barrier: Dissecting safety challenges of llms in multilingual contexts</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b272">
	<monogr>
		<title level="m" type="main">2022a. Language models are multilingual chain-of-thought reasoners</title>
		<author>
			<persName><forename type="first">Freda</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirac</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suraj</forename><surname>Srivats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soroush</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03057</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b273">
	<monogr>
		<title level="m" type="main">2022b. Xricl: Cross-lingual retrieval-augmented in-context learning for cross-lingual text-to-sql semantic parsing</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.13693</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b274">
	<monogr>
		<author>
			<persName><forename type="first">Oleh</forename><surname>Shliazhko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alena</forename><surname>Fenogenova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Tikhonova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladislav</forename><surname>Mikhailov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Kozlova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatiana</forename><surname>Shavrina</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.07580</idno>
		<title level="m">mgpt: Few-shot learners go multilingual</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b275">
	<monogr>
		<title level="m" type="main">Anti-lm decoding for zero-shot in-context machine translation</title>
		<author>
			<persName><forename type="first">Suzanna</forename><surname>Sia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Delucia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.08324</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b276">
	<monogr>
		<author>
			<persName><surname>Saleh Soltan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Shankar Ananthakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wael</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haidar</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charith</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Peris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Rawls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName><surname>Rumshisky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.01448</idno>
		<title level="m">Alexatm 20b: Few-shot learning using a large-scale multilingual seq2seq model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b277">
	<monogr>
		<author>
			<persName><forename type="first">Guijin</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwool</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaecheol</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Je</forename><forename type="middle">Won</forename><surname>Yeom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jihyu</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><forename type="middle">Woo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songseong</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.02706</idno>
		<title level="m">Hae-rae bench: Evaluation of korean knowledge in language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b278">
	<monogr>
		<title level="m" type="main">Sling: Sino linguistic evaluation of large language models</title>
		<author>
			<persName><forename type="first">Yixiao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalpesh</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajesh</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11689</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b279">
	<analytic>
		<title level="a" type="main">Tydip: A dataset for politeness classification in nine typologically diverse languages</title>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5723" to="5738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b280">
	<analytic>
		<title level="a" type="main">Holistic inter-annotator agreement and corpus coherence estimation in a large-scale multilingual annotation campaign</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Stefanovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Piskorski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="71" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b281">
	<monogr>
		<author>
			<persName><forename type="first">Hui</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houjin</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zilin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.10372</idno>
		<title level="m">Welm: A well-read pre-trained language model for chinese</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b282">
	<monogr>
		<title level="m" type="main">Asynchronous pipeline for processing huge corpora on medium to low resource infrastructures</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Javier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ortiz</forename><surname>Suárez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoît</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
		<respStmt>
			<orgName>Institut für Deutsche Sprache</orgName>
		</respStmt>
	</monogr>
	<note>In 7th Workshop on the Challenges in the Management of Large Corpora (CMLC-7</note>
</biblStruct>

<biblStruct xml:id="b283">
	<analytic>
		<title level="a" type="main">Xinyi Wang, and Graham Neubig. 2023a. A multi-dimensional evaluation of tokenizer-free multilingual pretrained models</title>
		<author>
			<persName><forename type="first">Jimin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Fernandes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EACL 2023</title>
		<imprint>
			<biblScope unit="page" from="1680" to="1690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b284">
	<monogr>
		<author>
			<persName><forename type="first">Tianxiang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengfu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunfan</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiong</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingjian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yining</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhejian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruixiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaogui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingling</forename><surname>Wu</surname></persName>
		</author>
		<title level="m">Zhangyue Yin, Xuanjing Huang, and Xipeng Qiu. 2023b. Moss: Training conversational language models from synthetic data</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b285">
	<monogr>
		<title level="m" type="main">Ernie 3.0: Large-scale knowledge enhanced pre-training for language understanding and generation</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shikun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyuan</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanbin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.02137</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b286">
	<monogr>
		<author>
			<persName><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yikang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinhong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenfang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Cox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.05910</idno>
		<title level="m">Yiming Yang, and Chuang Gan. 2023c. Salmon: Self-alignment with principle-following reward models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b287">
	<monogr>
		<title level="m" type="main">Multilingual llms are better cross-lingual in-context learners with alignment</title>
		<author>
			<persName><forename type="first">Eshaan</forename><surname>Tanwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhabrata</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanmoy</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.05940</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b288">
	<monogr>
		<title/>
		<author>
			<persName><surname>Coig Pc Team</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b289">
	<monogr>
		<author>
			<persName><forename type="first">Gemini</forename><surname>Team</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Schalkwyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anja</forename><surname>Hauth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.11805</idno>
		<title level="m">Gemini: a family of highly capable multimodal models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b290">
	<monogr>
		<title level="m" type="main">Huozi: An open-source universal llm</title>
		<author>
			<persName><forename type="first">Huozi</forename><surname>Team</surname></persName>
		</author>
		<ptr target="https://github.com/HIT-SCIR/huozi" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b291">
	<monogr>
		<title level="m" type="main">2023c. Internlm: A multilingual language model with progressively enhanced capabilities</title>
		<author>
			<persName><forename type="first">Internlm</forename><surname>Team</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b292">
	<monogr>
		<title level="m" type="main">Yulan-chat: An open-source bilingual chatbot</title>
		<author>
			<persName><forename type="first">Yulan</forename><surname>Team</surname></persName>
		</author>
		<ptr target="https://github.com/RUC-GSAI/YuLan-Chat" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b293">
	<monogr>
		<author>
			<persName><forename type="first">Nandan</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz</forename><surname>Bonifacio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Odunayo</forename><surname>Ogundepo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Kamalloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Alfonso-Hermelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boxing</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.11361</idno>
		<title level="m">Mehdi Rezagholizadeh, et al. 2023a. Nomiracl: Knowing when you don&apos;t know for robust multilingual retrieval-augmented generation</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b294">
	<monogr>
		<title level="m" type="main">Leveraging llms for synthesizing training data across many languages in multilingual dense retrieval</title>
		<author>
			<persName><forename type="first">Nandan</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><forename type="middle">Hernández</forename><surname>Ábrego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.05800</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b295">
	<monogr>
		<author>
			<persName><forename type="first">Ashish</forename><forename type="middle">V</forename><surname>Thapliyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12522</idno>
		<title level="m">Crossmodal-3600: A massively multilingual multimodal evaluation dataset</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b296">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Thulke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingbo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petrus</forename><surname>Pelser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rein</forename><surname>Brune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rricha</forename><surname>Jalota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Floris</forename><surname>Fok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Van Wyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdallah</forename><surname>Nasir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hayden</forename><surname>Goldstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.09646</idno>
		<title level="m">Climategpt: Towards ai synthesizing interdisciplinary research on climate change</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b297">
	<analytic>
		<title level="a" type="main">Parallel data, tools and interfaces in OPUS</title>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2214" to="2218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b298">
	<monogr>
		<title level="m" type="main">It&apos;s all in the heads: Using attention heads as a baseline for crosslingual transfer in commonsense reasoning</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Tikhonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Ryabinin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.12066</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b299">
	<monogr>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971</idno>
		<title level="m">Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b300">
	<monogr>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasmine</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288</idno>
		<title level="m">Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b301">
	<analytic>
		<title level="a" type="main">Interleaving retrieval with chain-of-thought reasoning for knowledgeintensive multi-step questions</title>
		<author>
			<persName><forename type="first">Harsh</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niranjan</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.acl-long.557</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="10014" to="10037" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b302">
	<analytic>
		<title level="a" type="main">Enhancing natural language inference of cross-lingual n-shot transfer with multilingual data</title>
		<author>
			<persName><forename type="first">Kuang</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chow-Sing</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 8th International Conference on Applied System Innovation (ICASI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="68" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b303">
	<monogr>
		<title level="m" type="main">Efficiently aligned cross-lingual transfer learning for conversational tasks using prompt-tuning</title>
		<author>
			<persName><forename type="first">Lifu</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Semih</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingbo</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.01295</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b304">
	<monogr>
		<title level="m" type="main">Anytext: Multilingual visual text generation and editing</title>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Tuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wangmeng</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun-Yan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifeng</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuansong</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.03054</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b305">
	<monogr>
		<author>
			<persName><forename type="first">Gökçe</forename><surname>Uludogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yirmibeşoglu</forename><surname>Zeynep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furkan</forename><surname>Balal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melikşah</forename><surname>Akkurt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Türker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Güngör</surname></persName>
		</author>
		<author>
			<persName><surname>Üsküdarlı</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.14373</idno>
		<title level="m">Turna: A turkish encoder-decoder language model for enhanced understanding and generation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b306">
	<monogr>
		<title level="m" type="main">Taco: Enhancing cross-lingual transfer for low-resource languages in llms through translation-assisted chain-ofthought processes</title>
		<author>
			<persName><forename type="first">Bibek</forename><surname>Upadhayay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vahid</forename><surname>Behzadan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.10797</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b307">
	<monogr>
		<title level="m" type="main">Pmindiasum: Multilingual and cross-lingual headline summarization for languages in india</title>
		<author>
			<persName><forename type="first">Ashok</forename><surname>Urlana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pinzhen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Shay B Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><surname>Haddow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08828</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b308">
	<monogr>
		<title level="m" type="main">mlongt5: A multilingual and efficient text-to-text transformer for longer sequences</title>
		<author>
			<persName><forename type="first">David</forename><surname>Uthus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santiago</forename><surname>Ontañón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandy</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b309">
	<monogr>
		<title level="m" type="main">Large scale multi-lingual multi-modal summarization dataset</title>
		<author>
			<persName><forename type="first">Yash</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anubhav</forename><surname>Jangra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghvendra</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriparna</forename><surname>Saha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.06560</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b310">
	<monogr>
		<title level="m" type="main">Don&apos;t rank, combine! combining machine translation hypotheses using quality estimation</title>
		<author>
			<persName><forename type="first">Giorgos</forename><surname>Vernikos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Popescu-Belis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.06688</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b311">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viresh</forename><surname>Ratnakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09102</idno>
		<title level="m">Prompting palm for translation: Assessing strategies and performance</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b312">
	<monogr>
		<title level="m" type="main">Overcoming catastrophic forgetting in zero-shot cross-lingual generation</title>
		<author>
			<persName><forename type="first">Tu</forename><surname>Vu</surname></persName>
			<affiliation>
				<orgName type="collaboration">Mohit Iyyer, and Noah Constant</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Barua</surname></persName>
			<affiliation>
				<orgName type="collaboration">Mohit Iyyer, and Noah Constant</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
			<affiliation>
				<orgName type="collaboration">Mohit Iyyer, and Noah Constant</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
			<affiliation>
				<orgName type="collaboration">Mohit Iyyer, and Noah Constant</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:2205.12647</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b313">
	<monogr>
		<author>
			<persName><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangkai</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ai</forename><surname>Ti Aw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.04766</idno>
		<title level="m">Seaeval for multilingual foundation models: From cross-lingual alignment to cultural reasoning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b314">
	<monogr>
		<author>
			<persName><forename type="first">Jiaan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunlong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhixu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.14229</idno>
		<title level="m">Crosslingual summarization via chatgpt</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b315">
	<monogr>
		<title level="m" type="main">2023c. Cross-lingual knowledge editing in large language models</title>
		<author>
			<persName><forename type="first">Jiaan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunlong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zengkui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarong</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.08952</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b316">
	<monogr>
		<author>
			<persName><forename type="first">Jiaan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duo</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhixu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.05599</idno>
		<title level="m">Clidsum: A benchmark dataset for cross-lingual dialogue summarization</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b317">
	<monogr>
		<author>
			<persName><forename type="first">Longyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianbo</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhirui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.02210</idno>
		<title level="m">Document-level machine translation with large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b318">
	<monogr>
		<author>
			<persName><forename type="first">Weixuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.13040</idno>
		<title level="m">Retrieval-augmented multilingual knowledge editing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b319">
	<monogr>
		<author>
			<persName><forename type="first">Wenxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youliang</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jen-Tse</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxiang</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><surname>Michael R Lyu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.00905</idno>
		<title level="m">All languages matter: On the multilingual safety of large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b320">
	<monogr>
		<author>
			<persName><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pegah</forename><surname>Alipoormolabashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeganeh</forename><surname>Kordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amirreza</forename><surname>Mirzaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anjana</forename><surname>Arunkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Ashok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arut</forename><surname>Selvan Dhanasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atharva</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Stap</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.07705</idno>
		<title level="m">Generalization via declarative instructions on 1600+ nlp tasks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>et al. 2022b. Super-naturalinstructions</note>
</biblStruct>

<biblStruct xml:id="b321">
	<monogr>
		<title level="m" type="main">Xing Xie, and Jitao Sang. 2023g. Cdeval: A benchmark for measuring the cultural dimensions of large language models</title>
		<author>
			<persName><forename type="first">Yuhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanxu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyuan</forename><surname>Yi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.16421</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b322">
	<monogr>
		<title level="m" type="main">Osama Mohammed Afzal, Tarek Mahmoud, Alham Fikri Aji, et al. 2023h. M4: Multigenerator, multi-domain, and multi-lingual black-box machine-generated text detection</title>
		<author>
			<persName><forename type="first">Yuxia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonibek</forename><surname>Mansurov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Shelmanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akim</forename><surname>Tsvigun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenxi</forename><surname>Whitehouse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14902</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b323">
	<monogr>
		<author>
			<persName><forename type="first">Zhiruo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><surname>Cuenca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.08388</idno>
		<title level="m">Mconala: a benchmark for code generation from multiple natural languages</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b324">
	<monogr>
		<title level="m" type="main">Daniel Fried, and Graham Neubig. 2022d. Execution-based evaluation for open-domain code generation</title>
		<author>
			<persName><forename type="first">Zhiruo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyan</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10481</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b325">
	<monogr>
		<author>
			<persName><forename type="first">Aman</forename><surname>Kassahun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wassie</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2311.14530</idno>
		<title level="m">Machine translation for ge&apos;ez language</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b326">
	<analytic>
		<title level="a" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b327">
	<monogr>
		<author>
			<persName><forename type="first">Tianwen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haihua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Lü</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.19341</idno>
		<title level="m">Skywork: A more open bilingual foundation model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b328">
	<monogr>
		<title level="m" type="main">2023b. Zeroshot information extraction via chatting with chatgpt</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingyu</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjun</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.10205</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b329">
	<monogr>
		<author>
			<persName><forename type="first">Xiangpeng</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingzhang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.06018</idno>
		<title level="m">Binbin Xie, et al. 2023c. Polylm: An open source polyglot large language model</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b330">
	<analytic>
		<title level="a" type="main">Counting the bugs in ChatGPT&apos;s wugs: A multilingual investigation into the morphological capabilities of a large language model</title>
		<author>
			<persName><forename type="first">Leonie</forename><surname>Weissweiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anjali</forename><surname>Kantharuban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ritam</forename><surname>Dutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amey</forename><surname>Hengle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anubha</forename><surname>Kabra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atharva</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Vijayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haofei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schuetze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kemal</forename><surname>Oflazer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mortensen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.emnlp-main.401</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="6508" to="6524" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b331">
	<analytic>
		<title level="a" type="main">Hyperpolyglot llms: Cross-lingual interpretability in token embeddings</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Yi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mimno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1124" to="1131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b332">
	<monogr>
		<author>
			<persName><forename type="first">Chenxi</forename><surname>Whitehouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monojit</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aji</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14288</idno>
		<title level="m">Llm-powered data augmentation for enhanced crosslingual performance</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b333">
	<monogr>
		<author>
			<persName><forename type="first">Chenxi</forename><surname>Whitehouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fantine</forename><surname>Huot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmijn</forename><surname>Bastings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chu-Cheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.08572</idno>
		<title level="m">Parameter-efficient multilingual summarisation: An empirical study</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b334">
	<analytic>
		<title level="a" type="main">2022a. Crosslingual few-shot learning on unseen languages</title>
		<author>
			<persName><forename type="first">Genta</forename><surname>Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thamar</forename><surname>Solorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Preotiuc-Pietro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online only. Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="777" to="791" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b335">
	<analytic>
		<title level="a" type="main">2023a. NusaX: Multilingual parallel sentiment dataset for 10 Indonesian local languages</title>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahmad</forename><surname>Mahendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fajri</forename><surname>Koto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ade</forename><surname>Romadhony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kemal</forename><surname>Kurniawan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Moeljadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radityo</forename><forename type="middle">Eko</forename><surname>Prasojo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jey</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.eacl-main.57</idno>
	</analytic>
	<monogr>
		<title level="m">the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="815" to="834" />
		</imprint>
	</monogr>
	<note>In Proceedings of the 17th Conference of the European Chapter Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b336">
	<monogr>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Xin</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thamar</forename><surname>Solorio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09660</idno>
		<title level="m">The decades progress on code-switching research in nlp: A systematic survey on trends and challenges</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b337">
	<monogr>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang-Kang</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.10964</idno>
		<title level="m">Soumya Vadlamannati, and Yash Chandarana. 2023b. Multilingual few-shot learning via language model retrieval</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b338">
	<monogr>
		<author>
			<persName><forename type="first">Bigscience</forename><surname>Workshop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzana</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ilić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Castagné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName><surname>Yvon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05100</idno>
		<title level="m">Bloom: A 176bparameter open-access multilingual language model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b339">
	<monogr>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlong</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinsong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingming</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.09954</idno>
		<title level="m">Eva-kellm: A new benchmark for evaluating knowledge editing of llms</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b340">
	<analytic>
		<title level="a" type="main">Exploring prompt engineering with gpt language models for documentlevel machine translation: Insights and findings</title>
		<author>
			<persName><forename type="first">Yangjian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Conference on Machine Translation</title>
		<meeting>the Eighth Conference on Machine Translation</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="166" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b341">
	<analytic>
		<title level="a" type="main">Task-agnostic low-rank adapters for unseen english dialects</title>
		<author>
			<persName><forename type="first">Zedian</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="7857" to="7870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b342">
	<monogr>
		<title level="m" type="main">2023a. A paradigm shift in machine translation: Boosting translation performance of large language models</title>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amr</forename><surname>Sharaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hany</forename><surname>Hassan Awadalla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.11674</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b343">
	<monogr>
		<author>
			<persName><forename type="first">Nan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaowei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.09827</idno>
		<title level="m">Cognitive overload: Jailbreaking large language models with overloaded logical thinking</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b344">
	<monogr>
		<title level="m" type="main">2023c. Are structural concepts universal in transformer language models? towards interpretable cross-lingual generalization</title>
		<author>
			<persName><forename type="first">Ningyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingting</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Menghan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.12794</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b345">
	<analytic>
		<title level="a" type="main">Language representation projection: Can we transfer factual knowledge across languages in multilingual language models?</title>
		<author>
			<persName><forename type="first">Shaoyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhuo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="3692" to="3702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b346">
	<analytic>
		<title level="a" type="main">End-to-end slot alignment and recognition for crosslingual NLU</title>
		<author>
			<persName><forename type="first">Weijia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Batool</forename><surname>Haider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saab</forename><surname>Mansour</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.410</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5052" to="5063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b347">
	<monogr>
		<title level="m" type="main">Vnhsge: Vietnamese high school graduation examination dataset for large language models</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Dao Xuan-Quy</surname></persName>
		</author>
		<author>
			<persName><surname>Ngoc-Bich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phan</forename><surname>Vo The-Duy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ngo</forename><surname>Xuan-Dung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nguyen</forename><surname>Bac-Bien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nguyen</forename><surname>Van-Tien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nguyen</forename><surname>Thi-My-Thanh</surname></persName>
		</author>
		<author>
			<persName><surname>Hong-Phuoc</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.12199</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b348">
	<monogr>
		<title level="m" type="main">Byt5: Towards a token-free future with pre-trained byte-to-byte models</title>
		<author>
			<persName><forename type="first">Linting</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="291" to="306" />
		</imprint>
	</monogr>
	<note>Transactions of the Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b349">
	<monogr>
		<author>
			<persName><forename type="first">Linting</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Siddhant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11934</idno>
		<title level="m">Aditya Barua, and Colin Raffel. 2020. mt5: A massively multilingual pre-trained text-to-text transformer</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b350">
	<analytic>
		<title level="a" type="main">Aditya Barua, and Colin Raffel. 2021. mt5: A massively multilingual pre-trained text-to-text transformer</title>
		<author>
			<persName><forename type="first">Linting</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Siddhant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b351">
	<monogr>
		<title level="m" type="main">Lahm: Large annotated dataset for multi-domain and multilingual hate speech identification</title>
		<author>
			<persName><forename type="first">Ankit</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Chandel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.00913</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Sushant Chatufale, and Anil Bandhakavi</note>
</biblStruct>

<biblStruct xml:id="b352">
	<monogr>
		<author>
			<persName><forename type="first">Aiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Borong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenxu</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.10305</idno>
		<title level="m">Fan Yang, et al. 2023a. Baichuan 2: Open large-scale language models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b353">
	<monogr>
		<title level="m" type="main">Investigating zero-shot generalizability on mandarin-english code-switched asr and speech-totext translation of recent foundation models with selfsupervision and weak supervision</title>
		<author>
			<persName><forename type="first">Chih-Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan-Po</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke-Han</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chun-Yi</forename><surname>Kuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi-Yuan</forename><surname>Hsiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung-Yi</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.00273</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b354">
	<monogr>
		<title level="m" type="main">2023c. Direct preference optimization for neural machine translation with minimum bayes risk decoding</title>
		<author>
			<persName><forename type="first">Guangyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinghong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Byrne</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.08380</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b355">
	<analytic>
		<title level="a" type="main">machine translation evaluation report</title>
		<author>
			<persName><forename type="first">Muyun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xixin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiliyaer</forename><surname>Jiaermuhamaiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Translation: 15th China Conference</title>
		<meeting><address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09-27">2019a. Ccmt 2019. September 27-29, 2019</date>
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="105" to="128" />
		</imprint>
	</monogr>
	<note>CCMT</note>
</biblStruct>

<biblStruct xml:id="b356">
	<monogr>
		<author>
			<persName><forename type="first">Wen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.18098</idno>
		<title level="m">Bigtrans: Augmenting large language models with multilingual translation capability over 100 languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b357">
	<monogr>
		<title level="m" type="main">Understanding calibration for multilingual question answering models</title>
		<author>
			<persName><forename type="first">Yahan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soham</forename><surname>Dan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Insup</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.08669</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b358">
	<monogr>
		<author>
			<persName><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Tar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.11828</idno>
		<title level="m">Paws-x: A cross-lingual adversarial dataset for paraphrase identification</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b359">
	<analytic>
		<title level="a" type="main">2023f. Mono-and multilingual gpt-3 models for hungarian</title>
		<author>
			<persName><forename type="first">Zijian</forename><surname>Győző</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">László</forename><forename type="middle">János</forename><surname>Laki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamás</forename><surname>Váradi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gábor</forename><surname>Prószéky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Text, Speech, and Dialogue</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="94" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b360">
	<monogr>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xijia</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.06688</idno>
		<title level="m">Language versatilists vs. specialists: An empirical revisiting on multilingual transfer ability</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b361">
	<monogr>
		<author>
			<persName><forename type="first">Meng</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Sikka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Atwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabit</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Divakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malihe</forename><surname>Alikhani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.09618</idno>
		<title level="m">Multilingual content moderation: A case study on reddit</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b362">
	<monogr>
		<author>
			<persName><forename type="first">Hritik</forename><surname>Da Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masoud</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liunian</forename><surname>Monajatipoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Harold Li</surname></persName>
		</author>
		<author>
			<persName><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12247</idno>
		<title level="m">Geomlama: Geo-diverse commonsense probing on multilingual pre-trained language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b363">
	<monogr>
		<author>
			<persName><forename type="first">Zheng-Xin</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ifeoluwa Adelani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Almubarak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungo</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Baruwa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09535</idno>
		<title level="m">Bloom+ 1: Adding language support to bloom for zero-shot prompting</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b364">
	<monogr>
		<title level="m" type="main">Prompting multilingual large language models to generate codemixed texts: The case of south east asian languages</title>
		<author>
			<persName><forename type="first">Zheng-Xin</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruochen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Zosa Forde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skyler</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holy</forename><surname>Lovenia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Christian Blaise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><surname>Phan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">2303</biblScope>
		</imprint>
	</monogr>
	<note>arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b365">
	<monogr>
		<author>
			<persName><forename type="first">Dongkeun</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.10695</idno>
		<title level="m">Seungone Kim, Sheikh Shafayat, and Minjoon Seo. 2024. Langbridge: Multilingual reasoning without multilingual supervision</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b366">
	<monogr>
		<author>
			<persName><forename type="first">Xinyan</forename><surname>Velocity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trina</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.15649</idno>
		<title level="m">Beyond counting datasets: a survey of multilingual dataset construction and necessary resources</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b367">
	<analytic>
		<title level="a" type="main">Lego-mt: Learning detachable models for massively multilingual machine translation</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinquan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="11518" to="11533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b368">
	<monogr>
		<title level="m" type="main">Exploring the impact of instruction data scaling on large language models: An empirical study on real-world use cases</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiping</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baochang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunjie</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.14742</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b369">
	<analytic>
		<title level="a" type="main">Universal dependencies 2.10</title>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Daniel Zeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elia</forename><surname>Abrams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noëmi</forename><surname>Ackermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Aepli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Željko</forename><surname>Aghaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Agić</surname></persName>
		</author>
		<author>
			<persName><surname>Ahmadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics (ÚFAL), Faculty of Mathematics and Physics</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b370">
	<monogr>
		<author>
			<persName><forename type="first">Aohan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanyu</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02414</idno>
		<title level="m">Glm-130b: An open bilingual pre-trained model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b371">
	<monogr>
		<author>
			<persName><forename type="first">Jiali</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongjing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.02851</idno>
		<title level="m">Improving machine translation with large language models: A preliminary study with cooperative arXiv preprint</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b372">
	<monogr>
		<author>
			<persName><forename type="first">Jiali</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongjing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.04408</idno>
		<title level="m">Tim: Teaching large language models to translate with comparison</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b373">
	<monogr>
		<author>
			<persName><forename type="first">Biao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.07069</idno>
		<title level="m">Prompting large language model for machine translation: A case study</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b374">
	<analytic>
		<title level="a" type="main">Improving massively multilingual neural machine translation and zero-shot translation</title>
		<author>
			<persName><forename type="first">Biao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.148</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1628" to="1639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b375">
	<monogr>
		<title level="m" type="main">2023b. xdialeval: A multilingual open-domain dialogue evaluation benchmark</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengguang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haizhou</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.08958</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b376">
	<monogr>
		<title level="m" type="main">The skipped beat: A study of sociopragmatic understanding in llms for 64 languages</title>
		<author>
			<persName><forename type="first">Chiyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khai</forename><surname>Duy Doan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qisheng</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Abdul-Mageed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.14557</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b377">
	<analytic>
		<title level="a" type="main">Leveraging multilingual knowledge graph to boost domain-specific entity translation of chatgpt</title>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Yanqing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaosong</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinglu</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Translation Summit XIX</title>
		<meeting>Machine Translation Summit XIX</meeting>
		<imprint>
			<publisher>Users Track</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="77" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b378">
	<monogr>
		<author>
			<persName><forename type="first">Ran</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jihed</forename><surname>Ouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.12916</idno>
		<title level="m">Crosslingual cross-temporal summarization: Dataset, models, evaluation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b379">
	<monogr>
		<author>
			<persName><forename type="first">Ruochen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14235</idno>
		<title level="m">Christian Blaise Cruz, and Alham Fikri Aji. 2023f. Multilingual large language models are not (yet) codeswitchers</title>
		<imprint>
			<date>Jan</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b380">
	<monogr>
		<title level="m" type="main">Crocosum: A benchmark dataset for cross-lingual code-switched summarization</title>
		<author>
			<persName><forename type="first">Ruochen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.04092</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b381">
	<monogr>
		<title level="m" type="main">2023g. Bayling: Bridging cross-lingual alignment and instruction following through interactive translation for large language models</title>
		<author>
			<persName><forename type="first">Shaolei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingkai</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuocheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengrui</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Langlin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengyu</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shangtong</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunji</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.10968</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b382">
	<monogr>
		<author>
			<persName><forename type="first">Susan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01068</idno>
		<title level="m">Opt: Open pre-trained transformer language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b383">
	<analytic>
		<title level="a" type="main">Bertscore: Evaluating text generation with bert</title>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b384">
	<monogr>
		<title level="m" type="main">Yew Ken Chia, and Lidong Bing. 2023h. M3exam: A multilingual, multimodal, multilevel benchmark for examining large language models</title>
		<author>
			<persName><forename type="first">Wenxuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharifah</forename><surname>Mahani Aljunied</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.05179</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b385">
	<monogr>
		<title level="m" type="main">2023i. Don&apos;t trust gpt when your question is not in english</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Senyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Hauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.16339</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b386">
	<monogr>
		<author>
			<persName><forename type="first">Xiaotian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyu</forename><surname>Ying</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.12474</idno>
		<title level="m">Liang He, and Xipeng Qiu. 2023j. Evaluating the performance of large language models on gaokao benchmark</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b387">
	<monogr>
		<author>
			<persName><forename type="first">Yusen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.04085</idno>
		<title level="m">Xsemplr: Cross-lingual semantic parsing in multiple natural languages and meaning representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b388">
	<analytic>
		<title level="a" type="main">Cpm-2: Large-scale cost-effective pre-trained language models</title>
		<author>
			<persName><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxian</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaojun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenbo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fanchao</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><surname>Ke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="216" to="224" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b389">
	<monogr>
		<author>
			<persName><forename type="first">Ziyin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yikang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weifang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyu</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.09033</idno>
		<title level="m">Mela: Multilingual evaluation of linguistic acceptability</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b390">
	<monogr>
		<author>
			<persName><forename type="first">Biao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiqiang</forename><surname>Jin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.15024</idno>
		<title level="m">Javier Del Ser, and Guang Yang. 2023a. Chatagri: Exploring potentials of chatgpt on cross-linguistic agricultural text classification</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b391">
	<monogr>
		<author>
			<persName><forename type="first">Kun</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beichen</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zican</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.18223</idno>
		<title level="m">A survey of large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b392">
	<analytic>
		<title level="a" type="main">HIT-SCIR at MMNLU-22: Consistency regularization for multilingual spoken language understanding</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhouyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuxuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.mmnlu-1.4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Massively Multilingual Natural Language Understanding Workshop (MMNLU-22)</title>
		<meeting>the Massively Multilingual Natural Language Understanding Workshop (MMNLU-22)<address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>United Arab Emirates (Hybrid). Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="35" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b393">
	<monogr>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Lin</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghao</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.05685</idno>
		<title level="m">Eric Xing, et al. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b394">
	<monogr>
		<title level="m" type="main">Let&apos;s think outside the box: Exploring leap-of-thought in large language models with creative humor generation</title>
		<author>
			<persName><forename type="first">Shanshan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongzhan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanghua</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wushao</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.02439</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b395">
	<monogr>
		<author>
			<persName><forename type="first">Wanjun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruixiang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiduo</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaobo</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amin</forename><surname>Saied</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.06364</idno>
		<title level="m">Agieval: A human-centric benchmark for evaluating foundation models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b396">
	<monogr>
		<title level="m" type="main">Rc3: Regularized contrastive cross-lingual cross-modal pretraining</title>
		<author>
			<persName><forename type="first">Chulun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunlong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinsong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.07927</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b397">
	<monogr>
		<author>
			<persName><forename type="first">Di</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinxian</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.09917</idno>
		<title level="m">Red ai? inconsistent responses from gpt3. 5 models on political issues in the us and china</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b398">
	<monogr>
		<author>
			<persName><forename type="first">Kairui</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.06358</idno>
		<title level="m">Accessible instruction-following agent</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b399">
	<monogr>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuaijie</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.07817</idno>
		<title level="m">Question translation training for better multilingual reasoning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b400">
	<monogr>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunzhe</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingxiu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.04948</idno>
		<title level="m">Extrapolating large language models to non-english by aligning languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b401">
	<analytic>
		<title level="a" type="main">The United Nations parallel corpus v1.0</title>
		<author>
			<persName><forename type="first">Michał</forename><surname>Ziemski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Pouliquen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3530" to="3534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b402">
	<analytic>
		<title level="a" type="main">Recently, Lou et al. (2023) proposed CCEval for Chinese-centric translation for comprehensive evaluation on MLLMs. Furthermore, due to the large gap between languages</title>
		<author>
			<persName><forename type="first">Vilém</forename><surname>Zouhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Dabre</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.01283</idno>
	</analytic>
	<monogr>
		<title level="m">Quality and quantity of machine translation references for automated metrics</title>
		<editor>
			<persName><surname>Wmt (kocmi</surname></persName>
		</editor>
		<imprint>
			<publisher>Stefanovitch and Piskorski</publisher>
			<date type="published" when="2020">2024. 2020. 2022. 2022. 2021. 2023. 2023. 2023. 2023. 2023. 2023. 2023. 2023. 2023. 2022. 2023. 2023. 2023</date>
			<biblScope unit="page">200</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>put capabilities. The most typical task is machine translation Vilar et al., 2022), currently commonly used data sets are: FLORES-101 Ramesh Lai et al., 2023a; Philippy et al., 2023; Ye et al., 2023a</note>
</biblStruct>

<biblStruct xml:id="b403">
	<monogr>
		<title/>
		<author>
			<persName><surname>Wassie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b404">
	<monogr>
		<title/>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b405">
	<monogr>
		<title level="m" type="main">focused more on low-resource language translation</title>
		<author>
			<persName><surname>Rakhimova</surname></persName>
		</author>
		<editor>Additionally, Yang et al.</editor>
		<imprint>
			<date type="published" when="2023">2024. 2023b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b406">
	<monogr>
		<title/>
		<author>
			<persName><surname>Gueuwou</surname></persName>
		</author>
		<editor>Zhong et al.</editor>
		<imprint>
			<date type="published" when="2023">2023. 2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b407">
	<monogr>
		<title level="m" type="main">further extend the translation and restatement tasks into multi-modal settings</title>
		<author>
			<persName><surname>Tuo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

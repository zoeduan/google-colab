<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations</title>
				<funder ref="#_27TMBN5">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-12-24">24 Dec 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Likang</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Career Science Lab</orgName>
								<orgName type="institution">BOSS Zhipin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhaopeng</forename><surname>Qiu</surname></persName>
							<email>zhpengqiu@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Career Science Lab</orgName>
								<orgName type="institution">BOSS Zhipin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhi</forename><surname>Zheng</surname></persName>
							<email>zhengzhi97@mail.ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Career Science Lab</orgName>
								<orgName type="institution">BOSS Zhipin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
							<email>zhuhengshu@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Career Science Lab</orgName>
								<orgName type="institution">BOSS Zhipin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
							<email>cheneh@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-12-24">24 Dec 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">041FDD058B739BB4F6F71D8F6BA65214</idno>
					<idno type="arXiv">arXiv:2307.05722v3[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Age: 25</term>
					<term>Education: Bachelor</term>
					<term>Graduation School: XXXX University</term>
					<term>Major: Computer Applied Science</term>
					<term>Work Experience: 2 years</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large Language Models (LLMs) have revolutionized natural language processing tasks, demonstrating their exceptional capabilities in various domains. However, their potential for graph semantic mining in job recommendations remains largely unexplored. This paper focuses on unveiling the capability of large language models in understanding behavior graphs and leveraging this understanding to enhance recommendations in online recruitment, including promoting out-of-distribution (OOD) applications. We present a novel framework that harnesses the rich contextual information and semantic representations provided by large language models to analyze behavior graphs and uncover underlying patterns and relationships. Specifically, we propose a meta-path prompt constructor that aids LLM recommender in grasping the semantics of behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias introduced by path-based sequence input. By facilitating this capability, our framework enables personalized and accurate job recommendations for individual users. We evaluate the effectiveness of our approach on comprehensive real-world datasets and demonstrate its ability to improve the relevance and quality of recommended results. This research not only sheds light on the untapped potential of large language models but also provides valuable insights for developing advanced recommendation systems in the recruitment market. The findings contribute to the growing field of natural language processing and offer practical implications for enhancing job search experiences. We release the code ‡ .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Online recruitment recommendations aim to suggest relevant job opportunities to job seekers based on their preferences and qualifications, improving the chances of matching the right employment. With the exponential growth of online recruitment platforms and the need for efficient and personalized job search experiences, the development of effective job recommendation systems has become crucial.</p><p>In online recruitment systems, job postings and resumes are written in natural language. Traditional approaches have treated job-resume matching as a supervised text-matching problem using paired data for training <ref type="bibr" target="#b14">(Qin et al. 2018;</ref><ref type="bibr" target="#b17">Shen et al. 2018</ref>). However, online recruitment platforms often suffer from sparse interaction data, with job postings attracting only a few candidates on average <ref type="bibr" target="#b16">(Ramanath et al. 2018</ref>). To address this, recent studies <ref type="bibr" target="#b1">(Bian et al. 2020;</ref><ref type="bibr" target="#b22">Yang et al. 2022)</ref> have explored the use of behavior graphs to capture high-order interactions and alleviate the sparse interaction issue. These behavior graphs leverage message passing to enhance the understanding of user preferences.</p><p>Unlike many general recommendation tasks, it is easy to find that textual understanding forms the backbone of job recommendation, and behavior modeling contributes to the personalized module. In our work, we strive to overcome the accuracy limitations of job recommenders by enhancing the semantic richness of textual representations. Inspired by several recent successful recommendations based on text pre-training <ref type="bibr" target="#b20">(Wu et al. 2023)</ref>, we introduce a large language model (LLM) as the foundational framework for job recommendation that directly generates targets. Adopting this approach is not only beneficial but also intuitive. For instance, out-of-distribution items usually appear in recruitment markets since new job demands are constantly emerging, such as prompt engineers for generative models. This issue is more complex than traditional cross-domain tasks <ref type="bibr" target="#b26">(Zhao et al. 2023;</ref><ref type="bibr" target="#b9">Jiang et al. 2023;</ref><ref type="bibr" target="#b23">Yu et al. 2023)</ref>. The powerful semantic mining ability and extensive external knowledge of LLMs augment the generation and associative power of recommenders, which is able to generate reasonable recommendation results for the hard OOD items.</p><p>However, the existing learning schema of LLM recommender cannot understand the non-textual behavior graph which weakens the personalized recommendation ability for different job seekers. To tackle this challenge, we propose a meta-path prompt constructor to encode the interaction information of graph into the natural language prompt. Specifically, in such a heterogeneous behavior graph, each metapath composed of various types of nodes and edges can be transferred into a description naturally since each type indicates a specific and meaningful interaction, e.g., interview, conversation, etc. Along this line, for each job seeker, the LLM captures the high-order interaction feature to augment her personality with the meta-path prompt.</p><p>Based on the above analysis, we explore the inclusion of graph data understanding in large language model-based recommendations for the first time. An efficient large language model named GLRec (Graph-understanding LLM Recommender) is proposed to optimize the recommended quality of job recommendation, which is fine-tuned with LoRa <ref type="bibr" target="#b6">(Hu et al. 2021</ref>) on our constructed instruction dataset for aligning the gap between pre-trained knowledge and actual recruitment domain. Especially, our exploration presents two valuable and important findings that largely influence the graph understanding strategy of LLM: (i). Different paths would present different weights for the model decision. (ii). The position bias of the order of path prompts brings unstable answers. For these issues, we carefully design path shuffling, adaptive path selector, and their hybrid path augmentation mechanism to mitigate the adverse effects posed by varying path prompts. The main contributions could be summarized as follows:</p><p>• To our best knowledge, we are the first to implement the fine-tuned large language model as job recommender, which promotes matching accuracy via the semantic richness and massive knowledge of LLM. • We propose the meta-path prompt constructor that leverages LLM recommender to comprehend behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias. • We conduct sufficient experiments on real-world recruitment datasets, and the experimental results and visualization cases show the superiority of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work Job Recommendation</head><p>Job Recommendation, especially job-resume matching is a necessary task in online recruitment, and it has been extensively studied in the literature <ref type="bibr" target="#b11">(Kenthapadi, Le, and Venkataraman 2017)</ref>. Early methods handled this problem <ref type="bibr" target="#b13">(Lu, El Helou, and Gillet 2013)</ref> relying on collaborative filtering assumptions. However, recent research focused more on text-matching technology. Various techniques have been proposed to encode job and resume information. For example, (Shen et al. 2018) utilized CNN for encoding, while (Qin et al. 2018) leveraged RNN and BiLSTM to capture sequential information. (Yan et al. 2019) introduced a profiling memory to learn latent preference representation by interacting with both job and resume. (Luo et al. 2019) explored the effectiveness of adversarial training for job-resume matching.</p><p>In addition to the aforementioned research, there were also researches that considered multigranularity interactions. The ranking-based loss can be used to capture multi-level interactions as supervision signals <ref type="bibr" target="#b12">(Le et al. 2019)</ref>. <ref type="bibr" target="#b5">(Fu et al. 2021</ref>) proposed a bilateral multibehavior sequence model to describe users' dynamic preferences. These approaches highlighted the importance of considering various interaction patterns and incorporating additional user information to improve the quality of job recommendations. However, online recruitment platforms frequently encounter challenges due to sparse interaction data, resulting in job postings attracting only a limited number of candidates on average <ref type="bibr" target="#b16">(Ramanath et al. 2018)</ref>. Recent studies <ref type="bibr" target="#b1">(Bian et al. 2020;</ref><ref type="bibr" target="#b22">Yang et al. 2022</ref>) have investigated the utilization of behavior graphs to capture high-order interactions and alleviate the problem of sparse interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Large Language Models for Recommendation</head><p>LLMs offer the potential to extract high-quality representations of textual features and leverage extensive external knowledge to enhance recommendation systems. <ref type="bibr" target="#b20">(Wu et al. 2023)</ref> conducted a systematic review and analysis of existing LLM-based recommendation systems. Existing work can be divided into two categories: discriminative models and generative models. Most discriminative models align the representations of pre-trained models like BERT with domain-specific data through fine-tuning. For example, (Qiu et al. 2021; Wu et al. 2021a) proposed pre-training and fine-tuning-based approach to learn users' representation, which leveraged content-rich domains to complement those users' features with insufficient behavior data. Additionally, some research explored training strategies like prompt tuning. (Penha and Hauff 2020) leveraged BERT's Masked Language Modeling (MLM) head to uncover its understanding of item genres using cloze-style prompts. Prompt4NR (Zhang and Wang 2023) pioneered the application of the prompt learning paradigm for news recommendation. Generative models usually translate recommendation tasks as natural language tasks, and then apply techniques such as in-context learning (Hou et al. 2023; Dai et al. 2022), prompt tuning <ref type="bibr" target="#b10">(Kang et al. 2023;</ref><ref type="bibr" target="#b0">Bao et al. 2023)</ref>, and instruction tuning <ref type="bibr">(Zhang et al. 2023;</ref><ref type="bibr" target="#b2">Cui et al. 2022)</ref> to adapt LLMs to directly generate the recommendation results. Compared to discriminative models, generative models have better natural language generation capabilities. In the recruitment area, there was a generative model which developed LLM with RLHF to generate potential JDs for more explainable recommendations <ref type="bibr" target="#b27">(Zheng et al. 2023)</ref>. However, despite their successes, LLM recommenders have a glaring limitation: they lack the ability to comprehend graph data, which impedes their potential for personalized adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head><p>In this section, the technical detail of GLRec in Figure <ref type="figure" target="#fig_0">1</ref> would be introduced progressively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preliminary</head><p>Problem Formulation Consider a set of candidates C = {c 1 , c 2 , . . . , c n1 } and a set of jobs J = {j 1 , j 2 , . . . , j n2 }, where n 1 and n 2 represent the total number of candidates (job seekers) and jobs, respectively. Each candidate and job are associated with textual documents that describe their resumes and job requirements. They are also linked to a collection of directed interaction records (such as interviewing and discussing) within the recruitment platform. These interactions are formally represented as</p><formula xml:id="formula_0">Ac i = {c i → j ′ |c i ∈ C, j ′ ∈ J } and Aj k = {j k → c ′ |j k ∈ J , c ′ ∈ C}, indi-</formula><p>cating the directed interactions initiated by candidate c i or employer j k (referred to as a job). Our objective is to predict the compatibility between a job posting and a candidate. Generative Large Language Models Generative LLMs are powerful language models capable of generating coherent and contextually relevant text. Models like GPT-3 and GPT-4 are trained on vast amounts of text data, enabling them to produce human-like text in response to a given prompt or input. Fine-tuning is a common adaption strategy to align the target of pre-trained model and domain-specific applications, such as two popular paradigms of prompt tuning, and instruction tuning. For all these tuning methods, they have an equal final objective loss of autoregressive training as follows:</p><formula xml:id="formula_1">L f = max Θ (x,y)∈T |y| t=1 log (P Θ (y t | x, y &lt;t )) ,<label>(1)</label></formula><p>Taking instruction tuning as an example, which designs and constructs instruction data to restrict the output scope and format. x and y represent the "Instruction Input" and "Instruction Output" in the self-instruct data, respectively, e.g., Instruction Input: "Do you like this item?", Instruction Output: "Yes.". And y t is the t-th token of the y, y &lt;t represents the tokens before y t , Θ is the original parameters of LLM, and T is the training set.</p><p>Task-specific Instruction In our work, we design two job recommendation tasks to test the LLM recommender following existing related work <ref type="bibr" target="#b0">(Bao et al. 2023)</ref>, i.e., pointwise and pair-wise job matching. Here we introduce our designed template for the sample in our dataset, where information related to privacy and business has been filtered. Assume there is a job seeker called candidate whose Candidate Profile Prompt and recommended JD Prompt are defined as: Candidate Profile Prompt: Age: 25, Education: Bachelor's degree, Graduation School: XXX University, Major: Computer Applied Science, Work Experience: 2 years. JD Prompt: Position Title: Full Stack Engineer, Educational Requirement: Bachelor's degree, Work Experience: 1-3 years, Skill Requirements: HTML/JAVA/Spring Boot/SQL. With the above-designed prompts and instruction, LLM is able to adapt to a domain recommendation situation. Note that, to ensure the stability of training, we append the JD prompt to the end of the ground truth to increase the predicted length. To further fuse interaction knowledge, in the next section, we will illustrate the understanding part of graph data for LLM: behavior meta-path prompt generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavior Meta-path Prompt Generation</head><p>To equip LLM with the ability to comprehend interactive relationships in graph data, we propose a meta-path-based prompt constructor to obtain prompt inputs that represent local subgraphs. Before delving into the details of our approach, it is necessary to provide a formal introduction to heterogeneous graph and meta-path <ref type="bibr">(Wu et al. 2021b</ref>). Definition 1. Heterogeneous Graph. G = (V, E), consists of an object set V and a link set E. G is also associated with a node type mapping function ϕ : V → V and a link type mapping function ψ : E → E. V and E denote the sets of predefined object types and link types, where</p><formula xml:id="formula_2">|V| + |E| &gt; 2. Definition 2. Meta-path. A meta-path P is defined as a path in the form of V 1 E1 -→ V 2 E2 -→ • • • E l -→ V l+1 (abbreviated as V 1 V 2 • • • V l+1 ), which describes a composite relation E 1 • E 2 • • • • • E l between objects V 1 and V l+1</formula><p>, where • denotes the composition operator on relations.  Heterogeneous graphs are more diverse and complex in terms of their semantics compared to homogeneous graphs. Meta-paths are commonly used techniques to mine and represent the interaction semantics within them. In the context of online recruitment, the interactions between job seekers and job positions, which involve different types of behaviors, form a behavior graph. This behavior graph is a typical heterogeneous graph, where different node types include Candidate, JD, and different edge types include messaging, interviewing, matching, and more.</p><p>Due to the unique and defined semantics of each type of edge in the behavior graph, it is natural to consider transferring the graph data format meta-path to a natural language description which is acceptable for the large language model. We only need to predefine the prompt template according to the appeared edges in a path and then fill in the template with the resume or job description information. For instance, given a typical meta-path c 1 interview ------→ j 1 message -----→ c 2 . The prompt template is constructed as: Meta-path Prompt: c 1 interviewed for position j 1 . This position discussed with a job seeker c 2 .</p><p>The node information, i.e., the description of candidates or JD, then will be filled in the meta-path prompt template to generate the final prompt data in our dataset. The real case can be referred to in Figure <ref type="figure" target="#fig_3">2</ref>. In addition, to avoid too similar meta-paths leading to redundancy, we define a simple similarity metric as follows,</p><formula xml:id="formula_3">S i,j = |P i ∩ P j | |P i ∪ P j | , P i , P j ∈ Φ P ,<label>(2)</label></formula><p>where Φ P denotes the set of sampled paths for a candidate. P i , P j indicates two meta-paths in Φ P . |P i ∩ P j | is the number of tokens that exist simultaneously in two paths, P i ∪ P j is the union of them. We ensure that S i,j ≤ γ between the final selected M paths and 0 ≤ γ ≤ 1 is a hyperparameter.</p><p>Path Debiasing and Soft Selection Different from the traditional network embedding, sequence-based meta-path prompts would lead to two challenges for LLM to understand the candidates' behavior sub-graph.</p><p>Challenge 1. Influence of Path Weight. Different metapaths would present different weights for the model decision.</p><p>Challenge 2. Position Bias of Path Prompt. The position bias of the order of path prompts brings unstable answers.</p><p>These two challenges appeared when recognizing the pretrained large language model as a recommender, which hinders the effective modeling of semantic relationships in the graph by LLM recommendation models. To provide a more intuitive explanation, we extracted a real-world case from the log of a popular recruitment platform and visualized them in Figure <ref type="figure" target="#fig_3">2</ref>. Specifically, for a job seeker in the IT industry, given his Candidate Profile Prompt, Meta-path Prompt 1, and Meta-path Prompt 2, we further feed the LLM with a Task-specific Instruction belonging to point-wise recommendation. The LLM recommender is expected to output the decision of "Yes" or "No" to present the preference of the candidate. Challenge 1 corresponds to Case 1 and Case 2 in this figure. We can find that the same profile and task description with different behavior meta-paths forces LLM to make different predictions. Obviously, the diversity of technology stacks in Path 1 reveals the candidate's preference for full-stack development, and compared to Path 2, the background of path-related job seeker is more close to our candidate. Therefore, for this candidate, Path 1 is evidently more important for the final decision. For Challenge 2, if we construct the input sequence as Case 3, i.e., the order is metapath prompt 1 → meta-path prompt 2, the LLM outputs the wrong answer "No". But with a reverse path prompt order, the LLM is able to provide an accurate prediction. Similar to the widely known position bias of candidate items <ref type="bibr" target="#b20">(Wu et al. 2023)</ref>, the position of context prompt clearly misleads the model to generate unstable outputs.</p><p>To address the negative impact of these two challenges on the recommendation results, we carefully design an augmentation module specifically for the meta-path prompt, which consists of three concise but effective strategies. The first strategy is Shuffle Mechanism. When preparing domain data for the model's supervised fine-tuning (SFT), for each sample that contains multiple paths, we randomly shuffle the meta-path prompts in the sample m times. Here m denotes the conducted times of shuffling. This data augmentation technique allows the model to learn semantic invariance patterns from different combinations of paths, leading to more stable results. It enhances the robustness of the model without introducing redundant information. The second strategy is Path Soft Selector. In this work, we regard the path sampling process in Behavior Meta-path Prompt Generation as a hard selection to heuristic selects semantically rich paths. The Path Soft Selector is used to further adaptively assign a learned weight distribution to the constructed meta-path prompts. Firstly, for a given meta-path prompt M i , i ∈ {1, 2, ..., M } (M denotes the number of paths), we obtain the LLM word embedding e t of each token t ∈ M i . So, the meta-path embedding H i of M i can be obtained via a mean pooling as follows,</p><formula xml:id="formula_4">H i = 1 |M i | t∈Mi e t , i ∈ {1, 2, ..., M }.</formula><p>(3)</p><p>Then we propose a soft selector to calculate the weight for each meta-path embedding as:</p><formula xml:id="formula_5">α i = softmax(W a H i ) = exp(W a H i ) M j=1 exp(W a H j ) ,<label>(4)</label></formula><p>where W a ∈ R 1×de is a trainable parameter, and d e denotes the dimension of E i . To avoid the training collapse caused by changed value scale, we utilize a controller parameter λ ∈ (0, 0.5] to update word embeddings in Eq. ( <ref type="formula" target="#formula_6">5</ref>).</p><formula xml:id="formula_6">êt = e t + λ • α i e t , t ∈ M i ,<label>(5)</label></formula><p>Compared with most existing tuned or non-tuned LLM models, our prompt augmentation mechanism considers phrasebased attention to distinguish different paths. Actually, this simple solution can be transferred to other similar situations, such as weighed sentence embeddings. What's more, the third strategy is the Hybrid Mechanism which implements Shuffle Mechanism and Path Soft Selector simultaneously. This hybrid module is expected to address the both two challenges. We will evaluate these three strategies in the experiment section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LLM Instruction Tuning and Recommendation</head><p>In this subsection, we will introduce the instruction tuning and recommendation process, which aims to align the used LLM with the recommendation task effectively and efficiently. For instruction tuning, we follow the general supervised fine-tuning method to minimize the autoregressive loss calculated by ground truth and corresponding LLM output. In our work, we mask the loss position of the prompt part. Specific prompt format, task-specific instruction, and ground truth have been introduced in the Preliminary section. However, direct fine-tuning of the entire model can be computationally intensive and time-consuming. To address this, we propose a lightweight fine-tuning strategy using LoRA, which involves freezing the pre-trained model parameters and introducing trainable rank decomposition matrices into each layer of the Transformer architecture. This approach facilitates lightweight fine-tuning while reducing GPU memory consumption. And the final learning objective can be computed as follows:</p><formula xml:id="formula_7">L f = max Θ L (x,y)∈T |y| t=1 log (P Θ+Θ L (y t | e x , y &lt;t )) , (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>where Θ L is the LoRA parameters and we only update LoRA parameters during the training process. Note that, different from existing fine-tuning frameworks for recommendation systems, we replace their token input x by the embedding e x in Eq. ( <ref type="formula" target="#formula_7">6</ref>), since we update the prompt token embedding in the soft selector.</p><p>As for the recommendation process, since the trained model has learned the output format of our defined ground Evaluation Metric. We evaluate the two tasks using the conventional metric: Area Under the Receiver Operating Characteristic (AUC), as our two tasks can be transferred to binary classification problems and the metric captures the similarity between our setting and predicting user interest in a target item. We do not employ ranking-based metrics because, during the fine-tuning process, the text sequence output of LLM requires ground truth for item order sequences, which, in reality, doesn't exist. Implementation Details. In this paper, we utilize BELLE-LLaMA-7B <ref type="bibr" target="#b8">(Ji et al. 2023)</ref> as the pre-trained LLM backbone due to its expanded Chinese vocabulary.</p><p>The instruction-tuning and model inference, using LoRa, are conducted on 4 Tesla A100 80G GPUs. To ensure consistent sequence inputs within each batch (batch size is 32), we apply padding to sequences with a maximum length of 512. Our approach incorporates the meta-path prompt and user-specific task instructions as model inputs for personalized recommendations. In our experiments, we investigate the impact of different numbers of paths, specifically M ∈ [0, 1, 2, 3], for GLRec, and the shuffled times m = 2 for M ≥ 2. In our work, we select paths with 3 nodes because they offer a balance between meaningful semantics and minimal redundancy with the experimental feedback. Further details regarding the path prompt and instructions can be found in the Methodology section. Additionally, both RobertaRec and HGT have a token embedding dimension of 768, and HGT utilizes mean pooling to obtain the initial node embedding. For all methods, we optimize model parameters using the Adam (Kingma and Ba 2014) optimizer with a default learning rate of 1e-4, minimizing the MSE loss as the optimization objective. For the hyperparameters of update controller λ and similarity threshold γ, we set λ = 0.1 and γ = 0.3 according to the experimental feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance Comparison</head><p>Quantitative Comparison. We conduct quantitative performance experiments on two datasets. As mentioned in the task definition in Section Methodology, the point-wise and pair-wise settings are implemented for evaluation. We also explore the influence of the OOD situation on different models. The experimental split settings of Random, OOD position, and OOD JD are introduced below:</p><p>• Random: We randomly split the training and testing dataset based on the interaction records of each user.</p><p>• OOD position: The intersection on JD's "job position" feature between training set and testing set is empty.</p><p>• OOD JD: The intersection on JD items between the training set and the testing set is empty. Our experimental results are reported in Table <ref type="table" target="#tab_4">2</ref>. Overall, our proposed GLRec model achieves the best performance among all baselines. There are distinctive score gaps between GLRec and all baselines according to the improvement in Table <ref type="table" target="#tab_4">2</ref>. It demonstrates the superiority and adaptability of the large-scale model framework that incorporates relationship understanding and extensive semantic knowledge in the job recommendation scenario. What's even more exciting is that GLRec demonstrates impressive performance on OOD tasks. While its performance may decline slightly compared to the random setting, our model achieves a significant breakthrough compared to other models, which essentially results in near-random guessing. This phenomenon illustrates the necessity of utilizing knowledge association for model generalization. Going deeper into the part of baselines, the graph-based HGT and DPGNN outperform the conventional dual-tower matching model (RobertaRec) in the context of job recommendation, which further proves the significance of learning relationships. What's more, we find that most models perform better on the pair-wise task than that of point-wise task. That is to say, directly determining whether an item is suitable is more challenging than comparing its priority with another item.</p><p>Qualitative Comparison. To give a more intuitive visualization, some qualitative comparison results produced by models are shown in Table <ref type="table" target="#tab_5">3</ref>, where the true (false) prediction is highlighted in blue (red) font. Specifically, the first two rows are straightforward, allowing multiple models to predict accurately. In the third row, solely using the user's profile isn't sufficient for prediction. It's crucial to note that the JAVA position (Node 1) the user interacted with aligns well with the target job in skill requirements. Consequently, only TALLrec and GLRec produced correct predictions. The final row emphasizes the significance of higher-order interactions, i.e., path, in LLM recommendations. Although there's a perceived mismatch between the candidate's finance major and the target job, interactions within the testing engineer and fintech sectors provide nuanced hints. For such complex cases, while the TALLrec model, relying on past behaviors, errs, only the GLRec model predicts correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Impact of Meta-path Number</head><p>We investigate the impact of meta-path number on the effectiveness of GLRec. Here we evaluate the point-wise per-  formance on Random setting using AUC for different numbers of meta-paths, ranging from 0 to 3. We also input the meta-path prompt (removing extra instruction text for feature conciseness) into RobertaRec for comparison. From the line graph of Figure <ref type="figure" target="#fig_4">3</ref>, we can observe the following trends:</p><p>• For GLRec, the results consistently increase as the number of meta-paths increases. • One notable observation is the significant improvement in GLRec's performance when transitioning from 0 meta-paths to 1 meta-path, and achieving the peak with only 2 or 3 meta-paths. The core increases from 0.71 to 0.88, indicating a substantial boost in recommendation effectiveness. This improvement suggests that the chainof-thought ability of the LLM, inspired by in-context learning, plays a crucial role in GLRec's performance. • For RobertaRec, which does not incorporate behavior graph understanding, the values remain relatively stable across different meta-path numbers. The reason is that discriminative BERT-based model lacks the ability to effectively understand prompts like generative LLMs.</p><p>The results indicate that the inclusion of behavior graph understanding through meta-path prompt has a significant positive impact on the effectiveness of GLRec. By leveraging the rich information, GLRec gains a deeper understanding of user-item interactions, leading to improved performance, which provides sufficient evidence for graph effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Impact of Bias of Meta-path Prompt</head><p>Due to the sequential nature of language model input, the construction of multi-path prompt sequences results in a human-induced position bias, or order bias, which disrupts the final decision-making of LLM model. Additionally, this input pattern does not allow the model to learn the importance of semantic information in different paths. Therefore, we design a path shuffle mechanism, a path soft selector, and a hybrid mechanism combining both to enhance the model's understanding of path information and mitigate bias. The experimental results on RecrX are reported in Figure <ref type="figure" target="#fig_5">4</ref>. Here the metric is AUC and the task is point-wise setting.</p><p>According to Figure <ref type="figure" target="#fig_5">4</ref>, our three strategies can all surpass the original input without path prompt augmentation in both two sub-experiments, which proves the necessity of path debiasing. Although the shuffle mechanism and soft selector have their own advantages and disadvantages in two different path scale experiments, both can relatively improve the quality of the results. And the hybrid module of both can bring more stable results, indicating that it is indeed necessary for the model to consider the position factors of input meta-paths and the influencing factors of different path prompts on decision-making in experiments, in order to cope with actual recommendation scenarios. Actually, in other similar scenarios, such as the input for LLM consists of multiple sentence prompts without prior order, our proposed shuffle mechanism and the soft selector can both play a certain role in enhancing the robustness of model training. We will continue to explore this property in our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In conclusion, this paper introduced GLRec, a pioneering job recommendation model that seamlessly integrated large language models (LLMs) with behavior graph comprehension. By capitalizing on the semantic depth and vast knowledge inherent to LLMs, GLRec surpassed sufficient baselines in the quality of recommendations. The innovative meta-path prompt constructor effectively translated the intricate interaction details into natural language prompts, thereby refining personalized recommendation strategies. In the testing stage, rigorous experimental evaluations affirmed GLRec's efficacy, highlighting its dominant performance across real-world recruitment datasets. This investigation not only propelled the evolution of LLM-centric job recommendations but also charted fresh avenues for harnessing graph data in enhancing the personalized recommendation capabilities of LLMs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The framework of GLRec for job recommendation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>For</head><figDesc>the point-wise task, we let the LLM recommender learn to predict the satisfaction of a candidate with a recommended job. The instruction is designed as: Point-wise Instruction: You are a recommender, determining whether a candidate would be satisfied with the recommended job position. Please answer with "Yes." or "No.". For the pair-wise task, we let the LLM recommender learn to justify the preference of a candidate for a recommended job pair. Given two jobs' JD Prompt "A" and "B", the instruction is designed as: Pair-wise Instruction: You are a recommender, determining which position will match the candidate. Please answer with "[A]." or "[B].".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>Prompt 2: The candidate interacted with a position for Automation, which requires a Python/C++/Automation Development background. This position discussed with a job seeker specializing Information Management,... JD Prompt: Position Title: Full Stack Engineer, Educational Requirements: College, Work Experience: 1-3 years, Skills Required: HTML/JAVA/Spring Boot/SQL Task-specific Instruction: You are a recommendation system, determining whether a candidate would be satisfied with the recommended job position. Please answer with "Yes." or "No."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The real cases of path weight and position bias of meta-path prompt input for LLM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The impact of meta-path number on model performance.</figDesc><graphic coords="6,323.03,54.00,114.47,93.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The Impact of Bias of Meta-path Prompt.</figDesc><graphic coords="7,57.53,213.32,114.48,76.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>The statistics of datasets.We conduct experiments on two datasets RecrX and RecrY with different scales which are collected from a real-world and large online recruitment platform in China to assess recommendation methods. The datasets were constructed from the online logs and contained two kinds of behavior: Match and Interaction, corresponding to the matching set and interaction set mentioned in Problem Formulation. Besides, each candidate (and job) is associated with a descriptive text (i.e., resume or job description). The overall statistics are shown in Table1. From the statistical data, it can be seen that job recommendation is a sparsely interactive scenario. The segmentation ratio of the training set and testing set is 5:1. Note that all sensitive or private information has been filtered out from the data.An advanced fine-tuned LLM recommender that uses instruction tuning on self-instruct data with users' historical interactions. The original backbone of its pre-trained model is LLaMA, and we change it by BELLE as the same as ours for the Chinese corpus.</figDesc><table><row><cell cols="5">Dataset # Candidates # Jobs # Match # Interaction</cell></row><row><cell>RecrX</cell><cell>12,440</cell><cell>19,318</cell><cell>23,879</cell><cell>54,147</cell></row><row><cell>RecrY</cell><cell>18,260</cell><cell>26,576</cell><cell>47,725</cell><cell>119,529</cell></row><row><cell cols="5">truth after several SFT alignment steps. So our designed an-</cell></row><row><cell cols="5">swer parsing is a simple way. We catch the softmax prob-</cell></row><row><cell cols="5">ability of label generation (the token used to denote label,</cell></row><row><cell cols="5">such as "Yes./No." or "[A]/[B]" in our work ) in the position</cell></row><row><cell cols="5">of model's output corresponding to that in the ground truth.</cell></row><row><cell cols="5">Along this line, the final prediction probability is calculated.</cell></row><row><cell></cell><cell cols="3">Experiments</cell><cell></cell></row><row><cell cols="2">Experimental Settings</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Datasets. Baseline. To provide a comprehensive evaluation of our</cell></row><row><cell cols="5">GLRec model, we compare it against both LLM-based</cell></row><row><cell cols="5">and related representative job recommendation methods.</cell></row><row><cell cols="5">RobertaRec (Liu et al. 2019): Candidate resume and JD</cell></row><row><cell cols="5">text are encoded into fixed-length vectors using RoBERTa</cell></row><row><cell cols="5">and then used to calculate similarity scores, enabling per-</cell></row><row><cell cols="5">sonalized recommendations. HGT (Hu et al. 2020): Het-</cell></row><row><cell cols="5">erogeneous Graph Transformer is a powerful graph learn-</cell></row><row><cell cols="5">ing model which propagates the embeddings (initialized by</cell></row><row><cell cols="5">RoBERTa) of candidates and jobs on graph to capture high-</cell></row><row><cell cols="5">order interactions. DPGNN (Yang et al. 2022): The ad-</cell></row><row><cell cols="5">vanced job recommender Dual-Perspective GNN incorpo-</cell></row><row><cell cols="5">rates two different nodes for each candidate (or job) to model</cell></row><row><cell cols="5">the two-way selection preference. TALLrec (Bao et al.</cell></row><row><cell>2023):</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Job recommendation performance of AUC on test set, where * indicates the best result among baselines. Improve ↑ refers to the average enhancement achieved by GLRec in comparison to the baseline models. RX (RY) indicates RecrX (RecrY).</figDesc><table><row><cell>Task</cell><cell></cell><cell></cell><cell cols="2">Point-wise</cell><cell></cell><cell></cell><cell cols="2">Pair-wise</cell></row><row><cell>Split</cell><cell cols="2">Random</cell><cell cols="2">OOD position</cell><cell cols="2">OOD JD</cell><cell cols="2">Random</cell></row><row><cell>Dataset</cell><cell>RX</cell><cell>RY</cell><cell>RX</cell><cell>RY</cell><cell>RX</cell><cell>RY</cell><cell>RX</cell><cell>RY</cell></row><row><cell cols="2">RobertaRec 0.710</cell><cell>0.734</cell><cell>0.503</cell><cell>0.528</cell><cell>0.506</cell><cell>0.536</cell><cell>0.727</cell><cell>0.740</cell></row><row><cell>HGT</cell><cell>0.744</cell><cell>0.756</cell><cell>0.572</cell><cell>0.595</cell><cell>0.576</cell><cell>0.593</cell><cell>0.747</cell><cell>0.751</cell></row><row><cell>DPGNN</cell><cell>0.727</cell><cell>0.743</cell><cell>0.596</cell><cell>0.603</cell><cell>0.588</cell><cell>0.617</cell><cell>0.744</cell><cell>0.756</cell></row><row><cell cols="2">TALLrec 0.842  GLRec 0.891</cell><cell>0.876</cell><cell>0.810</cell><cell>0.843</cell><cell>0.814</cell><cell>0.852</cell><cell>0.905</cell><cell>0.883</cell></row><row><cell>Improve ↑</cell><cell cols="8">18.4% 14.1% 25.2% 28.3% 26.4% 29.8% 15.5% 13.2%</cell></row></table><note><p>* 0.829 * 0.770 * 0.788 * 0.766 * 0.798 * 0.849 * 0.825 *</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Some representative cases of our implemented models in the performance comparison experiment. Node 1 and Node 2 denote the nodes in a sampled meta-path of Candidate. RobRec denotes RobertaRec, and GT denotes Ground Truth.</figDesc><table><row><cell>Candidate</cell><cell>Node 1 (Job)</cell><cell>Node 2 (Job Seeker)</cell><cell>Target Job</cell><cell cols="4">GT RobRec TALLrec GLRec</cell></row><row><cell>Bachelor's degree, Computer</cell><cell>Front-end Developer, Skill</cell><cell>Bachelor's degree, Computer</cell><cell>Java, Qualification: Bachelor's degree, 5-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Science, 3 years of work ex-</cell><cell>requirements: JavaScript /</cell><cell>Applications Technology, Work</cell><cell>10 years experience, Skill requirements:</cell><cell>No</cell><cell>No</cell><cell>No</cell><cell>No</cell></row><row><cell>perience, skills...</cell><cell>HTML5 /Vue</cell><cell>experience: 2 years, skills...</cell><cell>Java/System Architecture/Database</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Bachelor's degree, Business</cell><cell>Project Assistant, Skill re-</cell><cell>Bachelor's degree, International</cell><cell>Project Assistant, Qualification: Bachelor's</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Administration, 9 years of</cell><cell>quirements: Project Engi-</cell><cell>Economics and Trade, 3 years of</cell><cell>degree, 3 years or more, Skill requirements:</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>work experience, skills...</cell><cell>neering Management</cell><cell>work experience, skills...</cell><cell>Project Engineering Management</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Bachelor's degree, Computer</cell><cell>JAVA, Skill requirements:</cell><cell>Associate's degree, Internet of</cell><cell>Full Stack Engineer, Qualification: Asso-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Applications Tech, 2 years of</cell><cell>JAVA/Spring/Team Manage-</cell><cell>Things Technology, 4 years of</cell><cell>ciate's degree, 1-3 years of work experience,</cell><cell>Yes</cell><cell>No</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>work experience, skills...</cell><cell>ment Experience</cell><cell>work experience, skills...</cell><cell>Skill requirements: JAVA/Spring/HTML</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Bachelor's degree, Finance,</cell><cell>Functional Testing, Skill re-</cell><cell>Bachelor's degree, Financial En-</cell><cell>Test Engineer, Qualification: Bachelor's de-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>10 years of work experience,</cell><cell>quirements: Software Test-</cell><cell>gineering, 2 years of work expe-</cell><cell>gree, 3 years of work experience, Skill re-</cell><cell>Yes</cell><cell>No</cell><cell>No</cell><cell>Yes</cell></row><row><cell>skills...</cell><cell>ing/Requirement Alignment</cell><cell>rience, skills...</cell><cell>quirements: Functional Testing/Unit Testing</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was partially supported by grants from <rs type="funder">National Key Research and Development Program of China</rs> (Grant No. <rs type="grantNumber">2021YFF0901003</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_27TMBN5">
					<idno type="grant-number">2021YFF0901003</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<idno>CoRR, abs/2305.00447</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to match jobs with resumes from sparse interaction data using multi-view co-teaching network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<idno>CoRR, abs/2205.08084</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><surname>Corr</surname></persName>
		</author>
		<idno>abs/2212.10559</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Beyond matching: Modeling two-sided multibehavioral sequences for dynamic person-job fit</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<idno>CoRR, abs/2305.08845</idno>
	</analytic>
	<monogr>
		<title level="m">Database Systems for Advanced Applications: 26th International Conference</title>
		<meeting><address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021. 2023</date>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page" from="359" to="375" />
		</imprint>
	</monogr>
	<note>DASFAA Large Language Models are Zero-Shot Rankers for Recommender Systems</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09685</idno>
		<title level="m">Lora: Low-rank adaptation of large language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Heterogeneous graph transformer</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the web conference 2020</title>
		<meeting>the web conference 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2704" to="2710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<ptr target="https://github.com/LianjiaTech/BELLE" />
		<title level="m">BELLE: Be Everyone&apos;s Large Language model Engine</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Knowledge-Aware Cross-Semantic Alignment for Domain-Level Zero-Shot Recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 32nd ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="965" to="975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sathiamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Cheng</surname></persName>
		</author>
		<idno>CoRR, abs/2305.06474</idno>
		<title level="m">Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Personalized Job Recommendation System at LinkedIn: Practical Challenges and Lessons Learned</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kenthapadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2014">2017. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Adam: A method for stochastic optimization</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Towards effective and interpretable person-job fitting</title>
		<author>
			<persName><forename type="first">R</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1883" to="1892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Resumegan: An optimized deep representation learning framework for talent-job fit via adversarial learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>El Helou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM international conference on information and knowledge management</title>
		<meeting>the 28th ACM international conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2013">2019. 2013. 2019</date>
			<biblScope unit="page" from="1101" to="1110" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Roberta: A robustly optimized bert pretraining approach A recommender system for job seeking and recruiting website Proceedings of the 22nd International Conference on World Wide Web</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">What does BERT know about books, movies and music? Probing BERT for Conversational Recommendation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Penha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hauff</surname></persName>
		</author>
		<author>
			<persName><surname>Acm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st international ACM SIGIR conference on research &amp; development in information retrieval</title>
		<imprint>
			<date type="published" when="2018">2020. 2018</date>
			<biblScope unit="page" from="25" to="34" />
		</imprint>
	</monogr>
	<note>Enhancing person-job fit for talent recruitment: An ability-aware neural network approach RecSys</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">U-BERT: Pretraining User Representations for Improved Recommendation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4320" to="4327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards deep and representation learning for talent search at linkedin</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Inan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Polatkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ozcaglar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kenthapadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Geyik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2253" to="2261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A joint learning approach to intelligent job interview assessment</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="3542" to="3548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01274</idno>
		<title level="m">Contrastive user model pre-training</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning the implicit semantic representation on graph-structured data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Database Systems for Advanced Applications: 26th International Conference, DAS-FAA 2021</title>
		<meeting><address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021-04-11">2021. April 11-14, 2021</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.19860</idno>
		<title level="m">A Survey on Large Language Models for Recommendation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Interview Choice Reveals Your Preference on the Market: To Improve Job-Resume Matching through Profiling Memories</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Modeling Two-Way Selection Preference for Person-Job Fit</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixteenth ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Untargeted attack against federated recommendation systems via poisonous item embeddings and the defense</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="4854" to="4863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<idno>CoRR, abs/2305.07001</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05263</idno>
		<title level="m">Prompt Learning for News Recommendation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cross-Domain Recommendation via Progressive Structural Alignment</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.02157</idno>
		<title level="m">Generative Job Recommendations with Large Language Model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ASSISTED DEBATE BUILDER WITH LARGE LANGUAGE MODELS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-05-14">14 May 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Elliot</forename><surname>Faugier</surname></persName>
							<email>elliotfaugier@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ Lyon</orgName>
								<orgName type="institution" key="instit2">UCBL Villeurbanne</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Frédéric</forename><surname>Armetta</surname></persName>
							<email>frederic.armetta@univ-lyon1.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR5205</orgName>
								<orgName type="institution" key="instit1">Univ Lyon</orgName>
								<orgName type="institution" key="instit2">UCBL</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">INSA Lyon, LIRIS</orgName>
								<address>
									<postCode>F-69622</postCode>
									<settlement>Villeurbanne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Angela</forename><surname>Bonifati</surname></persName>
							<email>angela.bonifati@univ-lyon1.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR5205</orgName>
								<orgName type="institution" key="instit1">Univ Lyon</orgName>
								<orgName type="institution" key="instit2">UCBL</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">INSA Lyon, LIRIS</orgName>
								<address>
									<postCode>F-69622</postCode>
									<settlement>Villeurbanne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bruno</forename><surname>Yun</surname></persName>
							<email>bruno.yun@univ-lyon1.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR5205</orgName>
								<orgName type="institution" key="instit1">Univ Lyon</orgName>
								<orgName type="institution" key="instit2">UCBL</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">INSA Lyon, LIRIS</orgName>
								<address>
									<postCode>F-69622</postCode>
									<settlement>Villeurbanne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ASSISTED DEBATE BUILDER WITH LARGE LANGUAGE MODELS</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-05-14">14 May 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">957ACB969CA857D04BD967207DA04697</idno>
					<idno type="arXiv">arXiv:2405.13015v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Argumentation</term>
					<term>Relation-based argument mining</term>
					<term>Large language models</term>
					<term>Assistant tool</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce ADBL2, an assisted debate builder tool. It is based on the capability of large language models to generalise and perform relation-based argument mining in a wide-variety of domains. It is the first open-source tool that leverages relation-based mining for (1) the verification of preestablished relations in a debate and (2) the assisted creation of new arguments by means of large language models. ADBL2 is highly modular and can work with any open-source large language models that are used as plugins. As a by-product, we also provide the first fine-tuned Mistral-7B large language model for relation-based argument mining, usable by ADBL2, which outperforms existing approaches for this task with an overall F1-score of 90.59% across all domains.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, there has been a lot of research in artificial intelligence, focusing on leveraging argumentation theory for non-monotonic reasoning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Starting with Dung's seminal work <ref type="bibr" target="#b2">[3]</ref>, many researchers have considered abstract argumentation frameworks, composed of a set of arguments and a binary attack relation between them, and created many semantics for tasks such as computing accepted sets of arguments <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> or rank arguments <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>. This abstract argumentation framework was extended with many features such as supports <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref>, sets of attacking arguments <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, or probabilities <ref type="bibr" target="#b13">[14]</ref> among others. However, one important question that remained was: "Where do argumentation frameworks come from in real-life settings?".</p><p>While there are some pieces of evidence that the fundamental aspects of abstract argumentation frameworks have links with human reasoning <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>, humans debates or natural language texts are not always written as arguments and the relation between arguments is not always clear, even for experts <ref type="bibr" target="#b16">[17]</ref>. The question of the origin of argumentation frameworks is crucial to facilitate the application of argumentation theory semantics in real-world contexts. Some online debate platforms like Kialo<ref type="foot" target="#foot_0">foot_0</ref> , Debategraph<ref type="foot" target="#foot_1">foot_1</ref> , Rationale<ref type="foot" target="#foot_2">foot_2</ref> , or Argüman<ref type="foot" target="#foot_3">foot_3</ref> allow users to formalise (individually or collaboratively) debates into arguments and attacks/supports. While this constitute a possible source of argumentation frameworks, users are not assisted in the creation of arguments, leading to redundancies, poorly phrased arguments or wrongly classified relations. We argue that an automatic assistant is essential to help users elicit high quality argumentation frameworks. Moreover, this automatic assistant would need to be highly adaptable to a variety of debate domains, thus motivating the need for large language models (LLMs).</p><p>In this paper, our contributions are as follows:</p><p>• ADBL2, an assisted debate builder tool. It leverages the capability of large language models to generalise and perform relation-based argument mining (RBAM) in a wide-variety of domains. While RBAM has been used</p><p>for several tasks <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, ADBL2 is the first open-source tool that imports debates from Kialo and leverages RBAM for (2) the verification of existing relations in a debate, and (3) assist users in the creation of new arguments.</p><p>• An open-source and fine-tuned Mistral-7B LLM for the task of relation-based argument mining, embedded in ADBL2, which outperforms existing approaches in multiple domains.</p><p>This demonstration paper is structured as follows. In Section 2, we motivate the use of fine-tuned LLMs for the RBAM task. In Section 3, we introduce the architecture and use-cases of ADBL2. In Section 4, we explain the data collection, fine-tuning, and evaluation of our LLM. Finally, we conclude and discuss future work in Section 5.</p><p>The demo video is available at: <ref type="url" target="https://youtu.be/KMzqKJlH9lE">https://youtu.be/KMzqKJlH9lE</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">LLMs for Relation-based Argument Mining</head><p>Relation-based argument mining is a fundamental task in argument mining and is essential to support online debates and obtain high-quality argumentation frameworks <ref type="bibr" target="#b19">[20]</ref>. It consists in the automatic identification of argumentative relations, aiming at determining how different texts are related within the argumentative discourse. While RBAM can take many forms, we will focus on the binary version in this paper, i.e., classifying relations as supports or attacks. For example, given the following three argumentative texts from Kialo. a 1 = "It is important for sporting bodies to level the playing field among atheletes", a 2 = "The knowledge that they will never beat a competitor like Caster Semenya can damage the athlete's mental health", and a 3 = "By trying to weed out extraordinary sportswomen to cater for the majority, the sporting community could lose extremely talented atheletes". One can infer that a 2 supports a 1 as it illustrates the potential mental health concerns of not leveling the playing field in sports while a 3 attacks a 1 by suggesting that leveling the playing field could lead to unintended consequences (i.e., losing exceptionally talented athletes), thus weakening it. Here, contextual information about individuals (e.g., the identity or characteristics of Caster Semenya) or events (e.g., the breakdown of athlete Lynsey Sharp during the Rio's Olympic 800m final) are important for the prediction.</p><p>While there are some small transformer-based models (e.g., BERT-based models) that can perform relatively well on specific datasets by identifying language patterns and learning good latent representation of concepts, they are usually limited to specific domains <ref type="bibr" target="#b20">[21]</ref> and fail to generalise across multiple dataset <ref type="bibr" target="#b21">[22]</ref>. This generalisation capability is essential if one wants to have a single backbone model for a debate assistant tool.</p><p>The recent work of Gorur et al. <ref type="bibr" target="#b22">[23]</ref> explores the usage of two types of open-source LLMs (Meta AI's Llama-2 models <ref type="bibr" target="#b23">[24]</ref> and Mistral AI's models <ref type="bibr" target="#b24">[25]</ref>) for RBAM on ten datasets. They showed that LLMs equipped with few-shot examples (2 pairs of fixed arguments) outperform the RoBERTa baseline. However, while the larger models (70B parameters) had better performances, they also had slower inference time and greater GPU requirements. In this paper, we will explore whether fine-tuning smaller LLMs for RBAM can yield similar or better performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The ADBL2 Tool</head><p>ADBL2 is an online tool aiming to ease debate tree construction leveraging LLMs and prompt techniques to help the user formulating arguments which can be unclear. The source-code of the tool is available at: <ref type="url" target="https://github.com/4mbroise/ADBL2">https://github.com/  4mbroise/ADBL2</ref>.</p><p>ADBL2 allows users to verify existing relations and assist users in the creation of new arguments by relying on its underlying RBAM model. For example, in the unfolded scenario when one wants to edit an existing argument which is connected to other arguments, it is essential to verify that the existing relations remain the same or to modify them accordingly. In an other scenario where a user wants to add a new argument to a parent argument, the classification probability displayed to the user can help them to modify and refine their textual arguments to achieve the desired effect.</p><p>The architecture of ADBL2, represented in Figure <ref type="figure" target="#fig_0">1</ref>, can be divided in two main parts.</p><p>1. The Web UI which consists in a web application where the user can import an argumentation tree (using Kialo's format), explore it, apply changes, and export the result argumentation tree.</p><p>2. The inference core of ADBL2 translates the user input according to the prompt engineering technique (e.g., adding a few-shot priming or not) and the LLM chosen by the user (different LLMs have different prompt templates) into a final prompt. This inference core performs RBAM: the output of the LLM is constrained using LMQL <ref type="foot" target="#foot_4">5</ref> to obtain the probability to predict each label ("attack" and "support") which is given to the user via the Web UI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A Fine-tuned LLM for relation-based mining 4.1 Datasets</head><p>Our test dataset D consists of triples (x, y, z) ∈ D such that (x, y) is a pair of argument and z ∈ {attack, support} is the type of the relation from x to y. We collected these triples by exporting debates on various domains (Art, Climate Change, etc.) from Kialo between the 8th and 15th of March 2024. We made use of the random undersampling algorithm from the imbalanced-learn library <ref type="foot" target="#foot_5">6</ref> , first by domain and by relation type, to obtain a balanced dataset. The number of triples per domain is displayed in Table <ref type="table">4</ref>.2.</p><p>While it is not possible to reproduce the baseline protocol of Gorur et al. <ref type="bibr" target="#b22">[23]</ref> (as they do not provide the Kialo dataset they used), we wanted to get as close as possible to their settings. We created a similar dataset D l,p,s of arguments related to law, politics and sports debates. This dataset was separated in a train (D Train l,p,s with D Train l,p,s ∩ D = ∅) and test (D Test l,p,s ⊆ D) datasets, with a 77.8/22.2 split, while preserving class balance. Given a Kialo bipolar argumentation tree F = (A, S, C, r), where A is a set of arguments, S ⊆ A × A is a binary support relation between arguments, and C ⊆ A × A is a binary attack relation, and r is the root of the tree, the depth of an argument a ∈ A is n iff there exists a sequence of arguments (a 0 , a 1 , . . . , a n ) with a n = r, a 0 = a, and (a i , a i+1 ) ∈ C ∪ S for all 0 ≤ i ≤ n -1. Note that to ensure a high quality dataset for the training of our language model (D l,p,s ), we only extracted the pair of arguments closer to the root as they were more explored by the Kialo community and thus more refined. Namely, we only extracted the triples (x, y, z) such that the depth of x is less or equal to 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fine-tuning Mistral</head><p>For the fine-tuning, we used a Linux virtual machine with a 12-core Intel Xeon Processor (Skylake, IBRS), 125 Gb of RAM, and a NVIDIA A40 with 46Gb of VRAM. Our main goal was to restrict ourselves to large language models that can be run on consumer hardware. We selected Mistral-7B <ref type="bibr" target="#b24">[25]</ref> as our LLM as it was best performing LLM that could be run and fine-tuned on our setting.</p><p>Since a full fine-tuning of the model was not possible, we used a Parameter-Efficient Fine-Tuning technique (PEFT) called Low Rank Adaptation (LoRA) <ref type="bibr" target="#b25">[26]</ref> which reduces the VRAM consumption during the fine-tuning process. Namely, additional parameters are added to the model, and only those are trained while the initial parameters of the large language model are frozen. We also used QLoRA <ref type="bibr" target="#b26">[27]</ref> to further reduced the VRAM consumption, i.e., the LLM parameters are quantised to 8 bits (instead of 16 bits) before the fine-tuning.</p><p>Mistral 7B was fine-tuned on D Train l,p,s , the training dataset of D l,p,s . Each triple (x, y, z) ∈ D Train l,p,s was transformed into a prompt using x and y (see the prompt in Figure <ref type="figure" target="#fig_0">1</ref>). With this prompt as input, the LLM must predict a token ẑ ∈ {attack, support} which must correspond to z. The training parameters are r = 8, lora_alpha = 16, lora_dropout = 0.1, per_device_train_batch_size = 16, learning_rate = 1e -4, and bias = N one. We used an early stopping approach with a monitor on the loss. The final fine-tuned model was trained for 280 training steps (see Figure <ref type="figure" target="#fig_1">2</ref>).</p><p>The fine-tuned model is available at: <ref type="url" target="https://huggingface.co/4mbroise/ADBL2-Mistral-7B">https://huggingface.co/4mbroise/ADBL2-Mistral-7B</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation</head><p>We evaluated the performance and generalisation capabilities of our new quantised fine-tuned Mistral 7B model (as described in Section 4.2). As a baseline, we use Mistral 7B-16bit<ref type="foot" target="#foot_6">foot_6</ref> with a few-shot priming composed of the same four fixed pair of argument examples, similar to <ref type="bibr" target="#b22">[23]</ref>. To constrain the output generated by the two LLMs to {attack, support}, we used LMQL as described in Section 3.</p><p>In Table <ref type="table">4</ref>.2, we reported the attack (resp. support) F1-score of the two LLMs as well as the macro F1-score. We can see that our new fine-tuned model outperforms the Mistral 7B-16bit model equipped with the few-shot priming on all domains. Moreover, we can see that while we only fine-tuned our LLM on the law, politics, and sports domains, the model performance on all domains increased significantly, achieving an average macro F1-score of 90.59% across all domains.</p><p>5 Discussion and Future Work</p><p>In this paper, we introduced ADBL2, an assisted debate builder tool. It is based on the capability of large language models to generalise and perform relation-based argument mining in a wide-variety of domains. It is the first opensource tool that leverages relation-based mining for (1) the verification of existing relations in a debate and (2) the assisted creation of new arguments by means of large language models. ADBL2 is highly modular and can work with any open-source large language models that are used as plugins. As a by-product, we also provide the first fine-tuned Mistral-7B large language model for relation-based argument mining, usable by ADBL2, which outperforms existing approaches for this task with an overall F1-score of 90.59% across all domains.</p><p>While this work shows promising results for RBAM, we still need to assess the generalisation capabilities of our fine-tuned Mistral 7B model on other argumentative datasets (e.g, Essays, Nixon-Kennedy, etc.). Moreover, we would also need to extend the model to perform ternary RBAM to identify arguments that are not related. We also plan to explore other types of LLMs such as heavily quantised models, pruned LLMs <ref type="bibr" target="#b27">[28]</ref>, more recent LLMs (e.g., Llama 3<ref type="foot" target="#foot_7">foot_7</ref> , Gemma <ref type="bibr" target="#b28">[29]</ref>), or LLMs fine-tuned with other PEFT techniques <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32]</ref>.</p><p>Ethics statement We note that while there are risks to LLMs such as bias and misinformation, we only use LLMs to generate a single token, which is support/attack. Thus, there are no risks of generating biased or false information. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Representation of the architecture of the ADBL2 tool.</figDesc><graphic coords="3,79.23,72.00,453.52,135.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Plot of the loss (y-axis) on the training (orange) and test (blue) datasets during the fine-tuning per training iteration (x-axis).</figDesc><graphic coords="5,228.05,72.00,155.91,124.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Evaluation of Mistral 7B-16bits with few-shot priming and our fine-tuned Mistral 7B models on our test dataset.</figDesc><table><row><cell></cell><cell cols="2">Test data D</cell><cell>Mistral 7B-16bits + 4-Shots</cell><cell>Fine-tuned Mistral 7B</cell></row><row><cell></cell><cell cols="4">Attack Support Attack/Support/Macro F1-score Attack/Support/Macro F1-score</cell></row><row><cell>Art</cell><cell>94</cell><cell>129</cell><cell>73.1 / 83.9 / 78.5</cell><cell>89.5 / 92.1 / 90.8</cell></row><row><cell>Climate Change</cell><cell>419</cell><cell>508</cell><cell>66.6 / 82.1 / 74.3</cell><cell>93.3 / 94.5 / 93.9</cell></row><row><cell>Economics</cell><cell>298</cell><cell>298</cell><cell>72.0 / 79.8 / 75.9</cell><cell>90.0 / 90.1 / 90.3</cell></row><row><cell>Entertainment</cell><cell>490</cell><cell>612</cell><cell>64.3 / 81.9 / 73.1</cell><cell>92.0 / 93.5 / 92.7</cell></row><row><cell>Health</cell><cell>355</cell><cell>473</cell><cell>64.5 / 81.7 / 73.1</cell><cell>90.8 / 93.3 / 92.2</cell></row><row><cell>Lgbtq</cell><cell>277</cell><cell>338</cell><cell>67.4 / 80.9 / 74.2</cell><cell>90.9 / 92.4 / 91.6</cell></row><row><cell>Life</cell><cell>353</cell><cell>352</cell><cell>81.5 / 84.2 / 82.9</cell><cell>90.8 / 90.5 / 90.6</cell></row><row><cell>Privacy</cell><cell>164</cell><cell>167</cell><cell>71.5 / 79.9 / 75.7</cell><cell>89.7 / 89.8 / 89.7</cell></row><row><cell>Law, Politics, Sports</cell><cell>891</cell><cell>867</cell><cell>69.2 / 78.8 / 74.0</cell><cell>91.9 / 91.8 / 91.8</cell></row><row><cell>Technology</cell><cell>537</cell><cell>554</cell><cell>67.2 / 79.2 / 73.2</cell><cell>92.0 / 92.6 / 92.3</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://www.kialo.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://debategraph.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://www.rationaleonline.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://arguman.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://lmql.ai/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>https://imbalanced-learn.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>https://huggingface.co/mistralai/Mistral-7B-v0.1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>https://llama.meta.com/llama3/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">What can argumentation do for inconsistent ontology query answering?</title>
		<author>
			<persName><forename type="first">Madalina</forename><surname>Croitoru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srdjan</forename><surname>Vesic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scalable Uncertainty Management -7th International Conference, SUM 2013</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Weiru</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Subrahmanian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jef</forename><surname>Wijsen</surname></persName>
		</editor>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">September 16-18, 2013. 2013</date>
			<biblScope unit="volume">8078</biblScope>
			<biblScope unit="page" from="15" to="29" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Argumentation techniques for existential rules. (Techniques d&apos;argumentation pour les règles existentielles)</title>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Yun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<pubPlace>University of Montpellier, France</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games</title>
		<author>
			<persName><forename type="first">Phan</forename><surname>Minh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dung</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="321" to="358" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An introduction to argumentation semantics</title>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Caminada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimiliano</forename><surname>Giacomin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Eng. Rev</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="365" to="410" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semi-stable semantics</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Caminada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Models of Argument: Proceedings of COMMA 2006</title>
		<editor>
			<persName><forename type="first">Paul</forename><forename type="middle">E</forename><surname>Dunne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Trevor</forename><forename type="middle">J M</forename><surname>Bench-Capon</surname></persName>
		</editor>
		<meeting><address><addrLine>Liverpool, UK</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2006">September 11-12, 2006. 2006</date>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ranking-based semantics for argumentation frameworks</title>
		<author>
			<persName><forename type="first">Leila</forename><surname>Amgoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ben-Naim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scalable Uncertainty Management -7th International Conference, SUM 2013</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Weiru</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Subrahmanian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jef</forename><surname>Wijsen</surname></persName>
		</editor>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">September 16-18, 2013. 2013</date>
			<biblScope unit="volume">8078</biblScope>
			<biblScope unit="page" from="134" to="147" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A comparative study of ranking-based semantics for abstract argumentation</title>
		<author>
			<persName><forename type="first">Elise</forename><surname>Bonzon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jérôme</forename><surname>Delobelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Konieczny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Maudet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><forename type="middle">P</forename><surname>Wellman</surname></persName>
		</editor>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016">February 12-17, 2016. 2016</date>
			<biblScope unit="page" from="914" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Viewpoints using ranking-based argumentation semantics</title>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srdjan</forename><surname>Vesic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madalina</forename><surname>Croitoru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Bisquert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Models of Argument -Proceedings of COMMA 2018</title>
		<editor>
			<persName><forename type="first">Sanjay</forename><surname>Modgil</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Katarzyna</forename><surname>Budzynska</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Lawrence</surname></persName>
		</editor>
		<meeting><address><addrLine>Warsaw, Poland</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2018-09-14">12-14 September 2018. 2018</date>
			<biblScope unit="volume">305</biblScope>
			<biblScope unit="page" from="381" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the bipolarity in argumentation frameworks</title>
		<author>
			<persName><forename type="first">Leila</forename><surname>Amgoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudette</forename><surname>Cayrol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Christine Lagasquie-Schiex</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Workshop on Non-Monotonic Reasoning (NMR 2004)</title>
		<editor>
			<persName><forename type="first">James</forename><forename type="middle">P</forename><surname>Delgrande</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Torsten</forename><surname>Schaub</surname></persName>
		</editor>
		<meeting><address><addrLine>Whistler, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">June 6-8, 2004. 2004</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Gradual valuation for bipolar argumentation frameworks</title>
		<author>
			<persName><forename type="first">Claudette</forename><surname>Cayrol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Christine Lagasquie-Schiex</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symbolic and Quantitative Approaches to Reasoning with Uncertainty, 8th European Conference, ECSQARU 2005</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Lluís</forename><surname>Godo</surname></persName>
		</editor>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">July 6-8, 2005. 2005</date>
			<biblScope unit="volume">3571</biblScope>
			<biblScope unit="page" from="366" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Assessing the impact of agents in weighted bipolar argumentation frameworks</title>
		<author>
			<persName><forename type="first">Areski</forename><surname>Himeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Bisquert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madalina</forename><surname>Croitoru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SGAI 2021, Proceedings</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Max</forename><surname>Bramer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Richard</forename><surname>Ellis</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">13101</biblScope>
			<biblScope unit="page" from="75" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A generalization of dung&apos;s abstract framework for argumentation: Arguing with sets of attacking arguments</title>
		<author>
			<persName><forename type="first">Søren</forename><surname>Holbech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nielsen</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Parsons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Argumentation in Multi-Agent Systems, Third International Workshop</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Nicolas</forename><surname>Maudet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Simon</forename><surname>Parsons</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Iyad</forename><surname>Rahwan</surname></persName>
		</editor>
		<meeting><address><addrLine>Hakodate, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006-05-08">2006. May 8, 2006. 2006</date>
			<biblScope unit="volume">4766</biblScope>
			<biblScope unit="page" from="54" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ranking-based semantics for sets of attacking arguments</title>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srdjan</forename><surname>Vesic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madalina</forename><surname>Croitoru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020">February 7-12, 2020. 2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="3033" to="3040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Probabilistic reasoning with abstract argumentation frameworks</title>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Thimm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="565" to="611" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Empirical study on human evaluation of complex argumentation frameworks</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Guillaume</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logics in Artificial Intelligence -16th European Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Francesco</forename><surname>Calimeri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Leone</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marco</forename><surname>Manna</surname></persName>
		</editor>
		<meeting><address><addrLine>Rende, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-05-07">2019. May 7-11, 2019. 2019</date>
			<biblScope unit="volume">11468</biblScope>
			<biblScope unit="page" from="102" to="115" />
		</imprint>
	</monogr>
	<note>JELIA</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Graphical representation enhances human compliance with principles for graded argumentation semantics</title>
		<author>
			<persName><forename type="first">Srdjan</forename><surname>Vesic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Predrag</forename><surname>Teovanovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)</title>
		<editor>
			<persName><forename type="first">Piotr</forename><surname>Faliszewski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Viviana</forename><surname>Mascardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Catherine</forename><surname>Pelachaud</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</editor>
		<meeting><address><addrLine>Auckland, New Zealand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">May 9-13, 2022</date>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
	<note>21st International Conference on Autonomous Agents and Multiagent Systems</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Directionality of attacks in natural language argumentation</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Guillaume</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth Workshop on Bridging the Gap between Human and Automated Reasoning (IJCAI-ECAI 2018)</title>
		<editor>
			<persName><forename type="first">Claudia</forename><surname>Schon</surname></persName>
		</editor>
		<meeting>the fourth Workshop on Bridging the Gap between Human and Automated Reasoning (IJCAI-ECAI 2018)<address><addrLine>Stockholm, Schweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-14">July 14, 2018. 2018</date>
			<biblScope unit="volume">2261</biblScope>
			<biblScope unit="page" from="40" to="46" />
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Towards relation based argumentation mining</title>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Carstens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Toni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Argumentation Mining, ArgMining@HLT-NAACL 2015</title>
		<meeting>the 2nd Workshop on Argumentation Mining, ArgMining@HLT-NAACL 2015<address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2015-06-04">June 4, 2015. 2015</date>
			<biblScope unit="page" from="29" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A corpus of argument networks: Using graph properties to analyse divisive issues</title>
		<author>
			<persName><forename type="first">Barbara</forename><surname>Konat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joonsuk</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarzyna</forename><surname>Budzynska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Reed ; Nicoletta Calzolari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Goggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marko</forename><surname>Grobelnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bente</forename><surname>Maegaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hélène</forename><surname>Mazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation LREC 2016</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation LREC 2016<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">May 23-28, 2016. 2016</date>
		</imprint>
	</monogr>
	<note>Asunción Moreno, Jan Odijk, and Stelios Piperidis European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Argument mining: A survey</title>
		<author>
			<persName><forename type="first">John</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Reed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="765" to="818" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santiago</forename><surname>Marro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Medicine</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page">102098</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transformer-based models for automatic identification of argument relations: A cross-domain evaluation</title>
		<author>
			<persName><forename type="first">Ramon</forename><surname>Ruiz-Dolz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><surname>Alemany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><forename type="middle">Heras</forename><surname>Barberá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><surname>García-Fornes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="62" to="70" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Can large language models perform relation-based argument mining?</title>
		<author>
			<persName><forename type="first">Deniz</forename><surname>Gorur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Rago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Toni</surname></persName>
		</author>
		<idno>CoRR, abs/2402.11243</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Llama 2: Open foundation and fine-tuned chat models</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasmine</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Albert Q Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianna</forename><surname>Bressand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><surname>Saulnier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.06825</idno>
		<title level="m">Mistral 7b</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Lora: Low-rank adaptation of large language models</title>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyuan</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shean</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event</title>
		<imprint>
			<date type="published" when="2022">April 25-29, 2022. OpenReview.net, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Qlora: Efficient finetuning of quantized llms</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artidoro</forename><surname>Pagnoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Alice</forename><surname>Oh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tristan</forename><surname>Naumann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</editor>
		<meeting><address><addrLine>NeurIPS; New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023-12-10">2023. 2023. December 10 -16, 2023, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the structural pruning of large language models</title>
		<author>
			<persName><forename type="first">Xinyin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gongfan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Llm-Pruner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Alice</forename><surname>Oh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tristan</forename><surname>Naumann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</editor>
		<meeting><address><addrLine>NeurIPS; New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023-12-10">2023. 2023. December 10 -16, 2023, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Gemma</forename><surname>Team</surname></persName>
		</author>
		<title level="m">Open models based on gemini research and technology</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Galore: Memory-efficient LLM training by gradient low-rank projection</title>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beidi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<idno>CoRR, abs/2403.03507</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fewshot parameter-efficient fine-tuning is better and cheaper than in-context learning</title>
		<author>
			<persName><forename type="first">Haokun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Muqeeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Mohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tenghao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Sanmi Koyejo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Danielle</forename><surname>Agarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Belgrave</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Cho</surname></persName>
		</editor>
		<editor>
			<persName><surname>Oh</surname></persName>
		</editor>
		<meeting><address><addrLine>NeurIPS; New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022-11-28">2022. 2022. November 28 -December 9, 2022, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Relora: High-rank training through low-rank updates</title>
		<author>
			<persName><forename type="first">Namrata</forename><surname>Vladislav Lialin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherin</forename><surname>Shivagunde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Muckatira</surname></persName>
		</author>
		<author>
			<persName><surname>Rumshisky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fauno: The Italian Large Language Model that will leave you senza parole!</title>
				<funder ref="#_Zbkzn6b">
					<orgName type="full">FAIR</orgName>
				</funder>
				<funder ref="#_kjxTAHZ">
					<orgName type="full">European Union -NextGenera</orgName>
				</funder>
				<funder ref="#_v8cvpQ2">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
				</funder>
				<funder ref="#_qa2e8TA">
					<orgName type="full">ERC Starting</orgName>
				</funder>
				<funder ref="#_XAWNhzF #_V26yvFz #_pX48P5f">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-06-26">26 Jun 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Andrea</forename><surname>Bacciu</surname></persName>
							<email>bacciu@diag.uniroma1.it</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer</orgName>
								<orgName type="department" key="dep2">Control and Management Engineering</orgName>
								<orgName type="institution">Sapienza University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Giovanni</forename><surname>Trappolini</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer</orgName>
								<orgName type="department" key="dep2">Control and Management Engineering</orgName>
								<orgName type="institution">Sapienza University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><surname>Santilli</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Sapienza University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emanuele</forename><surname>Rodolà</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Sapienza University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabrizio</forename><surname>Silvestri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer</orgName>
								<orgName type="department" key="dep2">Control and Management Engineering</orgName>
								<orgName type="institution">Sapienza University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Italian Information Retrieval Workshop</orgName>
								<address>
									<addrLine>June 8th -9th</addrLine>
									<postCode>2023</postCode>
									<region>Pisa</region>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fauno: The Italian Large Language Model that will leave you senza parole!</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
						<imprint>
							<date type="published" when="2023-06-26">26 Jun 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">A37BC7E566657F1183706AB424F7D464</idno>
					<idno type="arXiv">arXiv:2306.14457v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Large Language Models</term>
					<term>Conversational AI</term>
					<term>Multilingual Models</term>
					<term>ChatGPT</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents Fauno, the first and largest open-source Italian conversational Large Language Model (LLM). Our goal with Fauno is to democratize the study of LLMs in Italian, demonstrating that obtaining a fine-tuned conversational bot with a single GPU is possible. In addition, we release a collection of datasets for conversational AI in Italian. The datasets on which we fine-tuned Fauno include various topics such as general question answering, computer science, and medical questions. We release our code and datasets on <ref type="url" target="https://github.com/RSTLess-research/Fauno-Italian-LLM">https://github.com/RSTLess-research/Fauno-Italian-LLM</ref> </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recently, there has been significant progress in enhancing the capabilities of natural language processing (NLP) methods. Notably, ChatGPT <ref type="bibr" target="#b0">[1]</ref> and GPT-4 <ref type="bibr" target="#b1">[2]</ref> have emerged as highly proficient chat models. These models exhibit an impressive aptitude for comprehending and producing human-like responses across various domains. Consequently, they have gained popularity in customer support, virtual assistants, and social media moderation applications. However, these models are often only accessible through restricted APIs, which hampers new research and development. Additionally, the limited availability of chat models creates challenges for researchers and practitioners, impeding the growth of the NLP community. This problem is further aggravated by the scarcity of publicly accessible and high-quality chat datasets for analyzing and improving these models. Recently, Baize <ref type="bibr" target="#b2">[3]</ref>, whose depiction can be seen in Figure <ref type="figure">3</ref>, has been introduced to tackle these challenges effectively, utilizing the capabilities of ChatGPT to generate a top-notch chat dataset comprising multiple conversational turns automatically. Their approach involves employing ChatGPT to engage in a simulated dialogue with itself, mimicking both user and AI responses. This generated dataset is a valuable resource for training and evaluating chat models in the context of multi-turn conversations. Additionally, by specifying an initial dataset, they extract samples from specific domains and fine-tune chat models to specialize in technology or healthcare. To fine-tune Large Language Models (LLM) with limited resources, they adopt an efficient tuning technique that maximizes the utilization of available computational capabilities. This strategy allows state-of-the-art language models to adapt and perform well in resource-constrained scenarios. Their primary objective is to enhance an open-source LLM, LLaMA <ref type="bibr" target="#b3">[4]</ref>, which they believe has the potential to serve as an accessible alternative to proprietary chat models. By fine-tuning LLaMA with their generated chat dataset, they introduce a new model called Baize (Bái zé), inspired by a legendary creature from Chinese folklore known for its linguistic prowess and vast knowledge. Baize reaches incredible performance; however, as with many other models in this category, its performance heavily depends on the language considered <ref type="bibr" target="#b4">[5]</ref>. In particular, these models tend to prefer the English language since this is the language they have seen the most during their training. Their performance in other languages, such as Italian, is vastly inferior, as it can be easily checked empirically by merely using these tools. For this reason, inspired by Latin mythology, in this paper, we introduce Fauno, the first and the largest open-source Italian conversational LLM. To build Fauno, we translated several datasets originally used by Baize in Italian. We use them to fine-tune and train our model, reaching good generation scores, as highlighted in later sections of this paper. Our goal is twofold. First, we want to provide the Italian (and the international) research community with an LLM that is highly proficient in Italian. We hope this will enhance and enable new research on this particular language by surpassing the current state-of-the-art capabilities of Italian. Second, we want to provide practitioners with a valid conversational AI able to deal with the Italian language. We provide an example for this latter case to hint at this tool's potential. Italy has one of the largest populations of elderly people. In the last twenty years, the number of people older than eighty has doubled, according to the Italian statistical entity (ISTAT). Furthermore, roughly 1.2 million people are older than 65 and live alone. These people are known in the medical literature to suffer from loneliness, which aggravates their health issues. With tools like Fauno, however, one could offer a conversational AI as a telehealth service. While not being a substitute for a human, this could improve the quality of life of millions of people and reduce the weight of the national health system. This is just one example of applications, and we hope our model can spark many such projects and research. Fauno can be operational on accessible hardware, thus expanding accessibility to a broader range of practitioners and researchers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Language Models for Chat</head><p>Transformers <ref type="bibr" target="#b5">[6]</ref>, introduced initially as a machine translation system, have had an arguably unprecedented impact on the AI world. Transformers and deep learning models, in general, are now used not only for NLP <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>, but also other fields such as image processing <ref type="bibr" target="#b10">[11]</ref>, audio <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>, 3D data <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>, recommendation systems <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>. Language Models (LMs), based on the transformer architecture, have gained significant attention in Natural Language Processing due to their ability to produce coherent human-like text. Radford et al. <ref type="bibr" target="#b19">[20]</ref> showed that LMs could learn a variety of tasks without direct human supervision but using self-supervision on large, noisy web corpora. Several works have developed this idea, further scaling the data and model size <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>. However, all these models are not explicitly designed with a conversational objective or training curriculum. Zhang et al. <ref type="bibr" target="#b23">[24]</ref> introduced DialoGPT, which is a fine-tuned version of GPT-2 on Reddit data; Adiwardana et al. <ref type="bibr" target="#b24">[25]</ref> proposed Meena, a 2.6B model trained with conversational data from social media; <ref type="bibr" target="#b25">[26]</ref> proposed LaMDA, a 137B model trained on public dialog data. Recently OpenAI released ChatGPT <ref type="bibr" target="#b0">[1]</ref>, a model optimized for conversational interaction trained with Reinforcement Learning with Human Feedback <ref type="bibr" target="#b26">[27]</ref>. With GPT-4 <ref type="bibr" target="#b1">[2]</ref>, this approach was further improved with additional reasoning capabilities. Recently, Xu et al. <ref type="bibr" target="#b2">[3]</ref> introduced Baize as a finetuned version of LLaMA <ref type="bibr" target="#b3">[4]</ref> for conversation by training the model on dialogs generated by ChatGPT. Our approach stems from this work and extends it to the Italian language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Language Models for Italian</head><p>To the best of our knowledge, no LMs are trained explicitly with a conversational objective or training curriculum for the Italian language. The currently available LMs for Italian include GePpeTto <ref type="bibr" target="#b27">[28]</ref>, a GPT-2 model finetuned on Italian Wikipedia and the ItWac corpus <ref type="bibr" target="#b28">[29]</ref>; IT5 <ref type="bibr" target="#b29">[30]</ref>, an Italian version of T5 trained on a cleaned version of the Italian mC4 corpus <ref type="bibr" target="#b30">[31]</ref>; BART-IT <ref type="bibr" target="#b31">[32]</ref>, an Italian version of BART <ref type="bibr" target="#b32">[33]</ref> trained on the same data mixture of IT5; Camoscio <ref type="bibr" target="#b33">[34]</ref>, an Italian version of Stanford Alpaca <ref type="bibr" target="#b34">[35]</ref> trained on the Alpaca dataset translated to Italian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Parameter-Efficient Tuning</head><p>Typical fine-tuning involves training all parameters of an LLM, which can be inefficient as the number of parameters increases. Various techniques have been proposed to address this issue under the umbrella term of Parameter-Efficient Fine-Tuning (PEFT). These techniques include Adapters <ref type="bibr" target="#b35">[36]</ref>, which adds a trainable layer inside the Transformer while freezing the others; BitFit <ref type="bibr" target="#b36">[37]</ref>, which only tunes bias terms in the linear layers; Prompting approaches like Prefix Tuning <ref type="bibr" target="#b37">[38]</ref>, P-Tuning <ref type="bibr" target="#b38">[39]</ref> or Prompt Tuning <ref type="bibr" target="#b39">[40]</ref> which fine-tune the optimal prompt parameters for a task; or LoRA <ref type="bibr" target="#b40">[41]</ref> which trains low-rank matrices while keeping all the remaining parameters frozen. This is a very active research area, and we refer the reader to Zhuang et al. <ref type="bibr" target="#b41">[42]</ref> for an up-to-date overview. Recently the community leveraged these techniques to train low-cost versions of Stanford Alpaca <ref type="bibr" target="#b34">[35]</ref> under the name of Alpaca-LoRA 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Conversational AI Datasets in Italian</head><p>In this section, we report the data we use to fine-tune Fauno and the data generation and translation process. We train Fauno on extensive Italian synthetic datasets, encompassing a wide range of fields such as medical data (MedQuad <ref type="bibr" target="#b42">[43]</ref>), technical content from StackOverflow, Quora discussions, and Alpaca <ref type="bibr" target="#b34">[35]</ref> data translated into Italian with 47.000, 57.000, 54.000 and, 22.000 dialogues, respectively. The synthetic generation of the data is described in Section 3.1. To produce conversational AI Datasets, we inherit Xu et al. 2023 <ref type="bibr" target="#b2">[3]</ref>'s dataset generation methodology. This methodology consists of allowing ChatGPT to engage in self-chatting to produce a conversation between a user and a helpful AI assistant in a conversational format. This self-chatting process is initiated with a question (or seed) from real users. For example, <ref type="bibr" target="#b2">[3]</ref> takes as seed questions froms Quora<ref type="foot" target="#foot_0">foot_0</ref> and Stack Overflow <ref type="foot" target="#foot_1">3</ref> . The generation methodology is shown in Figure <ref type="figure">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data Generation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Translation</head><p>To translate Fauno's data, we use two different translation systems to maximize translation accuracy and quality. Jiao et al. ( <ref type="formula">2023</ref>) <ref type="bibr" target="#b43">[44]</ref> have demonstrated that Google Translate is state-of-the-art among commercial translation systems. Nevertheless, Google Translate encounters significant issues when handling text incorporating natural language utterances and programming code. For instance, when translating a code snippet like "for i in range( <ref type="formula">10</ref>)" into Italian, Google Translate would incorrectly render it as "per i in intervallo( <ref type="formula">10</ref>)", which disrupts the syntax and functionality of the original code. This is due to Google Translate's inability to discern between natural language and programming code. To address this limitation, we opted to utilize ChatGPT 3.5 to translate datasets containing programming code, as it is better suited for preserving the integrity of the code's syntax and structure. Hence, we translate Alpaca and StackOverflow with ChatGPT 3.5 and the remaining datasets with Google Translate. We release the translated dataset of StackOverflow<ref type="foot" target="#foot_2">foot_2</ref> , MedQuad<ref type="foot" target="#foot_3">foot_3</ref> , Quora<ref type="foot" target="#foot_4">foot_4</ref> and Alpaca<ref type="foot" target="#foot_5">foot_5</ref> in the Huggingface hub. The cost of translating the StackOverflow dataset using the ChatGPT-3.5 API is $80, while the Alpaca Dataset translation costs around $30. For other datasets, we utilize Google's free translation API <ref type="foot" target="#foot_6">8</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Train setup</head><p>We use the same hyper-parameters of <ref type="bibr" target="#b2">[3]</ref> with a single epoch and batch size of 128 examples. We perform our experiments on a workstation equipped with an Intel Core i9-10940X (14-core CPU running at 3.3GHz) and 256GB of RAM, and a single Nvidia RTX A6000 with 48GB of VRAM. The training time for the 7B and 13B models are 19 and 35 hours, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Evaluation</head><p>As done by <ref type="bibr">Xu et al. 2023 [3]</ref> and Camoscio <ref type="bibr" target="#b33">[34]</ref>, we rely on a qualitative analysis of Fauno's outputs. In Table <ref type="table">1</ref>, we compare ChatGPT 3.5, Camoscio, and Fauno.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Answer</head><p>Question Qual è il senso della vita?</p><p>ChatGPT La domanda sul senso della vita è stata oggetto di riflessione filosofica e teologica per secoli, e non esiste una risposta definitiva o concorde. Tuttavia, molti individui trovano significato e scopo nella vita attraverso diverse vie. Alcuni cercano il senso nella connessione umana e nelle relazioni significative, altri nella realizzazione personale e nello sviluppo delle proprie passioni. Altri ancora si rivolgono alla spiritualità o alla fede per trovare un senso più profondo. In generale, il senso della vita può essere un'esperienza altamente individuale e soggettiva, e ognuno potrebbe trovare una risposta diversa a questa domanda.</p><p>Camoscio Il senso della vita è trovare la felicità e la soddisfazione nella vita.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fauno</head><p>Il senso della vita è una domanda popolare e complessa che ha suscitato dibattito in molte culture e generazioni. Alla fine, la comprensione di qual è il senso della vita dipende dalla prospettiva e dalle convinzioni personali di ogni singolo individuo. Alcune persone possono vedere il senso della vita in termini di un significato unico e globale, mentre altri possono sforzarsi di risolvere il mistero della vita trovando autentico benessere e piacere nei loro giorni quotidiani.</p><p>Question Come posso copiare un file da un server tramite ssh?</p><p>ChatGPT Per copiare un file da un server tramite SSH, puoi utilizzare il comando "scp" (Secure Copy). Ecco come puoi farlo: Apri una finestra di terminale sul tuo computer locale. Assicurati di avere il client SSH installato sul tuo sistema. Se stai utilizzando un sistema operativo basato su Unix (ad esempio Linux o macOS), lo avrai probabilmente già installato. Se stai utilizzando Windows, puoi utilizzare un client SSH come PuTTY o installare un'implementazione di SSH come OpenSSH. Utilizza il seguente comando "scp" per copiare il file dal server al tuo computer locale: scp username@indirizzo_server:percorso_del_file_locale per-corso_di_destinazion Camoscio Per copiare un file da un server tramite ssh, è necessario utilizzare l'opzione "scp" dell'utente ssh. Per esempio, per copiare un file dal server "server.example.com" all'utente "utente.example.com", l'utente dovrebbe utilizzare l'opzione "scp server.example.com:utente.example.com".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fauno</head><p>Per copiare un file da un server tramite ssh, puoi utilizzare il seguente comando: scp username@ip_dello_server:percorso/della/sorgente/del/file /percorso/della/destinazione/del/file Sostituisci i dettagli con il tuo nome utente, il nome dell'host, il percorso della sorgente e il percorso finale del file e clicca su "Avanti". Il file verrà copiato dal server alla tua macchina. C'è qualcos'altro di cui hai bisogno?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Qualitative analysis of ChatGPT-3.5, Camoscio, and Fauno 7B</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This work shows that it is possible to democratize the research for LLMs in multiple languages with limited resources. Furthermore, we believe that the release of the Italian datasets for conversational AI will help researchers to develop further Large Language Models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1</head><figDesc>https://github.com/tloen/alpaca-lora</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://huggingface.co/datasets/quora</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://huggingface.co/datasets/pacovaldez/stackoverflow-questions</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://huggingface.co/datasets/andreabac3/StackOverflow-Italian-Fauno-Baize</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>https://huggingface.co/datasets/andreabac3/MedQuaAD-Italian-Fauno-Baize</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>https://huggingface.co/datasets/andreabac3/Quora-Italian-Fauno-Baize</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>https://huggingface.co/datasets/teelinsan/camoscio_cleaned</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>https://pypi.org/project/googletrans/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACK</head><p>This work was partially supported by projects <rs type="funder">FAIR</rs> (<rs type="grantNumber">PE0000013</rs>) and SERICS (<rs type="grantNumber">PE00000014</rs>) under the <rs type="grantName">MUR National Recovery and Resilience Plan</rs> funded by the <rs type="funder">European Union -NextGenera</rs>-tionEU and by <rs type="funder">ERC Starting</rs> Grant No. <rs type="grantNumber">802554</rs> (SPECGEO) and <rs type="programName">PRIN 2020 project n.2020TA3K9N "LEGO.AI</rs>". Supported by the <rs type="funder">ERC</rs> Advanced Grant <rs type="grantNumber">788893</rs> <rs type="projectName">AMDROMA</rs>, <rs type="grantNumber">EC H2020RIA</rs> project "<rs type="projectName">SoBigData++</rs>" (871042), PNRR <rs type="projectName">MUR</rs> project <rs type="projectName">IR0000013-SoBigData</rs>.it.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Zbkzn6b">
					<idno type="grant-number">PE0000013</idno>
				</org>
				<org type="funding" xml:id="_kjxTAHZ">
					<idno type="grant-number">PE00000014</idno>
					<orgName type="grant-name">MUR National Recovery and Resilience Plan</orgName>
				</org>
				<org type="funding" xml:id="_qa2e8TA">
					<idno type="grant-number">802554</idno>
					<orgName type="program" subtype="full">PRIN 2020 project n.2020TA3K9N &quot;LEGO.AI</orgName>
				</org>
				<org type="funded-project" xml:id="_v8cvpQ2">
					<idno type="grant-number">788893</idno>
					<orgName type="project" subtype="full">AMDROMA</orgName>
				</org>
				<org type="funded-project" xml:id="_XAWNhzF">
					<idno type="grant-number">EC H2020RIA</idno>
					<orgName type="project" subtype="full">SoBigData++</orgName>
				</org>
				<org type="funded-project" xml:id="_V26yvFz">
					<orgName type="project" subtype="full">MUR</orgName>
				</org>
				<org type="funded-project" xml:id="_pX48P5f">
					<orgName type="project" subtype="full">IR0000013-SoBigData</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Optimizing language models for dialogue</title>
		<author>
			<persName><forename type="first">Chatgpt</forename><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/blog/chatgpt/" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<title level="m">OpenAI, Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Baize: An open-source chat model with parameterefficient tuning on self-chat data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.01196</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-A</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Azhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971</idno>
		<title level="m">Llama: Open and efficient foundation language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Ducel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lejeune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lepage</surname></persName>
		</author>
		<title level="m">Do we name the languages we study? the# benderrule in lrec and acl articles</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="564" to="573" />
		</imprint>
	</monogr>
	<note>Proceedings of the Thirteenth Language Resources and Evaluation Conference</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Polosukhin, Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="5485" to="5551" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multimodal neural databases</title>
		<author>
			<persName><forename type="first">G</forename><surname>Trappolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rodolà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unifying cross-lingual semantic role labeling with heterogeneous linguistic resources</title>
		<author>
			<persName><forename type="first">S</forename><surname>Conia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bacciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="338" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<title level="m">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00341</idno>
		<title level="m">Jukebox: A generative model for music</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Agostinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">I</forename><surname>Denk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Borsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verzetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tagliasacchi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.11325</idno>
		<title level="m">Musiclm: Generating music from text</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cycledrums: automatic drum arrangement for bass lines using cyclegan</title>
		<author>
			<persName><forename type="first">G</forename><surname>Barnabò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Trappolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lastilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Campagnano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discover Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Point transformer</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="16259" to="16268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Shape registration in the time of transformers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Trappolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cosmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moschella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Melzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rodolà</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="5731" to="5744" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards precise completion of deformable shapes</title>
		<author>
			<persName><forename type="first">O</forename><surname>Halimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Imanuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Trappolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rodolà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">August 23-28, 2020. 2020</date>
			<biblScope unit="page" from="359" to="377" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXIV 16</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Self-attentive sequential recommendation</title>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE international conference on data mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Integrating item relevance in training loss for sequential recommender systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bacciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Siciliano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tonellotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10824</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brunskill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07258</idno>
		<title level="m">On the opportunities and risks of foundation models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D L</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15556</idno>
		<title level="m">Training compute-optimal large language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Dialogpt: Large-scale generative pre-training for conversational response generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.00536</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Adiwardana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nemade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.09977</idno>
		<title level="m">Towards a human-like open-domain chatbot</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08239</idno>
		<title level="m">Lamda: Language models for dialog applications</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Geppetto carves italian into a language model</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Mattei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cafagna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dell'orletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guerini</surname></persName>
		</author>
		<ptr target="https://ceur-ws.org/Vol-2769/paper_46.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Italian Conference on Computational Linguistics, CLiC-it 2020</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Monti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Dell'orletta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Tamburini</surname></persName>
		</editor>
		<meeting>the Seventh Italian Conference on Computational Linguistics, CLiC-it 2020<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">March 1-3, 2021. 2020</date>
			<biblScope unit="volume">2769</biblScope>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings, CEUR-WS.org</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The wacky wide web: a collection of very large linguistically processed web-crawled corpora</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bernardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ferraresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zanchetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language resources and evaluation</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="209" to="226" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Large-scale text-to-text pretraining for italian language understanding and generation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.03759</idno>
	</analytic>
	<monogr>
		<title level="j">It</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A massively multilingual pre-trained text-to-text transformer</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.41</idno>
		<ptr target="https://aclanthology.org/2021.naacl-main.41.doi:10.18653/v1/2021.naacl-main.41" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bart-it: An efficient sequence-to-sequence model for italian text summarization</title>
		<author>
			<persName><forename type="first">M</forename><surname>La Quatra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cagliero</surname></persName>
		</author>
		<idno type="DOI">10.3390/fi15010015</idno>
		<ptr target="https://www.mdpi.com/1999-5903/15/1/15" />
	</analytic>
	<monogr>
		<title level="j">Future Internet</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.703</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.703.doi:10.18653/v1/2020.acl-main.703" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics<address><addrLine>BART</addrLine></address></meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Santilli</surname></persName>
		</author>
		<ptr target="https://github.com/teelinsan/camoscio" />
		<title level="m">Camoscio: An italian instruction-tuned llama</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<ptr target="https://github.com/tatsu-lab/stanford_alpaca" />
		<title level="m">Stanford alpaca: An instruction-following llama model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Parameter-efficient transfer learning for NLP</title>
		<author>
			<persName><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>De Laroussilhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="2790" to="2799" />
		</imprint>
	</monogr>
	<note>PMLR</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Zaken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ravfogel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>ACL, Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Prefix-tuning: Optimizing continuous prompts for generation</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4582" to="4597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">P-tuning: Prompt tuning can be comparable to fine-tuning across scales and tasks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-short.8</idno>
		<ptr target="https://aclanthology.org/2022.acl-short.8.doi:10.18653/v1/2022.acl-short.8" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">The power of scale for parameter-efficient prompt tuning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08691</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Low-rank adaptation of large language models</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lora</forename></persName>
		</author>
		<editor>ICLR, OpenReview.net</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">A survey on efficient training of transformers</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<idno>ArXiv abs/2302.01107</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A question-entailment approach to question answering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<title level="m">Is chatgpt a good translator? yes with gpt-4 as the engine</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

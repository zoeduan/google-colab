<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automated Repair of AI Code with Large Language Models and Formal Verification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-05-14">14 May 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yiannis</forename><surname>Charalambous</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Manchester</orgName>
								<address>
									<settlement>Manchester</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Edoardo</forename><surname>Manino</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Manchester</orgName>
								<address>
									<settlement>Manchester</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lucas</forename><forename type="middle">C</forename><surname>Cordeiro</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Manchester</orgName>
								<address>
									<settlement>Manchester</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Federal University of Amazonas</orgName>
								<address>
									<settlement>Manaus</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automated Repair of AI Code with Large Language Models and Formal Verification</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-05-14">14 May 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">0706FAD83524CC7F62489D774CFCE645</idno>
					<idno type="arXiv">arXiv:2405.08848v1[cs.SE]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The next generation of AI systems requires strong safety guarantees. This report looks at the software implementation of neural networks and related memory safety properties, including NULL pointer deference, out-of-bound access, double-free, and memory leaks. Our goal is to detect these vulnerabilities, and automatically repair them with the help of large language models. To this end, we first expand the size of NeuroCodeBench, an existing dataset of neural network code, to about 81k programs via an automated process of program mutation. Then, we verify the memory safety of the mutated neural network implementations with ESBMC, a stateof-the-art software verifier. Whenever ESBMC spots a vulnerability, we invoke a large language model to repair the source code. For the latest task, we compare the performance of various state-of-the-art prompt engineering techniques, and an iterative approach that repeatedly calls the large language model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In contrast to classic software development, neural networks are crafted via a long process of trial and error that terminates when their predictive performance reaches a satisfactory level <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b34">36]</ref>. The iterative and performance-driven nature of this process leaves neural networks vulnerable on many fronts <ref type="bibr" target="#b21">[23]</ref>: poor performance on out-of-distribution <ref type="bibr" target="#b19">[21]</ref> and adversarial inputs <ref type="bibr" target="#b30">[32]</ref>, misspecification of the neural architecture and training process <ref type="bibr" target="#b22">[24]</ref>, invocation of broken and deprecated libraries <ref type="bibr" target="#b28">[30]</ref>, outright software bugs <ref type="bibr" target="#b20">[22]</ref>. Unfortunately, many of these vulnerabilities are not easy to catch early in the development process and may remain hidden until after deployment.</p><p>Although efforts to debug the actual implementation of neural networks exist, they are based on automatic testing and thus cannot prove correctness for all inputs <ref type="bibr" target="#b31">[33,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b16">18]</ref>. This lack of guarantees is especially concerning for safety-critical systems since common software vulnerabilities <ref type="bibr" target="#b9">[11]</ref> (e.g., arithmetic overflows, invalid memory accesses) can make the networks produce wrong results, expose sensitive data or corrupt the system they are executed on.</p><p>In this report, we tackle the challenge of producing bug-free implementations of neural networks in the following way. First, we employ software verifiers to ensure full coverage of the state space. In the past, it has been claimed that software verifiers struggle to cope with neural network code due to its size, complexity and the presence of numerous calls to the standard mathematical library <ref type="bibr" target="#b24">[26]</ref>.</p><p>To verify this claim, we generate a large dataset of neural network code, by injecting memory vulnerabilities via program mutations. Our results show that software verifiers can find memory safety vulnerabilities in neural network code relatively easily, thus allowing us to use them as oracles for the correctness of neural network implementations.</p><p>Second, we adopt large language model as a powerful tool for program repair. In the past years, large language models have shown great promise in a wide variety of code processing tasks including program translation <ref type="bibr" target="#b37">[39]</ref>, code completion <ref type="bibr" target="#b23">[25]</ref> and automated repair <ref type="bibr" target="#b6">[8]</ref>. At the same time, the related literature always show a drop in performance on out-of-distribution samples, which are different from those seen during training. Here, we posit that neural network implementations, or AI code in short, fits in the latter category and constitutes an excellent benchmark for outof-distribution performance. Indeed, our results show that off-the-shelf large language models can repair AI code, but require very specific prompting techniques to do so at an acceptable level.</p><p>More specifically, this report covers the following topics:</p><p>• Our methodology to generate a large dataset of AI code examples. This is done by automatically increasing the size of the NeuroCodeBench dataset <ref type="bibr" target="#b24">[26]</ref> via code-specific data augmentation techniques.</p><p>• Experimental results on running the ESBMC software verifiers on the augmented dataset to classify benchmarks that contain memory safety vulnerabilities.</p><p>• A comparison of different prompt engineering techniques to optimise the repair performance of large language models. In this respect, we propose a few solutions to the issues of limited context windows, code formatting and including feedback from compilers and software verifiers.</p><p>• Preliminary results on the repair performance of large language model. Specifically, we analyse their output along four axes: correct syntax, relevance to task, compilability and successful repairs.</p><p>• Comparing and finding the best format of the history in iterative code repair affects iterative code repair performance.</p><p>• Impact of temperature on iterative code repair.</p><p>The structure of this report is the following. In Section 2, we give some background on Neu-roCodeBench, common safety vulnerabilities found in neural networks and the program mutation techniques we employ. In Section 3, we detail our methodology towards creating an AI code dataset, we present our empirical results in using ESBMC to label the dataset. In Section 4 we introduce a wide variety of state-of-the-art prompting techniques, we show how to employ them for code repair, and compare their code repair performance with ChatGPT.</p><p>This report is to be considered as the official documentation of the public software repository at <ref type="url" target="https://github.com/emanino/plain_c_nn_benchmark">https://github.com/emanino/plain_c_nn_benchmark</ref>, the staging repository can be found at <ref type="url" target="https://github.com/Yiannis128/plain_c_nn_benchmark">https://github.com/Yiannis128/plain_c_nn_benchmark</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background 2.1 NeuroCodeBench</head><p>NeuroCodeBench is a plain C benchmark of neural network implementations designed for formal software verification. In general, mainstream machine learning libraries (e.g., PyTorch <ref type="bibr" target="#b1">[3]</ref> and Tensorflow <ref type="bibr" target="#b3">[5]</ref>) have an opaque multi-language interpreted structure that can be easily tested <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b16">18]</ref>, Neural Network Category Inputs Outputs Layers Neurons Activations Architecture Conversion hopfield nets 4-64 4-64 1 4-64 Softsign/TanH Recurrent keras2c poly approx 1 1 1-4 16-1024 ReLU Feedforward keras2c reach prob density 3-14 3-14 2-3 64-192 ReLU Feedforward onnx2c reinforcement learning 4-8 2-8 2 128-512 ReLU Feedforward onnx2c</p><p>Table <ref type="table">1</ref>: Neural networks in NeuroCodeBench. The "Layers" and "Neurons" columns refer to the hidden layers only. The networks in hopfield nets have a number of iterations between 1 and 4.</p><p>but does not lend itself to automated software verification. For this reason, NeuroCodeBench opts for micro-controller frameworks, where the network's source code is fully available. More specifically, it uses two existing tools for converting high-level neural network specifications to standalone C code: onnx2c <ref type="bibr" target="#b35">[37]</ref> and keras2c <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b12">14]</ref>. Since November 2023, NeuroCodeBench is part of the official benchmark for the international software verification competition (SV-COMP).<ref type="foot" target="#foot_0">foot_0</ref> </p><p>In Table <ref type="table">1</ref>, we give an overview of the neural architectures of NeuroCodeBench. These have been designed to cover several use cases in machine learning and engineering, as detailed below:</p><p>Hopfield Networks. For a long time, it has been known that certain types of recurrent neural networks can act as error-correcting decoders <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b7">9]</ref>. The main idea is encoding a sequence of d bits into a vector x ∈ {±1} d , and letting the neural network flip the sign of the incorrect entries. Here, we choose Hopfield networks with Hebbian weights since their properties are well understood <ref type="bibr" target="#b0">[2]</ref>. Specifically, we build networks reconstructing a single pattern x = (1, . . . , 1). We vary the pattern length in d ∈ {4, 8, 16, 32, 64} and the number of recursions in t ∈ [1, 4]. For compatibility with keras2c <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b12">14]</ref>, we use Softsign and TanH activations (see Table <ref type="table">1</ref>) rather than traditional sign activations <ref type="bibr" target="#b0">[2]</ref>.</p><p>Polynomial Approximation Networks. In several engineering areas, neural networks are used to approximate the transfer function of electrical components <ref type="bibr" target="#b38">[40,</ref><ref type="bibr" target="#b25">27]</ref>. We emulate this process by defining a hypothetical polynomial component f (x) = 0.125x 4 -0.25x 3 -0.75x 2 + x + 0.5 with an oscillating transfer function. Then, we create a training set by uniformly sampling f (x) in x ∈ [-2, 3] and train 16 different feedforward ReLU networks f (x). The smallest has four layers with four neurons each, and the largest has a single hidden layer with 1024 neurons (see poly approx category in Table <ref type="table">1</ref>).</p><p>VNN-COMP Networks. Since its first edition in 2020, the International Verification of Neural Networks Competition (VNN-COMP) has published all its benchmarks <ref type="bibr" target="#b29">[31]</ref>. These benchmarks do not contain implementation details since they target a higher level of abstraction (real number arithmetic, no memory model). To provide a reference implementation, we translate the networks from ONNX format <ref type="bibr" target="#b10">[12]</ref> to C with onnx2c <ref type="bibr" target="#b35">[37]</ref>. From the 2022 edition <ref type="bibr" target="#b29">[31]</ref>, we select two categories with small networks (see Table <ref type="table">1</ref>): reach prob density <ref type="bibr" target="#b26">[28]</ref> and reinforcement learning <ref type="bibr" target="#b33">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Safety Properties</head><p>Originally, NeuroCodeBench <ref type="bibr" target="#b24">[26]</ref> was designed with the purpose of testing software verifiers. As such, it features very challenging verification problems centered around reachability properties <ref type="bibr" target="#b15">[17]</ref>. In contrast, our AI code dataset is meant to test the ability of large language models to repair code.</p><p>As the majority of real-world bugs <ref type="bibr" target="#b22">[24]</ref> are the result of programming mistakes, in this report, we focus on memory safety properties instead. Indeed, memory safety is the leading cause of software vulnerabilities <ref type="bibr" target="#b27">[29]</ref>. Here, we include a brief description of the different safety properties.</p><p>Reachability. For neural networks, we define reachability properties as necessary conditions over a set of inputs x ∈ X and outputs y ∈ Y, where y = f (x) and f is the neural network <ref type="bibr" target="#b4">[6]</ref>. In general, a reachability property would take the following form:</p><formula xml:id="formula_0">∀x ∈ X , y = f (x) =⇒ y ∈ Y (1)</formula><p>As a concrete example, consider the following. Take an error-correcting Hopfield network, which is trained to reconstruct the code y = (1, 1, . . . , 1) in the presence of input noise. Assume that all input vectors x of dimension d have at most three flipped inputs, i.e., X = {x|x i ∈ {±1} ∧</p><formula xml:id="formula_1">d i x i ≥ d -6}. The neural network is always able to reconstruct the correct code if Equation 1 holds for Y = {y = (1, 1 . . . 1)}.</formula><p>Memory safety. Properties encompass checking vulnerabilities regarding NULL pointer dereferences, out-of-bounds accesses, double-free, and memory leaks. In more broad terms, we check for situations where an illegal memory read or write can occur. ESBMC can check these properties by default by enabling the correct flags. For running the experiments, the following flags were enabled: --interval-analysis --goto-unwind --unlimited-goto-unwind --incremental-bmc --state-hashing --add-symex-value-sets --k-step 2 --floatbv --unlimited-k-steps --memory-leak-check --context-bound 2 --timeout 300 -Iincludes -Inetworks. These properties instruct ESBMC to encode memory safety criteria within the symbolic execution engine, ensuring that (1) all memory deallocations are valid, (2) all pointer dereferences are valid, and (3) all allocated memory is accurately tracked, encompassing pointed to or deallocated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Generative Language Models</head><p>AI has been used as mutation generators for automatically repairing code. In recent years, Large Language Models (LLMs) have taken precedence <ref type="bibr" target="#b18">[20]</ref>, however, the code that they generate is not secure and is filled with vulnerabilities <ref type="bibr" target="#b6">[8]</ref>. LLMs are a type of Recurrent Neural Network (RNN), an AI architecture that uses an encoder/decoder architecture, typically along with an attention mechanism <ref type="bibr" target="#b36">[38]</ref>. Opposite to conventional Recurrent Neural Networks (RNNs) that compute their values over a sequence of hidden states, LLMs with the encoder/decoder architecture can be heavily parallelized, allowing for more training in less time <ref type="bibr" target="#b36">[38]</ref>. Figure <ref type="figure">1</ref> shows a diagram of the layout of LLMs.</p><p>Furthermore, these developments have paved the way for OpenAI's GPT-3.5-Turbo, a closed source LLM. GPT-3.5-Turbo is a 175 billion parameter autoregressive language model <ref type="bibr" target="#b5">[7]</ref> that will be used in the experiments in this report.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Software Verification</head><p>There are many methods of verifying software, in this report we use Bounded Model Checking (BMC) to detect if the code in the experiments contains any memory vulnerabilities <ref type="bibr" target="#b14">[16]</ref>. BMC is a technique used where a given property is checked at a specified depth in a system <ref type="bibr" target="#b14">[16]</ref>. To elaborate, given a state transition system, and a property, BMC unrolls the system and translates it to a verification condition, if the verification condition is true, then the system is satisfiable up to Figure <ref type="figure">1</ref>: Diagrammatic layout of a transformer model architecture <ref type="bibr" target="#b36">[38]</ref>. that specified bound <ref type="bibr" target="#b14">[16]</ref>. Figure <ref type="figure" target="#fig_0">2</ref> visualizes how BMC works. The Efficient SMT-based Bounded Model Checker (ESBMC) is such a software verifier that uses bounded model checking to prove mathematically up to a certain depth the presence of software vulnerabilities <ref type="bibr" target="#b14">[16]</ref>. This report will use ESBMC to test samples of AI C code for the presence of vulnerabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Creating An AI Code Dataset</head><p>In order to fine-tune and evaluate the performance of large language models in repairing AI code, we need a dataset of neural network implementations. Since existing ones are fairly small, amounting to only a few hundred samples <ref type="bibr" target="#b24">[26]</ref>, we turn to data augmentation techniques to greatly expand their size. This is needed to obtain statistically significant evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Program Mutation</head><p>The test suite chosen for this task is the "practical mutation testing tool for C and C++" Mull <ref type="bibr" target="#b17">[19]</ref>. Mull comprises two key components, the compiler plugin and Mull Runner, an entirely separate program <ref type="bibr" target="#b17">[19]</ref>. The compiler plugin generates program mutations at the compilation stage and injects them into the LLVM bit code <ref type="bibr" target="#b17">[19]</ref>. The mutations enabled in Mull's configuration files are injected into the IR of the program but are hidden behind conditional flags that allow them to be individually enabled during runtime <ref type="bibr" target="#b17">[19]</ref>.</p><p>Mull Runner can run the program repeatedly with each mutation condition enabled <ref type="bibr" target="#b17">[19]</ref>. Mull runner will then check how the injection of the mutation affects the program's execution <ref type="bibr" target="#b17">[19]</ref>. Each mutation can be saved into a patch file and stored on disk <ref type="bibr" target="#b17">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Augmentation</head><p>The NeuroCodeBench dataset <ref type="bibr" target="#b24">[26]</ref> was expanded by a pipeline that aimed to automate the dataset generation as much as possible. The sheer size of the dataset is the reason for this, as it is not realistic to create a dataset with 81k samples in such a short time span using manual labor methods. The pipeline can be divided into three distinct sections that process and transform the base dataset from one form to the next. The process begins by building the base sample source code, followed by generating mutation patches using a mutation test suite; finally, the last step consists of using ESBMC to classify the samples. Figure <ref type="figure" target="#fig_1">3</ref> illustrates an overview of this pipeline process. Building the Base Samples. We follow the same procedure outlined by the NeuroCodeBench instructions for building the base dataset. The base dataset contains 505 samples. There are 79 Hopfield networks, 97 polynomial approximation networks, 34 probability density networks, and 295 reinforcement learning networks.</p><p>Generating Mutation Patches. Having obtained the base dataset, we use a mutation testing suite to generate patches for each sample that modify the code in a small way (see Section 3.1).</p><p>While Mull is designed to evaluate the quality of test suites for C programs <ref type="bibr" target="#b17">[19]</ref>, we have managed to use it to multiply the size of the base dataset by around 80x, reaching 81129 total samples. This is because we use the diff tool d to apply each patch generated y x to its original file f , yielding a new transformed file f ′ in the following process f ′ = d(f, y x ). Patches are produced through the Mull runner program $m$ via the following procedure: $y=m(f, c)$, where $c$ denotes Mull's configuration containing the specified mutations allowed for patch creation, and $y$ represents the collection of patches generated by the Mull compiler plugin. Creating a new sample for every patch</p><p>hopfield nets poly approx reach prob reinforcement 0 5,000 10,000 15,000 975 9,715 1,424 9,053 13,951 2,952 5 9,516 7,391 2,781 743 6,270 # verdicts Safe Unknown Unsafe (a) Number of safe and unsafe mutated programs. If ESBMC times out after 300s, the program is labeled unknown.  expands the size of the samples from 505 to 81129 samples; this increase depends on the amount of mutations that are enabled in the Mull configuration.</p><p>NeuroCodeBench samples also include calls VERIFIER assume(expression) and VERIFIERassert(expression) which instruct the verifiers to verify certain safety properties, as discussed in Section 2.2. As discussed previously, removing those statements is necessary as this dataset focuses on memory safety only<ref type="foot" target="#foot_1">foot_1</ref> .</p><p>Classifying the new Dataset. With the expanded dataset generated, ESBMC can then be used to verify the safety of each sample. As we are verifying only memory safety properties, the number of samples ESBMC can classify should be higher than when verifying the additional safety properties of the base dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Empirical Results</head><p>This section explores the experimental setup and results of processing this extended NeuroCodeBench dataset using the ESBMC verifier. The experiments were conducted on 6 machines with Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz, 198 GB RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification Results</head><p>Figure <ref type="figure" target="#fig_15">4a</ref> shows classifications assigned by ESBMC to each sample in each category. Note that each category exhibits different ratios of safe, unsafe, and unknown verdicts. Hopfield networks have the smallest amount of safe cases, compared to the amount of unsafe and unknown cases that they have, this is possibly due to the complexity of Hopfield networks, as they are recurrent neural networks. Probability density and reinforcement learning networks have a much higher portion of safe and unsafe cases compared to unknowns. These observations suggest that ESBMC is more capable at processing the latter two network types, possibly due to their simpler structure, as the symbolic execution would be less demanding due to possibly having less loop unrolling.</p><p>Verification Time Figure <ref type="figure" target="#fig_15">4b</ref> shows a box-plot of each category, illustrating various information about the verification time for safe or unsafe cases. As can be observed, Hopfield and polynomial approximation neural networks are much faster to complete on average than probability density and reinforcement learning graphs. One possible explanation is that these two categories of benchmarks use a different neural network library (keras2c) than the others (onnx2c). However, more data is needed to get a conlusive answer. Finally, note that while ESBMC could not successfully classify various samples, a sizable portion was processed successfully within a range of a few minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Lessons Learned</head><p>Overall, ESBMC is relatively efficient in verifying neural network code containing memory safety vulnerabilities. This contrasts with previous work on NeuroCodeBench, which showed that software verifiers such as ESBMC struggle to reason over reachability properties of neural networks. Still, the moderately large ratio of unknown verdicts, together with the long timeout of 300 seconds (or 5 minutes), leave room for improvements in terms of verification time. In the future, we might consider a portfolio approach combining falsification tools (e.g., fuzzers) with verification tools such as ESBMC.</p><p>For the time being, the sizeable number of conclusive verdicts (safe or unsafe) still allows us to build a large AI code dataset. With this dataset, we can explore the effectiveness of LLMs in recognizing potential vulnerabilities and repairing unsafe AI programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Repairing AI Code with Large Language Models</head><p>The AI code dataset we generate in Section 3 is a representative instance of out-of-distribution data. Indeed, while the original NeuroCodeBench is in the public domain, it was released in late 2023 <ref type="bibr" target="#b24">[26]</ref>, and it is thus unlikely to have been included in the training set of most state-of-the-art large language models <ref type="bibr" target="#b32">[34]</ref>. In addition, our automated mutation technique further ensures that our AI code dataset looks very different from any piece of software the current large language models have been trained on.</p><p>Against this background, we pose the following research question: can off-the-shelf large language models spot the memory vulnerabilities we introduced in Section 3 and eliminate them by repairing the code? Figure <ref type="figure" target="#fig_4">5</ref> displays a visualization of the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Prompt Templates</head><p>The consensus in the natural language processing community is that the performance of large language models depends on our ability to prompt them effectively <ref type="bibr" target="#b37">[39]</ref>. This has sparked much interest in prompt engineering techniques, which have sometimes entirely replaced the need to finetune a large language model <ref type="bibr" target="#b37">[39]</ref>. Here, we list a few state-of-the-art prompt engineering strategies relevant to the code generation task. Our overarching goal is to compare their empirical performance (See Section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Previous Experience with ESBMC-AI</head><p>An earlier technical report <ref type="bibr" target="#b6">[8]</ref> showed promising results by prompting large language models to repair vulnerable code. We included their prompt template in our experimental evaluation to establish a baseline. We list it here, with appropriate placeholders for the code to be repaired ({source}) and the verifier feedback ({esbmc}). We discuss dealing with these placeholders in Sections 4.1.4 and 4.1.5. For readability purposes, we remove newline characters \n and the backtick markers ''' that surround the source code and verifier output.</p><p>Listing 1: Old Prompt Template used in ESBMC-AI You are a secure code generator that parses vulnerable source code and output from a program called ESBMC, which contains vulnerability information about the source code. You should use the output from ESBMC to find the problem and correct the source code. ESBMC is always correct. You shall add a NULL check for every heap allocation you make. From this point on, you can only reply using the source code. You shall only output source code as a whole. The following text is the program's source code: {source} The following text is the output of ESBMC, reply OK if you understand: {esbmc} Generate a correction for the source code provided. Show the code only. Do not reply with acknowledgments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Simple Prompts</head><p>The prompt template in Section 4.1.1 is quite long and forces a specific order in the information provided: first, the code, then the verifier feedback. For comparison reasons, we deem it necessary to consider shorter prompts and vary the code's and bug trace's relative position. More specifically, we include three pairs of prompts of different lengths, which contain the following information:</p><p>• No verifier output provided;</p><p>• The verifier output is provided after the source code;</p><p>• The verifier output is provided before the source code.</p><p>For reference, we list all six prompt templates below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Listing 2: Simple Prompt Template with no ESBMC Output</head><p>The following source code segment might contain a memory vulnerability {source} Fix the source code segment.</p><p>Fix the memory vulnerability that may exist in the source code segment: {source} Fix the source code: {esbmc} {source}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Persona Prompts</head><p>Recent research has found that large language models produce better output when performing according to a specific role <ref type="bibr" target="#b37">[39]</ref>. This prompt engineering technique is usually called persona and creates many optimization opportunities. In our case, we ask the following research question:</p><p>• Does the role we assign to the large language model make a difference.</p><p>Here are the six roles we compare: Note that roles 1 and 2 are humanoid expert roles. Roles 3 and 4 are robotic expert roles. Roles 5 and 6 are wildcards, which were added as a control. These roles are inserted in the following prompt templates instead of the placeholder {role}. From now on, act as an {role} that repairs AI C code. You will be shown AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains a stack trace along with the type of error that occurred and its location. Provide the repaired C code as output, as would an {role}. Aside from the corrected source code, do not output any other text. The ESBMC output is {esbmc} The source code is {source}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Source Code</head><p>Large language models can only process a limited input text length. In the case of ChatGPT <ref type="bibr" target="#b32">[34]</ref>, which we use in our experiment of Section 4.2, the maximum input length is 16K tokens. As such, it is often impossible to feed the large language model the whole code to be repaired. To overcome this limitation, we employ the following two strategies.</p><p>Contextual. Most software verifiers, including ESBMC, do not just report the presence of a vulnerability, but they also include the line of code where it triggered an unwanted behavior. We cut the largest code window around the reported vulnerability to fit as much code as possible in the available space. More specifically, we select a window that contains around 90% lines of code before the vulnerability and 10% after.</p><p>One line. For memory safety vulnerabilities, such as array-out-of-bounds, it is likely that modifying the very same line of code that triggered the verifier is sufficient to repair it. For this reason, we run a full set of experiments showing the large language model with only one line of code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.5">Verifier Feedback</head><p>The output of most software verifiers contains a bug report with the violated property and a full bug trace with a concrete value for each state (counterexample). Our question is whether these pieces of information are useful to the large language model. For this reason, we run two sets of experiments that include either the full counterexample or just the short bug report. We observe no significant difference between these.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.6">Prompt Combinations</head><p>In summary, we have the following combinations of prompts:</p><p>• Without Verifier Feedback. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparing Templates</head><p>This section compares the repair performance of LLMs using the different prompting strategies listed above. Overall, we measure the LLM performance on four metrics of increasing difficulty:</p><p>• Syntax. Do the repair patches contain C code?</p><p>• Relevance. Do the repair patches match the input source code?</p><p>• Compilation. Do the repair patches compile?</p><p>• Verification. Do the repair patches solve the memory safety vulnerability?</p><p>Experimental Setup The experiments were run on a distributed computational infrastructure. For the duration of the experiments, GPT-3.5-Turbo was used as the LLM of choice, specifically gpt-3.5-turbo-0125, with a temperature of 1.0, which is the default set by the owners of the LLM API; no defaults were changed. ESBMC v7.4.0 was run on a server with Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz, 198 GB RAM. For each of the 144 prompt combinations listed in Section 4.1, we run 100 random samples from the AI code dataset we generate in Section 3, for a total of 14400 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntax of the LLM Patches</head><p>As a first sanity check, we want to confirm that the LLM produces C code rather than a mixture of textual instructions and small code snippets. We do so by running the automated code detector used in Visual Studio<ref type="foot" target="#foot_2">foot_2</ref> and extracting the score associated with C or C++. The results in Figure <ref type="figure" target="#fig_10">6</ref> illustrate markedly higher scores for a prompt containing a contextual window of source code rather than a single line. This is expected as the detector struggles to detect the language of short code snippets. Still, we can see that persona prompts yield a higher percentage of C-like LLM outputs for contextual strategy than other prompts (see Figure <ref type="figure" target="#fig_10">6a</ref>. Also, adding the ESBMC output to the prompt makes things worse for contextual strategy but better for single lines of code (Figure <ref type="figure" target="#fig_10">6b</ref>). Syntax Takeaway. Large language models produce C-like code fairly consistently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance of the LLM Patches</head><p>We know that the vulnerabilities introduced by Mull <ref type="bibr" target="#b17">[19]</ref> are due to a few character changes only, e.g., replacing &lt; with &lt;=. Thus, we expect a successful patch to copy most of the input code verbatim, except for a small difference. To see whether the LLM repair matches our expectations, we measure how many characters the input and output code have in common (not counting whitespaces) and report the results in  old simple pers-0 pers-1 pers-2 pers-3 pers-4 pers-5 0% 20% 40% 60% 80% 100% Source Code Match contextual one line (a) Prompt comparison. none before after 0% 20% 40% 60% 80% 100% Source Code Match (b) Verifier feedback. old simple pers-0 pers-1 pers-2 pers-3 pers-4 pers-5 none before after contextual 1.50% 1.25% 0.25% 0% 1.58% 2.16% 1.16% 1.25% 0.14% 1.32% 1.82% one line 63.0% 16.91% 61.25% 61.41% 31.8% 56.3% 38.9% 52.0% 54.9% 41.7% 40.0% Table 3: Percentage of repair patches that are successfully verified. All the patches that compile (see Table <ref type="table" target="#tab_3">2</ref>) are also successfully verified when using the contextual strategy.</p><p>has a low match, as the LLM sometimes reports only a few lines of code around the bug rather than copying the whole input code. One-liners (single) have a better match as it is easier for the LLM to repeat what we feed as input. The anomaly for single and simple prompts in Figure <ref type="figure" target="#fig_11">7a</ref> may be due to temporary changes in the ChatGPT backend that are out of our control rather than a real effect of our prompting technique <ref type="bibr" target="#b8">[10]</ref>. Again, adding feedback from ESBMC to our prompt seems to lower the performance of the LLM (see Figure <ref type="figure" target="#fig_11">7b</ref>).</p><p>Relevance Takeaway. Large language models skip over crucial portions of the input code.</p><p>Compiling the Repaired Code Even though we explicitly ask the large language model to produce valid C code as its output (see Section 4.1), there is no mechanism to guarantee that it does so. For this reason, we check whether introducing the repaired patch back into the original code yields a piece of code that compiles. The results in Table <ref type="table" target="#tab_3">2</ref> show that most of the runs did not produce compile code. However, there is a marked difference between how much source code is shown to the large language model. Indeed, letting the large language model repair only one line of code yields around 50% compilable patches across all settings.</p><p>Compilation Takeaway. Multi-line patches hardly compile, one-liners have a 50% chance.</p><p>Verifying the Repaired Code Finally, we evaluate whether the repaired code passes all checks for memory safety vulnerabilities. We do so by invoking ESBMC on the repaired code and counting how many programs are successfully verified (see Table <ref type="table">3</ref>). All the repair patches generated using the contextual strategy display an interesting property: if the code compiles, it is also successfully verified. However, while one-line repair patches might cause a verification failure or a time-out, they yield more successful repairs overall. In this respect, persona prompt techniques (no matter the specific role chosen) are the best.</p><p>Verification Takeaway. The best setting achieves less than 10% successful repairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparing Individual Prompts</head><p>The following section will compare all the individual prompts executed in the experiments and outline the best prompt for the Contextual and Single-line experiments. The grouping of the experiments and the use of "prompt" in this section refers to substituting the role and the ESBMC output type into a prompt template. The notation of a prompt is x.y.z where x describes the prompt index, y describes the role index used <ref type="foot" target="#foot_3">4</ref> , and z describes the ESBMC output type.</p><p>Contextual Figure <ref type="figure" target="#fig_13">8a</ref> shows the performance of the best prompts for the Contextual experiments. As evaluated in Section 4.2, it was discovered that Persona prompts performed overall better than the simple prompts; however, surprisingly, the Persona prompt assigned roles did not seem to affect the performance in an expected way. One note is that many prompts in the Contextual experiments did not successfully repair even one sample, so they have been omitted and not shown in Figure <ref type="figure" target="#fig_13">8a</ref>. Two prompts perform the best, they both use prompt template 9. The roles are "Automated Code</p><p>(a) Contextual experiments. (b) Single Line experiments. Repair Tool" and "Dog". The verifier output can both be violated property (VP) or counterexample (CE), as they both successfully repaired 4% of the samples.</p><p>Single Line Regarding the best prompt in Figure <ref type="figure" target="#fig_13">8b</ref>, the flipped Persona prompt template, index 11, was the most successful, at around 18%. The role that was used by the prompt was "Automated Code Repair Tool". The ESBMC output type used in the prompt was Counterexample (CE). The implications of these results suggest that, while assigning a specific role to the LLM is important, the role assigned may not impact performance consistently. However, it is worth noting that the "Automated Code Repair Tool" role seemed to have been among the best prompts in both Contextual and Single Line experiments. Also, longer prompts seemed to perform better in both Contextual and Single Line experiments.</p><p>Best Prompt Takeaway. The best prompt is the second prompt in Listing 7 in Section 4.1.3. Using the role "Automated Code Repair Tool".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Further Fine-Tuning of the Best Prompts</head><p>Prompts can be further refined to achieve better results. Here, we focus on the best two prompts found in Section 4.3: 9 and 11. Specifically, we consider two potential improvements. First, in Appendix A, we explore the role of backticks, which are usually added as a separator around code snippets. Second, in the current Section, we present two prompts with longer and more detailed instructions, which in previous experiments have yielded better performance (see Section 4). More specifically, we add further instruction to prompt templates 9 and 11 to do an additional 3 things. Firstly, we explicitly state to use the verifier output to find out what the fault of the sample is. Secondly, we instruct the LLM to repair only one line of code. Lastly, we instruct the LLM to minimize the size of the changes.</p><p>The modified prompt templates, referred to as 9-2 and 11-2 can be seen below: The impact of the new prompts will be presented in the following Section.</p><formula xml:id="formula_2">Prompt</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Lessons Learned</head><p>As shown in Section 4.2, repairing out-of-distribution code with large language models appears to be a delicate endeavour. On the one hand, some advanced prompt engineering techniques, e.g., assigning the model a persona role, seem to improve the success rate overall. However, the specific role does not seem to matter: the performance of "Dog" is more or less the same as that of a more credible role such as "Automated code repair tool". On the other hand, the choice of which information we show to the model seems crucial for obtaining good-quality patches. Perhaps surprisingly, providing feedback from a verifier about the nature of the vulnerability makes the performance worse. At the same time, choosing how many lines of code we include in the prompt is crucial for generating patches that compile and remove the vulnerabilities. Conversely, a cleverer choice of which lines of code to include in the prompt may be one of the most promising avenues for improvement. In this respect, formal methods such as static analysis can greatly help in identifying such program subsets.</p><p>Finally, the overall percentage of successfully repaired programs is just below 18%, even under the best settings. This suggests that it would take a large language model several attempts to propose a correct patch, thus greatly increasing the computational cost of automated program repair. We plan to minimize the cost of such an iterative approach in Work Package 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Iterative Automated Program Repair</head><p>Allowing the LLM to have multiple attempts at repairing the faulty sample may yield an increase in automated code repair (APR) performance. Figure <ref type="figure" target="#fig_16">9</ref> shows a diagram of how the iterative repair would function. It is an extended version of Figure <ref type="figure" target="#fig_4">5</ref> that adds an iterative loop element with the tracking of attempts. If the total attempts exceed the limit, in this case 5, then the verification fails.</p><p>With that in mind, we propose the following research questions:</p><p>1. Do large language models combined with formal verification increase automated program repair performance of AI C code when given multiple attempts to do so?</p><p>2. Does showing the history of patches to the LLM improve the performance of iterative APR?</p><p>3. What is the optimal way to show the history to the LLM?  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Methodology and Workflow</head><p>By adding the iterative loop element to the experimental setup, we expect an increase in the repair performance since the LLM has multiple attempts to repair the artifact successfully.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ESBMC-AI</head><p>The automated program repair functionality in ESBMC-AI builds a list of pairs of previously attempted repairs consisting of the source code and verifier output on top of the initial source code and verifier output <ref type="bibr" target="#b6">[8]</ref>. The iterative loop is described in Algorithm 1 <ref type="bibr" target="#b6">[8]</ref>:</p><p>1. The message list initially consists of the initial prompt and the source code, along with the verifier output, being substituted in. In the algorithm, Line 2 initializes an empty message prompt, and on Line 8 gets assigned to as described.</p><p>2. The LLM is sent the prompt instructing it to repair the source code, using the verifier output as a guide, as seen in Line 9.</p><p>3. The LLM returns the patched source code, and ESBMC is then tasked with verifying it is free of memory violations. If it is correct, then the APR process has successfully concluded.</p><p>Algorithm 1 Iterative APR</p><p>1: procedure FIX CODE(P, s, T, AI, V ) ▷ Tries to repair s in T attempts or less using AI. The prompt template is represented by P 2: m ← [] 3: for c ← 0, T do ▷ Check if we have exhausted allocated attempts 4: v, o ← V (s) ▷ Verify if s does not have memory vulnerabilities. The verifier verdict v and feedback o 5: if e then 6: return o 7: else 8: m ← (m, s, e) ▷ Creates a prompt using s and e, and previous messages m 9: s ← AI(m) ▷ Call the LLM and get patched source code 10: end if 11: end for 12:</p><p>return null ▷ No solution is found, all attempts exhausted 13: end procedure 4. If the verifier confirms that the patched code is still wrong, a new message is added to the message list consisting of a new prompt template with the latest source code, and new verifier output is also included.</p><p>5. The process repeats (from step 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Prompt Settings</head><p>Prompt Templates Prompts 9 and 11 will be used for the iterative repair experiments, along with prompts 9-2 and 11-2 from Section 4.4. Additionally, the old ESBMC-AI prompt will also be used in the experiments discussed in Section 4.1.1; the aim of including such a prompt is to observe the improvement in performance that the new prompts provide in an iterative environment, as it allows for an additional baseline measurement.</p><p>Source Code Due to the introduction of the iterative APR loop, the prompt structure becomes incompatible with the contextual experiments conducted in Section 4. The reason for this is that the contextual experiments were conducted to maximize the amount of source code and verifier output placed into the prompt. By its very nature, the creation of a contextual source code system with iterative loop mechanics would not work, as each iteration would require the space that the initial prompt had already taken. For the experiments in this section, the one-line format of displaying the source code has been chosen, as described in Section 4.1.4. The one-line experiments were also the group of experiments that performed better than contextual in every metric, as seen in Section 4.2.</p><p>Verifier Output In the previous experiments, the output of the verifier was either to show the counter-example stack trace and violated property, denoted as CE, or show only the violated property section of the verifier output, denoted as VP, as discussed in Section 4.1.5. Due to the structure of the AI C Code being repaired, the stack-trace generated is very large. Thus, the context window of the LLM fills up without going through all the cycles of the iterative APR loop, making running the AI C code experiments infeasible. For the iterative experiments, the VP output type was chosen, as it discards the large stack-trace produced by the verifier, instead keeping the violated property that contains a copy of the statement that the error occurs in, along with the type of error that the verifier had detected during the verification process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Message History</head><p>The iterative APR process introduces the concept of a message history: the collection of previous messages sent to the LLM. The three methods of representing current and previous messages are denoted as Latest State Only, Forward History, and Reverse History. The next paragraphs provide detailed explanations of each. Figure <ref type="figure" target="#fig_17">10</ref> visually represents each format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Latest State Only Experiments (LSO)</head><p>The LSO experiments are conducted to establish a baseline performance for the iterative APR approach. The iterative repair cycle of ESBMC-AI is modified to discard the history at each process of the APR loop. Effectively making it so that any previous repairs, aside from the last patch and verifier output, are discarded and not visible to the LLM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Forward History Experiments</head><p>The Forward History experiments construct the prompt sent to the LLM such that the messages are in chronological order. In addition, the experiments store information from previous messages. The LLM gets a complete history of prior messages from the start of the repair process until the end.</p><p>Reverse History Experiments Much like the Normal History experiments described previously, the Reverse History experiments use the same principle. However, the main difference is that the messages are reversed. The idea behind this is that the original state of the code would be displayed last in the message list. The last message read by the LLM would be the original state, which can potentially stop the LLM from drifting too far from the original code state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Setup</head><p>This section will explore the results of the iterative code repair experiments.</p><p>Hardware The iterative loop experiments will be conducted using the following environment:</p><p>• The experiments were conducted on a server running both Intel Ivybridge and Haswell CPUs with 32 GB of RAM.</p><p>• ESBMC-AI version 0.5.0rc4</p><p>• ESBMC version 7.4.0 64-bit x86 64 linux</p><p>• The LLM chosen is GPT-3.5-Turbo</p><p>• Each experiment was conducted over the 100 samples that the previous experiments used, in Section 4.</p><p>Each experiment will be carried out over the following temperatures: 0.0, 0.4, 0.7, 1.0, 1.3. Each of the temperatures aims to determine which temperature constitutes the best performance for AI C code APR. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimental Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Successful Verifications Per Attempt</head><p>Figure <ref type="figure" target="#fig_19">11</ref> illustrates the percentage of successful repairs at each attempt after the first, the total being the overall amount of samples repaired. The Forward History experiment performed best, followed by the LSO experiment and the Reverse History. The Forward History experiments had the most successful attempt at repairing the AI C code on the first try; from the 1st retry and onwards, the number of successful code repairs is significantly lowered. LSO had a similar number of 1st and 2nd attempt successful repairs of samples, dropping sharply on the 3rd attempt. This could be caused by the LLM changing the state of the line where the fault occurs too much by the 2nd attempt. Thus making it extremely unlikely that a correct solution will be found. Reverse History had the lowest performance and had no successful repairs by the 2nd retry.</p><p>(a) Latest State Only. (b) Forward History. (c) Reverse History. Optimal Attempts Takeaway. There is a sharp drop in successfully repairing a sample after the initial attempt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Successful Repairs Per Temperature</head><p>Figure <ref type="figure" target="#fig_21">12</ref> illustrates each experiment set's successful repairs per temperature. The main observation of each experiment is that temperature affects the number of successful repairs differently. Varying the temperature does not increase the repair performance for LSO. In contrast, the Forward History experiments have an inverse correlation between increasing the temperature and getting more repairs.</p><p>In other words, the lower temperature values, which make the LLM behave more deterministically, yield higher repair performance. Interestingly, the opposite is true for Reverse History. While the performance of Reverse History is the lowest of the three experiments, there is a direct correlation between the number of successful repairs and a higher temperature.</p><p>(a) Latest State Only. (b) Forward History. (c) Reverse History. Temperature Takeaway. A lower temperature yields a higher repair accuracy for AI C Code APR using LSO or Forward History. The reverse history shows no significantly better performance between any of the prompts; in general, it performs the worst of all the experiments. In all three experiments, the Old prompt failed to repair many prompts successfully; however, the reverse one was the most successful. Furthermore, we can observe the following if the new prompts are grouped into two types: modified and unmodified. The unmodified prompts have the highest amount of successful repairs in the Forward History experiments. However, the modified prompts perform better in the LSO experiments. In the end, the best prompts are, by far, prompt 9 and prompt 11 in the Forward History experiments. The most stable prompts are prompts 9-2 and 11-2, due to the added instructions, as they perform comparatively between the LSO and Forward History experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Successful Verifications Per Prompt</head><p>(a) Latest State Only. (b) Forward History.  Best Prompts Takeaway. The best prompts are prompt 9 and prompt 11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Lessons Learned</head><p>Iterative APR allows the LLM to make multiple attempts to fix a source file. As seen from the experiments, the best results of non-iterative APR were ∼18%, while the iterative approach explored in Section 5 increased the successful repairs to ∼25%. Throughout all the experiments conducted, the option to produce more repaired samples is to use a lower temperature, with 0.0 being the best for prompts 9 and 11. The best number of retries is 2, which means that the LLM has three attempts at resolving a single fault. The best type of history is the Forward History, where the LLM gains an advantage from past patches. LSO performed second best, but missing the history of repairs in the prompt leaves the LLM directionless in repairing the code. In summary, we can answer our research questions as follows:</p><p>1. Do large language models combined with formal verification increase automated program repair performance of AI C code when given multiple attempts to do so? LLMs with formal verification increase the automated program repair performance when given multiple attempts. The best number of attempts is 3 for prompts 9 and 11, as a successful repair becomes unlikely after the 2nd retry.</p><p>2. Does showing the history of patches to the LLM improve the performance of iterative APR? Yes, when comparing the number of successful repairs between the LSO experiments and the Forward History experiments, the latter has a much higher number of successful repairs.</p><p>3. What is the optimal way to show the history to the LLM? The best format to show the history is to display the oldest messages first and the last message being the latest. This has been observed when comparing Forward History and Reverse History.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>What is the optimal temperature to conduct APR of AI C Code? The optimal temperature to achieve the highest number of repaired samples is 0.0 for prompts 9 and 11 for Forward History. A higher temperature is necessary for less conventional prompts to allow the LLM to parse it correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>In this report, we expanded NeuroCodeBench to create a large dataset of memory-vulnerable AI C code using mutations. We used ESBMC to classify which samples contained memory vulnerabilities and which samples were secure.</p><p>In addition, we used GPT-3.5-Turbo and various prompt engineering techniques to explore how well an LLM could repair the mutated code. In the process, we discovered that a long persona prompt with the role Automated Code Repair Tool is the most optimized at repairing AI C Code. Furthermore, we proposed methods for extracting the faulty source code from the large volume of AI C code to circumvent the issues that arise due to LLMs' relatively small context window.</p><p>Lastly, we used ESBMC-AI to test how the iterative APR process improves repair performance. We have showed that the iterative repair process provides a substantial increase of 7% in repair performance. We also found that after attempt 3 the chances of successfully repairing a sample decrease significantly by 23%.</p><p>In the future, we plan to conduct more experiments using a diverse set of LLMs to discover whether our findings generalize beyond GPT-3.5-Turbo. In this respect, open-source LLMs would benefit our research, as they can be fine-tuned for program repair. experiments and understand the true impact that backticks have on the performance of prompts. The results are going to be explored for the remainder of this section.</p><p>C/C++ Detector Results Figure <ref type="figure" target="#fig_26">14</ref> illustrates the distribution of probability scores of the LLM output that the C/C++ detector assigned for each prompt, as described in Figure <ref type="figure" target="#fig_10">6</ref>. In each prompt shown in Figure <ref type="figure" target="#fig_26">14a</ref>, the main differences observed are that the experiments without backticks perform overall worse, aside from the simple prompts that did not display a noticeable difference. The old prompt contains a higher median value without backticks. And, the results for the persona prompts show a reduced confidence of the C/C++ detector, as observed by the Q1 and Q3 being lower, the median value was higher overall.</p><p>Figure <ref type="figure" target="#fig_26">14b</ref> shows the detection results when the verifier is excluded from the prompt, along with the results for when the verifier is included before and after the source code. The syntax detector assigned the contextual experiments with no verifier output in the prompt less confidence in it being valid C/C++ source code, as can be observed by a lower Q1 and median score. When verifier output is included, the experiments with no backticks perform slightly better than the experiments with backticks. The results, for verifier output before the source code, exhibit a higher Q3. The results for verifier output after the source code exhibit a slightly higher median and Q3. The results for the contextual experiments signify the need to clearly mark the boundaries of code and raw output with Markdown syntax code blocks, as it shows that the LLM could output more consistent C/C++ code as evidenced by the detector confidence results.</p><p>The experiments that were conducted using one line source code prompts show no major difference in results for each of the prompts. The results for the verifier output show a slightly higher max value for the experiments that include verifier output. This can be explained as experimental noise, as the difference is not significant enough.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance Results</head><p>The measurements that show how similar the proposed patches by the LLM were for the experiments without backticks can be observed in Figure <ref type="figure" target="#fig_28">15</ref>. As stated in the experiments with backticks, it is expected that the LLM outputs the code verbatim, aside from the single line of code to be patched. Figure <ref type="figure" target="#fig_28">15a</ref> illustrates a similarity box plot with the original code for each prompt. For the contextual experiments, the backtick-less match to the original prompt less in every prompt, as the max match values and Q3 values, and median values assigned in each prompt is lower for the backtick-less experiments. The results for one line mirror the results for contextual, aside from the fact that the overall difference is much more noticeable, and that some prompts have a higher max match value for backtick-less experiments.</p><p>Figure <ref type="figure" target="#fig_28">15b</ref> illustrates a box plot of how the results match the original for each type of verifier output experiment. As is observed, the performance seems lower in every metric. Contextual results have lower first<ref type="foot" target="#foot_4">foot_4</ref> quartiles, along with a lower median. For the verifier output experiments where no verifier output is included, there is a significantly less Q3 matching to the original prompt. For the one line experiments, experiments where no verifier output is included, and experiments where the verifier output is placed before source code, the max value of those experiments is higher for both, however, every other metric minimum value and Q1-3 are all lower.  Relevance Takeaway. The LLM outputs code that more closely matches the original input when the backticks are included in the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compilation Results</head><p>The experiments conducted to find out the difference in the amount of samples that successfully compile, as the LLM produces valid C code as its output without Markdown backticks, is shown in Table <ref type="table">4</ref>. The results for the contextual experiments are the exact same as with the Markdown backtick experiments, shown in Table <ref type="table" target="#tab_3">2</ref>. For the one line experiments, the experiments with backticks seem to perform worse, the prompts and the verifier output sections of the table both have a higher number of samples that successfully compile for the experiments that exclude the backticks from the prompts. old simple pers-0 pers-1 pers-2 pers-3 pers-4 pers-5 none before after contextual 1.50% 1.25% 0.25% 0% 1.58%</p><p>2.16% 1.16% 1.25% 0.14% 1.32% 1.82% one line 42.5% 19.91% 62.7% 71.5% 36.7% 57.5% 32.25% 58.5% 59.9% 42.1% 43.3%</p><p>Table 4: Percentage of repair patches that make the code compile. Asking the LLM to repair only one line of code yields patches that compile more consistently. Much like with Markdown backticks.</p><p>Compilation Takeaway. With large samples of code, as seen in the contextual experiments, the LLM does not exhibit an increase in compilable code output, the amount is the exact same as with backticks. For smaller samples, compilable code is produced more often when backticks are excluded.</p><p>Verifying the Code Results Table <ref type="table">5</ref> shows the verification success rate of each prompt and verifier feedback. For the contextual experiments, the results shown reflect the same pattern where the percentage of samples that successfully compiled is exactly the same as Tables <ref type="table" target="#tab_3">2</ref>, <ref type="table">3</ref>, and 4. This implies that when the contextual experiments compile, they will also have a successful verification.</p><p>For one line backtick-less experiments, the amount of samples that have been verified successfully is lower in all the metrics. old simple pers-0 pers-1 pers-2 pers-3 pers-4 pers-5 none before after contextual 1.50% 1.25% 0.25% 0% 1.58% 2.16% 1.16% 1.25% 0.14% 1.32% 1.82% one line 0.00% 4.16% 5.00% 5.83% 4.25% 6.50% 9.25% 7.00% 5.21% 7.67% 5.10%</p><p>Table <ref type="table">5</ref>: Percentage of repair patches that are successfully verified. All the patches that compile (see Table <ref type="table" target="#tab_3">2</ref>) are also successfully verified when using the contextual strategy.</p><p>Verification Takeaway. With large samples of code input, the code will compile and verify the same regardless of if code is surrounded in backticks or not. For smaller samples, the successful verification of code is slightly higher when backticks are included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Iterative Repair Experiment Details B.1 Successful Verifications By Prompt Per Temperature</head><p>The following figures are conducted over a range of temperatures, in order to further understand how the number of repairs are affected. Figures 16 to 20 shows the successful verifications by prompt for temperatures 0.0, 0.4, 0.7, 1.0, and 1.3 respectively. The general pattern that can be observed, is that as the temperature is increased, the LSO and Forward History performance increases, while the opposite is true for Reverse History. For LSO, prompts 9-2, 11 and 11-2 perform the best, as temperature increases, so does the number of successful repairs. Prompts 9 and Old do not manage to repair any samples. The only exception is that in temperature 1.3, prompt 9 performed as well as prompt 11, however, still lower than prompts 9-2 and 11-2. The best Forward History prompts are prompt 9 and prompt 11, they have the same number of successful repairs in temperature 0.0, which is the highest. Prompt 9 is only surpassed by the other prompts in Figures <ref type="figure" target="#fig_34">18</ref> and <ref type="figure" target="#fig_36">19</ref>. Aside from that, prompt 9 and 11 are the best performing prompts. Prompts 9 and 11 solve the exact same samples, however, the patches produced are different.</p><p>As seen in the previous experiments, the Reverse History experiments score the lowest in successfully repairing AI C code. In Figure <ref type="figure" target="#fig_30">16</ref>, Reverse History was unable to repair any samples. The reason for this is probably due to the indirect nature of displaying the history in reverse order, making the LLM perform worse as the instructions are not as clear for instruct models.</p><p>(a) Latest State Only. (b) Forward History. (a) Latest State Only. (b) Forward History. (c) Reverse History. (a) Latest State Only. (b) Forward History. (c) Reverse History. (a) Latest State Only. (b) Forward History. (c) Reverse History. (a) Latest State Only. (b) Forward History. (c) Reverse History.  (a) Latest State Only. (b) Forward History. (a) Latest State Only. (b) Forward History. (c) Reverse History. (a) Latest State Only. (b) Forward History. (c) Reverse History. (a) Latest State Only. (b) Forward History. (c) Reverse History.   At this stage, it is obvious that the best performing configuration for repairing AI C code is using temperature 0.0, and Forward History. Figures 26 to 29 show the percentage of successful repairs at each attempt for each prompt. As seen from the previous figures, the Reverse History and LSO experiments did not have any successful repairs for the prompt 9, so there is no figure shown for those experiments. Also, the old ESBMC-AI prompt did not successfully repair a single sample for temperature 0.0, so it is not shown either. The remaining bar graphs for the LSO experiments show that the most successful repairs occurred in prompt 9-2 and prompt 11-2, where the same amount of samples were repaired in the first two attempts.</p><p>For the Forward History experiments, prompt 9 has the highest performance, showing that samples were repaired in the first 3 attempts, after attempt 2, no further samples were repaired. Prompt 9-2 had a much lower number of successful repairs per attempt, however, there were some successful repairs on attempt 3. Prompt 11 had no successful repairs of samples during any retries, and only repaired samples successfully on the first attempt.</p><p>(a) Forward History.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A diagram visualization of how bounded model checking works. The visualization represents a state transition system M , a given property ϕ, and a verification condition ψ [15].</figDesc><graphic coords="6,168.04,106.36,259.20,65.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of the NeuroCodeBench expansion pipeline. It consists of three key stages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>Verification time for a small subset of safe and unsafe programs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance of ESBMC on 25952/81129 mutated programs, by neural network category.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Flowchart of a single attempt at repairing AI C Code with the LLM.</figDesc><graphic coords="8,124.84,106.36,345.61,115.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Listing 3 :</head><label>3</label><figDesc>Simple Prompt Template with ESBMC Output after Source CodeThe following source code contains a memory vulnerability {source} The following is the output of ESBMC describing the vulnerability {esbmc}. Fix the source code. Fix the source code: {source} {esbmc} Listing 4: Simple Prompt Template with ESBMC Output before Source Code ESBMC output describes a memory vulnerability in the source code; the following is ESBMC output: {esbmc} The following is the vulnerable source code: {source} Fix the source code.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><figDesc>1. Programmer with 1 million years of experience; 2. Senior software engineer; 3. Automated code repair tool; 4. Artificial intelligence that specializes in repairing C programs; 5. The smartest human in the universe; 6. Dog.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Listing 5 :</head><label>5</label><figDesc>Persona Prompt Template no ESBMC OutputYou're a {role}. You'll be shown some C code. Repair the code and display it. The code is {source} From now on, act as an {role} that repairs AI C code. You will be shown AI C code. Provide the repaired C code as output, as would an {role}. Aside from the corrected source code, do not output any other text. The code is {source} Listing 6: Persona Prompt Template with ESBMC Output after Source Code You're a {role}. You'll be shown some C code, along with ESBMC output. Repair the code and display it. The code is {source} The ESBMC output is {esbmc} From now on, act as an {role} that repairs AI C code. You will be shown AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains a stack trace along with the type of error that occurred and its location. Provide the repaired C code as output, as would an {role}. Aside from the corrected source code, do not output any other text. The code is {source} The ESBMC output is {esbmc} Listing 7: Persona Prompt Template with ESBMC Output before Source Code You're a {role}. You'll be shown some C code, along with ESBMC output. Repair the code and display it. The ESBMC output is {esbmc} The source code is {source}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><figDesc>(2 simple + 2 persona * 6 role) * 2 source • With Verifier Feedback. (1 old + 4 simple + 4 persona * 6 role) * 2 feedback * 2 source for a total of (2 + 2 * 6) * 2 + (1 + 4 + 4 * 6) * 2 * 2 = 144 prompts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>The</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Distribution of probability scores from the C/C++ detector used in Visual Studio on the LLM repair patches. Persona prompts cause the LLM to produce C/C++ code more consistently.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7:  String match between source code in the prompt and LLM output patch (ignoring whitespaces). When using the contextual strategy, the LLM tends to omit large swathes of the original code.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Prompt comparison for the best prompts. The Contextual Figure presents results greater than or equal to 3. The Single Line Figure presents results greater than or equal to 10.</figDesc><graphic coords="15,81.64,106.36,194.40,155.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>2 From</head><label>2</label><figDesc>Template 9-2 and Prompt Template 11now on, act as an {role} that repairs AI C code. You will be shown a line of AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains what type of error has occurred and its location. Provide the repaired C code as output, as would an {role}. Aside from the corrected line of source code, do not output any other text. The code is {source code} The ESBMC output is {esbmc output} Guideline: Always prefer to repair using a single line of C code, unless necessary. Guideline: Read the error in the ESBMC output and try to repair the fault. From now on, act as an {role} that repairs AI C code. You will be shown a line of AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains what type of error has occurred and its location. Provide the repaired C code as output, as would an {role}. Aside from the corrected line of source code, do not output any other text. The ESBMC output is {esbmc output} The source code is {source code} Guideline: Always prefer to repair using a single line of C code, unless necessary. Guideline: Read the error in the ESBMC output and try to repair the fault.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>4 .</head><label>4</label><figDesc>What is the optimal temperature to conduct APR of AI C Code? Section 5.1 will describe the implementation details of the experiments. Section 5.2 will describe the experimental setup used to conduct the experiments. Section 5.3 will analyze and interpret the results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Diagram of the iterative repair algorithm of ESBMC-AI.</figDesc><graphic coords="17,135.64,242.44,323.99,204.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: The 3 message history formats used in the experiments visualized.</figDesc><graphic coords="20,178.84,106.35,237.60,242.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Successful verifications by attempt.</figDesc><graphic coords="21,81.64,106.36,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Successful verifications by temperature.</figDesc><graphic coords="21,81.64,475.34,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 13</head><label>13</label><figDesc>Figure13illustrates the percentage of successful repairs per prompt for the three experiments. These percentages represent the entire range of temperatures. The LSO experiments show prompts 11 and 11-2 performing the best, possibly due to the added context of the prompt. As the LSO experiments do not contain historical patches, they help repair performance by providing additional instruction. Interestingly, the Forward History experiment shows the opposite; prompts 9 and 11 perform best. Prompts 9 and 11 were the best in Section 4 experiments. The reverse history shows no significantly better performance between any of the prompts; in general, it performs the worst of all the experiments. In all three experiments, the Old prompt failed to repair many prompts successfully; however, the reverse one was the most successful.Furthermore, we can observe the following if the new prompts are grouped into two types: modified and unmodified. The unmodified prompts have the highest amount of successful repairs in the Forward History experiments. However, the modified prompts perform better in the LSO experiments. In the end, the best prompts are, by far, prompt 9 and prompt 11 in the Forward History experiments. The most stable prompts are prompts 9-2 and 11-2, due to the added instructions, as they perform comparatively between the LSO and Forward History experiments.</figDesc><graphic coords="22,81.64,369.97,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><figDesc>(a) Latest State Only. (b) Forward History. (c) Reverse History.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Successful verifications by prompt.</figDesc><graphic coords="22,228.52,369.97,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><figDesc>Syntax Takeaway. Including verifier output causes the LLM to output more accurate C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Distribution of probability scores from the C/C++ detector used in Visual Studio on the LLM backtick-less repair patches. It exhibits a lower first quartile than the results with backticks included in the prompt, as illustrated in Figure 6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15:  String match between source code in the prompt and LLM output patch (ignoring whitespaces). This figure is the equivalent of Figure7for the backtick-less experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Successful verifications by prompt for temperature 0.0. Reverse History is not included as it did not yield any successful verifications.</figDesc><graphic coords="30,81.64,320.32,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><figDesc>(a) Latest State Only. (b) Forward History. (c) Reverse History.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Successful verifications by prompt for temperature 0.4.</figDesc><graphic coords="30,228.52,320.32,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Successful verifications by prompt for temperature 0.7.</figDesc><graphic coords="31,81.64,305.81,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_36"><head>Figure 19 :</head><label>19</label><figDesc>Figure 19: Successful verifications by prompt for temperature 1.0.</figDesc><graphic coords="31,81.64,505.26,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_38"><head>Figure 20 :</head><label>20</label><figDesc>Figure 20: Successful verifications by prompt for temperature 1.3.</figDesc><graphic coords="31,228.52,505.26,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_39"><head>Figures 21 to 25</head><label>25</label><figDesc>Figures 21 to<ref type="bibr" target="#b23">25</ref> show the next set of experiments, they are to find out the successful verifications by attempt for each temperature tested. For the LSO experiments, as the temperature is increased from 0, the number of successful repairs at each attempt does not change much. The only exception is temperature 1.0, where the performance is significantly lower for attempts 0 and 1. Furthermore, the Forward History experiments only decrease in successful repairs on the attempt 0, as the temperature is increased. The other attempts are largely unaffected. The only exception to this is on temperature 0.4, however, this fluctuation can be considered as experimental noise. The Reverse History experiments had only a couple of successful repairs in attempt 0 on temperature 0.7 and higher. All other attempts after the 2nd attempt yield 0 successful repairs.</figDesc><graphic coords="32,297.64,312.19,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_41"><head>Figure 21 :</head><label>21</label><figDesc>Figure 21: Successful verifications by attempt for temperature 0.0.</figDesc><graphic coords="32,156.07,312.19,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_43"><head>Figure 22 :</head><label>22</label><figDesc>Figure 22: Successful verifications by attempt for temperature 0.4.</figDesc><graphic coords="33,81.64,305.81,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_45"><head>Figure 23 :</head><label>23</label><figDesc>Figure 23: Successful verifications by attempt for temperature 0.7.</figDesc><graphic coords="33,81.64,505.26,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_47"><head>Figure 24 :</head><label>24</label><figDesc>Figure 24: Successful verifications by attempt for temperature 1.0.</figDesc><graphic coords="33,228.52,505.26,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_49"><head>Figure 25 :</head><label>25</label><figDesc>Figure 25: Successful verifications by attempt for temperature 1.3.</figDesc><graphic coords="34,81.64,106.36,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_51"><head>Figure 26 :</head><label>26</label><figDesc>Figure 26: Successful verifications by attempt for prompt 9 (temperature 0.0).</figDesc><graphic coords="35,156.07,305.81,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_52"><figDesc>(a) Latest State Only. (b) Forward History.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_53"><head>Figure 27 :</head><label>27</label><figDesc>Figure 27: Successful verifications by attempt for prompt 9-2 (temperature 0.0).</figDesc><graphic coords="35,156.07,505.26,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_55"><head>Figure 28 :</head><label>28</label><figDesc>Figure 28: Successful verifications by attempt for prompt 11 (temperature 0.0).</figDesc><graphic coords="35,297.64,505.26,138.24,138.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="5,189.64,106.36,216.00,302.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Percentage of repair patches that make the code compile. Asking the LLM to repair only one line of code yields patches that compile more consistently.</figDesc><table><row><cell></cell><cell>old</cell><cell cols="2">simple pers-0 pers-1 pers-2 pers-3 pers-4 pers-5 none before after</cell></row><row><cell cols="3">contextual 1.50% 1.25% 0.25%</cell><cell>0%</cell><cell>1.58% 2.16% 1.16% 1.25% 0.14% 1.32% 1.82%</cell></row><row><cell>one line</cell><cell cols="3">0.00% 4.25% 5.50% 5.83% 6.75% 8.25% 10.3% 10.5% 5.32% 9.57% 7.10%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://gitlab.com/sosy-lab/benchmarking/sv-benchmarks/-/merge_requests/1456</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Note that the expanded sample dataset may contain some duplicates after the assert declarations are removed.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://github.com/yoeo/guesslang</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Incidentally, non Persona prompts are always index 0 for role.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>On plots where the first quartile is not zero.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Testing Backtick Performance Effectiveness</head><p>The annotation of source code using Markdown code block syntax has always been an implicit feature in ChatGPT and LLMs <ref type="bibr">[1]</ref>. It is widely accepted that code should be surrounded by ``t o mark where it begins and ends. In Section 4, the single iteration experiments provided an understanding of how effective LLMs are at repairing AI C code vulnerabilities. To understand the effectiveness of backticks in the source code provided, the experiments will be executed again, with the only difference being the exclusion of backticks in the prompt. The goal of these experiments is to influence future prompt engineering design. If the results of the prompts without backticks are better than with backticks, then this could mean excluding them would yield better APR accuracy in future experiments, such as those conducted in Section 5.</p><p>Each of the aforementioned prompts in Section 4.1 has been modified to exclude the Markdown backticks. This is done in order to be able to directly compare the performance with the previous  Takeaway. For AI C code one line repair, the optimal total number of attempts is 3.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Information capacity of the hopfield model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Abu-Mostafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName><surname>Jacques</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Foundation</surname></persName>
		</author>
		<author>
			<persName><surname>Pytorch</surname></persName>
		</author>
		<ptr target="https://pytorch.org/" />
		<imprint>
			<date type="published" when="2023-08-31">2023. 31 August 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pitfalls in machine learning research: Reexamining the development cycle</title>
		<author>
			<persName><forename type="first">S</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Scheirer</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings on &quot;I Can&apos;t Believe It&apos;s Not Better!&quot; at NeurIPS Workshops</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Zosa Forde</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Ruiz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Pradier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Schein</surname></persName>
		</editor>
		<meeting>on &quot;I Can&apos;t Believe It&apos;s Not Better!&quot; at NeurIPS Workshops</meeting>
		<imprint>
			<date type="published" when="2020-12-12">12 Dec 2020</date>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="106" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">G</forename><surname>Brain</surname></persName>
		</author>
		<author>
			<persName><surname>Tensorflow</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org" />
		<imprint>
			<date type="published" when="2023-08-31">2023. 31 August 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Brix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Johnson</surname></persName>
		</author>
		<title level="m">The Fourth International Verification of Neural Networks Competition (VNN-COMP 2023): Summary and Results</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Charalambous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tihanyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ferrag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Cordeiro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14752</idno>
		<title level="m">A new era in software security: Towards self-healing software via large language models and formal verification</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bipartite expander hopfield networks as self-decoding high-capacity error correcting codes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fiete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">How is chatgpt&apos;s behavior changing over time</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09009</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Community</surname></persName>
		</author>
		<ptr target="https://cwe.mitre.org/top25/archive/2023/2023_top25_list.html" />
		<title level="m">cwe top 25 most dangerous software weaknesses</title>
		<imprint>
			<date type="published" when="2023-08-25">2023. 2023. 25 August 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Open neural network exchange: The open standard for machine learning interoperability</title>
		<author>
			<persName><forename type="first">O</forename><surname>Community</surname></persName>
		</author>
		<ptr target="https://onnx.ai/" />
		<imprint>
			<date type="published" when="2023-08-31">2023. 31 August 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">keras2c github repository</title>
		<author>
			<persName><forename type="first">R</forename><surname>Conlin</surname></persName>
		</author>
		<idno>Ac- cessed: 25</idno>
		<ptr target="https://github.com/f0uriest/keras2c" />
		<imprint>
			<date type="published" when="2023-08">2023. August 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Keras2c: A library for converting keras neural networks to real-time compatible c</title>
		<author>
			<persName><forename type="first">R</forename><surname>Conlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Erickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Abbate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kolemen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page">104182</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Software security</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cordeiro</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">SMT-Based Bounded Model Checking for Embedded ANSI-C Software</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cordeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marques-Silva</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0907.2072</idno>
		<imprint>
			<date type="published" when="2009-07">July 2009</date>
		</imprint>
	</monogr>
	<note>cs</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Model checking of real-time reachability properties using abstractions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Daws</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tripakis</surname></persName>
		</author>
		<editor>B. Steffen</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="313" to="329" />
			<pubPlace>Berlin, Heidelberg; Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>Tools and Algorithms for the Construction and Analysis of Systems</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Differential testing of cross deep learning framework APIs: Revealing inconsistencies and vulnerabilities</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd USENIX Security Symposium (USENIX Security 23)</title>
		<meeting><address><addrLine>Anaheim, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2023-08">Aug. 2023</date>
			<biblScope unit="page" from="7393" to="7410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mull it over: Mutation testing based on llvm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Denisov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pankevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)</title>
		<imprint>
			<date type="published" when="2018-04">April 2018</date>
			<biblScope unit="page" from="25" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automated repair of programs from large language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roychoudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1469" to="1481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploring the limits of out-of-distribution detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="7068" to="7081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Audee: Automated testing for deep learning frameworks</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering, ASE &apos;20</title>
		<meeting>the 35th IEEE/ACM International Conference on Automated Software Engineering, ASE &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="486" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability</title>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kroening</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Thamo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science Review</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">100270</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Taxonomy of real faults in deep learning systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Humbatova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jahangirova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bavota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Riccio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stocco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tonella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, ICSE &apos;20</title>
		<meeting>the ACM/IEEE 42nd International Conference on Software Engineering, ICSE &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1110" to="1121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<title level="m">Neural code completion</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">NeuroCodeBench: a Plain C Neural Network Benchmark for Software Verification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Manino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shmarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Cordeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Automated Formal Reasoning for Trustworthy AI Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep learning-based wave digital modeling of rate-dependent hysteretic nonlinearities for virtual analog applications</title>
		<author>
			<persName><forename type="first">O</forename><surname>Massi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Mezza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Audio, Speech, and Music Processing</title>
		<imprint>
			<biblScope unit="volume">2023</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2023-03">Mar 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning density distribution of reachable states for autonomous systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T B</forename><surname>Waez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Conference on Robot Learning</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Faust</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Hsu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Neumann</surname></persName>
		</editor>
		<meeting>the 5th Conference on Robot Learning</meeting>
		<imprint>
			<date type="published" when="2022-11">Nov 2022</date>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="page" from="8" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Trends and challenges in the vulnerability mitigation landscape</title>
		<author>
			<persName><forename type="first">M</forename><surname>Miller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>USENIX Association</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Bugs in machine learning-based systems: a faultload benchmark</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Morovati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nikanjam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Khomh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">62</biblScope>
			<date type="published" when="2023-04">Apr 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Johnson</surname></persName>
		</author>
		<title level="m">The third international verification of neural networks competition (vnn-comp 2022): Summary and results</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Simple black-box adversarial attacks on deep neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Narodytska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kasiviswanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">TensorFuzz: Debugging neural networks with coverage-guided fuzzing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</editor>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI Blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Safe reinforcement learning benchmark environments for aerospace control systems</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">J</forename><surname>Ravaioli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mccarroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gangal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dunlap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Hobbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE Aerospace Conference</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A framework for understanding sources of harm throughout the machine learning life cycle</title>
		<author>
			<persName><forename type="first">H</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Equity and Access in Algorithms, Mechanisms, and Optimization, EAAMO &apos;21</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">onnx2c github repository</title>
		<author>
			<persName><forename type="first">K</forename><surname>User</surname></persName>
		</author>
		<ptr target="https://github.com/kraiskil/onnx2c" />
		<imprint>
			<date type="published" when="2023-08-25">2023. 25 August 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elnashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Spencer-Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.11382</idno>
		<title level="m">A prompt pattern catalog to enhance prompt engineering with chatgpt</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Neural-based dynamic modeling of nonlinear microwave circuits</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yagoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Microwave Theory and Techniques</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2769" to="2780" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

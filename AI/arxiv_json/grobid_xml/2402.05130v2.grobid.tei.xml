<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LB-KBQA:Large-language-model and BERT based Knowledge-Based Question and Answering System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Yan</forename><surname>Zhao</surname></persName>
							<email>gzxzhaoyan@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Zhongyun</forename><surname>Li</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">dept. School of Advanced Technology XJTLU</orgName>
								<orgName type="institution">University of Liverpool Liverpool</orgName>
								<address>
									<settlement>Suzhou Suzhou</settlement>
									<country>China UK China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">th Jiaxing</orgName>
								<orgName type="institution">Wang University of Liverpool Liverpool</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">dept. School of Advanced Technology XJTLU</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LB-KBQA:Large-language-model and BERT based Knowledge-Based Question and Answering System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">510AE01BE6A8B170ED0FDF111AE61203</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Generative AI</term>
					<term>KBQA</term>
					<term>LLM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Generative Artificial Intelligence (AI), because of its emergent abilities, has empowered various fields, one typical of which is large language models (LLMs). One of the typical application fields of Generative AI is large language models (LLMs), and the natural language understanding capability of LLM is dramatically improved when compared with conventional AIbased methods. The natural language understanding capability has always been a barrier to the intent recognition performance of the Knowledge-Based-Question-and-Answer (KBQA) system, which arises from linguistic diversity and the newly appeared intent. Conventional AI-based methods for intent recognition can be divided into semantic parsing-based and model-based approaches. However, both of the methods suffer from limited resources in intent recognition. To address this issue, we propose a novel KBQA system based on a Large Language Model(LLM) and BERT (LB-KBQA). With the help of generative AI, our proposed method could detect newly appeared intent and acquire new knowledge. In experiments on financial domain question answering, our model has demonstrated superior effectiveness.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Recently, Generative Artificial Intelligence (AI) has gained much attention from both academia and industry as the emergent abilities of generative AI have great potential to empower various fields. Generative AI covers a wide range of applications, the most typical of which is large language models (LLMs) <ref type="bibr" target="#b0">[1]</ref>. A famous example is the GPT series <ref type="bibr" target="#b1">[2]</ref>, which has made noteworthy advancements in this domain <ref type="bibr" target="#b2">[3]</ref>. The GPT series models represent typical examples of large-scale language models. Scholars have observed that as the parameter count of GPT language models grows, their natural language understanding capabilities become increasingly powerful. For instance, GPT-3 boasts 170 billion parameters <ref type="bibr" target="#b3">[4]</ref>. This natural language understanding capability holds significant promise in both business and society and offers considerable potential in various domains <ref type="bibr" target="#b4">[5]</ref>.</p><p>The ability of natural language understanding is the most limiting factor in the field of question-answering (QA) sys-tems. The QA systems are utilized in open-world scenarios, which often result in issues of questions and answers (QA) mismatching problems due to linguistic diversity <ref type="bibr" target="#b5">[6]</ref>. The open-world scenario for the QA system usually means the training set is typically unable to encompass all possible user question inputs. The different expressions of the questions from users and the linguistic diversity usually lead to an unseen class problem <ref type="bibr" target="#b6">[7]</ref>, and this problem will further cause the QA mismatching problem and undermine the QA matching accuracy. Specifically, the negative impact caused by the unseen classes will be a disaster in the field of QA tasks with a fixed knowledge base, so-called Knowledge-based Question and Answer (KBQA) <ref type="bibr" target="#b7">[8]</ref>, as the mismatching problems will not just hurt the accuracy but might directly lead to the task failure.</p><p>With the rapid development of large-scale knowledge bases, the open-domain Knowledge-based Question and Answer (KBQA) has emerged. KBQA system is to understand natural language questions and answers based on external knowledge <ref type="bibr" target="#b8">[9]</ref>. The field of KBQA has gained significant attention from both academia and industry in recent years. The open-source knowledge bases have enabled KBQAs to provide accurate answers across various domains. For example, the broad knowledge graph called Knowledge Vault (KV) <ref type="bibr" target="#b9">[10]</ref> was integrated into Google's search engine for practical purposes and resulted in significant improvement in the user experience of the search engines. The basic idea of the KBQA is to find a mapping from the natural language question of users to the answers in the knowledge base. Additionally, the first step of the KBQA is to understand the question from the semantic level, and the questions are usually mapped to the intent of the users. The intents can be considered as fixed classes, and in essence, the intent recognition task will encounter the problem of unseen classes, or to be more precise, the unseen intents. Therefore, the problem of the unseen intents will directly cause the failure of the KBQA system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2402.05130v2 [cs.CL] 9 Feb 2024</head><p>This mapping is a difficult task in that it might introduce errors from linguistic diversity as there might be various ways to describe the same subject. Optimizing these systems requires correctly analyzing human language and providing appropriate responses. For the user intent natural language understanding (NLU), the intent recognition of KBQA can be divided into two technical paths: 1) the rule-based method and 2) the model-based method. Recently, semantic parsing has been one of the rule-based methods and has been the mainstream method in question-and-answer systems <ref type="bibr" target="#b10">[11]</ref>. However, the rule-based method ignores high-dimensional semantic information and struggles to handle complex queries that involve multiple entities. Additionally, the model-based method can capture the semantic information by the conventional AI (e.g., BB KBQA <ref type="bibr" target="#b11">[12]</ref>). Still, model-based approaches frequently encounter two challenges: firstly, they often struggle to provide precise answers for language data beyond the pre-training dataset; secondly, the expense of models acquiring new knowledge is comparatively high.</p><p>In this case, the Intent Recognition Task might suffer from severe failure caused by unseen intents at the very beginning. The unseen intents are very common in the application field of KBQA and can be considered into two categories, 1) unseen intents caused by linguistic diversity (e.g., different question representations of the same intent), and 2) the intents that have never been considered by the knowledge base.</p><p>To tackle the limitation of the unseen intents, we creatively introduce the large language model. Recently, the development of large-scale language models has represented a significant breakthrough in natural language processing <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b12">[13]</ref>. These models are artificial intelligence systems designed to generate text that is highly similar to human-generated text. They achieve this by processing vast quantities of textual data, enabling them to identify and learn various linguistic patterns and habits exhibited by users <ref type="bibr" target="#b13">[14]</ref>. Moreover, large language models can quickly acquire new knowledge through prompt learning, making them highly adaptable and capable of improving their performance in response to user input and exposure to novel information <ref type="bibr" target="#b12">[13]</ref>. The impressive performance of large language models has the potential to address the unseen intents problem.</p><p>To solve the problem of the unseen intents in the field of KBQA, we introduced our system named LB-KBQA, which could tackle intentions misunderstanding issues. Our knowledge base consists of two main components: an intent library that utilizes vector representation and a query library that utilizes the knowledge graph. The system is composed of five main parts, each with its specific function. Firstly, the language preprocessing module removes irrelevant symbols from the input text. The intention recognition module, which is the second part, comprises a rule-based intention recognition model, a high-dimensional semantic representation module based on BERT, and an unseen intents processing module based on pre-trained language models. By fusing these three models, the system effectively addresses the challenge of intention recognition failure caused by language diversity, which is explained in detail in the system design section. The third part is the answer generation module, in which the user's question and the matched answer are sent to LLM (large language models), and more readable answers are generated through prompt learning. To overcome the issue of intention recognition failure stemming from limitations of the knowledge base, we developed an adaptive learning module as the fourth part. The module gradually obtains the user's true intention through interaction between LLM and the user and updates it to the intent library. Finally, we designed a query library extension module to facilitate batch updates of the knowledge graph for users.</p><p>The contribution can be summarized as follows.</p><p>• The proposed method identifies the unseen intent for a specific-domain KBQA system. The unseen intents are divided into two parts, the diverse representation of intents and the newly appeared intents, and both of the unseen intents can be captured by the proposed method. • We provide a solution for building a KBQA system in the financial domain based on Generative AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. SYSTEM DESIGN</head><p>Figure <ref type="figure">1</ref> illustrates the system design, which comprises five main parts: 1) the language preprocessing module, 2) the intent recognition module, 3) the response generation module, 4) the adaptive learning module, and 5) the query library extension module. In this section, we will provide details about each of these components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Language Preprocessing Module</head><p>The language preprocessing module is responsible for removing stop words, punctuation, and special symbols from the input text <ref type="bibr" target="#b14">[15]</ref>. This process improves search efficiency and accuracy, as stop words and special symbols such as emojis do not provide any meaningful information. For example, words like "the," "is," and "in" are removed in English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Intent Recognition Module</head><p>The intent recognition module identifies the key entities in the input request. For example, if the request is related to time, the module selects key entities such as "year," "month," and "day." Accurate intent recognition is critical for providing accurate answers in a KBQA system.</p><p>Figure <ref type="figure">1</ref> shows the details of the intent recognition process. Firstly, the clean text will be compared with the question rule, which is a domain-specific semantic analysis model containing semantic rules. The rules are used to match the text with the intent label. The rule-based model has the advantage of being fast and scenario-oriented, but it cannot handle queries with complex semantics. If the rule-based model fails to make a prediction, the query is passed to the question embedding component, which extracts high-dimensional semantic information using the BERT model. The input query is converted to a context vector for further similarity calculation. Our implementation uses a similarity question vector base to store the questions in tuple type, which includes the intent label Fig. <ref type="figure">1</ref>. The LB-KBQA system is comprised of five distinct components: 1) the language preprocessing module, 2) the intent recognition module, 3) the response generation module, 4) the adaptive learning module, and 5) the query library extension module. and context vector. The cosine similarity method is used to measure the similarity between the context vector and the corresponding vector. The intention label that refers to the corresponding vector which is most similar will be selected <ref type="bibr" target="#b15">[16]</ref>.</p><p>However, utilizing the BERT model for question embedding may not entirely correspond to the diverse nature of natural language, as it cannot account for the potential variability in questioning habits and speaking styles. This variability in language usage may result in semantic errors in question embedding, which can subsequently impact the vector representation. In order to address this issue, a large language model is employed as a fallback approach. Initially, a threshold for cosine similarity is established. If the question vector represented by BERT is not deemed similar enough to any of the vectors in the Similarity Question Vector Base, as determined by this threshold, then the large model is implemented for intent determination. In the intent generation process, an incontext learning method is applied for prompt learning. The logical reasoning process for intent determination is regarded as input for the large model, along with the user's query. Consequently, the large model can generate user intent based on the user's input. Meanwhile, the generated intent labels will be subsequently updated in the intent library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Response Generation Module</head><p>The target of the Response Generation Module is to provide a readable answer according to user intents. It has three steps. First, the Jieba package is used to perform named entity recognition (NER) tasks. Then, the selected entities are converted into a query statement. As the knowledge graph is built using neo4j, the query language cipher is used to query the graph. The query statement includes a symbol, "XX," which is replaced with real entities. Finally, we prompt the Large Language Model with user query and matched knowledge to generate a readable answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Adopted Learning Module</head><p>The purpose of the Adaptive Learning Module is to enhance the understanding capability of unknown intents for the question-answering system. As illustrated in Figure <ref type="figure">1</ref>, the working mechanism of this module is as follows: if the user expresses dissatisfaction with the answer provided by the Knowledge-Based Question Answering system, the large language model will engage in a multi-turn dialogue with the user, based on preset prompts, to confirm 1) whether the user's dissatisfaction is due to intent recognition issues, and 2) what the user believes the correct intent is. Once the user provides the correct intent, the intent label is updated together with the question vector in the Similarity Question Vector Base. It should be noted that this module does not consider cases where user dissatisfaction is caused by non-intent recognition issues. By designing the adaptive learning module, the system can achieve rapid adaptation to unknown intents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Query Library Extension Module</head><p>Users can use the py2neo Python package to extend the existing knowledge graph with structured datasets. For unstructured datasets, semantic analysis toolkits are recommended to extract the entities and relationships based on semantic parsing. The query library extension module enables users to build a domain-specific knowledge graph and integrate it into the question-and-answer system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CASE STUDY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiment Setting</head><p>In typical question answering (QA), the confusion matrix is a commonly used evaluation factor. Previous studies, such as QASE(Question Answering with Subgraph Embeddings) <ref type="bibr" target="#b16">[17]</ref> and MCCNN(Multi-Column Convolutional Neural Networks) <ref type="bibr" target="#b17">[18]</ref>, have introduced the confusion matrix to evaluate the results of their methods. The previous research is based on general datasets, such as DBpedia and Freebase, which involves cross-domain datasets, and there exists the assumption of failure question matching. However, our QA system is designed specifically within a domain-specific knowledge base and does not take failure question matching assumption into consideration. Furthermore, our system is designed to address the problem of identifying unseen intent while disregarding answer failures caused by insufficient data. As a result, we have made a fundamental assumption that all questions can find corresponding answers within the domain knowledge base. Based on this, we still utilize the classic QA evaluation standard <ref type="bibr" target="#b18">[19]</ref>, but we contend that accuracy alone is sufficient to assess the efficacy of the system. To create our system, we utilized the Tushare financial dataset (<ref type="url" target="http://tushare.org/">http://tushare.org/</ref>), an open-source, python-friendly financial data package that offers users fast, clean, and diverse data.</p><p>Using the Tushare financial dataset, we created our knowledge graph and a test set containing 100 samples, comprising 50 simple relation questions and 50 complex relation questions. A simple relation question refers to a question whose answer can be found within a triplet of SPOs. For instance, if we ask, "Where is the headquarters of Wanke company located?" the answer "Shenzhen" is stored in the simple triplet as &lt; wanke -located -Shenzhen &gt;. In contrast, a complex relation question involves the system needing to search more than one SPO triplet to generate a final answer. An example of a complex relation question is "Please name the five most popular investment companies."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiment Result</head><p>We conducted ablation experiments to compare the impact of different model settings on the performance of our system. The abbreviation w/o, denoting the removal of a particular part from the model, is used in Table <ref type="table">I</ref> to illustrate the experimental groups. In this study, accuracy was adopted as the primary evaluation metric, calculated by dividing the number of correct answers by the total number of questions. Our experimental results show that the complete system for the question-answering task achieved an accuracy of 0.90. It should be emphasized that the system's ability to correct incorrect answers through adaptive learning is regarded as equivalent to providing the correct answers.</p><p>In order to evaluate the system's recognition performance for unseen intents, we conducted separate tests for various model settings. Our evaluation results demonstrate that the BERT-based question representation model and the similar question vector library are crucial for discovering unseen intents. The experimental results show that the accuracy decreased by 0.3 after removing the BERT module. Furthermore, the incorporation of LLM and Adaptive Learning Module can effectively address the diversity of language and improve the system's ability to recognize unseen intents. In contrast, the rule-based model has a limited impact on the system's recognition of unseen intents.</p><p>TABLE I EVALUATION RESULTS OF DIFFERENT SETTINGS ON THE TEST SPLIT OF THE FINANCIAL DATASET. Setting Accuracy All 0.90 w/o Rule Based Model 1 0.88 w/o Bert Based Model 2 0.60 w/o LLM 3 0.8 w/o Adaptive Learning Module 4 0.85 1 w/o Rule Based Model: without using the Rule Based Model in the intent recognition module. 2 w/o Bert Based Model: without using the Bert Based Model in the intent recognition module. 3 w/o LLM: without using the LLM in the intent recognition module. 4 w/o Adaptive Learning Module: without using the Adaptive Learning Module</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>We conducted ablation experiments to compare the impact of different model settings on the performance of our system. The abbreviation w/o, denoting the removal of a particular part from the model, is used in Table <ref type="table">1</ref> to illustrate the experimental groups. In this study, accuracy was adopted as the primary evaluation metric, calculated by dividing the number of correct answers by the total number of questions. Our experimental results show that the complete system for the question-answering task achieved an accuracy of 0.90. It should be emphasized that the system's ability to correct incorrect answers through adaptive learning is regarded as equivalent to providing the correct answers.</p><p>In order to evaluate the system's recognition performance for unseen intents, we conducted separate tests for various model settings. Our evaluation results demonstrate that the BERT-based question representation model and the similar question vector library are crucial for discovering unseen intents. The experimental results show that the accuracy decreased by 0.3 after removing the BERT module. Furthermore, the incorporation of Generative AI and Adaptive Learning Modules can effectively address the diversity of language and improve the system's ability to recognize unseen intents. In contrast, the rule-based model has a limited impact on the system's recognition of unseen intents.</p><p>Our proposed method provides evidence in the KBQA field that the natural language understanding capability of Generative AI effectively helps the traditional AI methods to tackle the barrier of linguistic diversity. Additionally, in an industrial context, we provide methodological contributions to solving the problem of unseen classes in the field of KBQA. Furthermore, at the application level, we present a Generative AI-based solution for constructing KBQA systems in the financial domain. Through ablation experiments, we verify the effectiveness of Generative AI in enhancing the natural language understanding capability of traditional AI.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="3,48.96,50.54,514.04,251.25" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mujtaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2307.04251</idno>
		<title level="m">ChatGPT in the Age of Generative AI and Large Language Models: A Concise Survey</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2302.09419</idno>
		<title level="m">A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Power of Generative AI: A Review of Requirements, Models, Input-Output Formats, Evaluation Metrics, and Challenges</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V S R</forename><surname>Adapa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">E V P K</forename><surname>Kuchi</surname></persName>
		</author>
		<idno type="DOI">10.3390/fi15080260</idno>
	</analytic>
	<monogr>
		<title level="j">Future Internet</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">260</biblScope>
			<date type="published" when="2023-07">Jul. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Survey on Evaluation of Large Language Models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2307.03109" />
	</analytic>
	<monogr>
		<title level="j">arXiv</title>
		<imprint>
			<date type="published" when="2023-10-17">Oct. 17, 2023. Oct. 21, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Toward an Architecture for Never-Ending Language Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Betteridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v24i1.7519</idno>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1306" to="1313" />
			<date type="published" when="2010-07">Jul. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A survey of knowledge based question answering with deep learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">157</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Openworld Machine Learning: Applications, Challenges, and Opportunities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chouhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Raychoudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rathore</surname></persName>
		</author>
		<idno type="DOI">10.1145/3561381</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2023-10">Oct. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">KBQA: An Online Template Based Question Answering System over Freebase</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI-16)</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI-16)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Constructing biomedical domain-specific knowledge graph with minimum supervision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10115-019-01351-4</idno>
	</analytic>
	<monogr>
		<title level="j">Knowl Inf Syst</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="317" to="336" />
			<date type="published" when="2020-01">Jan. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Knowledge vault: a web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<idno type="DOI">10.1145/2623330.2623623</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining<address><addrLine>New York New York USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014-08">Aug. 2014</date>
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
		<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BB-KBQA: BERT-Based Knowledge Base Question Answering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32381-37</idno>
	</analytic>
	<monogr>
		<title level="s">Chinese Computational Linguistics</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">11856</biblScope>
			<biblScope unit="page" from="81" to="92" />
			<date type="published" when="2019">2019</date>
			<publisher>Springer International Publishing</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
	<note>Lecture Notes in Computer Science</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.1145/3560815</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2023-09">Sep. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A Cookbook of Self-Supervised Learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Balestriero</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2304.12210</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A novel probabilistic graphic model to detect product defects from social media data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dss.2020.113369</idno>
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page">113369</biblScope>
			<date type="published" when="2020-10">Oct. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Natural language question answering over RDF: a graph data driven approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2014 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="313" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Question answering with subgraph embeddings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.3676</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Question answering over freebase with multi-column convolutional neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="260" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Information extraction over structured data: Question answering with freebase</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd annual meeting of the association for computational linguistics</title>
		<meeting>the 52nd annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="956" to="966" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

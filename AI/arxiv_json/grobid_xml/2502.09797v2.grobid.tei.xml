<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Survey on LLM-based News Recommender Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2015">2015 2016 2017 2018 2019 2020 2021 2022 2023 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rongyao</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Veronica</forename><surname>Liesaputra</surname></persName>
						</author>
						<author>
							<persName><roleName>Staff, IEEE</roleName><forename type="first">Zhiyi</forename><surname>Huang</surname></persName>
						</author>
						<title level="a" type="main">A Survey on LLM-based News Recommender Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015">2015 2016 2017 2018 2019 2020 2021 2022 2023 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">FDEA70BCCB42A11AE075087D2AA52701</idno>
					<note type="submission">This paper was produced by the IEEE Publication Technology Group. They are in Piscataway, NJ. Manuscript received April 19, 2021; revised August 16, 2021.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>News Recommender System</term>
					<term>Discriminative Large Language Models</term>
					<term>Generative Large Language Models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>News recommender systems play a critical role in mitigating the information overload problem. In recent years, due to the successful applications of large language model technologies, researchers have utilized Discriminative Large Language Models (DLLMs) or Generative Large Language Models (GLLMs) to improve the performance of news recommender systems. Although several recent surveys review significant challenges for deep learning-based news recommender systems, such as fairness, privacypreserving, and responsibility, there is a lack of a systematic survey on Large Language Model (LLM)-based news recommender systems. In order to review different core methodologies and explore potential issues systematically, we categorize DLLM-based and GLLM-based news recommender systems under the umbrella of LLM-based news recommender systems. In this survey, we first overview the development of deep learning-based news recommender systems. Then, we review LLM-based news recommender systems based on three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. Next, we examine the challenges from various perspectives, including datasets, benchmarking tools, and methodologies. Furthermore, we conduct extensive experiments to analyze how large language model technologies affect the performance of different news recommender systems. Finally, we comprehensively explore the future directions for LLMbased news recommendations in the era of LLMs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>A Large amount of news is generated in the era of Internet. It is difficult for users to find news that they are interested in from online news applications such as Google News, Bing News, and Toutiao. In these applications, news recommender systems are employed to help users alleviate this information overload as well as to improve users' reading experience <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. In recent years, increasing attention to news recommendation has led to a growing number of publications on news recommender systems as shown in Figure <ref type="figure" target="#fig_0">1</ref>. With the growth of deep-learning techniques in Natural Language Processing (NLP), various deep-learning methods are utilized in the news recommender systems and achieve state-of-the-art performances <ref type="bibr" target="#b2">[3]</ref>.</p><p>Most news recommender systems are built on deep neural network frameworks, such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Graph Neural Networks (GNNs), due to their superior abilities at representing and learning textual information. CNNs are leveraged to extract local textual features from news contents <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>, such as fine-grained news features, and knowledge-based news features. RNNs are utilized to capture users' diverse preferences based on their behavior sequences <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, for example, long-and short-term user interest and multiple user interest. Furthermore, GNNs are commonly employed to model structural news-user representations <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b11">[12]</ref> such as structural intent-aware user representation. Although these neural networks can improve the performance of the news recommender systems, many researchers have found that these general deep-learning methods tend to reach their limitations at learning more complex information <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b15">[16]</ref> such as deep news-user relationship and multi-modal representation.</p><p>With the advancement of Transformers <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b18">[19]</ref> in NLP, researchers utilize DLLMs, such as BERT <ref type="bibr" target="#b16">[17]</ref>, RoBERTa <ref type="bibr" target="#b19">[20]</ref> and BART <ref type="bibr" target="#b20">[21]</ref>, as news encoders to capture the potential semantic information in news content <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b23">[24]</ref>, or apply DLLMs' special training arXiv:2502.09797v2 [cs.IR] 21 Feb 2025 strategy to model news-user semantic relationship for news recommendation <ref type="bibr" target="#b24">[25]</ref>- <ref type="bibr" target="#b26">[27]</ref>. These DLLM-based methods achieve better performance than deep neural networks (e.g., CNNs, RNNs, GNNs). However, DLLMbased news recommender systems are constrained by their limited pre-trained knowledge, which makes it challenging to leverage them effectively for addressing coldstart problem and modeling accurate news and users' representations <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b25">[26]</ref>.</p><p>Recent GLLMs (e.g., GPT-4 <ref type="foot" target="#foot_0">1</ref> , LLaMA<ref type="foot" target="#foot_1">foot_1</ref> , PaLM <ref type="foot" target="#foot_2">3</ref> ) have a substantially larger number of parameters and are pre-trained on significantly higher amount of data, which makes it more powerful at semantic understanding and generation. Recently, there are rapid growth in GLLM-based news recommender systems, and some can achieve state-of-the-art performance <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b29">[30]</ref> because it can alleviate the cold-start problem by generating relevant information, and use its strong reasoning and learning abilities to explore accurate news features and model users' interests. However, GLLM-based news recommender systems typically require significant training time and resources.</p><p>Many comprehensive survey studies summarize and review various methodologies of news recommender systems. For instance, Wu et al. <ref type="bibr" target="#b2">[3]</ref> reviewed different challenges, technologies, and future directions of deep learning based personalized news recommender systems. While Meng et al. <ref type="bibr" target="#b30">[31]</ref> reviewed various significant parts of personalized news recommender system such as data collection, news recommendation model, and personalized news display. They focused on discussing different news recommendation methods based on graph structure learning. Iana et al. <ref type="bibr" target="#b31">[32]</ref> categorized knowledge-aware news recommendation into three parts: neural methods, non-neural entity-centric methods, and non-neural path-based methods. Specifically, they review different methodologies of news recommender systems which utilize external knowledge to enhance performance. However, currently, there is a gap in a systematic survey on LLM-based news recommender systems with extensive experiments.</p><p>In this paper, we summarize and review various LLM-based (including DLLM and GLLM) news recommendation approaches based on three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. Text-oriented modeling is defined as a set of foremost text-based encoding methods that use DLLMs and GLLMs for news recommendation. Then, we review methods that focus on building user profiles as user-oriented modeling for news recommendation. The prediction-oriented modeling represents methods relevant to prediction, i.e., optimizing predicting function based on users and news. Moreover, we examine the challenges from various perspectives, including datasets, benchmarking tools, and methodologies. We have also conducted comprehensive benchmark experiments to thoroughly compare and review the existing systems' performance, advantages, disadvantages, and limitations. The performance of each news recommender system is measured in terms of classification metrics, ranking metrics, diversity metrics, and personalization metrics. Finally, we review future directions on new recommendation in the era of LLMs to support future news recommendation research.</p><p>Our main contributions are as follows:</p><p>• As far as we know, this is the first systematic survey of news recommender systems by conducting extensive experiments in the era of LLMs. • We propose a unified research framework that reviews different LLM-based news recommendation models based on three aspects: news-oriented modeling, user-oriented modeling, and predictionoriented modeling. • Through objective experiments, we evaluate various LLM-based news recommender systems from different angles using a variety of metrics, i.e., classification metrics, ranking metrics, diversity metrics, and personalization metrics. This paper is organized as follows: Section II discusses different deep learning-based news recommendation methodologies. While, Section III reviews LLMbased news recommendation methods from three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. Section IV explores the challenges of LLM-based news recommender systems. Section V details our benchmark experiments' designs and results of various LLM-based news recommendation methodologies. Section VI explores future directions for LLM-based news recommender systems. Finally, in Section VII, we conclude our systematic survey and significant findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. OVERVIEW OF DEEP LEARNING-BASED NEWS RECOMMENDER SYSTEMS</head><p>Before the era of large language models, deep-learning methods (e.g., CNNs, RNNs, GNNs) were commonly used to design news recommender systems <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b38">[39]</ref>. Research works in each period have demonstrated consistent patterns across different deep-learning technology development stages. Based on our knowledge and previous works <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b31">[32]</ref>, we can conclude a general uniform news recommendation framework as shown in Figure <ref type="figure">2</ref>, which consists of three main components: news encoder, user encoder and click predictor. Specifically,</p><p>Candidate News News Encoder Click Predictor Ranking Score News Representation ... User User Behaviour User Encoder User Representation Fig. 2: A general uniform news recommendation framework the news encoder is devised to construct accurate news representations and support user interest modeling. The user encoder is designed to explore users' preferences and build users' representations based on accurate news representations. The click predictor is proposed to calculate matching scores between candidate news representations and users' representations. In this section, we categorize different research works into two types based on the characteristics of news recommendation as follows: news-oriented modeling and user-oriented modeling. To clearly illustrate our observations, an overview of deep learning-based news recommendation methodologies is presented in Table I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. News-oriented Modeling</head><p>Initially, most researchers focus on applying basic deep-learning methods to construct news embeddings. To be specific, CNNs are among the earliest deep-learning methods applied in news recommender systems. For example, Wang et al. <ref type="bibr" target="#b3">[4]</ref> managed to design CNN-based news encoders with a knowledge graph. Khattar et al. <ref type="bibr" target="#b39">[40]</ref> utilized 3D-CNNs to encode news representations. Moreover, attention mechanism (e.g., additive attention, multi-head self-attention) is employed to model accurate news representation <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b42">[43]</ref> as well as capture textual content representations <ref type="bibr" target="#b0">[1]</ref>. In particular, Gabriel et al. <ref type="bibr" target="#b41">[42]</ref> proposed a deep learning-based news recommendation architecture that applied deep neural networks (DNNs) and RNNs to encode content representations. Wu et al. <ref type="bibr" target="#b5">[6]</ref> designed a topic-aware news encoder to build news representations with news categories. To construct comprehensive news representations, other researchers focus on devising effective news encoders to encode informative news features. To capture sufficient textual information in news content, Wu et al. <ref type="bibr" target="#b51">[52]</ref> proposed a multi-view news encoder that can encode all informative news features such as title, category, and abstract. Lian et al. <ref type="bibr" target="#b55">[56]</ref> proposed applying multilayer fully connected networks and attention mechanisms to design a deep fusion model for news representation learning. The aforementioned models encode basic news features (e.g., title, category, abstract) with different deep-learning methods. Due to the limitations of deeplearning methods during this period, most researchers are interested in exploring different deep-learning methodologies to improve the accuracy of news recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. User-oriented Modeling</head><p>With the growth of deep learning-based news recommender systems, user representation learning has gained increasing attention from researchers. For example, Liu et al. <ref type="bibr" target="#b53">[54]</ref> utilized self-attention networks to encode deep user representations. Aiming to capture users' long-and short-term representations, An et al. <ref type="bibr" target="#b6">[7]</ref> proposed to employ RNNs (e.g., gated recurrent unit networks) to model users' consistent and temporal preferences. Ge et al. <ref type="bibr" target="#b46">[47]</ref> employed GNNs (e.g., graph attention networks) and modified transformer networks to model users' highorder relatedness. Although these representation learning methods are proposed to encode news and users' features in order to generate accurate embedding representations for news recommendation, they are only at the midexploration stage of deep learning-based news recommender systems.</p><p>During the rapid development stage of deep-learning methods ranging from 2020 to 2023, researchers have observed that deep-learning methods not only explore more accurate textual features but also model real-world user profiles (e.g., interest, intention, behaviour). Aiming to build accurate users' interests and obtain more effective recommendation performance, most works utilize different sufficient deep-learning methods to devise their innovative user interest models <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b59">[60]</ref>. They all aim to extract diverse user interests from historical records and achieve state-of-the-art performance in their experiments. By leveraging effective and accessible deep learning methods, we can obtain accurate representations of user interests as expected. For instance, applying RNNs could help our model capture long sequential features <ref type="bibr" target="#b7">[8]</ref>, while GNNs could assist in modeling structural interest representations and high-order relationships between news and users <ref type="bibr" target="#b9">[10]</ref>. Moreover, user intention is a critical concept in news recommendation, originating from the field of psychology <ref type="bibr" target="#b60">[61]</ref>. In order to</p><p>TABLE I: Overview of deep learning-based news recommender systems in recent years. We categorize the research based on their methodologies. Type Methodology Model News-oriented modeling Convolutional Neural Network (CNN) Weave&amp;Rec [40], DNN4NR [41] Recurrent Neural Network (RNN)</p><p>GRU <ref type="bibr" target="#b36">[37]</ref>, CHAMELEON <ref type="bibr" target="#b41">[42]</ref>, HRAM <ref type="bibr" target="#b34">[35]</ref> Attention Mechanism NRMS <ref type="bibr" target="#b42">[43]</ref>, DAN <ref type="bibr" target="#b32">[33]</ref>, DAINN <ref type="bibr" target="#b43">[44]</ref>, NPA <ref type="bibr" target="#b0">[1]</ref>, DNA <ref type="bibr" target="#b44">[45]</ref> Graph Neural Network (GNN) SI-News <ref type="bibr" target="#b45">[46]</ref>, GERL <ref type="bibr" target="#b46">[47]</ref> Knowledge Graph (KG) DKN <ref type="bibr" target="#b3">[4]</ref>, TEKGR <ref type="bibr" target="#b38">[39]</ref>, KOPRA <ref type="bibr" target="#b47">[48]</ref>, AnchorKG <ref type="bibr" target="#b48">[49]</ref>, KRED <ref type="bibr" target="#b49">[50]</ref>, CAGE <ref type="bibr" target="#b50">[51]</ref> Reinforcement Learning DRN [2] News Representation Learning TANR <ref type="bibr" target="#b5">[6]</ref>, NAML <ref type="bibr" target="#b51">[52]</ref>, WG4Rec <ref type="bibr" target="#b33">[34]</ref>, ANRS <ref type="bibr" target="#b52">[53]</ref> User-oriented modeling User Representation Learning LSTUR <ref type="bibr" target="#b6">[7]</ref>, HiFi-Ark <ref type="bibr" target="#b53">[54]</ref>, NRHUB <ref type="bibr" target="#b54">[55]</ref>, CNE-SUE <ref type="bibr" target="#b9">[10]</ref>, DFM <ref type="bibr" target="#b55">[56]</ref>, TANN <ref type="bibr" target="#b37">[38]</ref>, GNewsRec <ref type="bibr" target="#b8">[9]</ref>, HieRec <ref type="bibr" target="#b56">[57]</ref>, PP-Rec <ref type="bibr" target="#b57">[58]</ref>, CAUM <ref type="bibr" target="#b58">[59]</ref> Interest Modeling MINS <ref type="bibr" target="#b7">[8]</ref>, MINER <ref type="bibr" target="#b22">[23]</ref>, FIM <ref type="bibr" target="#b4">[5]</ref>, PENR <ref type="bibr" target="#b59">[60]</ref>, GREP <ref type="bibr" target="#b10">[11]</ref>,</p><p>TrNews <ref type="bibr">[</ref>36] Intention Modeling IPNR [61] Sentiment Modeling SentiRec [62], SentiDebias [63] Fairness Modeling FairRec [64], HDInt [65] Privacy-preserving Modeling CenNewsRec [66], FedRec [67] Satisfaction Modeling</p><p>CPRS <ref type="bibr" target="#b67">[68]</ref> model users' intentions from sequential history records, Wang et al. <ref type="bibr" target="#b11">[12]</ref> devised a GNN-based framework to extract intentions with a knowledge graph. In addition to modeling user representations, other aspects of the user experience (e.g., privacy, fairness, sentiment) should also be taken into account in news recommender systems. In terms of privacy, Yi et al. <ref type="bibr" target="#b66">[67]</ref> proposed using federated learning to protect users' privacy while reducing computation and communication costs. For fairness, Wu et al. <ref type="bibr" target="#b63">[64]</ref> first employed decomposed adversarial learning to learn bias-free representations in the news recommender system. Furthermore, Wu et al. <ref type="bibr" target="#b61">[62]</ref> devised to model sentiment-aware news representations with a sentiment prediction task. The aforementioned research directions have become prominent research topics in the field of news recommender systems in recent years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. LLM-BASED NEWS RECOMMENDATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHODOLOGY</head><p>In this section, we review how LLM-based methods are used to construct the three main components of a news recommendation system: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. News-oriented Modeling</head><p>Initially, most researchers utilize various DLLMs to encode the textual news content. Specifically, Wu et al. <ref type="bibr" target="#b14">[15]</ref> first proposed the use of BERT to enhance the natural language understanding capabilities of news recommender systems. Their core contribution is replacing the conventional news encoder module consisting of CNNs, RNNs and GNNs with a module composed of DLLMs and attention mechanisms. Huang et al. <ref type="bibr" target="#b68">[69]</ref> introduced a multi-factor fusion model to address the impact of specific news events (i.e., breaking news). To enable multi-aspect customization for news recommendation, such as incorporating news features like sentiment and categories, Iana et al. <ref type="bibr" target="#b69">[70]</ref> proposed a novel framework that leverages DLLMs and contrastive learning to model both content-and aspect-based news representations. These methods commonly leverage BERT-based models to enhance the comprehension of textual information for news recommendation. As demonstrated in these studies <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b70">[71]</ref>, BERT-based models have enhanced news recommender systems, achieving approximately a 3% improvement in performance compared to deep learningbased methods.</p><p>The application of GLLMs in news recommender systems is distinct from the approach used in DLLM-based news recommender systems. At the inception of GLLMs, most researchers favored incorporating additional critical information generated by GLLMs into news recommender systems. For example, Gao et al. <ref type="bibr" target="#b27">[28]</ref> proposed a novel generative news recommendation framework that constructs news narratives (e.g., personalized multi-news narratives) using GLLMs, with a newly proposed training method to enhance recommendation accuracy. Similarly, Yada et al. <ref type="bibr" target="#b71">[72]</ref> applied GLLMs (i.e., GPT-4) to generate category descriptions in the news recommender system. Chen et al. <ref type="bibr" target="#b29">[30]</ref> effectively leveraged GLLMs to construct rich semantic news representations and utilize Wikidata KG to tackle the long-tail problem in news recommender systems. Liu et al. <ref type="bibr" target="#b72">[73]</ref> proposed a novel framework to apply large language model technolegies (e.g., GPT-4, LLaMA) to learn contextual information with effective prompts and fine-tuning methods on the news recommendation dataset (e.g., MIND). In order to alleviate the problem of media bias, Ruan et al. <ref type="bibr" target="#b28">[29]</ref> proposed leveraging GLLMs to rewrite news headlines for users in news recommender systems. The researchers effectively leverage the powerful generative capabilities of GLLMs to achieve approximately a 10% improvement in the performance of news recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. User-oriented Modeling</head><p>Modeling users' preferences lies at the heart of news recommender systems. An advanced modeling method could enhance news recommendation models to understand users' needs and recommend relevant articles that meet their preferences. The applications of LLMs in news recommender systems not only improve the ability to understand textual information but also enable the creation of accurate user profiles by leveraging contextual features. For instance, Zhang et al. <ref type="bibr" target="#b26">[27]</ref> designed a user-news matching framework with BERT, whose core idea is matching clicked and candidate news with multigrained representations (i.e., word-level representations, news-level representations) in a BERT architecture. During the same period, the attentive multi-field matching framework is proposed by Zhang et al. <ref type="bibr" target="#b24">[25]</ref>. Although their methodology is similar to that of <ref type="bibr" target="#b26">[27]</ref>, the matching objects and granularity differ (i.e., news titles, abstracts, and bodies are used in this matching process). Similarly, Li et al. <ref type="bibr" target="#b22">[23]</ref> proposed a multi-interest matching framework that applies a poly attention scheme to extract multiple interests with BERT-based news encoders. To effectively model users' immediate and long-term preferences, Liu et al. <ref type="bibr" target="#b73">[74]</ref> utilized attention mechanisms and GLLMs to address these challenges, using clicked news articles as the basis. As far as we observed, GLLM-based user models are less than DLLM-based user models. Therefore, a significant gap exists in modeling user preferences using GLLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Prediction-oriented modeling</head><p>The prediction-oriented modeling consists of a combination of training strategies and prediction methods. Specifically, NewsBERT <ref type="bibr" target="#b25">[26]</ref> is a novel DLLM-based news recommendation framework that simultaneously learns valuable insights from both teacher and student models through the distillation of BERT. Yu et al. <ref type="bibr" target="#b74">[75]</ref> first proposed a self-supervised domain-specific posttraining approach into a DLLM-based news recommendation framework with a novel two-stage knowledge distillation methodology. Moreover, Xiao et al. <ref type="bibr" target="#b75">[76]</ref> proposed an innovative training framework SpeedyFeed to reduce the time and resource costs associated with training DLLM-based news recommender systems. To enhance the performance of news recommendation tasks, Bi et al. <ref type="bibr" target="#b21">[22]</ref> designed a multi-task framework that improves effectiveness by incorporating multi-field features, including news recommendation, news classification, and named entity recognition (NER). Furthermore, Liu et al. <ref type="bibr" target="#b76">[77]</ref> proposed a prompt-based news recommendation framework that demonstrates the effectiveness of a GLLM-based prompt strategy by leveraging an iterative bootstrapping process. Wang et al. <ref type="bibr" target="#b77">[78]</ref> proposed a GLLM-based news recommendation model that utilizes a GLLM to filter out low-value news and recommend high-value news to users, using a newly designed metric called CherryRec. These methods provide great strategies to assist us train and optimize LLM-based news recommender systems. However, research on GLLMbased news recommender systems is still in the early stages and presents researchers with more opportunities and challenges to overcome.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CHALLENGES</head><p>In this section, we discuss our observations on the challenges of LLM-based news recommender systems, focusing on datasets, tools, and methodologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Challenges of Datasets</head><p>There are some publicly available news recommendation datasets such as Globo <ref type="bibr" target="#b83">[84]</ref>, Plista <ref type="bibr" target="#b84">[85]</ref>, Adressa <ref type="bibr" target="#b85">[86]</ref>, MIND <ref type="bibr" target="#b86">[87]</ref>, NPR <ref type="bibr" target="#b87">[88]</ref>, xMIND <ref type="bibr" target="#b88">[89]</ref>, and EB-NeRD <ref type="bibr" target="#b89">[90]</ref>. We summarize their characteristics in Table <ref type="table">II</ref>. Specifically, Plista offers a large collection of news texts and user behaviors gathered from 13 German news portals. Globo only includes word embeddings of the news texts, without additional textual features, which significantly limits the available information. Because textual information is essential in constructing news and user representations. As we can observe, Adressa and MIND are two of popular news recommendation datasets, which include informative news and user features. NPR is an enhanced news dataset by Globo, offering more comprehensive news content and detailed user behavior data, which consists of metadata information about news articles, recommendation impressions and user consumption history. xMIND is a multilingual news recommendation dataset built on MIND, which includes 14 linguistically and geographically diverse languages. EB-NeRD is collected from the information of Ekstra Bladet, which consists of 37 million impression logs, 251 million interactions and news metadata.</p><p>Despite the availability of some resources, public news recommendation datasets face significant challenges as follows:</p><p>1) Quantity: The available public news datasets are insufficient to meet the rapid growth of news recommender systems. As we can see in Table <ref type="table">II</ref>,</p><p>TABLE II: Comparisons of different news recommendation datasets Released Year Dataset # News # User # Behavior Textual Feature Language Reference 2013 Plista 4 70,353 / 1,095,323 title, body, category German Jugovac et al. [79] 2018 Globo 5 46,000 314,000 3,000,000 word embeddings of texts Portuguese Gabriel et al. [42] 2018 Adressa 6 48,486 3,083,438 27,223,576 title, body, category, entity Norwegian Dan et al. [33], Hu et al. [9], Sheu et al. [51], Koo et al. [80], zhao et al. [81], Gharahighehi et al. [82], Bae et al. [83], Huang et al. [69], Yi et al. [67], Lee et al. [39] 2020 MIND 7 161,013 1,000,000 24,155,470 title, abstract, category, entity English Wang et al. [4], Wu et al. [1], [6], [14], [15], [26], [43], [52], [62], [64], An et al. [7], Wang et al. [5], Qi et al. [57]-[59], Qiu et al. [11], Li et al. [23], Mao et al. [10], [24], Wang et al. [8], [12], Zhang et al. [25], [27], Gao et al. [28], Yi et al. [67], Ge et al. [47], Liu et al. [54], Wang et al. [60], Lu et al. [53], Bi et al. [22] 2023 NPR 8 148,099 1,162,802 1,402,576 title, content, topic Portuguese -2024 xMIND 9 130,379 1,000,000 24,155,470 title, abstract Multi-languages -2024 EB-NeRD 10 125,541 1,103,602 37,966,985 title, abstract, body, category, subcategory, entities, URL, sentiment, topic Danish -</p><p>MIND dataset is the most popular dataset on which most researchers prefer to conduct experiments. However, the MIND dataset has nearly reached its limitation in some works <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b25">[26]</ref>. We are in the zone of model overfitting to this dataset. So we need more datasets to really evaluate the generalizability of the model. It is essential to release some new news datasets to enable researchers to conveniently design and conduct experiments across different datasets. 2) Information: MIND dataset contains the most informative features (e.g., title, abstract, category, entity) compared with others. However, this alone is insufficient to significantly enhance news recommender systems. This is because additional information (e.g., publisher, location, reading time, etc) is required to model more accurate user representations. Incorporating users' reading time per news article could improve the accuracy of modeling their preferences <ref type="bibr" target="#b67">[68]</ref>. Including publisher information could contribute to building fairness-aware news recommender systems <ref type="bibr" target="#b18">[19]</ref>. Additionally, utilizing images within news articles could enable researchers to develop multi-modal news recommender systems, which can empower news representation learning <ref type="bibr" target="#b90">[91]</ref>. As a result, the development of news recommender systems is constrained by available news datasets. Moreover, an LLM trained solely on English is unlikely to perform well on Norwegian or other language datasets without additional training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Challenges of Benchmarking Tools</head><p>Smart and user-friendly benchmarking tools enable researchers to conduct studies more easily. In recent years, several benchmarking tools have been released to support the development of news recommender systems. We collect and review important benchmarking tools related to news recommendation illustrated in Table <ref type="table">III</ref>, including Microsoft Recommenders <ref type="bibr" target="#b92">[93]</ref>, RecBole <ref type="bibr" target="#b93">[94]</ref>, News-Recommendation, NewsRecLib <ref type="bibr" target="#b70">[71]</ref>, and Legommender <ref type="bibr" target="#b91">[92]</ref>.</p><p>1) Microsoft Recommenders: Microsoft Recommenders <ref type="foot" target="#foot_3">11</ref> is published by Microsoft Recommenders team providing several examples and practices for building recommender systems. This benchmarking tool contains five essential news recommendation models including NRMS <ref type="bibr" target="#b42">[43]</ref>, NPA <ref type="bibr" target="#b0">[1]</ref>, NAML <ref type="bibr" target="#b51">[52]</ref>, LSTUR <ref type="bibr" target="#b6">[7]</ref> TABLE III: Comparison of important benchmarking tools Name Program Framework Program Language URL Author Year Model Dataset Recommenders TensorFlow Python <ref type="url" target="https://github.com/recommenders-team/recommenders">https:  //github.com/  recommenders</ref>-team/ recommenders Microsoft 2019 DKN [4], NAML [52], NPA [1], LSTUR [7], NRMS [43] MIND RecBole PyTorch Python <ref type="url" target="https://recbole.io/">https://recbole.io/</ref> RUCAIBox 2020 NRMS [43], NAML [52] MIND News-Recommendation PyTorch Python <ref type="url" target="https://github.com/yusanshi/news-recommendation">https://github.  com/yusanshi/  news-recommendation</ref> Yusanshi 2019 DKN [4], NAML [52], NPA [1], LSTUR [7], NRMS [43], HiFi-Ark [54] MIND NewsRecLib PyTorch-Lightening Python <ref type="url" target="https://github.com/andreeaiana/newsreclib">https://github.  com/andreeaiana/  newsreclib</ref> Iana et al. [71] 2023 CAUM [59], CenNews-Rec [66], DKN <ref type="bibr" target="#b3">[4]</ref>, LSTUR <ref type="bibr" target="#b6">[7]</ref>, MINER <ref type="bibr" target="#b22">[23]</ref>, MINS <ref type="bibr" target="#b7">[8]</ref>, NAML <ref type="bibr" target="#b51">[52]</ref>, NPA <ref type="bibr" target="#b0">[1]</ref>, NRMS <ref type="bibr" target="#b42">[43]</ref>, TANR <ref type="bibr" target="#b5">[6]</ref>, MANNeR <ref type="bibr" target="#b69">[70]</ref>, SentiDebias <ref type="bibr" target="#b62">[63]</ref>, SentiRec <ref type="bibr" target="#b61">[62]</ref> MIND, Adressa, xMIND Legommender PyTorch Python <ref type="url" target="https://github.com/Jyonn/Legommenders">https://github.  com/Jyonn/  Legommenders</ref> Liu et al <ref type="bibr" target="#b91">[92]</ref>. 2024 NAML <ref type="bibr" target="#b51">[52]</ref>, LSTUR <ref type="bibr" target="#b6">[7]</ref>, NRMS <ref type="bibr" target="#b42">[43]</ref>, PLMNR <ref type="bibr" target="#b14">[15]</ref>,ONCE <ref type="bibr" target="#b72">[73]</ref> MIND and DKN <ref type="bibr" target="#b3">[4]</ref>, which code is generated by Keras 12 in Tensorflow 13 programming environment. Although this repository offers several news recommendation models for practical use, it is not a specialized benchmarking tool for news recommendation. and only conducts experiments on a single news recommendation dataset (i.e., MIND).</p><p>2) RecBole: RecBole 14 is a general recommendation benchmarking tool developed by PyTorch 15 , which contains various recommendation algorithms such as sequential recommendation, context-aware recommendation, and knowledge-based recommendation. This repository also supports news recommender systems, but only two models (NRMS <ref type="bibr" target="#b42">[43]</ref> and NAML <ref type="bibr" target="#b51">[52]</ref>). Therefore, RecBole is insufficient for researchers studying news recommendation due to its limited number of models 12 <ref type="url" target="https://keras.io/">https://keras.io/</ref> 13 <ref type="url" target="https://github.com/tensorflow/tensorflow">https://github.com/tensorflow/tensorflow</ref> 14 <ref type="url" target="https://recbole.io/">https://recbole.io/</ref> 15 <ref type="url" target="https://pytorch.org/">https://pytorch.org/</ref> and reliance on a single news recommendation dataset.</p><p>3) News-Recommendation: News-Recommendation <ref type="foot" target="#foot_4">16</ref> is a personal open-source benchmarking tool available on GitHub. This benchmarking tool consists of six important news recommendation models such as DKN <ref type="bibr" target="#b3">[4]</ref>, NAML <ref type="bibr" target="#b51">[52]</ref>, NPA <ref type="bibr" target="#b0">[1]</ref>, NRMS <ref type="bibr" target="#b42">[43]</ref>, TANR <ref type="bibr" target="#b5">[6]</ref> and HiFi-Ark <ref type="bibr" target="#b53">[54]</ref>. Additionally, the author uses MIND datasets to conduct experiments. Although the repository implements various news recommendation models, the author will likely discontinue updating the code. As a result, these models are outdated and unable to support future research.</p><p>4) NewsRecLib: NewsRecLib<ref type="foot" target="#foot_5">foot_5</ref> is a news recommendation benchmarking tool built by a personal researcher based on PyTorch Lightning <ref type="foot" target="#foot_6">18</ref> and Hydra<ref type="foot" target="#foot_7">foot_7</ref> frameworks. This benchmarking tool contains various deep learning-based news recommender systems (e.g., TANR <ref type="bibr" target="#b5">[6]</ref>, CAUM <ref type="bibr" target="#b58">[59]</ref>, CenNewsRec <ref type="bibr" target="#b65">[66]</ref>, MINS <ref type="bibr" target="#b7">[8]</ref>, etc) and news datasets (e.g., MIND, Adressa, xMIND), which enables researchers to quickly reproduce news recommendation methods and conduct experiments among different datasets. Although this benchmarking tool categorizes news recommender systems into two classes: deep learning-based news recommendation and fairnessaware news recommendation, the models provided are insufficient to support future research due to the lack of multi-modal news recommender systems, GLLMbased news recommender. systems, etc. Several future directions require attention, including debiased news recommender systems, LLM-based news recommender systems, multi-modal news recommender systems, and privacy-preserving news recommender systems.</p><p>5) Legommender: Legommender is a content-based recommendation benchmarking tool released by personal researchers, which aims to support LLM-based recommender systems. This benchmarking tool contains four news recommendation models such as NAML <ref type="bibr" target="#b51">[52]</ref>, NRMS <ref type="bibr" target="#b42">[43]</ref>, LSTUR <ref type="bibr" target="#b6">[7]</ref>, and PLMNR <ref type="bibr" target="#b14">[15]</ref>. They devised this tool to serve their research such as ONCE <ref type="bibr" target="#b72">[73]</ref>, SPAR <ref type="bibr" target="#b94">[95]</ref>, GreenRec <ref type="bibr" target="#b95">[96]</ref> and UIST <ref type="bibr" target="#b96">[97]</ref>. Legommender guides researchers on effectively applying LLMs to news recommendations including DLLM-and GLLMbased frameworks. However, it is not sufficient to support a wide range of news recommendation models with LLMs. Furthermore, additional news recommendation datasets are expected to better serve LLM-based news recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Challenges of Methodologies</head><p>LLM-based news recommender systems face several challenges in the era of LLMs. We will review these various challenges from three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling.</p><p>1) News-oriented Modeling: News representation modeling is critical for accurate news recommendation, strongly related to NLP technologies such as word embedding <ref type="bibr" target="#b36">[37]</ref> and LLMs. LLM-based news recommender systems utilize LLMs as news encoders to learn informative news representations, and their superior performance has been validated in numerous studies <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b70">[71]</ref>, <ref type="bibr" target="#b72">[73]</ref>. Although language models offer promising advantages for news representations, challenges still need to be addressed. First of all, the information generated by GLLMs is not always credible (i.e., GLLMs may exhibit hallucinations.) <ref type="bibr" target="#b97">[98]</ref>. Therefore, it is essential to develop more reliable methodologies to validate the accuracy of generated representations. Second, processing large volumes of textual information with LLMs consumes significant time and resources <ref type="bibr" target="#b98">[99]</ref>. Third, LLM-based news recommender systems are unable to process long documents due to their limited context window, which restricts their ability to construct comprehensive news representations. Furthermore, modeling multiple languages poses a significant challenge for LLM-based news recommender systems, as not all LLMs are equipped to handle multiple languages effectively. In summary, more effective and efficient LLM-based news encoders are needed to better leverage LLMs for constructing informative news representations.</p><p>2) User-oriented Modeling: User-oriented modeling plays a critical role in news recommender systems. As far as we know, most researchers prefer to model user and news representations simultaneously using DLLMs <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b24">[25]</ref>- <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b68">[69]</ref>, <ref type="bibr" target="#b69">[70]</ref>, <ref type="bibr" target="#b74">[75]</ref>. As a result, there is limited research focused on building special user representations independently such as multiple interests modeling, intention modeling, and sentiment modeling <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b61">[62]</ref>. In the real world, user behaviors are complex and dynamic. Current user representation models cannot describe complex and dynamic user behaviors. For example, users' interests might be influenced by breaking news along with time. It is essential to carefully analyze and understand users' interests based on their behaviors. Although DLLMs enhance news representations as well as user representations, it is not sufficient to fully understand real complex users' behaviors. On the other hand, limited research has focused on modeling user representations using GLLMs <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b29">[30]</ref>. They propose generating additional information such as narratives by GLLMs and then aggregating it with the original features of news articles. However, these published studies ignore exploring deep and various user behaviours based on GLLM-enhanced context. For example, user behaviours when reading online newspapers may be influenced by their purpose and preferences. Therefore, efficiently building complex and dynamic user representations using GLLMs remains a significant challenge for news recommendation.</p><p>3) Prediction-oriented Modeling: Prediction-oriented modeling is related to training strategies and prediction including different training frameworks, evaluation methods, and ranking methodologies. It is more and more pivotal for news recommender systems in the period of LLMs. Due to the high time and resource consumption of DLLMs and GLLMs, LLM-based news recommender systems require optimization during training and prompting. First of all, LLM-based news recommender systems often apply one-tower architecture to match candidate news and user interests <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b26">[27]</ref>. These ranking methods can accurately explore the relatedness between candidate news and user interests with multi-grained features. However, these methods are unsuitable for low-latency or low-resource scenarios due to their high inference time and resource requirements <ref type="bibr" target="#b18">[19]</ref>. Moreover, training open-source GLLMs, such as LLaMA, for use in news recommendation requires significant time and expensive hardware to support these experiments. Efficient and effective training frameworks and ranking methods are required to accelerate prediction without high time and resource consumption. Second, current LLM-based methods lack accountability for their generated results. Many researchers have already utilized LLMs to replace traditional prediction frameworks such as the two-tower model as shown in Figure <ref type="figure">2</ref> [100]- <ref type="bibr" target="#b102">[103]</ref>. However, the generated results by GLLMs are not credible. Therefore, how to evaluate the accuracy of the generated information is a significant challenge. Moreover, new metrics are required to support LLMbased news recommender systems in order to verify their robustness, reliability, and performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>In this section, we introduce experimental settings such as datasets, metrics, and news recommendation models that we used in our experiments. Further, we conduct extensive experiments in order to answer the following questions:</p><p>Q1: How is the performance of LLM-based news recommendation models compared with deep learningbased news recommendation models in terms of classification and ranking?</p><p>Q2: Do LLM-based news recommendation models outperform deep learning-based news recommendation models in terms of diversity and personalization?</p><p>Q3: Do LLMs improve the performance of news recommendation sharply compared with the original deep learning-based news recommendation models?</p><p>Q4: How do GLLM-based news recommendation models perform compared with DLLM-based news recommendation models?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>For our experiments, we will utilize the two most commonly used datasets in our experiments: MIND <ref type="bibr" target="#b86">[87]</ref> and Adressa <ref type="bibr" target="#b85">[86]</ref>.</p><p>1) MIND: MIND was released by Microsoft in 2020 <ref type="bibr" target="#b86">[87]</ref> and constructed based on anonymous user logs obtained from Microsoft News platform. There are two versions: MIND-small and MIND-large. MIND-small contains 65,238 news metadata and 347,727 logs generated by 94,057 users. MIND-large consists of 24,155,470 logs of 1,000,000 users and 161,013 pieces of news. Each piece of news contains titles, abstracts, categories, and entities In terms of users, MIND provides their IDs and clicked logs including news clicks and impressions.</p><p>2) Adressa: Adressa was published by Norwegian University of Science and Technology, which contains a collection of news articles and sessions from Adressavisen news platform <ref type="bibr" target="#b85">[86]</ref>. There are two sub-datasets: one-week and ten-week. The one-week Adressa dataset is comprised of 11,207 articles and 2,286,835 session logs of 561,733 users. The 10-week Adressa dataset is composed of 48,486 articles and 27,223,576 session logs of 3,083,438 users. Each news article consists of titles, categories, bodies, and entities. Each session log includes various information about the user such as IDs, regions, time, browser, and city.</p><p>Due to the limitation of training time and resources, we use the MIND-small and one-week Adressa dataset to conduct our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation Metrics</head><p>Several evaluation metrics are utilized to verify the performance of news recommender systems in terms of ranking, classification, diversity, and personalization. In this section, we present the metrics employed in our experiments.</p><p>1) Classification Metrics: News recommendation can be considered as a classification task. Hence, several classification metrics can be used. Area Under Curve (AUC) score is commonly used in the evaluation of news recommendations. A high AUC score indicates that the news recommendation model has a stronger ability to distinguish between negative and positive samples, enabling it to recommend relevant news to users effectively. The score is calculated as follows:</p><formula xml:id="formula_0">AUC = 1 |P | × |N | p∈P n∈N I(s(p) &gt; s(n)),<label>(1)</label></formula><p>where P is positive samples, N is negative samples, p is one of positive samples, n is one of negative samples, s(p) is the predicting score of positive samples, s(n) is the predicting score of negative samples. I(s(p) &gt; s(n)) indicates that if s(p) &gt; s(n), the result is 1; otherwise, it is 0, computed as follows:</p><formula xml:id="formula_1">I(s(p) &gt; s(n)) = 1, if s(p) &gt; s(n) 0, otherwise .<label>(2)</label></formula><p>Additionally, there are other popular metrics used in the evaluation of news recommender systems such as Precision, Recall, and Hit Rate (HR), which are computed as follows:</p><formula xml:id="formula_2">Precision = T P T P + F P ,<label>(3)</label></formula><formula xml:id="formula_3">Recall = T P T P + F N ,<label>(4)</label></formula><formula xml:id="formula_4">HR@k = 1 |U | u∈U I(Ru ∩ Ru(k) ̸ = ∅),<label>(5)</label></formula><p>where T P indicates true positive samples, F P means false positive samples, F N indicates false negative samples, R u is the collection of interested items for user u, Ru (k) is a top-k list of interested items for user u, I is exponential function, if true, return 1; otherwise, return 0. In summary, AUC is widely utilized to evaluate the models' ability to recognize positive and negative samples. Precision measures the accuracy of correctly predicting positive samples. Recall is widely used to verify the ability to distinguish all positive samples. Hit rate is proposed to evaluate whether the recommended news list contains the user's interested news.</p><p>2) Ranking Metrics: News recommendation can be considered as a ranking task. Therefore, there are several ranking metrics used in the evaluation of news recommender systems. Apart from AUC, which is also a ranking metric, Mean Reciprocal Rank (MRR) and Normalized Discounted Cumulative Gain (nDCG). Specifically, MRR is utilized to evaluate whether interested news appears in the top positions of the recommended news list. nDCG measures whether the most relevant news appears in the top positions of the recommended news list, which focuses on the ranking quality and relevance of recommended results. MRR and nDCG@k are formulated as follows:</p><formula xml:id="formula_5">MRR = 1 |Q| |Q| i=1 1 Ranki ,<label>(6) nDCG</label></formula><formula xml:id="formula_6">@k = k i=1 rel i log 2 (i+1) k i=1 rel * i log 2 (i+1) , (<label>7</label></formula><formula xml:id="formula_7">)</formula><p>where Q is the set of queries, |Q| is the total number of queries, Rank i is the rank position of the first relevant to the i-th query. rel i is the relevance score of the i-th result, rel * i is relevance score under ideal ranking. 3) Diversity Metrics: In order to measure the diversity of news recommendations, Iana et el. <ref type="bibr" target="#b69">[70]</ref> proposed aspect-based diversity metrics as follows:</p><formula xml:id="formula_8">DA p @k = - j∈Ap p (j) log p (j) log (|Ap|) , (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>where A p is the collection of aspects, |A p | is the number of aspects. 4) Personalization Metrics: The Jaccard similarity <ref type="bibr" target="#b103">[104]</ref> is used to evaluate the personalization of news recommendations, which is computed as follows:</p><formula xml:id="formula_10">P SA p @k = |Ap| j=1 min (Rj, Hj) |Ap| j=1 max (Rj, Hj) , (<label>9</label></formula><formula xml:id="formula_11">)</formula><p>where H is the user history, R is the recommendation list, H j and R j are the probability of a piece of news with class j. In our experiments, we denote categ div as the topical category-based diversity and sent div as sentiment-based diversity. Moreover, we consider categ pers as the topical category-based personalization and sent pers as sentiment-based personalization.</p><p>In our experiments, we compute top 5 and 10 scores in terms of nDCG, Hit, Recall, Precision, diversity, and personalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Baselines</head><p>In order to evaluate the performance of LLM-based news recommendation models, we conduct extensive experiments on various methodologies which are classified into three groups: deep learning-based news recommendation models, DLLM-based news recommendation models, and GLLM-based news recommendation.</p><p>1) Deep Learning-based News Recommendation Models:</p><p>• NPA <ref type="bibr">[</ref>1], a personalized news recommendation model, which applies users' IDs to improve the performance of news recommendation with CNNs and attention mechanisms. • TANR [6], a topic-aware news recommendation model, which promotes news recommendations with a topic classification task using CNNs and attention mechanisms. • NAML [52], a deep learning-based news recommendation model with multi-viewing learning, which builds news representations from various news features such as titles, abstracts, and categories using CNNs and attention mechanisms. • LSTUR [7], a deep learning-based news recommendation model, which employs RNNs to learn longand short-term user representations. • NRMS [43], a deep learning-based news recommendation model, which utilizes multi-head selfattention mechanisms to capture complex news and users' features. • CenNewsRec [66], a privacy-preserving news recommendation model, which applies federated learning to jointly train accurate news recommender systems on users' devices and servers. • CAUM [59], a candidate-aware news recommendation model, which learns candidate-aware user representations using self-attention mechanisms and CNNs in order to accurately match users' interests. • MINS [8], a deep learning-based news recommendation model, which can learn multi-interest user representations through a multi-channel network consisting of RNNs and self-attention mechanisms. • SentiDebias [63], a deep learning-based news recommendation model, which employs decomposed adversarial learning to achieve fairness-aware news recommendation in terms of different sentiments. • SentiRec [62], a diversity-aware news recommendation model, which applies Transformers to model sentiment-aware news and user representations, jointly training with a sentiment prediction task. 2) DLLM-based News Recommendation Models: • MINER [23], a DLLM-based news recommendation model, which proposes a poly attention scheme to learn multi-interest user representations over BERT. • MANNeR [70], a DLLM-based news recommendation model, which proposes a modular framework to learn aspect-specific representations over BERT. • LSTUR-DLLM, TANR-DLLM, NRMS-DLLM, and NAML-DLLM are DLLM-empowered news recommendation models, in which the original news encoders are modified to incorporate DLLMs, inspired by previous works [15], [71]. 3) GLLM-based News Recommendation Models: • LKPNR [30], a generative news recommendation framework, which integrates a knowledge graph and GLLMs into deep learning-based news recommendation models. • ONCE [73], a hybrid content-based recommendation framework, which leverages both open-and closed-source GLLMs to enhance the performance of content-based recommender systems including news recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental Setup</head><p>We use similar configurations with NewsRecLib <ref type="bibr" target="#b70">[71]</ref> in terms of deep learning-based news recommendation models and DLLM-based news recommendation models. Besides, we employ official codes to reproduce GLLM-based news recommendation models (e.g., ONCE <ref type="foot" target="#foot_8">20</ref> , LKPNR <ref type="foot" target="#foot_9">21</ref> ) on the MIND dataset. Specifically, we only reproduce DIRE (Discriminative Recommendation Framework)-NAML to conduct our main experiments in Table <ref type="table">IV</ref>. Each model is trained and tested five times. For the sake of fairness and impartiality of the results, we calculate their average and standard deviation as shown in Table <ref type="table">IV</ref>, Table VI and Table V. E. Performance Evaluation 1) Reply to Q1: LLM-based news recommendation models vs. deep learning-based news recommendation models w.r.t. classification and ranking: As we can see in Table IV, the classification metrics including AUC and Recall reflect the performance of positive and negative classification in news recommender systems. For experiments on the MIND dataset, the LLM-based news recommendation model MANNeR achieves the best performance in terms of the main metric AUC, improving<ref type="foot" target="#foot_10">foot_10</ref> by approximately 13% compared to the deep learningbased news recommendation model TANR. Moreover, LKPNR significantly outperforms the best deep learningbased news recommendation model NAML in terms of Recall metrics, achieving an average 7% improvement.</p><p>These improvements prove the effectiveness of LLMbased news recommendation models in terms of classification and ranking capability on the MIND dataset. However, results on the Adressa dataset exhibit conflicting phenomena. Notably, deep learning-based news recommendation models such as CAUM and LSTUR markedly outperform all LLM-based news recommendation models. This happens to be because it isn't effective for LLM-based news recommendation models to encode multilingual information such as Norwegian on the Adressa dataset.</p><p>To more intuitively evaluate the accuracy of news recommendation models, we enrich our experiments using Hit Rate and Precision. Figure <ref type="figure">3</ref> demonstrates the results in terms of Hit Rate and Precision on the MIND dataset. MANNeR achieves the best performance w.r.t. Hit Rate on the MIND dataset. This superiority can be attributed to the effectiveness of a novel aspect-based framework with LLM-based methodologies which can learn aspectspecific representations for news recommendation. In addition, MANNeR obviously outperforms other news recommendation models in terms of Precision as shown in Figure <ref type="figure" target="#fig_1">4</ref>. This emphasizes the superiority of LLMbased news recommendation models in terms of Hit Rate and Precision on the MIND dataset. However, the results illustrate different tendencies on the Adressa dataset. To be specific, LSTUR and CAUM stand out as two of deep learning-based news recommendation models as indicated by Hit@k. This is likely due to the fact that LLM-based news recommendation models cannot effectively encode multilingual news features, leading to decreased performance on the Adressa dataset. In contrast, LLM-based news recommendation models, such as LSTUR-DLLM and NAML-DLLM, exhibit better precision compared to deep learning-based news recommendation models. This superiority can be attributed to the fact that LLM-based news recommendation models can model informative news representations, which is effective in deriving higher precision.</p><p>In summary, LLM-based news recommendation models have demonstrated great potential, while deep learning methods still have their advantages.</p><p>2) Reply to Q2: LLM-based news recommendation models vs. deep learning-based news recommendation models w.r.t. diversity and personalization: Table V presents results of diversity and personalization on the MIND dataset. Notably, LLM-based news recommendation models like MINER and NRMS-DLLM outperform deep learning-based news recommendation models in</p><p>TABLE IV: This table illustrates the performance of different news recommendation approaches including deep learning-based news recommendation models and LLM-based news recommendation models in terms of classification and ranking metrics on the MIND and Adressa datasets. Based on the analysis of these results, we can conclude that LLM-based news recommendation models outperform deep learning-based news recommendation models on the MIND dataset. The reported values represent the mean and standard deviation derived from five distinct experimental runs. Bold indicates the best experimental results on the same dataset. Underline means the second-best experimental results on the same dataset. Gary's color represents LLM-based news recommendation models. Dataset Model Metric AUC MRR NDCG@5 NDCG@10 Recall@5 Recall@10 MIND NPA 57.12±0.0035 30.61±0.0046 28.68±0.0036 34.89±0.0031 41.95±0.0043 59.98±0.0022 LSTUR 56.31±0.017 33.09±0.0057 31.31±0.0068 37.61±0.0068 45.37±0.0055 63.5±0.0044 TANR 60.83±0.0066 32.88±0.0037 30.93±0.0045 37.19±0.0034 44.71±0.007 62.51±0.0047 NRMS 55.63±0.0229 28.63±0.0158 26.78±0.014 33.3±0.0133 40.38±0.0135 59.17±0.0125 NAML 50.17±0.0004 34.55±0.0066 32.69±0.0055 38.93±0.0048 46.73±0.0048 64.59±0.0023 CenNewsRec 53.85±0.015 26.6±0.0105 24.98±0.0105 31.67±0.0092 39.05±0.0123 58.35±0.0078 CAUM 60.63±0.0111 34.15±0.0091 32.23±0.0084 38.69±0.0076 44.75±0.0331 63.36±0.0294 MINS 58.78±0.0161 33.76±0.0036 31.87±0.0034 38.29±0.0033 46±0.0066 64.39±0.0054 SentiDebias 54.82±0.0204 25.6±0.0142 23.3±0.0133 30.12±0.0129 35.59±0.0127 55.32±0.0105 SentiRec 52.87±0.0085 29.44±0.0188 27.18±0.0175 33.62±0.0167 40.25±0.0178 58.83±0.0159 LSTUR-DLLM 50±0 30.15±0.0079 28.56±0.0077 34.92±0.0077 42.02±0.0112 60.27±0.0111 TANR-DLLM 49.95±0.0013 25.32±0.0143 22.81±0.0148 29.17±0.0152 34.16±0.0222 52.61±0.0229 NRMS-DLLM 50±0 20.77±0.0228 18.37±0.0231 24.83±0.0218 28.71±0.0327 47.63±0.0273 NAML-DLLM 52.59±0.0189 30.13±0.0128 28.42±0.0123 34.95±0.012 41.89±0.0147 60.61±0.0146 MINER 51.08±0.0062 24.9±0.0039 22.6±0.0062 28.85±0.0054 34.44±0.0083 52.58±0.0053 MANNeR 68.44±0.0088 37.3±0.017 35.67±0.0163 41.79±0.0142 49.96±0.0134 67.4±0.0069 LKPNR 67.32±0.0004 31.99±0.0003 35.46±0.0005 41.77±0.0002 50.27±0.001 68.21±0.0004 ONCE 65.06±0.0031 32.76±0.0046 34±0.0054 40.17±0.0049 48.37±0.0054 65.9±0.0046 Adressa NPA 52.72±0.0366 32.94±0.0223 32.51±0.0303 38.77±0.0387 45.93±0.0539 65.43±0.0879 LSTUR 68.37±0.0104 36.85±0.0194 37.68±0.029 44.85±0.0241 54.23±0.0462 76.39±0.0439 TANR 50.22±0.0028 33.99±0.0222 33.71±0.0323 41.5±0.0256 48.4±0.0492 72.65±0.0278 NRMS 64.54±0.0259 30.35±0.0207 28.63±0.0285 38.85±0.0342 42.09±0.0444 73.78±0.0897 NAML 50±0 35.52±0.016 35.15±0.0227 42.42±0.0213 48.99±0.0378 71.71±0.0499 CenNewsRec 64.77±0.0295 29.63±0.021 26.97±0.0305 36.74±0.0347 38.04±0.0533 68.62±0.0773 CAUM 72.33±0.0475 35.68±0.0327 36.04±0.0443 44.42±0.0473 52.48±0.0723 78.5±0.0778 MINS 68.68±0.0486 33.49±0.039 32.13±0.0514 40.84±0.0489 45.04±0.0717 72.26±0.0796 SentiDebias 68.7±0.0361 31.1±0.0361 30.51±0.0559 39.66±0.039 45.87±0.0868 74.19±0.0464 SentiRec 55.59±0.0096 27.14±0.0118 24.35±0.0107 30.78±0.0112 33.32±0.0082 53.49±0.0262 LSTUR-DLLM 56.86±0.0334 34.34±0.039 35.58±0.0433 42.31±0.0509 48.66±0.0719 68.3±0.1049 TANR-DLLM 50.03±0.0007 35.17±0.024 35.09±0.0277 41.27±0.0322 47.49±0.045 66.39±0.0669 NRMS-DLLM 52.8±0.0516 28.89±0.1134 27.95±0.1382 33.48±0.1505 38.74±0.1898 55.23±0.2353 NAML-DLLM 50±0.0001 33.43±0.0331 34.45±0.0314 40.65±0.0297 43.23±0.0593 68.64±0.0429 MINER 56.96±0.0741 26.5±0.1134 25.68±0.1253 32.21±0.1256 32.28±0.2281 66.7±0.1282 MANNeR 50±0 35.35±0.0489 36.38±0.0687 44.19±0.0602 51.11±0.0979 75.66±0.0766 Hit@5 Hit@10 0.3 0.4 0.5 0.6 0.7 0.8 Hit Rate Hit Rate on the MIND dataset Hit@5 Hit@10 Hit Rate Hit Rate on the Adressa dataset NPA LSTUR TANR NRMS NAML CenNewsRec CAUM MINS SentiDebias SentiRec LSTUR-DLLM TANR-DLLM NRMS-DLLM NAML-DLLM MINER MANNeR Fig. 3: The Hit Rate on the MIND and Adressa dataset. terms of diversity, achieving an average 7% improvement over SentiRec. Table VI indicates that LLM-based news recommendation models outperform deep learning-based news recommendation models on the Adressa dataset, with improvements up to 6%. These results verify the superiority of LLM-based news recommendation models in enhancing the diversity and personalization of news recommendations. However, deep learning-based news recommendation model like LSTUR exhibits better personalization on the MIND dataset, as indicated by categ pers@k. In contrast, deep learning-based news recommendation models, such as SentiRec and MINS, present a better diversity of news recommendations on the Adressa dataset, as illustrated in Table VI.</p><p>In summary, the experimental results on the two datasets are complex, and LLM-based news recommendation models do not necessarily outperform deep learning-based methods, while deep learning-based methods still benefit news recommendation systems in terms of diversity and personalization.</p><p>3) Reply to Q3: DLLM-empowered news recommendation models vs. original news recommendation models: There are four DLLM-empowered news recommendation models such as LSTUR-DLLM, TANR-DLLM, NRMS-DLLM, and NAML-DLLM in Table <ref type="table">IV</ref>. We can observe that DLLM-empowered news recommendation models do not perform superior to the original models on both datasets. This may be because DLLMs are not effectively trained on a small-scale dataset. It is worth noting that a previous study <ref type="bibr" target="#b14">[15]</ref> has demonstrated significant improvements in DLLM-empowered news recommendation models over original models on a large-scale dataset. In addition, we make an interesting observation: DLLM-empowered news recommendation models show apparent improvements in Precision on the Adressa dataset as illustrated in Figure <ref type="figure" target="#fig_1">4</ref>. We assume that DLLM-empowered news recommendation models, such as NAML-DLLM and LSTUR-DLLM, can better capture semantic information from news titles due to the Adressa dataset's emphasis on shallow semantic features, such as titles and keywords.</p><p>In addition, we analyze the performance in terms of diversity and personalization as shown in Table <ref type="table">V</ref> and Table <ref type="table">VI</ref>. We find that most results of DLLM-based news recommendation models illustrate suboptimal performance. In contrast, NRMS-DLLM achieves the best performance in terms of categ div@k on the MIND dataset, while NAML-DLLM demonstrates significant improvements in terms of categ pers@k.</p><p>In summary, the improvements of DLLM-empowered news recommendation models are limited by specific factors, such as dataset scale, while deep learning-based news recommendation models continue to offer benefits for news recommendation.</p><p>4) Reply to Q4: DLLM-based news recommendation models vs. GLLM-based news recommendation models: As shown in Table <ref type="table">IV</ref>, LKPNR exhibits lower performance than MANNeR but still achieves competitive results compared with other baselines. It is evident that using GLLM-based approaches is not necessarily effective compared with DLLM-based news recommendation models. Due to the limitation of time and computing resources, we haven't conducted additional experiments on other datasets and metrics. In the future, we will enrich our experiments and explore more GLLM-based news recommendation models in terms of different metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. FUTURE DIRECTIONS</head><p>LLM-based news recommendation has already achieved state-of-the-art performance over the past time. However, there are some challenges to be Precision@5 Precision@10</p><p>0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 Precision Precision on the MIND dataset Precision@5 Precision@10 Precision Precision on the Adressa dataset NPA LSTUR TANR NRMS NAML CenNewsRec CAUM MINS SentiDebias SentiRec LSTUR-DLLM TANR-DLLM NRMS-DLLM NAML-DLLM MINER MANNeR TABLE V: Comparison of different news recommendation models in terms of personalization and diversity on MIND. Through analyzing these results, we can have a conclusion that LLM-based approaches enhance the performance of news recommendation models in terms of diversity and personalization. The reported values represent the mean and standard deviation derived from five distinct experimental runs. Bold indicates the best experimental results. Underline means the second-best experimental results.</p><p>Model Metric categ div@5 categ div@10 categ pers@5 categ pers@10 sent div@5 sent div@10 sent pers@5 sent pers@10 NPA</p><p>37.05±0.0075 51.09±0.0073 16.96±0.0019 22.69±0.0019 56.67±0.017 67.33±0.0083 25.56±0.0017 34.7±0.0024 LSTUR 29.91±0.0089 43.45±0.009 20.28±0.0056 25.69±0.0043 56.28±0.0179 66.13±0.0087 26.25±0.0024 35.11±0.0021 TANR 35.08±0.006 49.13±0.0041 18.83±0.0025 24.2±0.0022 58.19±0.0051 67.21±0.0019 26.11±0.0018 35.05±0.0023 NRMS 36.57±0.0093 50.97±0.0051 15.15±0.0061 21.34±0.0071 59.44±0.0158 67.2±0.0062 26.07±0.0019 34.97±0.0008 NAML 32.74±0.0046 47.4±0.0046 20.06±0.0027 25.09±0.0026 56.93±0.0066 66.77±0.0041 25.92±0.003 34.99±0.0023 CenNewsRec 36.24±0.008 51.04±0.0034 14.74±0.003 20.73±0.0021 59.07±0.0227 67.02±0.0085 25.92±0.005 35±0.002 CAUM 33.67±0.0073 47.17±0.0026 19.28±0.0032 25.21±0.0033 57.78±0.0125 66.56±0.0077 26.21±0.0022 35.2±0.0011 MINS 32.79±0.0036 46.56±0.0055 19.37±0.0065 24.99±0.0055 56.96±0.0111 66.11±0.0075 26.22±0.0025 35.16±0.002 SentiDebias 41.11±0.0082 53.58±0.0059 14.69±0.0059 20.97±0.004 57.21±0.0295 66.77±0.016 26.29±0.0053 35.01±0.0034 SentiRec 37.49±0.0237 52.02±0.0146 15.08±0.0079 21.16±0.0074 60.68±0.015 68.46±0.0074 25.31±0.0041 34.6±0.0036 LSTUR-DLLM 24.68±0.0232 38.19±0.0174 18.88±0.0074 24.06±0.0064 58.23±0.0298 66.97±0.017 25.72±0.0025 34.53±0.0021 TANR-DLLM 40.17±0.0177 52.09±0.0167 14.03±0.0135 19.7±0.0165 56.46±0.0231 66.03±0.0161 25.13±0.01 33.79±0.01 NRMS-DLLM 44.03±0.0092 54.99±0.0042 14.49±0.0042 20.62±0.0037 59.44±0.0158 67.2±0.0062 26.07±0.0019 34.97±0.0008 NAML-DLLM 25.87±0.0268 39.38±0.022 20.46±0.0079 25.07±0.0078 57.28±0.0149 66.48±0.0084 26.09±0.0039 34.89±0.0038 MINER 42.94±0.0017 54.75±0.0011 15.11±0.0025 21.24±0.0024 60.58±0.0022 68.71±0.001 25.4±0.0018 34.29±0.0017 MANNeR 33.95±0.0147 48.06±0.01 19.4±0.0048 24.63±0.0047 51.09±0.0276 63.99±0.0168 26.32±0.0018 35.1±0.0005</p><p>TABLE VI: Comparison of different news recommendation models in terms of personalization and diversity on Adressa. By comparing deep learning-based news recommendation models with LLM-based news recommendation models in this table, the results demonstrate that general deep-learning methodologies are still effective in processing news data w.r.t. diversity and personalization on Adressa. The reported values represent the mean and standard deviation derived from five distinct experimental runs. Bold indicates the best experimental results. Underline means the second-best experimental results.</p><p>Model Metric categ div@5 categ div@10 categ pers@5 categ pers@10 sent div@5 sent div@10 sent pers@5 sent pers@10 NPA</p><p>26.13±0.0112 31.34±0.0025 27.25±0.0019 33.78±0.0028 52.48±0.0064 60.72±0.0041 33.09±0.0012 41.92±0.0007 LSTUR 23.13±0.0107 24.87±0.0111 30.67±0.0124 37.49±0.0098 51.91±0.0062 59.87±0.0037 33.18±0.0012 41.99±0.0007 TANR 25.41±0.0085 30.05±0.0048 28.43±0.0051 34.91±0.0029 52.29±0.0051 60.64±0.0027 33.13±0.0009 41.94±0.0004 NRMS 27.9±0.0074 31.72±0.0028 26.72±0.0022 34.07±0.0024 52.16±0.0121 60.66±0.0033 33±0.0011 41.88±0.0004 NAML 26.2±0.0195 30.55±0.0223 29.96±0.0117 36.12±0.0118 52.17±0.0045 60.52±0.0027 33.13±0.0007 41.96±0.0006 CenNewsRec 27.91±0.0077 32.11±0.0061 26.29±0.0034 33.76±0.0044 52.44±0.0102 60.69±0.0037 32.96±0.0012 41.87±0.0005 CAUM 27.36±0.0242 30.31±0.0274 28.61±0.0154 35.89±0.011 52.61±0.0073 56.83±0.0836 38.61±0.124 41.93±0.0005 MINS 30.78±0.013 33.11±0.0136 25.41±0.0136 34.13±0.0084 53.35±0.0024 60.75±0.0027 32.88±0.0007 41.87±0.0006 SentiDebias 27.16±0.0052 31.92±0.0044 26.92±0.0019 33.87±0.0018 52.84±0.0044 60.93±0.0042 33.01±0.0006 41.89±0.0008 SentiRec 31.05±0.0027 34.99±0.0035 24.52±0.0023 32.34±0.0018 57.93±0.0055 66.98±0.0035 27.32±0.0035 39.17±0.0011 LSTUR-DLLM 23.43±0.0416 23.45±0.045 28.94±0.0359 38.38±0.015 53.18±0.0021 60.51±0.0025 32.84±0.0006 41.91±0.0003 TANR-DLLM 19.98±0.1262 22.33±0.1623 29.26±0.0877 35.94±0.0695 51.52±0.0236 59.43±0.0181 32.91±0.0045 41.78±0.0035 NRMS-DLLM 26.44±0.0181 32.61±0.016 26.62±0.0096 32.77±0.011 52.77±0.0151 61.07±0.0083 32.87±0.0024 41.68±0.0015 NAML-DLLM 21.65±0.0451 21.9±0.0696 31.78±0.0256 39.6±0.0311 52.66±0.0036 60.17±0.0037 33.03±0.0009 41.97±0.0006 MINER 26.68±0.0218 32.24±0.0132 26.48±0.0077 33.25±0.0068 52.77±0.0124 61.17±0.005 32.92±0.002 41.8±0.0012 MANNeR 25.56±0.0123 30.91±0.0138 28.36±0.0064 34.44±0.0056 51.69±0.0139 60.06±0.0088 33.28±0.0023 42.03±0.0008</p><p>addressed, including datasets, news-oriented modeling, user-oriented modeling, prediction-oriented modeling, and etc. In this section, we discuss several promising directions for news recommendation to guide researchers toward more valuable approaches in the future.</p><p>1) Informative News Recommendation Dataset: News recommendation dataset is necessary for the development of LLM-based news recommender systems. Although several datasets (e.g., MIND, Adressa) are used in news recommendation research, they are insufficient for exploring more comprehensive information such as publisher, image, location, video, and editor. Due to the lack of this important information, the growth of news recommender systems is limited. There are three directions to develop LLM-based news recommendation datasets. Firstly, it is essential to release more informative news recommendation datasets supporting multi-modal and more effective news recommender systems. Second, as news recommender systems continue to grow, more supervised labels are required. For example, fairness-aware news recommendation requires bias labels to support this popular direction. Third, multilingual news recommendation datasets are required to develop multilingual news recommender systems. Although xMIND <ref type="bibr" target="#b88">[89]</ref> is a released multilingual news recommendation dataset, it is a translation of the English MIND dataset <ref type="bibr" target="#b86">[87]</ref> using GLLMs, which compromises the credibility and originality of the source material.</p><p>2) Deep News Modeling: News modeling is a basic and critical component in LLM-based news recommender systems. An effective news encoder is a signal of a superior news recommender system. This is because clicked news contents represent potential user preferences, which contribute to user modeling. The future directions for deep news modeling are as follows. First of all, multi-modal information is required for deep news modeling. For example, image and video information could enhance news representations. Second, multiple aspects of news information need to be applied in news modeling. For instance, information from publishers may influence fairness in LLM-based news recommender systems. Third, structural news representations are required to support a deep understanding of news content. For example, news representations with knowledge graphs could promote understanding of news content.</p><p>3) Deep User Modeling: News recommendation focuses on modeling user preferences and then recommending interested news to users. However, it is difficult to explore accurate and overall user interests. This is because users' preferences are complex and dynamic in the real-world scenario. There are three future directions to improve deep user modeling for LLM-based news recommendation. Firstly, a unified user modeling framework is required in LLM-based news recommender systems. Most research has explored various types of user preferences such as long-and short-term user interests <ref type="bibr" target="#b6">[7]</ref>, intentions <ref type="bibr" target="#b11">[12]</ref>, and multiple interests <ref type="bibr" target="#b7">[8]</ref>. However, there is no unified user modeling framework that supports the representation of various user preferences. Second, LLM-based news recommender systems are required to understand dynamic user preferences. This is because user preferences commonly evolve over time. For example, breaking news can quickly shift users' interests during that period.</p><p>4) Effective Prediction Method: Prediction is a crucial component of news recommender systems, as it determines the outputs of the entire system. It is common for most research <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b56">[57]</ref> to apply MLP and dot-product calculating results in news recommender systems. As far as we are concerned, two future directions are discussed as follows. Firstly, prediction with contrastive learning enables to enhance performance of news recommender systems. This is because contrastive learning excels at maximizing similarity between positive samples while minimizing similarity between negative samples. Second, prediction with casual inference promotes the interpretability and robustness of news recommender systems. Due to the black-box nature of deep learning-based methods, the outputs of news recommender systems lack explainability. Therefore, improving the explainability of predictions has become a crucial direction for future research.</p><p>5) Efficient Training Strategy: LLM-based news recommender systems require a large training time to obtain the best performance. Hence, it is necessary to develop efficient training methods reducing time and resource consumption. There are two future directions to promote training methods. First of all, training with knowledge distillation is required in LLM-based news recommender systems. This is because knowledge distillation helps extract essential information, thereby reducing time and resource consumption. Second, training with metalearning can achieve better performance using less data. Meanwhile, applying meta-learning could help alleviate the cold-start problem in news recommender systems.</p><p>6) Trustworthy LLM-based News Recommender System: Building trustworthy news recommender systems is a crucial future direction, encompassing aspects such as modeling fairness, reducing bias, improving explainability, and ensuring privacy preservation in news recommender systems. It is essential to develop trustworthy news recommender systems due to the incredible out-puts of large language models and deep learning-based methods. Additionally, trustworthy news recommender systems enable to enhance users' experience. For example, most users prefer to know reasons why systems recommend interesting news articles to them. Providing explainability can enhance trust in news recommender systems.</p><p>7) Social-driven LLM-based News Recommender System: Social-driven news recommender systems can be developed by implementing LLMs. This is because LLMs can explore related content on the Internet and then learn users' preferences based on real-world relations. For example, if Tom, who likes the NBA, is shown as Jerry's friend on Facebook, we can infer that Jerry may also like the NBA based on their related online activities. Therefore, leveraging social relationships on the Internet can help systems extract users' latent preferences and build more accurate user profiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>News recommendation is a crucial technology that benefits both individuals and society. A large amount of previous research demonstrates the superiority of deep learning-based news recommender systems compared to statistical machine learning-based methods. With the advancement of large language model technology, news recommendation faces great opportunities and challenges. In order to assist researchers in studying better this field and guide new researchers in the correct direction, we systematically and comprehensively review LLM-based news recommender systems including methodologies, challenges, and future directions. Moreover, we propose a unified research framework to review different research. Notably, it is the first survey to conduct extensive experiments in terms of deeplearning-and LLM-based news recommendation models. Through this survey, we not only illustrate the superiority of LLM-based news recommender systems but also present the effectiveness of deep learning-based news recommender systems. In the future, we will evaluate the diversity and personalization of LLM-based news recommendation models and review more LLM-based news recommendation models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: The tendency of news recommendation papers published between 2015 and 2024, based on Google Scholar data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: The Precision on the MIND and Adressa dataset.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://openai.com/index/gpt-4/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.llama.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://ai.google/discover/palm2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_3"><p>https://github.com/recommenders-team/recommenders</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_4"><p>https://github.com/yusanshi/news-recommendation</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_5"><p>https://github.com/andreeaiana/newsreclib</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_6"><p>https://lightning.ai/docs/pytorch/stable/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_7"><p>https://hydra.cc/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_8"><p>https://github.com/Jyonn/ONCE</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21" xml:id="foot_9"><p>https://github.com/Xuan-ZW/LKPNR</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="22" xml:id="foot_10"><p>The improvement is over the suboptimal performing baseline methods.</p></note>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This should be a simple paragraph before the References to thank those individuals and institutions who have supported your work on this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. REFERENCES SECTION</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">NPA: Neural news recommendation with personalized attention</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<biblScope unit="page" from="2576" to="2584" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Drn: A deep reinforcement learning framework for news recommendation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 world wide web conference</title>
		<meeting>the 2018 world wide web conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Personalized news recommendation: Methods and challenges</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="50" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">DKN: Deep knowledge-aware network for news recommendation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="1835" to="1844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fine-grained interest matching for neural news recommendation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="836" to="845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural news recommendation with topic-aware news representation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1154" to="1159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural news recommendation with long-and short-term user representations</title>
		<author>
			<persName><forename type="first">M</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="336" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">News recommendation via multi-interest news sequence modelling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="page" from="7942" to="7946" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Graph neural news recommendation with long-term and short-term interest modeling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">102142</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural news recommendation with collaborative news encoding and structural user encoding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="46" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Graph neural news recommendation with user existing and potential interest modeling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Intention-aware user modeling for personalized news recommendation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Database Systems for Advanced Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="179" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><surname>Polosukhin</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Fastformer: Additive attention can be all you need</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.09084</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Empowering news recommendation with pre-trained language models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1652" to="1656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multimodal recommender systems: A survey</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3695461</idno>
		<ptr target="https://doi.org/10.1145/3695461" />
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2024-10">Oct. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations</title>
		<meeting>the 2020 conference on empirical methods in natural language processing: system demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A survey on large language models for recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Wide Web</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">60</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13461</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mtrec: Multi-task learning over bert for news recommendation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2663" to="2669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">MINER: Multi-interest matching network for news recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="343" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unitrec: A unified text-to-text transformer and joint contrastive learning framework for text-based recommendation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1160" to="1170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Amm: Attentive multi-field matching for news recommendation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval</title>
		<meeting>the 44th international ACM SIGIR conference on research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1588" to="1592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Newsbert: Distilling pre-trained language model for intelligent news application</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.04887</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unbert: User-news matching bert for news recommendation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3356" to="3362" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generative news recommendation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM on Web Conference 2024</title>
		<meeting>the ACM on Web Conference 2024</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="3444" to="3453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rewriting bias: Mitigating media bias in news recommender systems through automated rewriting</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leavy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Mac</forename><surname>Namee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization</title>
		<meeting>the 32nd ACM Conference on User Modeling, Adaptation and Personalization</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="67" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Lkpnr: Large language models and knowledge graph for personalized news recommendation framework</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers, Materials &amp; Continua</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A survey of personalized news recommendation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="396" to="416" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">A survey on knowledgeaware news recommender systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Iana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Paulheim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="62" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
	<note>Semantic Web</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dan: Deep attention neural network for news recommendation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5973" to="5980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Wg4rec: Modeling textual content with word graph for news recommendation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1651" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Hram: A hybrid recurrent attention machine for news recommendation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Khattar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM international conference on information and knowledge management</title>
		<meeting>the 27th ACM international conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1619" to="1622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Trnews: Heterogeneous user-interest transfer learning for news recommendation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter</title>
		<meeting>the 16th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Main Volume</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="734" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Embedding-based news recommendation for millions of users</title>
		<author>
			<persName><forename type="first">S</forename><surname>Okura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tagami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tajima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<biblScope unit="page" from="1933" to="1942" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Time-aware attentive neural network for news recommendation with long-and shortterm user representation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Science, Engineering and Management: 13th International Conference</title>
		<meeting><address><addrLine>Hangzhou, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">August 28-30, 2020. 2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="76" to="87" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II 13</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">News recommendation with topic-enriched knowledge graphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM international conference on information &amp; knowledge management</title>
		<meeting>the 29th ACM international conference on information &amp; knowledge management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="695" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Weave&amp;rec: A word embedding based 3-d convolutional network for news recommendation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Khattar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM international conference on information and knowledge management</title>
		<meeting>the 27th ACM international conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1855" to="1858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep neural networks for news recommendations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2255" to="2258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Chameleon: a deep learning meta-architecture for news recommender systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>De Souza Pereira Moreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems</title>
		<meeting>the 12th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="578" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Neural news recommendation with multi-head self-attention</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6390" to="6395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Dynamic attention-integrated neural network for session-based news recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gulla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Machine Learning</publisher>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="1851" to="1875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dynamic news recommendation with hierarchical attention network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1456" to="1461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Si-news: Integrating social information for news recommendation with attention-based graph convolutional network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">494</biblScope>
			<biblScope unit="page" from="33" to="42" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Graph enhanced representation learning for news recommendation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><surname>Huang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2863" to="2869" />
		</imprint>
	</monogr>
	<note>in Proceedings of the web conference 2020, 2020</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Joint knowledge pruning and recurrent graph convolution for news recommendation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval</title>
		<meeting>the 44th international ACM SIGIR conference on research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Reinforced anchor knowledge graph generation for news recommendation reasoning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1055" to="1065" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Kred: Knowledge-aware document representation for news recommendations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM conference on recommender systems</title>
		<meeting>the 14th ACM conference on recommender systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="200" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Knowledge-guided article embedding refinement for session-based news recommendation</title>
		<author>
			<persName><forename type="first">H.-S</forename><surname>Sheu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="7921" to="7927" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Neural news recommendation with attentive multi-view learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="3863" to="3869" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Aspect-driven user preference and news representation learning for news recommendation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">307</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Hi-fi ark: Deep user representation via high-fidelity archive network</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="3059" to="3065" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Neural news recommendation with heterogeneous user behavior</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing</title>
		<meeting>the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4874" to="4883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Towards better representation learning for personalized news recommendation: A multi-channel deep fusion approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="3805" to="3811" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">HieRec: Hierarchical user interest modeling for personalized news recommendation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5446" to="5456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Pp-rec: News recommendation with personalized user interest and time-aware news popularity</title>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5457" to="5467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">News recommendation with candidate-aware user modeling</title>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">19171921</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Popularity-enhanced news recommendation with multi-view interest representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1949" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Intention nets: Psychology-inspired user choice behavior modeling for next-basket prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">Z</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Orgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6259" to="6266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Sentirec: Sentiment diversity-aware neural news recommendation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st conference of the Asia-Pacific chapter of the association for computational linguistics and the 10th international joint conference on natural language processing</title>
		<meeting>the 1st conference of the Asia-Pacific chapter of the association for computational linguistics and the 10th international joint conference on natural language processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="44" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Removing ais sentiment manipulation of personalized news delivery</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Humanities and Social Sciences Communications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Fairness-aware news recommendation with decomposed adversarial learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4462" to="4469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A hierarchical and disentangling interest learning framework for unbiased and true news recommendation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="3200" to="3211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Privacypreserving news recommendation model learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.09592</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Efficientfedrec: Efficient federated learning framework for privacypreserving news recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2814" to="2824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">User modeling with click preference and reading satisfaction for news recommendation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="3023" to="3029" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Personal or general? a hybrid strategy with multi-factors for news recommendation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tengfei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Train once, use flexibly: A modular framework for multi-aspect neural news recommendation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Iana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Glavaš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Paulheim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.16089</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Newsreclib: A pytorch-lightning library for neural news recommendation</title>
		<idno type="arXiv">arXiv:2310.01146</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">News recommendation with category description by a large language model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yamana</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.13007</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Once: Boosting content-based recommendation with both open-and closedsource large language models</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM International Conference on Web Search and Data Mining</title>
		<meeting>the 17th ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Modeling user viewing flow using large language models for article recommendation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the ACM on Web Conference 2024</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Tiny-newsrec: Effective and efficient plm-based news recommendation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5478" to="5489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Training large-scale news recommenders with pretrained language models in the loop</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Middha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4215" to="4225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Recprompt: A prompt tuning framework for news recommendation using large language models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lawlor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.10463</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Cherryrec: Enhancing news recommendation quality via llm-driven framework</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.12243</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Streamingrec: a framework for benchmarking stream-based news recommenders</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jugovac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jannach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM conference on recommender systems</title>
		<meeting>the 12th ACM conference on recommender systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="269" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Accurate news recommendation coalescing personal and global temporal preferences</title>
		<author>
			<persName><forename type="first">B</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining: 24th Pacific-Asia Conference, PAKDD 2020</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">May 11-14, 2020. 2020</date>
			<biblScope unit="page" from="78" to="90" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I 24</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Dynamic hierarchical attention network for news recommendation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">255</biblScope>
			<biblScope unit="page">124667</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Fair multistakeholder news recommender system with hypergraph ranking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gharahighehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pliakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">102663</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Lancer: A lifetimeaware news recommender system</title>
		<author>
			<persName><forename type="first">H.-K</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-W</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="4141" to="4148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">News session-based recommendations using deep neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>De Souza Pereira Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Da Cunha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd workshop on deep learning for recommender systems</title>
		<meeting>the 3rd workshop on deep learning for recommender systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="15" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">The plista dataset</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Heintz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 international news recommender systems workshop and challenge</title>
		<meeting>the 2013 international news recommender systems workshop and challenge</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">The adressa dataset for news recommendation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ö</forename><surname>Özgöbek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on web intelligence</title>
		<meeting>the international conference on web intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1042" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">MIND: A large-scale dataset for news recommendation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuhan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3597" to="3606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Npr: a news portal recommendations dataset</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F G</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>De Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NORMalize@ RecSys</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Mind your language: A multilingual dataset for cross-lingual news recommendation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Iana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Glavaš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Paulheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="553" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Eb-nerd a large-scale dataset for news recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kruse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lindskow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kalloori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Polignano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Uppal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Frellsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Recommender Systems Challenge</title>
		<meeting>the Recommender Systems Challenge</meeting>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Mm-rec: Visiolinguistic model empowered multimodal news recommendation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval</title>
		<meeting>the 45th international ACM SIGIR conference on research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2560" to="2564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Legommenders: A comprehensive content-based recommendation library with llm support</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-M</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.15973</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Microsoft recommenders: tools to accelerate developing recommender systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-K</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Conference on Recommender Systems</title>
		<meeting>the 13th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="542" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Recbole: Towards a unified, comprehensive and efficient framework for recommendation algorithms</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4653" to="4664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Spar: Personalized content-based recommendation via long engagement attention</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abdul-Mageed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.10555</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Benchmarking news recommendation in the era of green ai</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the ACM on Web Conference 2024</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="971" to="974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Discrete semantic tokenization for deep ctr prediction</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the ACM on Web Conference 2024</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="919" to="922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Halogen: Fantastic llm hallucinations and where to find them</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ravichander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2501.08292</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Enhancing llm&apos;s ability to generate more repository-aware unit tests through precise contextual information injection</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2501.07425</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Prompt learning for news recommendation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="227" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Prompt-based generative news recommendation (pgnr): Accuracy and controllability</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Malthouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="66" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Multi-agent collaboration framework for recommender systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.15235</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.02552</idno>
		<title level="m">When large language model based agent meets user behavior analysis: A novel user simulation paradigm</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">An efficient recommendation generation using relevant jaccard similarity</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Tiwari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">483</biblScope>
			<biblScope unit="page" from="53" to="64" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

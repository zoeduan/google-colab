<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Knowledge Engineering using Large Language Models</title>
				<funder ref="#_V2rEKep">
					<orgName type="full">EU</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-10-01">1 Oct 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bradley</forename><forename type="middle">P</forename><surname>Allen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lise</forename><surname>Stork</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Groth</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<region>NL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Vrije Universiteit Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<region>NL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<region>NL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Dagstuhl Publishing</orgName>
								<orgName type="institution">TGDK Schloss Dagstuhl -Leibniz-Zentrum für Informatik</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Knowledge Engineering using Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-10-01">1 Oct 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">C9D6943321E0B55CB2AEBA3C17575BE2</idno>
					<idno type="DOI">10.1234/0000000.00000000</idno>
					<idno type="arXiv">arXiv:2310.00637v1[cs.AI]</idno>
					<note type="submission">Received 2023-07-14 Accepted To be completed by Dagstuhl editorial office</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge engineering is a discipline that focuses on the creation and maintenance of processes that generate and apply knowledge. Traditionally, knowledge engineering approaches have focused on knowledge expressed in formal languages. The emergence of large language models and their capabilities to effectively work with natural language, in its broadest sense, raises questions about the foundations and practice of knowledge engineering. Here, we outline the potential role of LLMs in knowledge engineering, identifying two central directions: 1) creating hybrid neuro-symbolic knowledge systems; and 2) enabling knowledge engineering in natural language. Additionally, we formulate key open research questions to tackle these directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2012">ACM Subject Classification</head><p>Computing methodologies → Natural language processing, Computing methodologies → Machine learning, Computing methodologies → Philosophical/theoretical foundations of artificial intelligence, Software and its engineering → Software development methods Keywords and Phrases knowledge engineering, large language models Digital Object Identifier 10.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Knowledge engineering (KE) is a discipline concerned with the development and maintenance of automated processes that generate and apply knowledge <ref type="bibr">[4,</ref><ref type="bibr">93]</ref>. Knowledge engineering rose to prominence in the nineteen-seventies, when Edward Feigenbaum and others became convinced that automating knowledge production through the application of research into artificial intelligence required a domain-specific focus <ref type="bibr">[32]</ref>. The period from the mid-nineteen-seventies into the nineteen-eighties saw the knowledge engineering of rule-based expert systems for the purposes of the automation of decision making in business enterprise settings. By the early nineteen-nineties, however, it became clear that the expert systems approach, given its dependence on manual knowledge acquisition and rule-based representation of knowledge by highly skilled knowledge engineers, resulted in systems that were expensive to maintain and difficult to adapt to changing requirements or application contexts. Feigenbaum argued that, to be successful, future knowledge-based systems would need to be scalable, globally distributed, and interoperable <ref type="bibr">[34]</ref>.</p><p>The establishment of the World Wide Web and the emergence of Web architectural principles in the mid-nineteen-nineties provided a means to address these requirements. Tim Berners-Lee argued for a "Web of Data" based on linked data principles, standard ontologies, and data sharing protocols that established open standards for knowledge representation and delivery on and across the Web <ref type="bibr">[11]</ref>. The subsequent twenty years witnessed the development of a globally federated open linked data "cloud" <ref type="bibr">[13]</ref>, the refinement of techniques for ontology engineering <ref type="bibr">[51]</ref>, and methodologies for the development of knowledge-based systems <ref type="bibr">[86]</ref>. During the same period, increasing use of machine learning and natural language processing techniques led to new means of knowledge production through the automated extraction of knowledge from natural language documents and structured data sources <ref type="bibr">[26,</ref><ref type="bibr">68]</ref>. Internet-based businesses in particular found value in using such technologies to improve access to and discovery of Web content and data <ref type="bibr">[43]</ref>. A consensus emerged around the use of knowledge graphs as the main approach to knowledge representation in the practice of knowledge engineering in both commercial and research arenas, providing easier reuse of knowledge across different tasks and a better developer experience for knowledge engineers <ref type="bibr">[45]</ref>.</p><p>More recently, the increase in the availability of graphical processing hardware for fast matrix arithmetic, and the exploitation of such hardware to drive concurrent innovations in neural network architectures at heretofore unseen scales <ref type="bibr">[106]</ref>, has led to a new set of possibilities for the production of knowledge using large language models (LLMs). LLMs are probabilistic models of natural language, trained on very large corpora of content, principally acquired from the Web. Similiar to previous approaches to language modelling , given a sequence of tokens LLMs predict a probable next sequence of tokens based on a learned probability distribution of such sequences. However, presumably due to the vast amount of content processed in learning and the large size and architecture of the neural networks involved, LLMs exhibit remarkable capabilities for natural language processing that far exceed earlier approaches <ref type="bibr">[60]</ref>.</p><p>These capabilities include the ability to do zero-or few-shot learning across domains <ref type="bibr">[20]</ref>, to generalize across tasks, including the ability to perform domain-independent question answering integrating large amounts of world knowledge <ref type="bibr">[77]</ref>, to generate text passages at human levels of fluency and coherence <ref type="bibr">[28,</ref><ref type="bibr">96]</ref>, to deal gracefully with ambiguity and long-range dependencies in natural language [104], and to reduce or even eliminate the need for manual feature engineering <ref type="bibr">[98]</ref>. LLMs also exhibit the ability to generate and interpret structured and semi-structured information, including programming language code [6, 100], tables <ref type="bibr">[46,</ref><ref type="bibr">53]</ref>, and RDF metadata <ref type="bibr">[106,</ref><ref type="bibr">58,</ref><ref type="bibr">7]</ref>. The generalization of language models (termed "foundation models" by some) to other modalities including images and audio have led to similarly significant advances in image understanding <ref type="bibr">[23,</ref><ref type="bibr">117]</ref>, image generation <ref type="bibr">[38,</ref><ref type="bibr">79,</ref><ref type="bibr">83]</ref>, speech recognition, and text-to-speech generation <ref type="bibr">[78,</ref><ref type="bibr">105]</ref>. Such capabilities have prompted a significant amount of research and development activity demonstrating potential applications of LLMs <ref type="bibr">[66,</ref><ref type="bibr">84,</ref><ref type="bibr">54]</ref>. However, the means of incorporating LLMs into structured, controllable, and repeatable approaches to developing and fielding such applications in production use are only just beginning to be considered in detail <ref type="bibr">[73]</ref>.</p><p>This paper engages with the question of how LLMs can be effectively employed in the context of knowledge engineering. We start by examining the different forms that knowledge can take, both as inputs for constructing knowledge systems and as outputs of such systems. We argue that the distinction between knowledge expressed in natural language (or other evolved, naturally occurring modalities such as images or video) and knowledge expressed in formal languages (for example, as knowledge graphs or rules), sheds light how LLMs can be brought to bear on the development of knowledge systems.</p><p>Based on this perspective, we then describe two potential paths forward. One approach involves treating LLMs as components within hybrid neuro-symbolic knowledge systems. The other approach treats LLMs and prompt engineering [57] as a standalone approach to knowledge engineering 1 , using natural language as the primary representation of knowledge. We then enumerate a set of open research problems in the exploration of these paths. These problems aim to determine the feasibility of and potential approaches to using LLMs with existing KE methodologies, as well XX:3 as the development of new KE methodologies centered around LLMs and prompt engineering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Forms of knowledge and their engineering</head><p>In the history of the computational investigation of knowledge engineering, knowledge has been often treated primarily as symbolic expressions. However, as [39] noted, knowledge is actually encoded in a variety of media and forms, most notably in natural language (e.g. English) but also in images, video, or even spreadsheets. This fact becomes even more apparent when looking at institutional knowledge practices that have developed over centuries, for example, in the sciences or archives <ref type="bibr">[44]</ref>. We now illustrate this point by describing the many ways in which knowledge manifests itself in the context of biodiversity informatics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The multimodal richness of knowledge: an example from biodiversity sciences</head><p>The ultimate goal of biodiversity science is to understand species evolution, variation, and distribution, but finds applications in a variety of other fields such as climate science and policy. At its heart is the collection and observation of organisms, providing evidence for deductions about the natural world <ref type="bibr">[59]</ref>. Such knowledge is inherently multimodal in nature, most commonly appearing in the form of images, physical objects, tree structures and sequences, i.e., molecular data. Historically, organism sightings have been carefully logged in handwritten field diaries to describe species behaviour and environmental conditions. Detailed drawings and later photographs were made to capture colour, organs and other knowledge about an organism's traits used for identification, which is best conveyed visually but which is challenging to preserve in natural specimens. These manuscripts are housed, together with the physical zoological specimens and herbaria which they describe, in museums and collection facilities across the world. Both the multimodal nature of these knowledge sources as well as their distributed nature hamper knowledge integration and synthesis.</p><p>Metadata describes the specimen's provenance: where specimens were found, who found them, and provides an attempt at identifying the type of organism (such as the preserved squid specimen shown in Figure <ref type="figure" target="#fig_0">1</ref>). Such knowledge is paramount, as it allows researchers to understand resources within the context in which they were produced, enabling researchers to carry out ecological studies such as distribution modeling over time.</p><p>For a systematic comparison of the multitude of resources available, the biodiversity sciences have had a long-standing tradition of developing information standards <ref type="bibr">[67]</ref>. From Linnaeus' Systema naturae mid 18th century as well as his formal introduction of zoological nomenclature, taxonomists have started categorizing natural specimens according to tree-like hierarchical structures. The process is challenging, given that biologist up until this day do not have a full picture of all living organisms on earth, and incomplete, naturally evolved and fuzzy knowledge is not easily systematized.</p><p>The development of digital methods has opened up new pathways for comparison and analysis. Gene sequencing technology has lead biologist to the genetic comparison of species, by the calculation of ancestry and construction of evolutionary tree structures in the study of phylogeny <ref type="bibr">[50]</ref>. More importantly, digital methods allowed the transfer of analog resources, such as specimen collection scans [14] and metadata, to the digital world. Such techniques have furthered formalisation and thereby interoperability of collected data through the use of Web standards, such as globally unique identifiers for species names [72] as well as shared vocabularies for data integration across collections <ref type="bibr">[10]</ref>. The Global Biodiversity Information Facility (GBIF) and their data integration toolkit serves as a great example of such integration efforts <ref type="bibr">[97,</ref><ref type="bibr">81]</ref>. Currently, there is a large emphasis on linking up disparate digital resources in the creation of an interconnected network of digital collection objects on the Web, linked up with relevant ecological, environmental and other related data in support of machine actionability (i.e., the ability of computational systems to find, access, interoperate, and reuse data with minimal intervention) for an array of interdisciplinary tasks such as fact-based decision-making and forecasting <ref type="bibr">[41]</ref>.Using data standards for describing and reasoning over collection data can aid researchers counter unwanted biases via transparency. However, making data comply with data standards can also lead to oversimplification or reinterpretation <ref type="bibr">[71]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T G D K</head><p>Machine learning and knowledge engineering strategies can help to (semi-)automatically extract and structure biodiversity knowledge according [102, 91], for instance using state-of-the-art computer vision or natural language processing techniques as well as crowd-sourcing platforms for the annotation of field diaries and other collection objects with formal language [92, 29]. Nevertheless, a bottleneck in the digitization of collections and their use for machine actionability is the amount of work and domain expertise required for the formalisation of such knowledge, and the extraction from unstructured texts, images and video's. Historical resources, i.e. handwritten texts, pose an additional challenge, as they are exceptionally challenging to interpret within the current scientific paradigm <ref type="bibr">[107]</ref>.</p><p>The variety and usefulness of different forms of knowledge both natural and formal and the challenges they pose is not limited to the biodiversity domain as described above. We see the same diversity happening in law [82], medicine [16, 21] and even self-driving vehicles [9]. To summarize:</p><p>domain knowledge is often best represented in a variety of modalities, i.e., images, taxonomies, or free text, each modality with its own data structure and characteristics which should be preserved, and no easy way of integrating, interfacing with or reasoning over multimodal knowledge in a federated way exists; provenance of data is paramount in understanding knowledge within the context in which it was produced; fuzzy, incomplete, or complex knowledge is not easily systematized; using data standards for describing and reasoning over collection data can aid researchers counter unwanted biases via transparency; making data comply with data standards can lead to oversimplification or reinterpretation;</p><p>the production of structured domain knowledge, for instance from images or free text, requires domain expertise, and is therefore labour intensive and costly; knowledge evolves, and knowledge-based systems are required to deal with updates in their knowledge bases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">KE as the transformation of knowledge expressed in natural language into knowledge expressed in a formal language</head><p>This sort of rich and complex array of modalities for the representation of knowledge has traditionally posed a challenge to knowledge engineers <ref type="bibr">[33]</ref>. Much of the literature on knowledge engineering methodology has focused on the ways in which knowledge in these naturally-occurring forms can be recast into a structured symbolic representation, e.g., using methods of knowledge elicitation from subject matter experts [88], for instance by the formulation of competency questions for analysing application ontologies <ref type="bibr">[12]</ref>. One way to think about this is as the process of expressing knowledge presented in a natural, humanly evolved language in a formally-defined language. This notion of the transformation of natural language into a formal language as a means of enabling effective reasoning has a deep history rooted in methodologies developed by analytical philosophers of the early twentieth century [24, 69], but dating even further back to Liebniz's lingua rationalis <ref type="bibr">[35]</ref> and the thought of Ramón Lull <ref type="bibr">[37]</ref>. Catarina Dutilh <ref type="bibr">Novaes [69]</ref> has argued that formal languages enable reasoning that is less skewed by bias and held beliefs, an effect achieved through de-semantification, i.e., the process of replacing terms in a natural language with symbols that can be manipulated without interpretation using a system of rules of transformation. Coupled with sensorimotor manipulation of symbols in a notational system, people can reason in a manner that outstrips their abilities unaided by such a technology. While Dutilh Novaes' analysis focuses on this idea of formal languages as a cognitive tool used by humans directly, e.g. through the manipulation of a system of notation using paper and pencil, she notes that this manipulation of symbols is the route to the mechanization of reasoning through computation. When externally manifested as a function executed by a machine through either interpretation by an inference engine, or through compilation into a machine-level language, this approach of formalization yields the benefits of reliability, greater speed and efficiency in reasoning.</p><p>This idea captures precisely the essence of the practice of knowledge engineering: Starting from sources of knowledge expressed in natural language and other modalities of human expression, through the process of formalization [51, 95], knowledge engineers create computational artifacts embodying this knowledge. These computational artifacts then enable us to reason using this knowledge in a predictable, efficient, and repeatable fashion. This is done either by proxy through the action of autonomous agents, or in the context of human-mediated decision-making processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">LLMs as a general-purpose technology for transforming natural language into formal language</head><p>Until recently, there have been two ways in which this sort of formalization could be performed: through the manual authoring of symbolic/logical representations, e.g., as in the traditional notion of expert systems [34], or through the use of machine learning and natural language processing to extract such representations automatically from natural language text <ref type="bibr">[61]</ref>. But what has become evident with the emergence of LLMs, with their capabilities for language learning and processing, is that they provide a new and powerful type of general purpose tool for mapping T G D K XX:6 Knowledge Engineering using Large Language Models between natural language<ref type="foot" target="#foot_1">foot_1</ref> and formal language, as well as other modalities. LLMs have shown state-of-the-art performance on challenging NLP tasks such as relation extraction <ref type="bibr">[5]</ref> or text abstraction/summarization [114], and have been used to translate between other modalities, such as images and text (called vision-language models [119, 77]) in computer vision tasks, or from natural language to code [113, 47], in which a pretrained task-agnostic language model can be zero-shot and few-shot transferred to perform a certain task <ref type="bibr">[20,</ref><ref type="bibr">52]</ref>. If one accepts the position that KE can be generally described as the process of transforming knowledge in natural language into knowledge in formal language, then it becomes clear that LLMs provide an advance in our ability to perform knowledge engineering tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The use of LLMs in the practice of knowledge engineering: two scenarios</head><p>Given the above discussion, the natural question that arises is: what might be the utility and impact of the use of LLMs for the transformation of natural language into formal language, when applied in the context of the practice of knowledge engineering? When LLMs emerged as a new technology in the mid-2010s, two views of the relationship between LLMs and knowledge bases (KBs) were put forward. One was the LLM can be a useful component for various processes that are part of a larger knowledge engineering workflow (i.e. "LMs for KBs" [3]); the other was that that the LLM is a cognitive artifact that can be treated as a knowledge base in and of itself (i.e., "LMs as KBs" [75]). We exploit this dichotomy to formulate a pair of possible future scenarios for the use of LLMs in the practice of KE. One is to use LLMs as a technology for or tool in support of implementing knowledge tasks that have traditionally been build using older technologies such as rule bases and natural language processing (NLP). Another is to use LLMs to remove the need for knowledge engineers to be fluent in a formal language, i.e., by allowing knowledge for a given knowledge task to be expressed in natural language, and then using prompt engineering as the primary paradigm for the implementation of reasoning and learning. We now explore each of these scenarios in turn, and consider the open research problems that they raise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">LLMs as components or tools used in knowledge engineering</head><p>We illustrate the first scenario through reference to CommonKADS [86], a structured methodology that has been used by knowledge engineers since the early 2000's. CommonKADS is the refinement of an approach to providing a disciplined approach to the development of knowledge systems. This approach saw initial development in the nineteen-eighties as a reaction to both the ad-hoc nature of early expert systems development <ref type="bibr">[111]</ref> and to the frequency of failures in the deployment of expert systems in an organizational context <ref type="bibr">[</ref>34]. Stemming from early work on making expert systems development understandable and repeatable [42], CommonKADS is distinguished from methodologies more focused on ontology development (e.g., NeON [94], Kendall and McGuinness's "Ontology 101" framework [51], and Presutti's ontology design patterns [76])</p><p>in that it provides practical guidance for specification and implementation of knowledge systems components in a broader sense. It attempts to provide a synoptic guide to the full scope of activities involved in the practice of KE, and show how it relates to the activities of the organization in which that engineering is taking place. As such, in the context of this paper we can use it as a framework to explore for what tasks and in what ways LLMs can be used for KE. Some tasks identified by CommonKADS as part of the KE process may remain largely unchanged by the use of LLMs. These include knowledge task identification and project organizational design. But others can involve the use of LLMs. LLMs can assist knowledge engineers and/or knowledge providers in the performance of knowledge engineering tasks. They can also be a means for the implementation of modules performing knowledge-intensive tasks. Examples of these uses include the following:</p><p>Knowledge acquisition and elicitation LLMs can be used to support knowledge acquisition and elicitation in a given domain of interest. Engineers can create prompts that target specific aspects of the domain, using the responses as a starting point for building the knowledge base. Dialogs between LLMs trained using such prompts and knowledge providers, the subject matter experts, can support the review, validation, and refinement of the acquired knowledge <ref type="bibr">[8]</ref>.</p><p>Knowledge organization LLMs can be used to organize the acquired knowledge into a coherent structure using natural language, making it easy to understand and update. Prompt engineering can be used to develop a set of prompts that extract formal language using the LLM, e.</p><p>g., for text to graph generation [40] or vice versa [18, 2]. Moreover, LLMs are used for program synthesis [113, 47], the generation of metadata [56] or for fusing knowledge graphs [118].</p><p>Data augmentation LLMs can be used to generate synthetic training data to aid in testing the knowledge system by evaluating its performance on instances of the specific task <ref type="bibr">[116]</ref>.</p><p>Testing and refinement Feedback from subject matter experts and users can be used to prompt an LLM to refine the natural language knowledge base and improve the system's accuracy and efficiency through self-correction of prompts and tuning of the LLM model settings as needed to optimize the system's performance <ref type="bibr">[110]</ref>.</p><p>Maintenance LLMs can be used to monitor new information and trends, and to then propose new prompts integrating those updates into the knowledge base.</p><p>Consider the CommonKADS knowledge task hierarchy shown in Figure <ref type="figure" target="#fig_1">2</ref>. Synthetic knowledgeintensive tasks, e.g. design or configuration, are amenable to generative approaches [109]; analytic knowledge-intensive tasks can involve LLM components within a hybrid neuro-symbolic knowledge system. A shortcoming of using CommonKADS for our purposes, however, is that it predates the widespread use of machine learning and statistical natural language processing in KE. A number of architectural approaches have since been developed that extend the CommonKADS concepts of a knowledge-intensive task type hierarchy and knowledge module templates. These include modeling the fine-grained data flows and workflows associated with knowledge systems that combine components that ingest, clean, transform, aggregate and generate data, as well as generate and apply models built using machine learning <ref type="bibr">[103,</ref><ref type="bibr">19,</ref><ref type="bibr">27,</ref><ref type="bibr">31,</ref><ref type="bibr">101</ref>]. These architectures are put forward as providing a general framework for composing heterogeneous tools for knowledge representation and inference into a single integrated hybrid neuro-symbolic system. The design pattern notations put forward in recent work <ref type="bibr">[103,</ref><ref type="bibr">101,</ref><ref type="bibr">31</ref>] treat data, models, and symbolic representations as the inputs and outputs of components composed into a variety of knowledge system design patterns. Generalizing these into natural language and formal language inputs and outputs can provide a simple way to extend these design notations to accommodate both LLMs as well as a richer set of knowledge representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T G D K</head><p>XX:8 Knowledge Engineering using Large Language Models </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Knowledge engineering as prompt engineering</head><p>Given that LLMs enable knowledge modeling in natural language, it is conceivable that the programming of knowledge modules could take place entirely in natural language. Consider that prompt programming is "finding the most appropriate prompt to allow an LLM to solve a task" <ref type="bibr">[57]</ref>. One can through this lens view knowledge engineering as the crafting of dialogues in which a subject matter expert (SME) arrives at a conclusion by considering the preceding context and argumentation <ref type="bibr">[80,</ref><ref type="bibr">109,</ref><ref type="bibr">89,</ref><ref type="bibr">60]</ref>. This framing of knowledge engineering as prompt engineering is the second scenario we wish to explore.</p><p>From the perspective of the CommonKADS knowledge-intensive task type hierarchy, this would involve a redefinition of the types and hierarchy to use LLMs and prompt programming design patterns, e.g. as described in <ref type="bibr">[57]</ref>. Several aspects of this redefinition could include: Natural language inference LLMs can be used to build natural language inference engines that use the organized knowledge to perform the specific task by taking input queries and generate output using prompt engineering to guide the LLM towards generating accurate inferences, e.g. using zero-or few-shot chain-of-thought design patterns. The benefit here is that the gap between the knowledge engineer, knowledge provider (the subject matter expert) and the user is smaller since a translation to a formal language (the language of the engineer) is no longer required. Knowledge-intensive task execution through human/machine dialog LLMs can be used to a conversational interface that allows users to interact with the knowledge system and receive task-specific support. Testing and refinement through human/machine dialog Feedback from subject matter experts and users can be used to prompt an LLM to refine the natural language knowledge base and improve the system's accuracy and efficiency through self-correction of prompts and tuning of the LLM model settings as needed to optimize the system's performance.</p><p>One possible benefit of this approach would be that the barrier to adoption of knowledge engineering as a practice could be lowered significantly. Knowledge elicitation could be conducted entirely within natural language, meaning that subject matter experts without training in formal knowledge representations could perform these tasks directly. However, this approach assumes that predictable inference [101] using natural language is satisfactory. The propensity of current LLMs to "hallucinate", i.e., to confabulate facts, is an obstacle to the realization of this idea <ref type="bibr">[48]</ref>. Multiple efforts have been devoted to the creation of prompt programming patterns that address this issue, ranging from chain-of-thought approaches [108] to retrieval-assisted generation, i.e. the augmentation of LLMs with authoritative document indexes and stores <ref type="bibr">[84,</ref><ref type="bibr">65]</ref>. Recent work [73] has described ways in which knowledge graphs as a formal language can be integrated with natural language and LLM-based language processing and reasoning to provide knowledge systems architectures that directly address this issue. [115] surveys work in this direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Open research questions</head><p>Using the scenarios outlined above, we can identify a number of open research questions to be addressed to realize either or both of these two possible approaches to the use of LLMs in knowledge engineering. These questions touch on three general areas: the impact of LLMs on the methodologies used to build knowledge systems, on the architectural design of knowledge systems incorporating and/or based on LLMs, and on the evaluation of such systems. For each of these open questions, we provide a link back to the biodiversity scenario discussed in Section 2.1 denoted by a .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">How can knowledge engineering methodologies best be adapted to use LLMs?</head><p>How can we harmoniously meld the considerable body of work on knowledge engineering methodologies [51, 36, 76, 94, 87, 85, 90] with the new capabilities presented by LLMs? Schreiber's conceptualization of knowledge engineering as the construction of different aspect models of human knowledge [86], as discussed above, offers a framework for further elaboration. The distinctive characteristics of LLMs, coupled with prompt engineering, present unique challenges and opportunities for building agents within a knowledge system, one that is consistent with the CommonKADS approach.</p><p>While the role definitions within KE methodologies might mostly remain the same, the skills required for knowledge engineers will need morphing to adapt to the LLM environment. This evolution of roles calls for an extensive investigation into what these new skills might look like, and how they can be cultivated. Additionally, the adaptability of the various knowledge-intensive task type hierarchies described by CommonKADS and its descendants in the literature on hybrid neuro-symbolic systems (e.g., as described in <ref type="bibr">[19]</ref>) to accommodate LLMs is another fertile area for exploration.</p><p>LLM-based applications, likened to synthetic tasks within these knowledge engineering frameworks, raise compelling research questions regarding accuracy and the prevention of hallucinations. LLM-based applications have a lower bar to reach with respect to notions of accuracy and avoidance of hallucinations, but still must provide useful and reliable guidance to users and practitioners.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T G D K XX:10 Knowledge Engineering using Large Language Models</head><p>Connecting back to the biodiversity domain, answering these questions would provide guidance on the appropriate methodology to adopt when developing a new specimen curation and collection knowledge management system that needs to deal with multimodal assets like handwritten text or images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">How do principles of content and data management apply to prompt engineering?</head><p>Applying content and/or data management principles to collections of prompts and prompt templates, integral to work with LLMs, is an area ripe for exploration. Properly managing these resources could improve efficiency and guide the development of improved methodologies in knowledge engineering. This calls for a rigorous investigation of current data management practices, their applicability to LLMs, and potential areas of refinement. Ensuring the reproducibility of LLM engineering from a FAIR data standpoint [112] is a crucial yet complex challenge. Developing and validating practices and protocols that facilitate easy tracing and reproduction of LLM-based processes and outputs is central to this endeavour. Addressing this challenge will aid researchers in applying LLM engineering in a FAIR way. Doing so is critical for biodiversity research and science in general where precision, reproducibility and provenance are key for knowledge discovery and research integrity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">What are the cognitive norms that govern the conduct of KE?</head><p>A crucial area of inquiry involves the identification and understanding of cognitive norms, as described by <ref type="bibr">Menary [62]</ref>, that govern the practice of knowledge engineering. Cognitive norms are established within a human community of practice as a way of governing the acceptable use of "external representational vehicles to complete a cognitive task" <ref type="bibr">[63]</ref>. As the consumer adoption of LLM technology has progressed, we see a great deal of controversy about when and how it is appropriate to use, e.g. in the context of education or the authoring of research publications. Understanding how these norms shape the use of LLMs in this context is an under-explored field of study. By unravelling the interplay between these cognitive norms and LLM usage, we can gain valuable insights into the dynamics of knowledge engineering practices and possibly foster more effective and responsible uses of LLMs.</p><p>In the biodiversity sciences, this means understanding the cognitive norms specific to the domain, to understand how LLMs can be used in a way that respects the domain's practices and standards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">How do LLMs impact the labor economics of KE?</head><p>A related but distinct question pertains to the impact of LLMs on the economic costs associated with knowledge engineering. The introduction and application of LLMs in this field may significantly alter the economic landscape, either by driving costs down through automation and efficiency or by introducing new costs tied to system development, maintenance, and oversight. Thoroughly exploring these economic implications can shed light on the broader effects of integrating LLMs into knowledge engineering.</p><p>The realm of labor economics as it pertains to hybrid or centaur systems [1], is another area ripe for investigation. Understanding how the deployment of these systems influences labor distribution, skill requirements, and job roles could provide valuable input into the planning and implementation of such technologies. Additionally, it could reveal the potential societal and economic impacts of this technological evolution.</p><p>Developments for LLM-based KE can help mitigate labour of knowledge experts in the biodiversity sciences, for instance by the development of more efficient KE workflows for the digitization of museum specimens or manuscripts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Architecture</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">How can hybrid neuro-symbolic architectural models incorporate</head><p>LLMs?</p><p>Design patterns for hybrid neuro-symbolic systems, as described in [103], offer a structured approach to comprehend the flow of data within a knowledge system. Adapting this model to account for the differences between natural and formal language could significantly enhance our ability to trace and manage data within knowledge systems. A salient research question emerging from this scenario pertains to the actual process of integrating LLMs into knowledge engineering data processing flows <ref type="bibr">[27]</ref>. Understanding the nuances of this process will involve a deep examination of the shifts in methodologies, practices, and the potential re-evaluations of existing knowledge engineering paradigms. The perspective of KE enabled by LLMs as focused on the transformation of natural language into formal language provides insights that can be used to improve the motivation for hybrid neuro-symbolic systems; e.g., [19] references [17] in using dual process theories of reasoning (i.e. the "System 1/System 2" model described in [49]) as a motivation for hybridization in knowledge systems, but more recent analyses [69, 64] cast doubt on the validity of such models, and point to more nuanced perspectives that provide a better grounding for the benefits of hybridization. Addressing these questions would shed light on tasks for which hybridization using LLMs would prove favourable, e.g., image classification of species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">How can prompt engineering patterns support reasoning in natural language?</head><p>One fundamental question that arises is how prompt engineering patterns can be utilized to facilitate reasoning in natural language. Exploring this topic involves understanding the mechanics of these patterns and their implications on natural language processing capabilities of LLMs. This line of research could open new possibilities for enhancing the functionality and efficiency of these models.</p><p>A related inquiry concerns the structure, controllability, and repeatability of reasoning facilitated by LLMs. Examining ways to create structured, manageable, and reproducible reasoning processes within these models could significantly advance our capacity to handle complex knowledge engineering tasks and improve the reliability of LLMs.</p><p>The interaction of LLMs and approaches to reasoning based on probabilistic formalisms is also an underexplored area of research. A particularly evocative effort in this area is that described in <ref type="bibr">[113]</ref>, which describes the use of LLMs to transform natural language into programs in a probabilistic programming language, which can then be executed to support reasoning in a particular problem domain. We note that this work provides an excellent example of the knowledge engineering as the transformation of natural language into formal language perspective and of the impact of LLMs in advancing that perspective. Investigating how to automatically generate and assess other nuanced forms of knowledge within LLMs could lead to a more refined understanding of these models and their capabilities.</p><p>Given that biodiversity knowledge is often best represented in a variety of modalities each with their own data structures and characteristics, research may explore how LLMs can act as T G D K XX:12 Knowledge Engineering using Large Language Models natural language interfaces to such multimodal knowledge bases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">How can we manage bias, trust and control in LLMs using knowledge graphs?</head><p>Trust, control, and bias in LLMs, especially when these models leverage knowledge graphs, are critical areas to explore. Understanding how to detect, measure, and mitigate bias, as well as establish trust and exert control in these models, is an essential aspect of ensuring ethical and responsible use of LLMs. Furthermore, investigating methods to update facts in LLMs serving as knowledge graphs is a crucial area of research. Developing strategies for efficient and reliable fact updating could enhance the accuracy and usefulness of these models.</p><p>Another key question involves understanding how we can add provenance to statements produced by LLMs. This line of research could prove vital in tracking the origin of information within these models, thus enhancing their reliability and usability. It opens the door to more robust auditing and validation practices in the use of LLMs.</p><p>Addressing this challenge can help biodiversity researchers detect and mitigate biases, as use of LLMs might further exacerbate knowledge gaps, e.g., groups of individuals omitted from historical narratives in archival collections. Moreover, novel update mechanisms can aid researchers to reliably update facts or changing knowledge structures learned by LLMs, for instance when domain knowledge evolves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Is extrinsic explanation sufficient?</head><p>A significant area of interest pertains to how we can effectively address the explainability of answers generated using LLMs <ref type="bibr">[30]</ref>. This exploration requires a deep dive into the functioning of LLMs and the mechanisms that govern their responses to prompts. Developing a thorough understanding of these processes can aid in creating transparency and trust in LLMs, as well as fostering their effective use.</p><p>The need for explanation in LLMs also leads to the question of whether extrinsic explanation is sufficient for the purposes of justifying a knowledge system's reasoning, as argued in general for the intelligibility of knowledge systems by Cappelen and Devers [22], or if intrinsic explainability is a necessary requirement [55]. This question calls for a thoughtful exploration of the value and limitations of both extrinsic and intrinsic explanation methodologies, and their implications for the understanding and usage of LLMs. An exciting research avenue arises from the work of Tiddi [99], concerning explainability with formal languages. The exploration of this topic could reveal significant insights into how we can leverage formal languages to enhance the explainability of LLMs. This could pave the way for new methods to increase transparency and intelligibility in these models.</p><p>In the sciences in general, answering these questions would aid explainability of LLMgenerated answers via curated facts, increasing transparency and trust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5">How can LLMs support the engineering of hybrid human/machine knowledge systems?</head><p>Another topic of interest involves exploring the potential of hybrid systems that combine human cognition with machine capabilities within a dialogical framework [64, 70]. As an exciting example of the possibilities for new approaches to human/machine collaboration in this vein, we point to the recent results reported by <ref type="bibr">[74]</ref> on the creation of conversational agents that simulate goaldirected human conversation and collaboration on tasks. One can imagine coupling LLM-based agents with human interlocutors working collaboratively in this manner on specific knowledgeintensive tasks. Understanding how to develop these types of systems, and what their implications might be for the practice of knowledge engineering presents a fertile research line. It requires the careful analysis of human-machine interaction, the study of system design principles, and the investigation of their potential impact.</p><p>Research in this avenue can help mitigate the workload of the knowledge expert, for instance in the elicitation of domain knowledge, or crowdsourcing of annotations from unstructured sources such as herbaria or manuscripts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">How do we evaluate knowledge systems with LLM components?</head><p>The first point of interest involves the evaluation of knowledge-based systems, with a focus beyond just logic. This area calls for innovative methodologies to assess the system's capacity to manage and utilize knowledge efficiently, going beyond traditional logical evaluations. This topic of evaluation naturally extends to the question of how we evaluate ontologies and design patterns within knowledge engineering. Evaluating these aspects would require a deep dive into the structures and mechanisms underpinning these elements, potentially leading to the development of refined evaluation metrics and methodologies.</p><p>Interestingly, the long-standing paradigm of machine learning evaluation, relying on benchmarking against a standard train/test dataset, seems to falter in the era of <ref type="bibr">LLMs [25]</ref>. This presents an intriguing challenge for researchers and engineers alike. It is quite possible that traditional methods may need to be significantly buttressed by methodologies and supporting tools for the direct human evaluation of knowledge system performance. This has implications concerning the cost and speed of evaluation processes, encouraging the rethink of current approaches to perhaps develop new strategies that balance accuracy, cost-effectiveness, and timeliness. Reimagining evaluation methodologies in this new context could provide transformative insights into how we can gain confidence in the reliability engineering of knowledge systems that use LLMs.</p><p>Developments in this direction may aid biodiversity researchers to get a better understanding of the real-world efficacy of employing knowledge-based systems with LLM components in their institutions. One can think of improving access to collections, knowledge discovery, or accuracy in describing institutional knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">What is the relationship between evaluation and explainability?</head><p>Lastly, there is an inherent dependency of evaluation on effective solutions for explainability within knowledge systems. Understanding this relationship could help in the creation of more comprehensive evaluation models that take into account not only the performance of a system but also its explainability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Summary</head><p>In this paper, we have advocated for a reconsideration of the practice and methodology of knowledge engineering in light of the emergence of LLMs. We argued that LLMs allow naturallyoccurring and humanly-evolved means of conveying knowledge to be brought to bear in the automation of knowledge tasks. We described how this can enhance the engineering of hybrid neuro-symbolic knowledge systems, and how this can make knowledge engineering possible by people who do not necessarily have the experience of recasting natural language into formal, structured representation languages. Both of these possibilities will involve addressing a broad</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T G D K</head><p>range of open questions, which we have attempted to outline above. Given the rapid pace of the development of this area of research, it is our earnest hope that the coming months and years will yield results shedding light on these questions.</p><p>ences, 426(1 Computer Cult):91-107, November 1984. doi:10.1111/j.1749-6632.1984.tb16513.x. 34Edward A Feigenbaum. A personal view of expert systems: Looking back and looking ahead. Knowledge Systems Laboratory, Department of Computer Science, Stanford . . . , 1992. 35Dov M Gabbay and John Woods. The rise of modern logic: from Leibniz to Frege. Elsevier, 2004. 36Aldo Gangemi and Valentina Presutti. Ontology design patterns. In Handbook on ontologies, pages 221-243. Springer, 2009. 37Clark Glymour, Kenneth M Ford, and Patrick J Hayes. Ramón lull and the infidels. AI Magazine, 19(2):136-136, 1998. 38Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Communications of the ACM, 63(11):139-144, 2020. 39Paul Groth, Aidan Hogan, Lise Stork, Katherine Thornton, and Vrandečić Denny. Knowledge graphs vs. other forms of knowledge representation. Dagstuhl Reports, 12(9):101-105, 2023. 40Qipeng Guo, Zhijing Jin, Xipeng Qiu, Weinan Zhang, David Wipf, and Zheng Zhang. Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training. arXiv preprint arXiv:2006.04702, 2020. 41Alex R Hardisty, Elizabeth R Ellwood, Gil Nelson, Breda Zimkus, Jutta Buschbom, Wouter Addink, Richard K Rabeler, John Bates, Andrew Bentley, José AB Fortes, et al. Digital extended specimens: Enabling an extensible network of biodiversity data records as integrated digital objects on the internet. BioScience, 72(10):978-987, 2022. 42Frederick Hayes-Roth, Donald A Waterman, and Douglas B Lenat. Building expert systems. Addison-Wesley Longman Publishing Co., Inc., 1983. 43James Hendler, Fabien Gandon, and Dean Allemang. Semantic web for the working ontologist: Effective modeling for linked data, RDFS, and OWL. Morgan &amp; Claypool, 2020. 44Birger Hjørland. What is knowledge organization (ko)? KO Knowledge Organization, 35(2-3):86-101, 2008. 45Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia d'Amato, Gerard de Melo, Claudio Gutierrez, Sabrina Kirrane, José Emilio Labra Gayo, Roberto Navigli, Sebastian Neumaier, et al. Knowledge graphs. ACM Computing Surveys (CSUR), 54(4):1-37, 2021. 46Madelon Hulsebos, Kevin Hu, Michiel Bakker, Emanuel Zgraggen, Arvind Satyanarayan, Tim Kraska, Çagatay Demiralp, and César Hidalgo. Sherlock: A deep learning approach to semantic data type detection. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, pages 1500-1508, 2019. 47Naman Jain, Skanda Vaidyanath, Arun Iyer, Nagarajan Natarajan, Suresh Parthasarathy, Sriram Rajamani, and Rahul Sharma. Jigsaw: Large language models meet program synthesis. In Proceedings of the 44th International Conference on Software Engineering, pages 1219-1231, 2022. 77Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 8748-8763. PMLR, 2021. 78Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. Robust speech recognition via large-scale weak supervision. In International Conference on Machine Learning, pages 28492-28518. PMLR, 2023. 79Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical textconditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022. 80Laria Reynolds and Kyle McDonell. Prompt programming for large language models: Beyond the few-shot paradigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, pages 1-7, 2021. 81Tim Robertson, Markus Döring, Robert Guralnick, David Bloom, John Wieczorek, Kyle Braak, Javier Otegui, Laura Russell, and Peter Desmet. The gbif integrated publishing toolkit: facilitating the efficient publishing of biodiversity data on the internet. PloS one, 9(8):e102623, 2014. 82Víctor Rodríguez-Doncel and Elena Montiel-Ponsoda. Lynx: Towards a legal knowledge graph for multilingual europe. Law Context: A Socio-Legal J., 37:175, 2020. 83Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. Highresolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10684-10695, 2022. 84Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools, 2023. arXiv:2302.04761, doi:10.48550/arXiv.2302.04761. 85Guus Schreiber. Knowledge engineering. Foundations of Artificial Intelligence, 3:929-946, 2008. 86Guus Schreiber, Hans Akkermans, Anjo Anjewierden, Nigel Shadbolt, Robert de Hoog, Walter Van de Velde, and Bob Wielinga. Knowledge engineering and management: the CommonKADS methodology. MIT press, 2000. 87Guus Schreiber and Lora Aroyo. Principles for knowledge engineering on the web. In AAAI Spring Symposium: Symbiotic Relationships between Semantic Web and Knowledge Engineering, pages 78-82, 2008. 88Nigel R Shadbolt, Paul R Smart, J Wilson, and S Sharples. Knowledge elicitation. Evaluation of human work, pages 163-200, 2015. 89Murray Shanahan. Talking about large language models. arXiv preprint arXiv:2212.03551, 2022. 90Steffen Staab and Rudi Studer. Handbook on ontologies. Springer Science &amp; Business Media, 2010. 91Lise Stork. Knowledge extraction from archives of natural history collections. PhD thesis, Ph. D. Dissertation, Leiden University, 2021. 92Lise Stork, Andreas Weber, Eulàlia Gassó Miracle, Fons Verbeek, Aske Plaat, Jaap van den Herik, and Katherine Wolstencroft. Semantic annotation of natural history collections. Journal of Web Semantics, 59:100462, 2019. 93Rudi Studer, V Richard Benjamins, and Dieter Fensel. Knowledge engineering: Principles and methods. Data &amp; knowledge engineering, 25(1-2):161-197, 1998. doi:10.1016/S0169-023X(97) 00056-6. 94Mari Carmen Suárez-Figueroa, Asunción Gómez-Pérez, and Mariano Fernández-López. The neon methodology for ontology engineering. In Ontology engineering in a networked world, pages 9-34. Springer, 2011. 95Mari Carmen Suárez-Figueroa, Asunción Gómez-Pérez, Enrico Motta, and Aldo Gangemi. Introduction: Ontology engineering in a networked world. Springer, 2012. 96Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27, 2014. 97Anders Telenius. Biodiversity information goes public: Gbif at your service. Nordic Journal of Botany, 29(3):378-381, 2011. 98Ian Tenney, Dipanjan Das, and Ellie Pavlick. Bert rediscovers the classical nlp pipeline. arXiv preprint arXiv:1905.05950, 2019. 99Ilaria Tiddi and Stefan Schlobach. Knowledge graphs as tools for explainable machine learning: A survey. Artificial Intelligence, 302:103627, 2022. 100Priyan Vaithilingam, Tianyi Zhang, and Elena L Glassman. Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models. In Chi conference on human factors in computing systems extended abstracts, pages 1-7, 2022. 101Michael van Bekkum, Maaike de Boer, Frank van Harmelen, André Meyer-Vitali, and Annette ten Teije. Modular design patterns for hybrid learning and reasoning systems: a taxonomy, patterns and use cases. Applied Intelligence, 51(9):6528-6546, 2021. 102M.G.J. van Erp. Accessing natural history: Discoveries in data cleaning, structuring, and retrieval. PhD thesis, Tilburg University, 2010. Series: TiCC Ph.D. Series Volume: 13. 103Frank Van Harmelen and Annette ten Teije. A boxology of design patterns for hybrid learning and reasoning systems. arXiv preprint arXiv:1905.12389, 2019. 104Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. 105Chengyi Wang, Sanyuan Chen, Yu Wu, Ziqiang Zhang, Long Zhou, Shujie Liu, Zhuo Chen, Yanqing Liu, Huaming Wang, Jinyu Li, et al. Neural codec language models are zero-shot text to speech synthesizers. arXiv preprint arXiv:2301.02111, 2023. 106Haohan Wang and Bhiksha Raj. On the origin of deep learning. arXiv preprint arXiv:1702.07800, 2017.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 A</head><label>1</label><figDesc>Figure 1 A specimen of the Loligo vulgaris Lamarck, 1798 species from the Naturalis-Zoology and Geology catalogues. a Images free of known restrictions under copyright law (Public Domain Mark 1.0). a https://bioportal.naturalis.nl/nl/specimen/RMNH.MOL.5009890</figDesc><graphic coords="4,96.38,98.65,419.48,147.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2 Hierarchy of knowledge-intensive task types from CommonKADS ([86], p.125)</figDesc><graphic coords="8,108.96,117.70,394.37,236.75" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>As defined by [57], prompt engineering is finding the most appropriate prompt or input text to an LLM to have it solve a given task.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Again, we note that natural language should be read to include all modalities. Hence, the term "foundation model"[15]  to refer to LLMs.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was partially supported by the <rs type="funder">EU</rs>'s <rs type="programName">Horizon Europe research and innovation programme</rs> within the <rs type="projectName">ENEXA</rs> project (grant Agreement no. <rs type="grantNumber">101070305</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_V2rEKep">
					<idno type="grant-number">101070305</idno>
					<orgName type="project" subtype="full">ENEXA</orgName>
					<orgName type="program" subtype="full">Horizon Europe research and innovation programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A research agenda for hybrid intelligence: augmenting human intellect with collaborative, adaptive, responsible, and explainable artificial intelligence</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Balliet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Dignum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guszti</forename><surname>Dignum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antske</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Fokkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koen</forename><surname>Grossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Hindriks</surname></persName>
		</author>
		<author>
			<persName><surname>Hoos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="18" to="28" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Prompting as probing: Using language models for knowledge base construction</title>
		<author>
			<persName><forename type="first">Dimitrios</forename><surname>Alivanistos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Selene</forename><forename type="middle">Báez</forename><surname>Santamaría</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cochez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Kalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emile</forename><surname>Van Krieken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thiviyan</forename><surname>Thanapalasingam</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Sneha Singhania, Tuan-Phong Nguyen, and Simon Razniewski, editors, LM-KBC 2022 Knowledge Base Construction from Pre-trained Language Models 2022, CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A review on language models as knowledge bases</title>
		<author>
			<persName><forename type="first">Millicent</forename><surname>Alkhamissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><surname>Ghazvininejad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.06031</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Identifying and consolidating knowledge engineering requirements</title>
		<author>
			<persName><forename type="first">Filip</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Ilievski</surname></persName>
		</author>
		<author>
			<persName><surname>Joshi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.15124</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fine-tuning pre-trained transformer language models to distantly supervised relation extraction</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Alt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonhard</forename><surname>Hübner</surname></persName>
		</author>
		<author>
			<persName><surname>Hennig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1388" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Program synthesis with large language models</title>
		<author>
			<persName><forename type="first">Augustus</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07732,2021.7</idno>
		<idno>arXiv:2307.07312</idno>
	</analytic>
	<monogr>
		<title level="m">Agnes Axelsson and Gabriel Skantze. Using large language models for zero-shot natural language generation from knowledge graphs</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">PromptSource: An integrated development environment and repository for natural language prompts</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng Xin</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nihal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abheesht</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taewoon</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Fevry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manan</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqing</forename><surname>Santilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srulik</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunjan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Chhablani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maged</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanya</forename><surname>Al-Shaibani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urmish</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Thakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangru</forename><surname>Almubarak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><surname>Tian-Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-demo.9</idno>
		<ptr target="https://aclanthology.org/2022.acl-demo.9" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022-05">May 2022</date>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Self-driving cars: A survey</title>
		<author>
			<persName><forename type="first">Rânik</forename><surname>Badue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Guidolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Vivacqua Carneiro</surname></persName>
		</author>
		<author>
			<persName><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vinicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avelino</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luan</forename><surname>Forechi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Jesus</surname></persName>
		</author>
		<author>
			<persName><surname>Berriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thiago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filipe</forename><surname>Paixao</surname></persName>
		</author>
		<author>
			<persName><surname>Mutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page">113816</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tdwg standards documentation specification</title>
		<author>
			<persName><forename type="first">Roger</forename><surname>Baskauf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanley</forename><surname>Hyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Rees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Sachs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Whitbread</surname></persName>
		</author>
		<author>
			<persName><surname>Wieczorek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biodiversity Information Standards</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The semantic web</title>
		<author>
			<persName><forename type="first">James</forename><surname>Berners-Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ora</forename><surname>Hendler</surname></persName>
		</author>
		<author>
			<persName><surname>Lassila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific american</title>
		<imprint>
			<biblScope unit="volume">284</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="34" to="43" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Evaluating ontologies with competency questions</title>
		<author>
			<persName><forename type="first">Fred</forename><surname>Bezerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filipe</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><surname>Santana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="284" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Tom</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kingsley</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Idehen</surname></persName>
		</author>
		<author>
			<persName><surname>Berners-Lee</surname></persName>
		</author>
		<title level="m">Proceedings of the 17th international conference on World Wide Web</title>
		<meeting>the 17th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="1265" to="1266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">No specimen left behind: industrial scale digitization of natural history collections</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Blagoderov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Kitching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">J</forename><surname>Livermore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><forename type="middle">S</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ZooKeys</title>
		<imprint>
			<biblScope unit="volume">209</biblScope>
			<biblScope unit="page" from="133" to="146" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On the opportunities and risks of foundation models</title>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<idno>abs/2108.07258</idno>
		<ptr target="https://arxiv" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<idno type="DOI">10.48550/arXiv.2108.07258</idno>
		<idno type="arXiv">arXiv:2108.07258</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A review of biomedical datasets relating to drug discovery: a knowledge graph perspective</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">P</forename><surname>Bonner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rowan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ola</forename><surname>Swiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Engkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">Tapley</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hoyt</surname></persName>
		</author>
		<author>
			<persName><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Briefings in Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">404</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Thinking fast and slow in ai</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Booch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lior</forename><surname>Fabiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiran</forename><surname>Horesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Lenchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Linck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keerthiram</forename><surname>Loreggia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Murgesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Mattei</surname></persName>
		</author>
		<author>
			<persName><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="15042" to="15046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">COMET: Commonsense transformers for automatic knowledge graph construction</title>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaitanya</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asli</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1470</idno>
		<ptr target="https://aclanthology.org/P19-1470" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="4762" to="4779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Andreea Iana, Heiko Paulheim, Jan Portisch, Artem Revenko, Annette ten Teije, et al. Combining machine learning and semantic web: A systematic mapping study</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Breit</surname></persName>
		</author>
		<author>
			<persName><surname>Waltersdorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fajar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Ekaputra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Sabou</surname></persName>
		</author>
		<author>
			<persName><surname>Ekelhart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>ACM Computing Surveys</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Language models are fewshot learners. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><surname>Askell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Knowledge-based biomedical data science</title>
		<author>
			<persName><forename type="first">J</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignacio</forename><forename type="middle">J</forename><surname>Tripodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harrison</forename><surname>Pielke-Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><forename type="middle">E</forename><surname>Hunter</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-biodatasci-010820-091627</idno>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Biomedical Data Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="41" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Making AI intelligible: Philosophical foundations</title>
		<author>
			<persName><forename type="first">Cappelen</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Dever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Emerging properties in selfsupervised vision transformers</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishan</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hervé</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9650" to="9660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Carnap and twentieth-century thought: Explication as enlightenment</title>
		<author>
			<persName><surname>Carus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A survey on evaluation of large language models</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jindong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaijie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunxiang</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yidong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.03109</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Data journeys: explaining ai workflows through abstraction. Semantic Web</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Daga</surname></persName>
		</author>
		<author>
			<persName><surname>Groth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Personalized nichesourcing: Acquisition of qualitative annotations from niche communities</title>
		<author>
			<persName><surname>29chris Dijkshoorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Archana</forename><surname>Mieke Hr Leyssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasper</forename><surname>Nottamkandath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myriam</forename><forename type="middle">C</forename><surname>Oosterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lora</forename><surname>Traub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Aroyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wan</forename><forename type="middle">J</forename><surname>Bozzon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geert-Jan</forename><surname>Fokkink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrike</forename><surname>Houben</surname></persName>
		</author>
		<author>
			<persName><surname>Hovelmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UMAP Workshops</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Explainable artificial intelligence: A survey</title>
		<author>
			<persName><forename type="first">Karlo</forename><surname>Došilović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Brčić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikica</forename><surname>Hlupić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 41st International convention on information and communication technology, electronics and microelectronics (MIPRO)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="210" to="0215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">32Edward A Feigenbaum. The art of artificial intelligence: Themes and case studies of knowledge engineering</title>
		<author>
			<persName><forename type="first">Majlinda</forename><surname>Ekaputra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Llugiqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Sabou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiko</forename><surname>Ekelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Paulheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Breit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Revenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kheir</forename><forename type="middle">Eddine</forename><surname>Waltersdorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sören</forename><surname>Farfar</surname></persName>
		</author>
		<author>
			<persName><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Fifth International Joint Conference on Artificial Intelligence<address><addrLine>Boston</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1977">2023. 1977</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="372" to="389" />
		</imprint>
	</monogr>
	<note>Describing and organizing semantic web and machine learning systems in the swemls-kg European Semantic Web Conference</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Survey of hallucination in natural language generation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Feigenbaum ; Ziwei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nayeon</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rita</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiezheng</forename><surname>Frieske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Etsuko</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sci-48</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2023">2023</date>
			<publisher>ACM Computing Surveys</publisher>
		</imprint>
	</monogr>
	<note>Knowledge engineering</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Thinking, fast and slow. macmillan</title>
		<author>
			<persName><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Phylogenetic tree building in the genomic age</title>
		<author>
			<persName><forename type="first">Ziheng</forename><surname>Kapli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximilian</forename><forename type="middle">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><surname>Telford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Genetics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="428" to="444" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Ontology engineering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><forename type="middle">L</forename><surname>Mcguinness</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">Shixiang</forename><forename type="middle">Shane</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Christian</forename><surname>Korini</surname></persName>
		</author>
		<author>
			<persName><surname>Bizer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.00745</idno>
		<title level="m">Column type annotation using chatgpt</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models</title>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arielle</forename><surname>Cheatham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Czarina</forename><surname>Medenilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorie</forename><forename type="middle">De</forename><surname>Sillos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Camille</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Elepaño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rimel</forename><surname>Madriaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giezel</forename><surname>Aggabao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Diaz-Candido</surname></persName>
		</author>
		<author>
			<persName><surname>Maningo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS digital health</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">198</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Rethinking explainability as a dialogue: A practitioner&apos;s perspective</title>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Slack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.01875</idno>
		<ptr target="https://arxiv.org/abs/2202.01875" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Toward keyword generation through large language models</title>
		<author>
			<persName><forename type="first">Minki</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeonhak</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunggu</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><surname>Jung</surname></persName>
		</author>
		<idno type="DOI">10.1145/3581754.3584126</idno>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the 28th International Conference on Intelligent User Interfaces, IUI &apos;23 Companion</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="37" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Data-to-text generation for severely under-resourced languages with gpt-3.5: A bit of help needed from google translate</title>
		<author>
			<persName><forename type="first">Anya</forename><surname>Lorandi</surname></persName>
		</author>
		<author>
			<persName><surname>Belz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.09957</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Naturalists in the field: collecting, recording and preserving the natural world from the fifteenth to the twenty-first century</title>
		<author>
			<persName><surname>Macgregor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Brill</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">A</forename><surname>Mahowald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idan</forename><forename type="middle">A</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Blank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Kanwisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evelina</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><surname>Fedorenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.06627</idno>
		<title level="m">Dissociating language and thought in large language models: a cognitive perspective</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Information extraction meets the semantic web: A survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Martinez-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Lopez-Arevalo</surname></persName>
		</author>
		<idno type="DOI">10.3233/sw-180333</idno>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="255" to="335" />
			<date type="published" when="2020-02">February 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Writing as thinking</title>
		<author>
			<persName><surname>Menary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language sciences</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="621" to="632" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">64Hugo Mercier and Dan Sperber. The enigma of reason</title>
		<author>
			<persName><surname>Menary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dimensions of mind. Phenomenology and the Cognitive Sciences</title>
		<imprint>
			<publisher>Harvard University Press</publisher>
			<date type="published" when="2010">2010. 2017</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="561" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Mialon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Dessì</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoforos</forename><surname>Lomeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ram</forename><surname>Nalmpantis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberta</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><surname>Raileanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Baptiste Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asli</forename><surname>Dwivedi-Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Celikyilmaz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.07842</idno>
		<title level="m">Augmented language models: a survey</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Recent advances in natural language processing via large pre-trained language models: A survey</title>
		<author>
			<persName><forename type="first">Hayley</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elior</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Sulem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Pouran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien</forename><surname>Veyseh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Huu Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Sainz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilana</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Heintz</surname></persName>
		</author>
		<author>
			<persName><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.1145/3605943</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<date type="published" when="2023-06">jun 2023</date>
		</imprint>
	</monogr>
	<note>Just Accepted</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">67Staffan Müller-Wille. Names and numbers:&quot;data&quot; in classical natural history</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="109" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Named entity recognition and relation extraction: State-ofthe-art</title>
		<author>
			<persName><forename type="first">Syed</forename><forename type="middle">Waqar</forename><surname>Nasar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Jaffry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malik</forename><surname>Kamran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Formal languages in logic: A philosophical and cognitive analysis</title>
		<author>
			<persName><forename type="first">Dutilh</forename><surname>Novaes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">70Catarina Dutilh Novaes. The dialogical roots of deduction: Historical, cognitive, and philosophical perspectives on reasoning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Encoding the haunting of an object catalogue: on the potential of digital technologies to perpetuate or subvert the silence and bias of the early-modern archive</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Ortolja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Baird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julianne</forename><surname>Nyhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Scholarship in the Humanities</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="844" to="867" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Biodiversity informatics: the challenge of linking data and the role of shared identifiers</title>
		<author>
			<persName><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Briefings in bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="345" to="354" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Unifying large language models and knowledge graphs: A roadmap</title>
		<author>
			<persName><forename type="first">Linhao</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiapu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xindong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.08302</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">Sung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C O'</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><forename type="middle">J</forename><surname>Brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><surname>Bernstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03442</idno>
		<title level="m">Generative agents: Interactive simulacra of human behavior</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Tim</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01066</idno>
		<title level="m">Language models as knowledge bases? arXiv preprint</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">extreme design with content ontology design patterns</title>
		<author>
			<persName><forename type="first">Enrico</forename><surname>Presutti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aldo</forename><surname>Daga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eva</forename><surname>Gangemi</surname></persName>
		</author>
		<author>
			<persName><surname>Blomqvist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop on Ontology Patterns</title>
		<meeting>Workshop on Ontology Patterns</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Towards a digital infrastructure for illustrated handwritten archives</title>
		<author>
			<persName><forename type="first">Mahya</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Ameryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>Wolstencroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Stork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lambert</forename><surname>Heerlien</surname></persName>
		</author>
		<author>
			<persName><surname>Schomaker</surname></persName>
		</author>
		<idno>ITN-DCH 2017</idno>
	</analytic>
	<monogr>
		<title level="m">Digital Cultural Heritage: Final Conference of the Marie Skłodowska-Curie Initial Training Network for Digital Cultural Heritage</title>
		<meeting><address><addrLine>Olimje, Slovenia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">May 23-25, 2017. 2018</date>
			<biblScope unit="page" from="155" to="166" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Toward general design principles for generative ai applications</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Weisz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><surname>Houde</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.05578</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Chatgpt prompt patterns for improving code quality, refactoring, requirements elicitation, and software design</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quchen</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">C</forename><surname>Spencer-Smith</surname></persName>
		</author>
		<author>
			<persName><surname>Schmidt</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.07839</idno>
		<idno type="arXiv">arXiv:2303.07839</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Kads: A modelling approach to knowledge engineering</title>
		<author>
			<persName><forename type="first">Th</forename><surname>Wielinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jost</forename><forename type="middle">A</forename><surname>Schreiber</surname></persName>
		</author>
		<author>
			<persName><surname>Breuker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge acquisition</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="53" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The FAIR guiding principles for scientific data management and stewardship</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Dumontier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Ijsbrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabrielle</forename><surname>Aalbersberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myles</forename><surname>Appleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arie</forename><surname>Axton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Baak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan-Willem</forename><surname>Blomberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz</forename><surname>Boiten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename><surname>Bonino Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jildau</forename><surname>Bourne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><forename type="middle">J</forename><surname>Bouwman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Brookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mercè</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingrid</forename><surname>Crosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Dillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Dumon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">T</forename><surname>Edmunds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Evelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandra</forename><surname>Finkers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alasdair</forename><forename type="middle">J G</forename><surname>Gonzalez-Beltran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carole</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">S</forename><surname>Goble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaap</forename><surname>Grethe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">A</forename><surname>Heringa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>C 't Hoen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Hooft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruben</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joost</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">J</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maryann</forename><forename type="middle">E</forename><surname>Lusher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Martone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abel</forename><forename type="middle">L</forename><surname>Mons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bengt</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Persson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Rocca-Serra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rene</forename><surname>Roos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susanna-Assunta</forename><surname>Van Schaik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Sansone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Schultes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Sengstag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Slater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morris</forename><forename type="middle">A</forename><surname>Strawn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Swertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Van Der Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Van Mulligen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andra</forename><surname>Velterop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Waagmeester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Wittenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wolstencroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barend</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><surname>Mons</surname></persName>
		</author>
		<idno type="DOI">10.1038/sdata.2016.18</idno>
	</analytic>
	<monogr>
		<title level="m">Scientific Data</title>
		<imprint>
			<date type="published" when="2016-03">March 2016</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">K</forename><surname>Grand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">D</forename><surname>Lew</surname></persName>
		</author>
		<author>
			<persName><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vikash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Mansinghka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><surname>Tenenbaum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.12672</idno>
		<title level="m">From word models to world models: Translating from natural language to the probabilistic language of thought</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Pre-trained language models with domain knowledge for biomedical extractive summarization</title>
		<author>
			<persName><forename type="first">Qianqian</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prayag</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">252</biblScope>
			<biblScope unit="page">109460</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Logical reasoning over natural language as knowledge representation: A survey</title>
		<author>
			<persName><forename type="first">Xinya</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinjie</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><surname>Cambria</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.12023</idno>
		<idno type="arXiv">arXiv:2303.12023</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Gpt3mix: Leveraging large-scale language models for text augmentation</title>
		<author>
			<persName><forename type="first">Min</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongju</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewook</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang-Woo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Woomyeong</forename><surname>Park</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08826</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">Zirui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Legg</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mojtaba</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Seyedhosseini</surname></persName>
		</author>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01917</idno>
		<title level="m">Coca: Contrastive captioners are image-text foundation models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Structure pretraining and prompt tuning for knowledge graph transfer</title>
		<author>
			<persName><forename type="first">Yushan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufeng</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenting</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huajun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3543507.3583301</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2023, WWW &apos;23, page 2581-2590</title>
		<meeting>the ACM Web Conference 2023, WWW &apos;23, page 2581-2590<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Learning to prompt for visionlanguage models</title>
		<author>
			<persName><forename type="first">Jingkang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2337" to="2348" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Assessment on Comprehending Mental Health through Large Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-02-02">2 Feb 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mihael</forename><surname>Arcan</surname></persName>
							<email>mihael@luahealth.io</email>
						</author>
						<author>
							<persName><roleName>Ireland</roleName><forename type="first">Lua</forename><surname>Health</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David-Paul</forename><surname>Niland</surname></persName>
							<email>david-paul@luahealth.io</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">FIONN DELAHUNTY</orgName>
								<orgName type="institution">Lua Health</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Lua Health</orgName>
								<address>
									<settlement>Galway David-Paul Niland</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Fionn Delahunty</orgName>
								<orgName type="institution">Lua Health</orgName>
								<address>
									<settlement>Galway</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Lua Health</orgName>
								<address>
									<settlement>Galway</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Assessment on Comprehending Mental Health through Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-02-02">2 Feb 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">2BD17D48943CA489E49822F301001FA0</idno>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
					<idno type="arXiv">arXiv:2401.04592v2[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>AI</term>
					<term>Large Language Models</term>
					<term>Mental Health</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Mental health challenges pose considerable global burdens on individuals and communities. Recent data indicates that more than 20% of adults may encounter at least one mental disorder in their lifetime. On the one hand, the advancements in large language models have facilitated diverse applications, yet a significant research gap persists in understanding and enhancing the potential of large language models within the domain of mental health. On the other hand, across various applications, an outstanding question involves the capacity of large language models to comprehend expressions of human mental health conditions in natural language.</p><p>This study presents an initial evaluation of large language models in addressing this gap. Due to this, we compare the performance of Llama-2 and ChatGPT with classical Machine as well as Deep learning models. Our results on the DAIC-WOZ dataset show that transformer-based models, like BERT or XLNet, outperform the large language models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Progress in large language models (LLMs) has enabled a wide range of applications, but there remains a substantial research gap in comprehending and improving LLMs' potential in the realm of mental health. Within various applications, an unresolved query pertains to the extent of LLMs' capability to grasp human mental health conditions expressed in natural language. Mental ill-health issues pose a substantial challenge to individuals and communities on a global scale. Recent data indicates that over 20% of adults are likely to encounter at least one mental disorder during their lifetime, with 5.6% experiencing severe psychotic disorders that severely impact their functioning. Moreover, depression and anxiety alone contribute to an annual global economic productivity loss of approximately $1 trillion.</p><p>Over the last ten years, there has been an abundance of research in the fields of natural language processing (NLP) and computational social science aimed at identifying mental ill-health issues using online text data, such as social media content <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref>. However, a majority of these investigations have concentrated on constructing specialised machine learning (ML) models for specific tasks like stress detection <ref type="bibr" target="#b16">[17]</ref> or depression prediction <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b32">33]</ref>. Even conventional pre-trained language models like BERT <ref type="bibr" target="#b11">[12]</ref> necessitate fine-tuning for particular downstream tasks. Some studies have explored multi-task setups <ref type="bibr" target="#b1">[2]</ref>, like simultaneously predicting depression and anxiety, but they are often limited to predefined task sets, offering minimal flexibility <ref type="bibr" target="#b26">[27]</ref>.</p><p>On another front, a separate line of research has explored the use of chatbots in mental health services <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b21">22]</ref>. Most chatbots operate on rule-based systems and could benefit from more advanced models that enhance their capabilities <ref type="bibr" target="#b0">[1]</ref>. Despite the growing body of research aimed at empowering AI for mental ill-health, it is crucial to recognise that existing techniques may inadvertently introduce biases and even provide harmful advice to users <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>Anxiety disorders are marked by an excessive sense of fear and worry, accompanied by related behavioral disturbances. These symptoms are severe enough to cause significant distress or impair daily functioning. There are various types of anxiety disorders, including generalised anxiety disorder (characterised by excessive worrying), panic disorder (defined by panic attacks), social anxiety disorder (involving excessive fear and apprehension in social situations), separation anxiety disorder (involving intense fear or anxiety regarding separation from emotionally significant individuals), and others. Effective psychological interventions are available, and in certain cases, depending on factors like age and the severity of the condition, medication may also be considered as a potential treatment option Depression stands apart from the usual shifts in mood and brief emotional reactions to daily challenges. During a depressive episode, an individual consistently experiences a low mood (such as feeling sad, irritable, or empty) or a diminished capacity to experience pleasure or interest in activities, enduring for the majority of the day, virtually every day, for a minimum of two weeks. Additionally, several other symptoms manifest, which may encompass difficulties in concentration, overwhelming feelings of guilt or diminished self-esteem, a sense of hopelessness about the future, contemplations of death or suicide, disrupted sleep patterns, alterations in appetite or body weight, and heightened fatigue or reduced energy levels. It's crucial to note that individuals with depression face an elevated risk of suicidal thoughts and actions. Fortunately, effective psychological therapies are available, and depending on factors like age and the severity of the condition, medication may also be considered as a viable treatment option.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>To address Major Depressive Disorder (MDD), <ref type="bibr" target="#b10">[11]</ref> proposes a passive diagnostic system that integrates clinical psychology, machine learning, and conversational dialogue systems. Through the use of sequence-to-sequence neural networks, a real-time dialogue system engages individuals, while specialised machine learning classifiers monitor conversations to predict critical depression symptoms. Evaluation results indicate potential advancements in human-like chatbots and depression identification. Despite acknowledging limitations in data representation and a small sample size, the study suggests the possibility of enhancing support for individuals with MDD through real-time communication tools. Similarly, <ref type="bibr" target="#b9">[10]</ref> introduces a deep neural network for predicting PHQ-4 scores (depression and anxiety levels) from written text. Leveraging the Universal Sentence Encoder and a deep learning Transformer neural network, the model demonstrates efficacy in psychometric score prediction. Exploring application to social media data, the study incorporates psycholinguistic features and a multi-dimensional deep neural network, noting challenges related to domain-specificity and generalizability. In addressing MDD, <ref type="bibr" target="#b23">[24]</ref> employs natural language processing to create a neural classifier detecting depression from speech transcripts. By predicting individual depression symptoms, the study utilises a symptom network analysis approach and achieves comparable results to state-of-the-art models in binary diagnosis and depression severity prediction. Similarly, <ref type="bibr" target="#b2">[3]</ref> focuses on toxic workplace communication in emails, introducing ToxiScope, a taxonomy to detect and quantify toxic language patterns. Through annotation tasks and machine learning models, the study reveals insights into implicit and explicit workplace toxicity. The research suggests refining detection methods and exploring correlations between toxicity, power dynamics, and biases in workplace communication for future directions. <ref type="bibr" target="#b18">[19]</ref> explore the potential of objective digital biomarkers in assessing psychiatric disorders.</p><p>By investigating behavioral and physiological signals extracted from remote interviews, the research assesses the complementary information provided by multimodal features. The study derives time series features from four conceptual modes: facial expression, vocal expression, linguistic expression, and cardiovascular modulation. These features are extracted from audio and video recordings of remote interviews, using task-specific and foundation models. Four binary classification tasks are defined, including the detection of clinically-diagnosed psychiatric disorders, major depressive disorder, self-rated depression, and self-rated anxiety. Results indicate statistically significant feature differences between controls and subjects with mental ill-health conditions, with correlations found between features and self-rated depression and anxiety scores. The best unimodal performance is achieved by visual heart rate dynamics, with areas under the receiver-operator curve (AUROCs) ranging from 0.68 to 0.75. Combining multiple modalities enhances performance, yielding AUROCs of 0.72 to 0.82. Task-specific models outperform foundation models, suggesting the effectiveness of specific features. This comprehensive multimodal analysis on 73 subjects, using remotely-recorded telehealth interviews, reveals informative characteristics of clinically diagnosed and self-rated mental health status.</p><p>The study provides early evidence of the utility of multimodal digital biomarkers extracted from low-cost, non-labcontrolled data, offering insights into the most suitable modalities and methods for automated remote mental health assessments.</p><p>Large language models (LLMs), such as GPT-3, GPT-4, and Google's PaLM, show potential to revolutionise psychotherapy by supporting, augmenting, or possibly replacing human-led interventions, addressing challenges in mental healthcare capacity and providing personalised treatments. <ref type="bibr" target="#b27">[28]</ref> offer a roadmap for the responsible application of clinical LLMs in psychotherapy. It provides a technical overview, discusses integration stages with parallels to autonomous vehicle technology, explores potential applications in clinical care, training, and research, and offers recommendations for responsible development and evaluation. While recognizing the promise of LLMs, the paper urges caution, emphasizing the need for psychologists to approach integration with care, educate the public about risks, and actively engage with technologists. It advocates for ongoing monitoring and advocacy for responsible and ethical use of LLMs in psychotherapy to ensure patient well-being. <ref type="bibr" target="#b7">[8]</ref> delves into primary challenges in LLM development for psychological counseling, addressing model hallucination, interpretability, bias, privacy, and clinical effectiveness.</p><p>Practical solutions are suggested based on the authors' experiences. While medical applications of LLMs have been experimented with, superior performance over human doctors is noted alongside evidence of limitations in mental health counseling. AI acceptance in medicine, especially mental ill-health, requires substantial improvements and responsible development. The paper anticipates LLM integration into the medical field, acknowledging increased regulatory scrutiny. Challenges are detailed from academic research, advocating a holistic approach and emphasizing diverse data representation and cautious model fine-tuning. Regulatory bodies are expected to play pivotal roles, demanding evidence of beneficial model use. Despite potential shifts in the AI landscape, leveraging the current paradigm is deemed imperative amid escalating global mental health disorders. The paper underscores the necessity of enhancing existing LLMs for psychological counseling tools, recognizing exceptional benefits despite formidable challenges. <ref type="bibr" target="#b24">[25]</ref> highlight the increasing attention on generative artificial intelligence, particularly large language models (LLMs), and their potential in analyzing extensive medical records for insights into neurology. The paper explores various use cases for LLMs in neurology, including early diagnosis, patient and caregiver support, and assisting clinicians. It acknowledges potential ethical and technical challenges, such as privacy concerns, data security, biases in training data, and the importance of rigorous validation. While recognizing these challenges, the paper emphasises the promising opportunities LLMs present for enhancing the care and treatment of neurologic disorders, underscoring the need for responsible research practices. <ref type="bibr" target="#b34">[35]</ref> addresses the growing significance of social media as a valuable source for automatic mental health analysis, focusing on interpretable models. While recent large language models (LLMs) have been explored for this purpose, their unsatisfactory performance in zero-shot/few-shot scenarios poses challenges. To tackle this, the authors introduce the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset, containing 105K data samples from diverse social media sources. They use ChatGPT to generate explanations and rigorously evaluate correctness, consistency, and quality. The resulting MentaLLaMA, an open-source instruction-following LLM series, achieves stateof-the-art performance, generating ChatGPT-level explanations and displaying strong generalizability to unseen tasks on the IMHI benchmark. The paper contributes a comprehensive dataset and model for interpretable mental health analysis on social media. <ref type="bibr" target="#b33">[34]</ref> present a comprehensive evaluation of various Language Models (LLMs), including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4, in the context of mental ill-health prediction tasks using online text data.</p><p>The experiments cover zero-shot prompting, few-shot prompting, and instruction finetuning, revealing key insights.</p><p>The context enhancement strategy consistently improves performance for all LLMs, and mental health enhancement proves effective for models with a substantial number of trainable parameters. Few-shot prompting consistently boosts model performance, even with just one example per class. Crucially, instruction finetuning across multiple datasets significantly enhances model performance across various mental health prediction tasks. The top finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform larger models like GPT-3.5 and GPT-4, performing on par with the state-of-the-art task-specific model Mental-RoBERTa. An exploratory case study on reasoning capabilities underscores both promising potential and notable limitations of LLMs. The findings are distilled into guidelines for researchers, developers, and practitioners enhancing LLMs' understanding of mental health for downstream tasks. Emphasis is placed on the ethical considerations in this research domain, highlighting that practical deployment of LLMs in mental health applications is currently distant. <ref type="bibr" target="#b3">[4]</ref> focus on fine-tuning an LLM for a specific function in psychology using Reinforcement Learning from Human Feedback (RLHF) and explores its viability. The theoretical foundation of LLMs, RLHF, and the ethical considerations of developing a psychological AI are presented. Previous studies on RLHF and AI in psychology demonstrate the feasibility of the proposed goal. The methodology for training and evaluating the model involves comparing a pre-trained model with the fine-tuned one, whereby the study finds no clear difference between the used models. The study also delves into an ethical framework for a digital psychology assistant, proposing a suitable introduction to the market and the division of responsibilities. The discussion extends to rules and regulations applicable to this research field, emphasizing the need for governments to introduce relevant regulations for AI innovation, encompassing ethics, accountability, and personal data protection. <ref type="bibr" target="#b14">[15]</ref> investigate the capability of Large Language Models (LLMs), specifically Med-PaLM 2, trained on extensive medical knowledge, to predict psychiatric functioning from patient interviews and clinical descriptions without specific training for such tasks. Analyzing 145 depression, 115 PTSD assessments, and 46 clinical case studies across various disorders, the results indicate that Med-PaLM 2 can assess psychiatric functioning effectively. The strongest performance is observed in predicting depression scores (Accuracy range= 0.80 -0.84), which is statistically indistinguishable from human clinical raters. The findings suggest the potential of general clinical language models to flexibly predict psychiatric risk based on free descriptions from both patients and clinicians.</p><p>[20] address the growing interest in utilizing LLMs in mental health research and identifies a lack of a comprehensive benchmark for evaluating their capabilities in this domain. The authors introduce PsyEval, the first benchmark tailored to the unique characteristics of mental ill-health, consisting of six sub-tasks across three dimensions. Eight advanced LLMs are evaluated using PsyEval, revealing significant room for improvement in current LLMs in mental health-related tasks. Notably, GPT-4 shows satisfactory performance in mental health Question-Answering (QA) but still requires advancement. The benchmark highlights performance gaps, particularly in tasks involving disease prediction from social media posts and accurate forecasting of depression and suicide severity in simulated doctor-patient dialogues. The results emphasise the need for further advancements in tailoring language models for mental health applications, and PsyEval is positioned as a valuable tool for assessing and guiding such developments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>Within this section we provide our methods on data preprocessing as well as the predictive models used in this work.</p><p>We further provide insights on leveraging prompts for finetuning the used LLM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Preprocessing</head><p>For every participant in the dataset, there is a corresponding PHQ-4 score that is divided into four variables. These variables align to each of the variables in the PHQ-4 questionaire; Generalised Anxiety Disorder 1 and 2 (GAD-1, GAD-2), Patient Health Questionaire 1 and 2 (PHQ-1 and PHQ-2). GAD 1 and GAD 2 relate to anxiety and PHQ-1 and PHQ-2 relate to depression. One participant may have many messages, but that participant has only one overall PHQ4 score.</p><p>Their score is divided into the four separate categories; GAD-1, GAD-2, PHQ-1 and PHQ-2. As some of the messages were quite short in the dataset, we decided to lengthen the messages to add more contextual information to a PHQ4 score that might be associated with that particular person. We concatenated messages to a maximum of 50 words per observation. We only concatenated messages together that were from the same person. We did not concatenate messages together that were from two different people. After the concatenation step and duplicates and missing values removed, there were 28,186 observations in the training set and 8,710 in the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">XGBoost</head><p>The messages were loaded into a pre-trained Transformer model, which produced a dense vector representation of the text. This vector was then loaded into the XGBoost classifier. We used five-fold cross validation to find the optimal hyperparameters. The best model was selected based on weighted F1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Prompting LLMs</head><p>In order to retrieve a specific response from the LLMs, we prompted the targeted LLMs with five different queries and evaluated each of them on their performance. The variation differed in terms of lexicalised outputs as well as the definitions and length of the promps provided to the LLM. Some initial exploratory experiments led to the formation of templates to structure the prompts that were used. We tailored each prompting strategy to each one of the PHQ or GAD questions. This meant that there was a total of 20 different prompts. Differences between versions of prompts only varied slightly. Some differences were minor, such as using "on a scale of zero to three" in one prompt and "one a scale of 0 to 3" in another. Some prompts were brief (cf. Version 3 in 1), while others were lengthy and included examples of messages that had been evaluated based on specific GAD or PHQ questions within the prompt.</p><p>The goal of the prompts was that the LLM would return a number corresponding to the PHQ or GAD question that the prompt was structured around, whereby we had regular expressions to handle the outputs. These consisted of taking the first digit number out of the string or converting numbers in linguistic format to integers. For example, Version 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GAD-1</head><p>On a scale of zero to three, estimate how anxious this person is with zero being a little anxious and three being incredibly anxious: + TEXT GAD-2</p><p>On a scale of zero to three, estimate how worried this person is with zero being a little worried and three being incredibly worried: + TEXT PHQ-1</p><p>On a scale of zero to three, estimate how depressed this person is with zero being a little depressed and three being incredibly depressed: + TEXT PHQ-2</p><p>On a scale of zero to three, estimate if this person is expressing no interest in previously enjoyed activities with zero being a little and three being incredibly: + TEXT Version 2</p><p>GAD-1 On a scale of 0 to 3, estimate how anxious this person is with 0 being a little anxious and 3 being incredibly anxious: + TEXT GAD-2</p><p>On a scale of 0 to 3, estimate how worried this person is with 0 being a little worried and 3 being incredibly worried: + TEXT PHQ-1</p><p>On a scale of 0 to 3, estimate how depressed this person is with 0 being a little depressed and 3 being incredibly depressed: + TEXT PHQ-2</p><p>On a scale of 0 to 3, estimate if this person is expressing no interest in previously enjoyed activities with 0 being a little and 3 being incredibly: + TEXT Version 3</p><p>GAD-1 On a scale of zero to three, rate the anxiety of this message: + TEXT GAD-2</p><p>On a scale of zero to three, rate the worry in this message: + TEXT PHQ-1</p><p>On a scale of zero to three, rate the depression in this message: + TEXT PHQ-2</p><p>On a scale of zero to three, rate the interest in previously enjoyed activities in this message: + TEXT Version 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GAD-1</head><p>Generalised anxiety disorder is a mental health illness that is defined by people having feelings of excessive anxiety. On a scale of zero to three, rate the anxiety in this message: + TEXT GAD-2</p><p>Generalised anxiety disorder is a mental health illness that is defined by people having feelings of excessive worry. On a scale of zero to three, rate the anxiety in this message: + TEXT PHQ-1</p><p>Depression, or major depressive disorder is a mental health illness that is categorised by people feeling down, depressed or hopeless. On a scale of zero to three, rate the depression in this message: + TEXT PHQ-2</p><p>Depression, or major depressive disorder is a mental health illness that is categorised by people having little interest or pleasure in doing things. On a scale of zero to three, rate the depression in this message: + TEXT Table <ref type="table">1</ref>. Examples for different prompting versions for GAD and PHQ questions.</p><p>if the chatbot responded with "This messages looks like it is showing zero levels of anxiety", then our system would return "0". This was to make it easier to analyse and evaluate.</p><p>Version 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GAD-1</head><p>Generalised anxiety disorder is a mental health illness that is defined by people having feelings of exessive anxiety. The anxiety in this example is rated zero: "like uh a a a guy that likes to see different sights and go different places uh like different i'm a big movie person so i like going to theatres stuff like that try to free myself from the situation to clear my mind usually take a walk or something" The anxiety in this example is rated one: "got stuck out here then i had my baby and i just stayed be doing a little bit of everything a good night's sleep i grew up not getting to know who my mom was out there just on the food basis they like to give you a lotta food" The anxiety in this example is rated two: "it was it was great and now it's just okay i'm hardworking i'm uh i care about everyone i yep i suppose going on a trip to canada with my daughter was very memorable i love la i love the traffic on the four o five i love the beach" The anxiety in this example is rated three: "regret right now is um that's just how she is value we were always what what's the word i'm looking for um also the weather was just it was absolutely awful there and it was just it was very difficulties in my life she's very touchy i would say in." On a scale of zero to three, rate the anxiety in this message: + TEXT</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GAD-2</head><p>Generalised anxiety disorder is a mental health illness that is defined by people having feelings of excessive worry. The worry in this example is rated zero: "i've added that to my life she's a great woman and uh that started a future in in athletics and that's what i wanted to do so i accomplished my goals so at the time it was a great a great thing and it still is a great thing it's" The worry in this example is rated one: "lot of stress every day just everyday stress uh yeah pretty much that's what triggers it play like games like i like to play video games those are fun stuff like that okay thanks eh my family it's just eh we're not like too too close we kinda argue a" The worry in this example is rated three: "guess that and not and then there's you i don't completely lose it for days at a time when i can get really into that and sort of shut out the rest of the world um the music and the the thoughts just kind of it really makes me a" On a scale of zero to three, rate the anxiety in this message: + TEXT</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PHQ-1</head><p>Depression, or major depressive disorder is a mental health illness that is categorised by people feeling down, depressed or hopeless. The depression in this example is rated zero: "like uh a a a guy that likes to see different sights and go different places uh like different i'm a big movie person so i like going to theatres stuff like that try to free myself from the situation to clear my mind usually take a walk or something" The depression in this example is rated one: "of my friend i wish i would've handled his sister a little differently as far as the dirt it has been yes it was uh it's very close um no i have not we've always maintained our friendship um i can't recall one off hand no problem and that's all" The depression in this example is rated two: "fight or anything or yeah any of that my grandma she's always giving me encouragement and um she's a therapist a licensed therapist so she's always you know made it really really um yeah i'm okay yeah um i just try to stay positive i try to think like okay" The depression in this example is rated three: "to my son my son and daughter-in-law and my daughter and i went out to have hawaiian food got together it's always fun to get together we got together at my house on christmas i enjoyed just getting together with them i guess the newness wore off that just have" On a scale of zthat'sero to three, rate the depression in this message: + TEXT</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PHQ-2</head><p>Depression, or major depressive disorder is a mental health illness that is categorised by people having little interest or pleasure in doing things. The depression in this example is rated zero: "like uh a a a guy that likes to see different sights and go different places uh like different i'm a big movie person so i like going to theatres stuff like that try to free myself from the situation to clear my mind usually take a walk or something" The depression in this example is rated one: "of my friend i wish i would've handled his sister a little differently as far as the dirt it has been yes it was uh it's very close um no i have not we've always maintained our friendship um i can't recall one off hand no problem and that's all" The depression in this example is rated two: "um feel uninhibited uninhibited and i was better prepared about three years ago um i was happy that he was safe try not to she has a house i mean a roof over her head to resort to the situation that he was in um because and to have been" The depression in this example is rated three: "i don't sleep well um well i start to like cry a lot and i start to get really irritable um i argued with my mom and sister yesterday it was just something stupid over like yeah i was like okay well this is the problem and it i just" «/SYS» On a scale of zero to three, rate the depression in this message: + TEXT Table <ref type="table">2</ref>. Examples for version 5 prompting for the GAD and PHQ questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">ChatGPT</head><p>For chatGPT, we used the same prompting structure that worked best for Llama-2, which was Version 3 (see Table <ref type="table">1</ref>).</p><p>All other aspects of evaluation and extracting information from the chatbot responses were the same for ChatGPT as it was for Llama-2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL SETUP</head><p>In this section, we provide insights on the models and the dataset used in our work. We further provide information on the questionnaire and the evaluation metrics used to present the outcomes of our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Models</head><p>4.1.1 XGBoost. XGBoost (Extreme Gradient Boosting) <ref type="bibr" target="#b6">[7]</ref> is a machine learning algorithm used for both classification and regression tasks. XGBoost is based on the gradient boosting framework, which is an ensemble learning technique.</p><p>It builds an ensemble of decision trees sequentially, where each tree corrects the errors made by the previous ones.</p><p>The model uses a customizable objective function that needs to be optimised during training. For regression tasks, the objective is often mean squared error (MSE), while for classification tasks, it can be log loss (binary or multiclass).</p><p>To prevent overfitting, XGBoost incorporates L1 (Lasso) and L2 (Ridge) regularization techniques into the objective function. 4.1.3 LLama. LLaMA-1 (Large Language Model Meta AI) <ref type="bibr" target="#b29">[30]</ref> is a series of large language models developed by Meta AI. The initial release included models with varying parameter sizes: 7 billion, 13 billion, 33 billion, and 65 billion parameters. LLaMA employs the Transformer architecture with some architectural differences, including the use of SwiGLU activation functions, rotary positional embeddings, and root-mean-squared layer normalization. The foundational models were trained on a vast dataset comprising 1.4 trillion tokens from various publicly available sources.</p><p>Human annotators were involved in AI alignment by providing prompts and evaluating model outputs, and reinforcement learning from human feedback (RLHF) was employed with a new technique based on Rejection sampling followed by Proximal Policy Optimization (PPO). Additionally, LLaMA aimed to improve multi-turn consistency in dialogues using the "Ghost attention" technique during training to respect system messages throughout conversations. LLaMA-2 <ref type="bibr" target="#b30">[31]</ref> remains mostly consistent with that of LLaMA-1 models, with the notable change being the utilization of 40% more data for training the foundational models. LLaMA-2 encompasses both foundational models and models specifically fine-tuned for dialogues, referred to as LLaMA-2 Chat. Within this work, we leveraged Llama2 model with 13B parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Transformer Models.</head><p>For a comparison to LLMs, we leverage the Transformer models <ref type="bibr" target="#b31">[32]</ref>, which rely on a selfattention mechanism, allowing it to capture contextual dependencies in input sequences efficiently. The model consists of an encoder-decoder structure, with multi-head self-attention layers enabling parallelised processing of input tokens.</p><p>Positional encoding is used to provide information about the token's position in the sequence. The Transformer's attention mechanism facilitates capturing long-range dependencies, making it highly effective for tasks requiring context understanding. Within this work, we compare the BERT and Roberta Transformer models and their distilled versions, i.e. DistilBert and Dsitil-Roberta. In addition to that we leverage the XLNet models as well. The BERT model <ref type="bibr" target="#b12">[13]</ref> is pre-trained on large corpora and can then be fine-tuned for specific natural language processing (NLP) tasks, such as text classification, named entity recognition, and question answering, among others. BERT embeddings have been widely adopted and have significantly improved the state-of-the-art performance in various NLP applications. Distil-BERT <ref type="bibr" target="#b25">[26]</ref> is a distilled version of BERT, offering a more compact and faster alternative for tasks in natural language processing (NLP). Despite having fewer parameters, DistilBERT embeddings can be utilised in various NLP applications, providing a balance between computational efficiency and model performance. RoBERTa <ref type="bibr" target="#b22">[23]</ref>, or Robustly optimised BERT approach, is a variant of the BERT (Bidirectional Encoder Representations from Transformers) model, uses dynamic masking during pre-training, removing the Next Sentence Prediction (NSP) objective, and training with larger mini-batches and learning rates. These modifications result in a more robust and efficient model. XLNet <ref type="bibr" target="#b35">[36]</ref> is a</p><p>Transformer-based language model, which combines ideas from autoregressive language modeling (as seen in models like GPT) and autoencoding (as in BERT) to capture bidirectional context and maintain long-term dependencies in sequences. Instead of predicting the next word in a sentence, XLNet is trained to predict a permutation of the words.</p><p>This approach allows the model to consider bidirectional context while preventing it from seeing the entire context during training, enhancing its ability to capture dependencies.</p><p>For all models, we leverage the base version of the transformer models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">DAIC-WOZ Dataset</head><p>Within this comparison, we leveraged the DAIC-WOZ dataset <ref type="bibr" target="#b15">[16]</ref>, which comprises clinical interviews aimed at aiding the assessment of psychological distress conditions like anxiety, depression, and post-traumatic stress disorder. These interviews were gathered as part of a broader initiative to develop a computer-based system that conducts interviews with individuals and recognises verbal and nonverbal cues associated with mental health issues. Specifically, it encompasses data from Wizard-of-Oz interviews, where an animated virtual interviewer named Ellie, under the control of a human interviewer in a separate location, conducted the interviews. The data, which consists of 189 interaction sessions, each lasting between 7 to 33 minutes, has been originally transcribed and annotated to encompass a range of verbal and non-verbal characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">PHQ-4 estionnaire</head><p>The Patient Health Questionnaire-4 (PHQ-4) <ref type="bibr" target="#b20">[21]</ref> was developed to address the challenge posed by the high prevalence of anxiety and depression in the general population. Since these two mood disorders often co-occur and individuals with these conditions may struggle with fatigue or difficulty concentrating, the PHQ-4 offers a concise and accurate assessment tool. The PHQ-4 consists of four questions, each answered on a four-point Likert-type scale. It serves the purpose of providing a very brief yet precise measurement of the fundamental symptoms associated with depression and anxiety. It combines a two-item measure for depression (PHQ-2), which focuses on core depressive criteria, and a two-item measure for anxiety (GAD-2), both of which have been independently proven to be effective screening tools.</p><p>The total PHQ-4 score complements the scores of these subscales, offering an overall assessment of symptom burden, functional impairment, and disability. While an elevated PHQ-4 score is not diagnostic, it serves as an indicator for further evaluation to confirm the presence or absence of a clinical disorder that requires treatment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Metrics</head><p>Besides analysing the widely used metrics, i.e., weighted precision, recall and F1 for our experiments, we extend our metrics with further metrics in the field of statistics and medicine. Weighted specificity describes the accuracy of a test that reports the presence or absence of a medical condition. It can be useful for "ruling in" disease since the test rarely gives positive results in healthy patients. A test with a specificity of 1.0 will recognise all patients without the disease by testing negative, therefore a positive test result would rule in the presence of the disease. Nevertheless, a negative result from a test with high specificity is not necessarily useful for "ruling out" a disease. As an example, a test that always returns a negative test result will have a specificity of 1.0 because specificity does not consider false negatives. A test like that would return negative for patients with the disease, making it useless for "ruling out" the disease.</p><p>Furthemore, we leverage the Hamming loss and the AUC-ROC Curve. The Hamming loss is a metric used in multilabel classification to quantify the accuracy of predictions by measuring the fraction of incorrectly predicted labels across all instances. It is calculated as the average fraction of incorrectly predicted labels per instance, with a score of 0 indicating perfect predictions and 1 indicating complete misclassification. The Hamming loss accounts for both false positives and false negatives in the predicted label sets, making it a valuable measure for evaluating the overall performance of multi-label classification models. The AUC-ROC (Area Under the Receiver Operating Characteristic Curve) is a graphical representation of a binary classification model's performance across various threshold settings.</p><p>It plots the true positive rate against the false positive rate, illustrating the trade-off between sensitivity and specificity.</p><p>The AUC-ROC value quantifies the model's ability to distinguish between classes, with a higher AUC indicating better overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>Within this section, we provide the insights on evaluating different prompting strategies, as well as how Llama-2 and</p><p>ChatGPT persorm compared to XGBoost and different Transformer models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Llama-2 Prompting</head><p>Leveraging Llama-2, we prompted the LLM with different lexical inputs as seen in Tables <ref type="table">1</ref> and <ref type="table">2</ref>. As seen in Table <ref type="table">3</ref>, we evaluated each GAD and PHQ question separately. For GAD- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Overall Comparison</head><p>We further summarise all best approaches obtained by prompting Llama-2, i.e. prompting version 3, and Distil-RoBERTa, which performed overall best on the GAD and PHQ questions. In addition to that, we evaluate the predictions using XGBoost (see Section 4.1.1) as well as ChatGPT, a commercial LLM built by OpenAI. As seen in Table <ref type="table" target="#tab_0">5</ref>, XGBoost always outperforms all used models in terms of the Hamming loss metric. Comparing Llama-2 with ChatGPT, we observe minor advantages using ChatGPT, which outperforms Llama-2 on the GAD-2, PHQ-1 and PHQ-2 questions.</p><p>Finally, we compare the Distil-RoBERTa transformer model with Llama-2 and ChatGPT. Our study shows that the later outperforms all targeted models for all GAD and PHQ questions in terms of weighted precision, recall and F1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>In conclusion, mental ill-health challenges globally impact a significant portion of the population, highlighting the pressing need for effective interventions. Despite the advancements of large language models in various NLP tasks and their diverse applications, a substantial research gap persists regarding their understanding and optimisation within the realm of mental health. This study addresses this gap by conducting an initial evaluation of large language models, comparing the performance of Llama-2 and ChatGPT with the classical machine and deep learning models. Leveraging Llama-2 and ChatGPT, we explore different prompting strategies and evaluate their effectiveness on GAD and PHQ questions. The results indicate that transformer-based models, such as BERT or XLNet, outperform large language models with a significantly larger parameter set. Notably, Distil-RoBERTa consistently outperforms all models for all GAD and PHQ questions in terms of weighted precision, recall, and F1 score. These findings contribute valuable insights for the future development and application of language models in addressing mental health concerns. Nevertheless the outcomes of our initial study, we will further study large language models and how to adapt them to the challenges in mental ill-health. Due to the sensitive nature of mental health information, we will further analyse biases in training data and the dynamic nature of mental health that are the biggest hurdles in achieving comprehensive and unbiased model performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>4. 1 . 2</head><label>12</label><figDesc>ChatGPT. GPT-3 (Generative Pre-trained Transformer) follows the decoder-only Transformer architecture and employs attention mechanisms, allowing it to focus on the most relevant segments of input text, using an extensive context of 2048 tokens and an unprecedented 175 billion parameters. The model exhibited remarkable zero-shot and few-shot learning capabilities across various tasks. The training data for GPT-3 is primarily sourced from a filtered version of Common Crawl, contributing to 60% of the weighted pre-training dataset, comprising 410 billion bytepair-encoded tokens. Other data sources include 19 billion tokens from WebText2, 12 billion tokens from Books1, 55 billion tokens from Books2, and 3 billion tokens from Wikipedia. GPT-3 was trained on a vast corpus of text and has demonstrated proficiency in programming languages such as CSS, JSX, and Python, among others.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 5 .</head><label>5</label><figDesc>1, prompting Version 3, i.e., On a scale of zero to three, rate the anxiety of this message, showed the best performance in terms of weighted F1, as well in weighted precision, recall, Hamming loss and AUC-ROC. For the specificity metric, version 1 slightly outperforms all other prompting options. For GAD-2, the best F1 score is obtained by various prompting versions, with the highest F1 score of 0.53.Comparison on weighted precision, recall, F1, Hamming loss (HammL) and AUC-ROC (Area Under the Receiver Operating Characteristic Curve for XGBoost, Llama-2, ChatGPT and Distil-Roberta (bold scores represent best result for each metric).</figDesc><table><row><cell>The best specificity for GAD-2 is achieved by version 3 while prompting with version 1 provides the best AUC-ROC</cell></row><row><cell>result. In terms of PHQ-1, the best weighted F1 score is obtained using prompting version 1, while the best precision</cell></row><row><cell>is obtained using version 3 prompting. Similar to the GAD questions, leveraging prompting version 3 for the PHQ-2</cell></row><row><cell>question provided the best results in terms of F1, as well as precision and specificity.</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Transformer Models</head><p>As a comparison to LLMs, we deployed different baseline transformer models, which were fine-tuned on the DAIC-WOZ dataset. Table <ref type="table">4</ref> shows the results for the different GAD and PHQ questions, whereby Distil-Roberta performs best for GAD-1 and GAD-2 in terms of F1. Specificity scores were best using BERT, RoBERTa or XLNet for GAD-1, while for GAD-2, specificity was best using DistilBERT or XLNet.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An overview of the features of chatbots in mental health: A scoping review</title>
		<author>
			<persName><forename type="first">Alaa</forename><forename type="middle">A</forename><surname>Abd-Alrazaq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohannad</forename><surname>Alajlani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Abdallah Alalwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bridgette</forename><forename type="middle">M</forename><surname>Bewick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mowafa</forename><surname>Househ</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijmedinf.2019.103978</idno>
		<ptr target="https://doi.org/10.1016/j.ijmedinf.2019.103978" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Medical Informatics</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page">103978</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Multi-Task Learning for Mental Health using Social Media Text</title>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Benton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.03538[cs.CL]</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Say &apos;YES&apos; to Positivity: Detecting Toxic Language in Workplace Communications</title>
		<author>
			<persName><forename type="first">Moorthy</forename><surname>Meghana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saghar</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Hassan Awadallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weisheng</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.173</idno>
		<ptr target="https://doi.org/10.18653/v1/2021.findings-emnlp.173" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana</title>
		<editor>
			<persName><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Scott</forename><surname>Wen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">-Tau</forename><surname>Yih</surname></persName>
		</editor>
		<meeting><address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">2021. 16-20 November, 2021</date>
			<biblScope unit="page" from="2017" to="2029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Fine-tuning a LLM using Reinforcement Learning from Human Feedback for a Therapy Chatbot Application (Independent thesis Basic level, degree of Bachelor)</title>
		<author>
			<persName><forename type="first">Desiree</forename><surname>Bill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodor</forename><surname>Eriksson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>KTH</publisher>
		</imprint>
		<respStmt>
			<orgName>School of Electrical Engineering and Computer Science (EECS)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Assessing the Usability of a Chatbot for Mental Health Care</title>
		<author>
			<persName><forename type="first">Gillian</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gavin</forename><surname>Megaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Bond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maurice</forename><surname>Mulvenna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Siobhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cherie</forename><surname>Neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Armour</surname></persName>
		</author>
		<author>
			<persName><surname>Mctear</surname></persName>
		</author>
		<editor>Internet Science, Svetlana S. Bodrunova, Olessia Koltsova, Asbjørn Følstad, Harry Halpin, Polina Kolozaridi, Leonid Yuldashev, Anna Smoliarova, and Heiko Niedermayer</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="121" to="132" />
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Can AI Help Reduce Disparities in General Medical and Mental Health Care?</title>
		<author>
			<persName><forename type="first">Irene</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marzyeh</forename><surname>Ghassemi</surname></persName>
		</author>
		<ptr target="https://api.semanticscholar.org/CorpusID" />
	</analytic>
	<monogr>
		<title level="j">AMA journal of ethics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">73498305</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">XGBoost: A Scalable Tree Boosting System</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2939672.2939785</idno>
		<ptr target="https://doi.org/10.1145/2939672.2939785" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>San Francisco, California, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Challenges of Large Language Models for Mental Health Counseling</title>
		<author>
			<persName><forename type="first">Neo</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung</forename></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lennart</forename><surname>Brocki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.13857[cs.CL]</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">CLPsych 2015 Shared Task: Depression and PTSD on Twitter</title>
		<author>
			<persName><forename type="first">Glen</forename><surname>Coppersmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristy</forename><surname>Hollingshead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/W15-1204</idno>
		<ptr target="https://doi.org/10.3115/v1/W15-1204" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality</title>
		<meeting>the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="31" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Passive Diagnosis Incorporating the PHQ-4 for Depression and Anxiety</title>
		<author>
			<persName><forename type="first">Fionn</forename><surname>Delahunty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihael</forename><surname>Arcan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Social Media Mining for Health Applications</title>
		<meeting>the Social Media Mining for Health Applications<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>SMM4H) Workshop</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">First Insights on a Passive Major Depressive Disorder Prediction System with Incorporated Conversational Chatbot</title>
		<author>
			<persName><forename type="first">Fionn</forename><surname>Delahunty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">D</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihael</forename><surname>Arcan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Irish Conference on Artificial Intelligence and Cognitive Science</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>arxiv:1810.04805Comment: 13 pages</idno>
		<ptr target="http://arxiv.org/abs/1810.04805" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://doi.org/10.18653/v1/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<editor>
			<persName><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christy</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thamar</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Facebook language predicts depression in medical records</title>
		<author>
			<persName><forename type="first">Johannes</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raina</forename><forename type="middle">M</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Crutchley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Preoţiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Asch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1802331115</idno>
		<ptr target="https://www.pnas.org/doi/pdf/10.1073/pnas.1802331115" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="11203" to="11208" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Isaac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Galatzer-Levy</surname></persName>
		</author>
		<author>
			<persName><surname>Mcduff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Vivek Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Karthikesalingam</surname></persName>
		</author>
		<author>
			<persName><surname>Malgaroli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.01834[cs.CL]</idno>
		<title level="m">The Capability of Large Language Models to Measure Psychiatric Functioning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Distress Analysis Interview Corpus of human and computer interviews</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gale</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giota</forename><surname>Stratou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Nazarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jill</forename><surname>Boberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Devault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stacy</forename><surname>Marsella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skip</forename><surname>Rizzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2014/pdf/508_Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<editor>
			<persName><forename type="first">Nicoletta</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thierry</forename><surname>Declerck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hrafn</forename><surname>Loftsson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bente</forename><surname>Maegaard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Joseph</forename><surname>Mariani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Asuncion</forename><surname>Moreno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jan</forename><surname>Odijk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stelios</forename><surname>Piperidis</surname></persName>
		</editor>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3123" to="3128" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA)</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Understanding and Measuring Psychological Stress using Social Media</title>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Sharath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anneke</forename><surname>Guntuku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kokil</forename><surname>Buffone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><forename type="middle">C</forename><surname>Jaidka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><forename type="middle">H</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName><surname>Ungar</surname></persName>
		</author>
		<idno>ArXiv abs/1811.07430</idno>
		<ptr target="https://api.semanticscholar.org/CorpusID" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page">53717562</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Detecting depression and mental illness on social media: an integrative review</title>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Sharath</surname></persName>
		</author>
		<author>
			<persName><surname>Guntuku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><forename type="middle">L</forename><surname>David B Yaden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><forename type="middle">H</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><forename type="middle">C</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><surname>Eichstaedt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cobeha.2017.07.005</idno>
		<ptr target="https://doi.org/10.1016/j.cobeha.2017.07.005" />
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="43" to="49" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note>Big data in the behavioural sciences</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multimodal mental health assessment with remote interviews using facial, vocal, linguistic, and cardiovascular patterns</title>
		<author>
			<persName><forename type="first">Zifan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salman</forename><surname>Seyedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Griner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Bahrami Rad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeokhyen</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">O</forename><surname>Cotes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gari</forename><forename type="middle">D</forename><surname>Clifford</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.09.11.23295212</idno>
		<ptr target="https://doi.org/10.1101/2023.09.11.23295212" />
	</analytic>
	<monogr>
		<title level="j">medRxiv</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Haoan</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengyue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenny</forename><forename type="middle">Q</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.09189[cs.CL]</idno>
		<title level="m">PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for Mental Health</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An ultra-brief screening scale for anxiety and depression: The PHQ-4</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kroenke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jbw</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Löwe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychosomatics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="613" to="621" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Designing a Chatbot as a Mediator for Promoting Deep Self-Disclosure to a Real Mental Health Professional</title>
		<author>
			<persName><forename type="first">Yi-Chieh</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naomi</forename><surname>Yamashita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3392836</idno>
		<ptr target="https://doi.org/10.1145/3392836" />
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Hum.-Comput. Interact. 4, CSCW1, Article 31</title>
		<meeting>ACM Hum.-Comput. Interact. 4, CSCW1, Article 31</meeting>
		<imprint>
			<date type="published" when="2020-05">2020. may 2020</date>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<ptr target="http://arxiv.org/abs/1907.11692" />
		<title level="m">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards automatic text-based estimation of depression through symptom prediction</title>
		<author>
			<persName><forename type="first">Kirill</forename><surname>Milintsevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kairit</forename><surname>Sirts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaël</forename><surname>Dias</surname></persName>
		</author>
		<idno type="DOI">10.1186/s40708-023-00185-9</idno>
		<ptr target="https://doi.org/10.1186/s40708-023-00185-9" />
	</analytic>
	<monogr>
		<title level="j">Brain Informatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Large Language Models in Neurology Research and Future Practice</title>
		<author>
			<persName><forename type="first">F</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludy</forename><forename type="middle">C</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rhoda</forename><surname>Paschalidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijaya</forename><forename type="middle">B</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName><surname>Kolachalama</surname></persName>
		</author>
		<idno type="DOI">10.1212/WNL.0000000000207967</idno>
		<ptr target="https://www.neurology.org/doi/pdf/10.1212/WNL.0000000000207967" />
	</analytic>
	<monogr>
		<title level="j">Neurology</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="1058" to="1067" />
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108[cs.CL]</idno>
		<title level="m">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Predicting Depression and Anxiety on Reddit: A Multi-Task Learning Approach</title>
		<author>
			<persName><forename type="first">Shailik</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdulaziz</forename><surname>Alhamadani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lulwah</forename><surname>Alkulaib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang-Tien</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1109/ASONAM55673.2022.10068655</idno>
		<ptr target="https://doi.org/10.1109/ASONAM55673.2022.10068655" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (Istanbul, Turkey) (ASONAM &apos;22)</title>
		<meeting>the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (Istanbul, Turkey) (ASONAM &apos;22)</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="427" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Large language models could change the future of behavioral healthcare: A proposal for responsible development and evaluation</title>
		<author>
			<persName><forename type="first">Elizabeth</forename><forename type="middle">C</forename><surname>Stade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shannon</forename><forename type="middle">Wiltsey</forename><surname>Stirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cody</forename><forename type="middle">L</forename><surname>Boland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">B</forename><surname>Yaden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João</forename><surname>Sedoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Derubeis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robb</forename><surname>Willer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/cuzvr</idno>
		<ptr target="https://doi.org/10.31234/osf.io/cuzvr" />
	</analytic>
	<monogr>
		<title level="j">PsyArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Call to Action on Assessing and Mitigating Bias in Artificial Intelligence Applications for Mental Health</title>
		<author>
			<persName><forename type="first">Adela</forename><forename type="middle">C</forename><surname>Timmons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacqueline</forename><forename type="middle">B</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><forename type="middle">Simo</forename><surname>Fiallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodore</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huong</forename><surname>Phuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quynh</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Ahle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">S</forename><surname>Comer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">La</forename><surname>Princess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brewer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stacy</forename><forename type="middle">L</forename><surname>Frazier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodora</forename><surname>Chaspari</surname></persName>
		</author>
		<idno type="DOI">10.1177/17456916221134490</idno>
		<ptr target="https://doi.org/10.1177/17456916221134490" />
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1062" to="1096" />
			<date type="published" when="2023-09">2023. Sept. 2023</date>
		</imprint>
	</monogr>
	<note>Publisher Copyright: © The Author(s) 2022</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelien</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971[cs.CL]</idno>
		<title level="m">LLaMA: Open and Efficient Foundation Language Models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasmine</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Bikel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Blecher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian Canton</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Esiobu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jude</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedanuj</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Hartshorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saghar</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hakan</forename><surname>Inan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Kardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kerkez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madian</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Kloumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Korenev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punit</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenya</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Liskovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinghai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuning</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushkar</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Molybog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Poulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Reizenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rashi</forename><surname>Rungta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalyan</forename><surname>Saladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Schelten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruan</forename><surname>Silva</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288[cs.CL]</idno>
	</analytic>
	<monogr>
		<title level="m">Open Foundation and Fine-Tuned Chat Models</title>
		<editor>
			<persName><forename type="first">Eric</forename><surname>Michael</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Smith</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ranjan</forename><surname>Subramanian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ellen</forename><surname>Xiaoqing</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Binh</forename><surname>Tan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ross</forename><surname>Tang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Adina</forename><surname>Taylor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jian</forename><surname>Williams</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Puxin</forename><surname>Xiang Kuan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Zheng</forename><surname>Xu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Iliyan</forename><surname>Yan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yuchen</forename><surname>Zarov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angela</forename><surname>Zhang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Melanie</forename><surname>Fan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sharan</forename><surname>Kambadur</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aurelien</forename><surname>Narang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Robert</forename><surname>Rodriguez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sergey</forename><surname>Stojnic</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Edunov</surname></persName>
		</editor>
		<editor>
			<persName><surname>Scialom</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł Ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2017/file/3" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Von Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
	<note>f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Leveraging Collaborative-Filtering for Personalized Behavior Modeling: A Case Study of Depression Detection among College Students</title>
		<author>
			<persName><forename type="first">Xuhai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prerna</forename><surname>Chikersal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janine</forename><forename type="middle">M</forename><surname>Dutcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasaman</forename><forename type="middle">S</forename><surname>Sefidgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Woosuk</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Tumminia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniella</forename><forename type="middle">K</forename><surname>Villalba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheldon</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kasey</forename><forename type="middle">G</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">David</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Afsaneh</forename><surname>Doryab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paula</forename><forename type="middle">S</forename><surname>Nurius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eve</forename><surname>Riskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anind</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Mankoff</surname></persName>
		</author>
		<idno type="DOI">10.1145/3448107</idno>
		<ptr target="https://doi.org/10.1145/3448107" />
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Interact. Mob. Wearable Ubiquitous Technol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2021-03">2021. mar 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data</title>
		<author>
			<persName><forename type="first">Xuhai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingsheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhe</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saadia</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Hendler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marzyeh</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anind</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dakuo</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.14385[cs.CL]</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Kailai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyan</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianqian</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimin</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.13567[cs.CL]</idno>
		<title level="m">MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">XLNet: Generalized Autoregressive Pretraining for Language Understanding</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Neural Information Processing Systems</title>
		<meeting>the 33rd International Conference on Neural Information Processing Systems<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">517</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

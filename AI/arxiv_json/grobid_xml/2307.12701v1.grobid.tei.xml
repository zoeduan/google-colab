<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Leveraging Large Language Models (LLMs) for Process Mining (</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-07-24">24 Jul 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Alessandro</forename><surname>Berti</surname></persName>
							<email>a.berti@pads.rwth-aachen.de</email>
							<affiliation key="aff0">
								<orgName type="department">Process and Data Science Group</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<addrLine>Ahornstrasse 55</addrLine>
									<postCode>52074</postCode>
									<settlement>Aachen</settlement>
									<region>NRW</region>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Process Intelligence</orgName>
								<orgName type="institution">Fraunhofer FIT</orgName>
								<address>
									<addrLine>Schloss Birlinghoven Konrad-Adenauer-Straße</addrLine>
									<postCode>53757</postCode>
									<settlement>Sankt Augustin</settlement>
									<region>NRW</region>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mahnaz</forename><forename type="middle">Sadat</forename><surname>Qafari</surname></persName>
						</author>
						<title level="a" type="main">Leveraging Large Language Models (LLMs) for Process Mining (</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-07-24">24 Jul 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">9508B2A9C98733567CE9EC267A464A74</idno>
					<idno type="arXiv">arXiv:2307.12701v1[cs.DB]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Large Language Models</term>
					<term>Process Mining</term>
					<term>GPT-4</term>
					<term>Querying Language</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This technical report describes the intersection of process mining and large language models (LLMs), specifically focusing on the abstraction of traditional and object-centric process mining artifacts into textual format. We introduce and explore various prompting strategies: direct answering, where the large language model directly addresses user queries; multi-prompt answering, which allows the model to incrementally build on the knowledge obtained through a series of prompts; and the generation of database queries, facilitating the validation of hypotheses against the original event log. Our assessment considers two large language models, GPT-4 and Google's Bard, under various contextual scenarios across all prompting strategies. Results indicate that these models exhibit a robust understanding of key process mining abstractions, with notable proficiency in interpreting both declarative and procedural process models. In addition, we find that both models demonstrate strong performance in the object-centric setting, which could significantly propel the advancement of the object-centric process mining discipline. Additionally, these models display a noteworthy capacity to evaluate various concepts of fairness in process mining. This opens the door to more rapid and efficient assessments of the fairness of process mining event logs, which has significant implications for the field.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table">1</ref>: Simple example of a traditional event log Event logs are pivotal to process mining, representing empirical data that drives operations such as process discovery, conformance checking, and model enhancement. Extracted from information systems, these logs comprise collections of events, each characterized by an activity and timestamp and associated with a particular process. As primary artifacts, event logs provide a robust basis for data-driven process analysis.</p><p>Traditional event logs adhere to a format where each event is tied to a specific case, signifying a unique execution of the process. Every event is defined by its activity-representing the operation performed, and a timestamp-indicating when the operation took place. The Extensible Event Stream (XES) standard <ref type="bibr" target="#b5">Acampora et al (2017)</ref> has been established for storing and exchanging these event logs, facilitating systematic documentation and analysis of process events. An example of traditional event logs is reported in Table <ref type="table">1</ref>. We have three cases. For Case1, we have three events with activities A,B,C. For Case2, we have two events with activities A and B. For Case3, we have three events with activities A,C,D. Table <ref type="table">2</ref>: Simple example of an object-centric event log Object-centric event logs, on the other hand, cater to more complex scenarios by associating each event with multiple objects of different types. Each event still holds information about its activity and timestamp, but instead of relating to a single process execution, it ties into multiple entities. The OCEL standard <ref type="bibr" target="#b23">Ghahfarokhi et al (2021)</ref> has been proposed as a standard for the storage of object-centric event logs, capturing detailed interaction patterns between diverse process entities. An example is reported in Table <ref type="table">2</ref>. For example, we see that the event with identifier Event1 is related to one object of type order, two objects of type order item, and one object of type invoice.</p><p>Object-centric event logs allow for the capture of complex, intertwined, multi-object scenarios, opening avenues for more nuanced process mining tasks. However, the complexity of these logs presents unique challenges for process mining, such as how to structure the data for analysis. A significant stride has been made in addressing these challenges with the proposal by <ref type="bibr">Adams et al.</ref> in their 2022 study <ref type="bibr" target="#b7">Adams et al (2022b)</ref> to partition object-centric event logs into "executions". Their methodology, inspired by traditional case-oriented process mining, breaks down the intricate graph structure of object-centric event logs into manageable "process executions", effectively the equivalent of cases in traditional event logs. By extending the case concept to object-centric data, the authors enable a more refined application of process mining tasks to these logs, enabling practitioners to query specific aspects of a process. Furthermore, through the application of graph isomorphism, they are able to identify equivalent process executions with respect to an attribute, thereby discovering object-centric variants. This approach offers a method for handling the complexities inherent in object-centric event logs without resorting to flattening the data, thereby preserving information and structure. As example, the object-centric event log in Table <ref type="table">2</ref> is split in four distinct connected components <ref type="bibr">( {Order1,</ref><ref type="bibr">Item1,</ref><ref type="bibr">Item2,</ref><ref type="bibr">Invoice1},</ref><ref type="bibr">{Order2,</ref><ref type="bibr">Item3,</ref><ref type="bibr">Invoice2},</ref><ref type="bibr">{Order3,</ref><ref type="bibr">Item5,</ref><ref type="bibr">Item6,</ref><ref type="bibr">Invoice3},</ref><ref type="bibr">{Order4,</ref><ref type="bibr">Item8,</ref><ref type="bibr">Invoice4} )</ref>.</p><p>Activity A (3) Activity B (2) 2 Activity C (2) 1 1 ■ 1 Activity D (1) 1 1 1 • 3 Frequency Annotation Activity A Activity B 22m Activity C 30m 15m ■ 1 Activity D 15m 1 1 • 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance Annotation</head><p>Fig. <ref type="figure">1</ref>: Example directly-follows graph (DFG) computed on the event log described in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Procedural Process Models</head><p>Procedural process models, as a fundamental tool in process mining, systematically depict the order of activities and their interrelations within a process. These models capture the idea that some activities must precede others, clearly indicating the sequence or procedure that needs to be followed to attain a particular outcome. They represent a step-by-step visualization of a process, guiding us from the beginning to the end, hence the name 'procedural.' In such models, each step is contingent on the output of the preceding one, reinforcing a precise flow of tasks in a process. Now, let's delve into some common types of procedural process models.</p><p>Activity B Activity A ■ Activity C Activity D</p><p>• Fig. <ref type="figure">2</ref>: Example Petri net obtained from the event log described in Table <ref type="table">1</ref> using the Inductive miner process discovery algorithm <ref type="bibr" target="#b32">Leemans et al (2013)</ref>.</p><p>A primary example of a procedural process model is the directly-follows graph (DFG) <ref type="bibr" target="#b3">van der Aalst (2016)</ref>. This model encapsulates the succession relationship between activities, where an edge from activity A to activity B signifies that B has directly followed A in the process. DFGs provide an intuitive, visual way to comprehend the sequence of activities in a process and can be an effective starting point for process discovery. An example of a directly-follows graph, annotated with frequency and performance information, is reported in Figure <ref type="figure">1</ref>.</p><formula xml:id="formula_0">Activity A X X Activity B X X</formula><p>Activity C X X Activity D Fig. <ref type="figure">3</ref>: Example BPMN model obtained from the event log described in Table <ref type="table">1</ref> using the Inductive miner process discovery algorithm <ref type="bibr" target="#b32">Leemans et al (2013)</ref>.</p><p>In the realm of formal procedural process models, Petri nets have gained wide acceptance in process mining van der Aalst (1998). They offer a graphical and mathematical modelling tool well suited to capture concurrency, synchronization and shared resources. In a Petri net, places (represented as circles) can contain tokens, and transitions (represented as rectangles) can consume and produce these tokens, in line with predefined rules.</p><p>Different process discovery algorithms have Petri nets as eventual output, including the Alpha van der <ref type="bibr" target="#b4">Aalst et al (2004)</ref>, the Inductive <ref type="bibr" target="#b32">Leemans et al (2013)</ref> and the Heuristics <ref type="bibr" target="#b50">Weijters and Ribeiro (2011)</ref> miners. An example of Petri net model, discovered from Table <ref type="table">1</ref> using the Inductive miner, is presented in Figure <ref type="figure">2</ref>.</p><p>Another common procedural modelling notation used in business process management is the Business Process Model and Notation (BPMN 2.0 Aagesen and Krogstie (2015)). It is a rich, graphical representation for specifying business processes in a business process model, offering a more extensive set of symbols compared to Petri nets, thereby allowing more precise business communication <ref type="bibr" target="#b27">Kalenkova et al (2017</ref><ref type="bibr" target="#b28">Kalenkova et al ( , 2019))</ref>. However, the expressiveness of BPMN can lead to ambiguity due to the potential for different interpretations of its constructs <ref type="bibr" target="#b19">Dijkman et al (2008)</ref>; <ref type="bibr" target="#b36">Ouyang et al (2006)</ref>. An example of BPMN model is represented in Figure <ref type="figure">3</ref>. We also provide an example of BPMN 2.0 XML<ref type="foot" target="#foot_0">foot_0</ref> .</p><p>In the realm of object-centric process mining, procedural process models extend their scope to encapsulate the multiple object types involved in a process. This leads to the creation of two key variants: object-centric directlyfollows graphs and object-centric Petri nets. An object-centric directly-follows  <ref type="table">2</ref>. Different annotations (i.e., frequency and performance) are computed <ref type="bibr" target="#b11">Berti and van der Aalst (2023)</ref>.</p><p>graph Berti and van der Aalst (2023) represents a direct evolution from the traditional directly-follows graph, with each object type having its own graph portraying the succession of activities involving that particular object. This collation of graphs offers a nuanced view of the process, maintaining the simplicity of the traditional format. On the other hand, the object-centric Petri net van der Aalst and <ref type="bibr" target="#b4">Berti (2020)</ref> extends traditional Petri nets to capture the lifecycle of each individual object type within the process. Each object type is represented by its own Petri net, and their integration forms the objectcentric Petri net. This detailed representation provides a comprehensive view of the process, accounting for the interactions between the multiple object types. These models provide a powerful means for analyzing complex, objectcentric processes, enabling an in-depth understanding of the process from the perspective of individual object types and their interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Declarative Process Models</head><p>Declarative process models provide a different perspective compared to the traditional procedural process models. While procedural models specify the explicit sequence of activities in a process, declarative models describe the process through a set of constraints or rules that prescribe what cannot happen, leaving a degree of flexibility for what can happen.</p><p>A common notation used for declarative modeling in the process mining field is the DECLARE framework <ref type="bibr" target="#b34">Maggi et al (2011)</ref>. It targets the controlflow perspective of a process by specifying constraints on the sequence, choice, and parallelism of activities. For instance, a DECLARE model can express that if activity 'A' happens, then activity 'B' must eventually follow, capturing the interdependence between activities.</p><p>Source Activity Target Activity Average Time Standard Deviation Activity A Activity B 1350.0 636.40 Activity A Activity C 1800.0 0.00 Activity B Activity C 900.0 0.00 Activity A Activity D 2700.0 0.00 Activity C Activity D 900.0 0.00</p><p>Table 3: Temporal profile model <ref type="bibr" target="#b46">Stertz et al (2020)</ref> for the traditional event log presented in Table <ref type="table">1</ref>.</p><p>Furthermore, declarative process models extend beyond control-flow constraints to capture other aspects of the process. Temporal declarative models incorporate temporal constraints into the process <ref type="bibr" target="#b46">Stertz et al (2020)</ref>; <ref type="bibr" target="#b10">Barrientos et al (2023)</ref>, providing further refinement on when activities should occur. Data-driven declarative models integrate data conditions to determine the valid sequence of activities, thus introducing a context-sensitive dimension to the process model. An example temporal model is presented in Table <ref type="table">3</ref>.</p><p>Overall, declarative process models offer a flexible and holistic approach to process modeling, allowing for a wide range of scenarios and conditions to be incorporated, thereby addressing the complex, dynamic nature of many real-world processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Extraction of Numerical Features</head><p>Feature extraction is a fundamental process in transforming raw event log data into a format that machine learning algorithms can interpret and learn from. In the context of process mining, feature extraction plays a significant role in various tasks, including predictive process monitoring, anomaly detection, and process enhancement, among others de <ref type="bibr" target="#b33">Leoni et al (2016)</ref>.</p><p>The primary strategy to convert an event log into numeric features is through the use of encoding techniques such as one-hot encoding. In this strategy, each unique activity in the event log is assigned a distinct binary (0 or 1) feature, thus creating a binary vector representation for each case in the log. This enables machine learning algorithms to effectively capture and learn the presence or absence of specific activities within each case. This transformation is crucial since machine learning algorithms primarily work with numeric data. A numeric feature table computed on the traditional event log in Table <ref type="table">1</ref> is presented in Table <ref type="table">4</ref>.</p><p>Apart from the straightforward one-hot encoding, more advanced feature extraction methods can be considered. For instance, there are aggregate features that summarize specific characteristics of a case, like the total number of events, the mean time between events, or the standard deviation of the time between events. Another advanced technique is sequence encoding, where the order of activities is preserved. This is particularly beneficial when the sequence of activities is of paramount importance to the process. Other techniques include using n-grams <ref type="bibr" target="#b51">Zandkarimi et al (2020)</ref>, which capture sequences of 'n' consecutive activities, or using methods from natural language processing, such as word embeddings <ref type="bibr" target="#b26">Junior et al (2020)</ref>, to encode activities and their context within the case.</p><p>Case ID Activity A Activity B Activity C Activity D Count Total Duration Case1 1 1 1 0 3 30 Case2 1 1 0 0 2 30 Case3 1 0 1 1 3 45</p><p>Table 4: Numeric feature table for the traditional event log presented in Table <ref type="table">1</ref>.</p><p>In the realm of object-centric event logs, numeric feature extraction expands to accommodate the complexity and multidimensionality of these logs. Features are designed to represent the intricate dynamics involving multiple object types, their interactions, and temporal associations <ref type="bibr">Berti et al (2023a)</ref>; <ref type="bibr">Adams et al (2022a)</ref>. A numeric feature table computed on the object-centric event log in Table <ref type="table">2</ref> is presented in Table <ref type="table">5</ref>.</p><p>Activity features from object-centric event logs encapsulate the actions occurring on specific objects or types of objects. For each unique activity, a binary indicator or count variable can be created to signify whether a particular activity has occurred or how often it has taken place on each object. This not only helps encapsulate the inherent processes but also provides a granular understanding of different object types' behaviors.</p><p>Inter-object features delve into the relationships between different objects in an object-centric log. When objects of different types consistently appear together, a feature is devised to symbolize this co-occurrence. This might be a binary flag signaling the presence of such a relationship or a count of the frequency of these interactions, offering insight into patterns of object interdependencies and interplay.</p><p>Temporal features are instrumental in encapsulating the timing aspects associated with events. For each object type, these can include the timestamp of the first or last event, the mean time between events, or the overall duration of processes involving the object. The temporal features help shed light on the pace and sequence of events across different objects, an essential aspect of understanding the overall process flow.</p><formula xml:id="formula_1">Order Activity A Activity B Activity C Activity D Related Items Related Invoices Order1 1 1 0 0 2 1 Order2 1 1 1 0 2 1 Order3 1 0 1 1 2 1 Order4 1 1 0 0 2 1</formula><p>Table <ref type="table">5</ref>: Numeric feature table (for the object type Order ) derived from the object-centric event log presented in Table <ref type="table">2</ref>.</p><p>Finally, data attribute features cater to any additional attributes tied to the events or objects themselves. If an event or object comes with associated data attributes such as cost or resource allocation, these attributes can be incorporated as features. This inclusion ensures any vital context-specific or process-related information is not overlooked during the feature extraction process Qafari and van der Aalst (2021), thereby enhancing the explanatory power of the derived features.</p><p>By generating suitable features from event logs, we can create informative inputs for machine learning algorithms, enhancing their ability to model and predict complex process behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Fairness Concepts in Process Mining</head><p>Fairness in process mining is a central theme of increasing importance <ref type="bibr" target="#b41">Qafari and van der Aalst (2019)</ref>. In essence, it aims to ensure that the algorithms and models developed based on event data do not unfairly favor or disadvantage certain instances or groups. This is crucial because process mining techniques are often used to inform operational decisions and business strategies that can significantly impact people and resources. For example, they may be used to optimize workflows, allocate resources, or make predictive decisions. If these models or algorithms are biased or unfair, the resulting decisions can be unjust, leading to significant negative consequences. Therefore, maintaining fairness in process mining is not just an ethical imperative, but also a necessary condition for building trust and ensuring the overall sustainability of business processes. Fairness in process mining can be thought of as a continuum that spans from the individual to the group level, incorporating notions of procedural and counterfactual fairness along the way <ref type="bibr" target="#b38">Pohl et al (2022)</ref>.</p><p>At the individual level, fairness centers on ensuring that every case in a process is treated equitably. This could involve examining each instance independently to determine whether the same rules and decisions were applied consistently. For example, in a loan application process, individual fairness would imply that each application is evaluated based on the same set of criteria and not influenced by irrelevant attributes such as the applicant's race or gender.</p><p>Progressing towards the group level, fairness becomes about ensuring equitable outcomes across different groups within a process. This could mean analyzing whether certain groups are systematically disadvantaged compared to others. For example, in an employee onboarding process, group fairness would imply that new hires from all backgrounds receive equal access to resources and opportunities for training and development.</p><p>The notion of procedural fairness emphasizes the importance of the process itself being fair, beyond merely the outcomes it produces. Procedural fairness is concerned with the transparency, consistency, and unbiased nature of the processes. For instance, in a complaint handling process, procedural fairness would mean that all complaints are handled following the same, predefined steps and procedures without any bias.</p><p>Counterfactual fairness Qafari and van der Aalst (2021) introduces a more complex, hypothetical element into the fairness equation. It considers whether the outcome of a process would have been the same had an irrelevant attribute been different. For example, in an employee promotion process, counterfactual fairness would mean that an employee's promotion decision would have been the same, irrespective of their gender.</p><p>One of the key challenges in the development of fairness-oriented techniques in process mining is the scarcity of publicly available event logs that feature fairness concerns. Such data sets are crucial for testing and refining techniques. They not only provide a ground truth against which the effectiveness of methods can be evaluated, but also highlight the real-world complexities and nuances that such techniques need to handle. Currently, the only public collection of simulated event logs that are designed to exhibit fairness issues is provided in <ref type="bibr">Pohl and Berti (2023)</ref>. These logs and their characteristics are described in detail in the paper <ref type="bibr">Pohl et al (2023)</ref>. This availability gap underlines the need for greater openness and collaboration in the field, and the importance of creating and sharing more such resources, so as to advance the development and validation of fairness-oriented process mining techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>In the forthcoming section, we unpack our unique approach to leveraging large language models for process mining tasks. Initially, we focus on developing textual abstractions for process mining artifacts Section 2.1, a vital foundation for enabling the language model's comprehension of processrelated entities. This step includes particular emphasis on process models and event logs Section 2.1.1 Section 2.1.2. Subsequently, we delineate various prompting strategies Section 2.2 to guide the model in problem resolution. These strategies span from direct answering to multi-prompt answering, and even generation of database queries Section 2.2.1 Section 2.2.2 Section 2.2.3. Through an effective synergy between these components, we navigate the nuanced landscape of process mining with large language models, ensuring efficient analysis and meaningful insights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Textual Abstractions of Process Mining Artifacts</head><p>In order to leverage the capabilities of Large Language Models (LLMs) for process mining, we need to convert process mining artifacts into a format that these models can understand and interpret effectively. The initial and crucial step in this transformation process is the textual encoding of these artifacts. The goal of this encoding is to convey the essential information embedded in the artifacts while maintaining the constraints imposed by the context window of the LLM.</p><p>Listing 1: Textual abstraction of the directly-follows graph presented in Figure <ref type="figure">1</ref> (obtained using the method pm4py.llm.abstract dfg). In our research, we have developed distinct textual abstractions for different types of event logs and process models. On the one hand, we address traditional and object-centric event logs, which provide a chronological record of events related to a particular process. On the other hand, we also consider procedural and declarative process models. Procedural models focus on the sequence of activities necessary to accomplish a process, while declarative models describe the rules and constraints that govern the execution of the process. Our textual abstractions offer a balanced summary of these artifacts that preserve their critical properties while remaining accessible to LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Textual Abstractions of Process Models</head><p>One of the fundamental process mining artifacts is the directly-follows graph (DFG) introduced in Section 1.2. To translate this information into a form digestible by Large Language Models (LLMs), we need to convert the DFG into a textual abstraction. This conversion, as exemplified in Listing 1, is a careful process that aims to maintain the core information contained in the graph while conforming to the text-based input restrictions of the LLMs. Each arc in the DFG is translated into a textual sentence that describes the transition from one activity to another, along with its frequency and performance. Frequency signifies how often a particular sequence of activities occurs in the process, while performance captures the average time it takes to move from one activity to the next. The arcs are listed in order of decreasing frequency to prioritize the most common transitions in the process. If the total length of the textual abstraction threatens to exceed the context window limitation of the LLM, some of the less frequent arcs may be omitted. This ensures that the model is fed with the most representative information about the process within the imposed text length constraint, thus enabling effective query answering and process analysis. In addition to the standard textual encoding of the DFG, it is worth noting that advanced large language models exhibit significant flexibility in understanding various text representations of process flows. They are capable of interpreting and reasoning about different encodings for the same underlying information. For instance, the transition from "Activity A" to "Activity B" could be expressed in several ways, such as "Activity A is followed by Activity B", "Activity A → Activity B", or even as a pair "(Activity A, Activity B)". Despite the stylistic differences, the LLMs can recognize these expressions as conveying the same transition in the process. This flexibility makes LLMs robust and adaptable tools for analyzing process mining artifacts represented in different textual formats.</p><p>Listing 2: Textual abstraction of the Petri net presented in Figure <ref type="figure">2</ref> (obtained using the method pm4py.llm.abstract petri net).</p><p>If I have a Petri net: places: [ p 3, p 4, p 5, sink, source ] transitions: [ (0309dbf9-52f9-42a5-a73a-79da3a2ea20a, 'Activity B'), (37ede306 -4d81-499a-8dbe-b23b5a31372a, 'Activity C'), (5f5a9dd2-b140-4e88-ac73-b05c3ab17b63, 'Activity A'), (eba11fc0-143b-4765-adb0-2 b736b348f88, 'Activity D'), (skip 1, None), (skip 2, None), (skip 3, None) ] arcs: [ (0309dbf9-52f9-42a5-a73a-79da3a2ea20a, 'Activity B')-&gt;p 4, (37ede306 -4d81-499a-8dbe-b23b5a31372a, 'Activity C')-&gt;p 5, (5f5a9dd2-b140-4 e88-ac73-b05c3ab17b63, 'Activity A')-&gt;p 3, (eba11fc0-143b-4765-adb0 -2b736b348f88, 'Activity D')-&gt;sink, (skip 1, None)-&gt;p 4, (skip 2, None) -&gt;sink, (skip 3, None)-&gt;sink, p 3-&gt;(0309dbf9-52f9-42a5-a73a-79 da3a2ea20a, 'Activity B'), p 3-&gt;(skip 1, None), p 4-&gt;(37ede306-4d81-499 a-8dbe-b23b5a31372a, 'Activity C'), p 4-&gt;(skip 2, None), p 5-&gt;(eba11fc0 -143b-4765-adb0-2b736b348f88, 'Activity D'), p 5-&gt;(skip 3, None), source-&gt;(5f5a9dd2-b140-4e88-ac73-b05c3ab17b63, 'Activity A') ] initial marking: ['source:1'] final marking: ['sink:1']</p><p>In our process of creating a textual representation of Petri nets (Section 1.2), we assign unique identifiers to both places and transitions within the net, as demonstrated in Listing 2. Visible transitions are accompanied by a specific label, while arcs serve as the connectors between places and transitions and are depicted accurately. This approach enables a clear and precise representation of the Petri net's structure, making it easy for large language models to comprehend and reason about. As with directly-follows graphs, it is important to note that there is not a single "correct" way to textually encode Petri nets. Advanced large language models are capable of understanding a wide range of textual encodings, provided the chosen method clearly communicates the structure and components of the Petri net. Different encodings might express the same Petri net, using various terminologies or formatting conventions to depict places, transitions, and arcs. As long as the encoding is clear and unambiguous, the language model will be able to understand and analyze the underlying Petri net effectively. In addition, it is crucial to note that, unlike with directly-follows graphs, we cannot employ the same approach to addressing the context window limitation when dealing with Petri nets. The nature of Petri nets makes it necessary to abstract the entire model textually. The interconnected structure of places, transitions, and arcs in a Petri net forms a unified whole that cannot be easily segmented or reduced without potentially losing critical information or misrepresenting the process logic. Hence, the complete Petri net, regardless of its size, needs to be translated into text for the large language model to process effectively. This characteristic emphasizes the importance of developing efficient, concise and clear abstraction methods to avoid exceeding the context window of the large language model. Listing 3: Textual abstraction of a DECLARE process model computed on top of Table <ref type="table">1</ref> (obtained using the method pm4py.llm.abstract declare).</p><p>I have a DECLARE declarative process model containing the following constraints (here we provide a short explanation): Existence: the activity is executed at least once. Absence: the activity is not executed. Exactly 1: the activity is executed exactly one time. Initialization: the trace starts with one of the given activities. Responded existence: given a couple of activities (A, B), if A occurs then B also occurs. Co-Existence: given a couple of activities (A, B), if A occurs then B also occurs. Response: given a couple of activities (A, B), if A occurs then B also occurs in the future of the trace. Precedence: given a couple of activities (A, B), if B occurs then also A occurs in the past of the trace. Succession: given a couple of activities (A, B), both the response and precedence constraints are satisfied. Alternate response, alternate precedence, alternate succession: as the constraints mentioned above, but strenghtened by specifying that the events must alternate without repetitions. Chain response, chain precedence, chain succession: as the constraints mentioned above, strenghtened by imposing the directly-follows relation.</p><p>Non Co-Existence: given a couple of activities (A, B), if A occurs then B should not occur. Non Succession and non Chain succession: given a couple of activities (A, B), B should not follow A. These are the constraints of the model: Existence: Activity A Exactly 1: Activity A Initialization: Activity A</p><p>When it comes to DECLARE process models (Section 1.3), a declarative process modeling notation, our approach to abstraction changes. These models are expressed as a set of constraints, each representing specific interdependencies and relationships between process activities. Given the non-trivial nature of these constraints, it becomes crucial to adequately explain them to the large language model. A textual representation of a DECLARE model, as shown in Listing 3, translates these constraints into a readable format. However, unlike with procedural models, the form in which the constraints and explanations are presented is not rigid. Advanced large language models are capable of interpreting the constraints, regardless of how they're expressed, as long as the explanation remains clear and coherent. However, one of the significant challenges when dealing with DECLARE models is the context window limitation. Real-life processes often involve hundreds of constraints, making their textual representations considerably long. To tackle this issue, one possible preprocessing strategy could be to rename the activities using alphabet letters or abbreviations. This approach considerably reduces the length of the textual encoding, ensuring it fits within the context window of the large language model, without losing the integrity of the model's information.</p><p>Listing 4: Textual abstraction of temporal profile process model presented in Table 3 (obtained using the method pm4py.llm.abstract temporal profile). The temporal profile is a model describing the average and the standard deviation of the times between couples of activities eventually (not only directly) following each other in at least a process execution (so in a trace &lt;A,B,C,D&gt; the couples (A,B) (A,C) (A,D) (B,C) (B,D) (C,D) shall be considered). Given a positive value ZETA, a deviation occurs in a process execution when the time between two activities is lower than AVG -ZETA * STDEV or greater than AVG + ZETA * STDEV. For this process, the model is: Activity A -&gt; Activity B : AVG: 1350.00 s STD: 636.40 s Activity A -&gt; Activity C : AVG: 1800.00 s STD: 0.00 s Activity B -&gt; Activity C : AVG: 900.00 s STD: 0.00 s Activity A -&gt; Activity D : AVG: 2700.00 s STD: 0.00 s Activity C -&gt; Activity D : AVG: 900.00 s STD: 0.00 s</p><p>In addition to the abstractions we've discussed, there are also temporal profile models to consider. A temporal profile model, another type of declarative process model (Section 1.3), is primarily concerned with the timing aspects of a process. The abstraction for such a model, as shown in Listing 4, encapsulates the temporal dependencies between various pairs of activities. Specifically, for each pair of activities that can potentially follow one another in the process, the abstraction provides the average and standard deviation of the time elapsed between them. Just as with other models, advanced large language models are flexible in terms of the representation used for these constraints. As long as the pairs of activities and their corresponding time intervals are clearly stated, the large language model can interpret them, regardless of how they are presented in the abstraction. This versatility makes advanced large language models a potent tool for generating meaningful insights from abstracted temporal profile models.</p><p>Listing 5: Textual abstraction of the OC-DFG presented in Figure <ref type="figure" target="#fig_2">4</ref> (obtained using the method pm4py.llm.abstract ocel ocdfg).</p><p>If I have an object-centric event log with the following directly follows graph ( split between the different object types):</p><p>Object type: Order "Activity A" -&gt; "Activity B" (frequency (number of events) = 3, frequency ( number of objects) = 3, duration = 1200.00) "Activity C" -&gt; "Activity A" (frequency (number of events) = 1, frequency ( number of objects) = 1, duration = 1800.00) "Activity A" -&gt; "Activity C" (frequency (number of events) = 1, frequency ( number of objects) = 1, duration = 1800.00) "Activity C" -&gt; "Activity D" (frequency (number of events) = 1, frequency ( number of objects) = 1, duration = 900.00)</p><p>Object type: Invoices "Activity A" -&gt; "Activity B" (frequency (number of events) = 3, frequency ( number of objects) = 3, duration = 1200.00) "Activity C" -&gt; "Activity A" (frequency (number of events) = 1, frequency ( number of objects) = 1, duration = 1800.00) "Activity A" -&gt; "Activity C" (frequency (number of events) = 1, frequency ( number of objects) = 1, duration = 1800.00) "Activity C" -&gt; "Activity D" (frequency (number of events) = 1, frequency ( number of objects) = 1, duration = 900.00)</p><p>Object type: OrderItems "Activity A" -&gt; "Activity B" (frequency (number of events) = 2, frequency ( number of objects) = 3, duration = 900.00) "Activity A" -&gt; "Activity D" (frequency (number of events) = 1, frequency ( number of objects) = 1, duration = 2700.00) "Activity C" -&gt; "Activity A" (frequency (number of events) = 1, frequency ( number of objects) = 1, duration = 1800.00) "Activity A" -&gt; "Activity C" (frequency (number of events) = 1, frequency ( number of objects) = 1, duration = 1800.00)</p><p>When it comes to object-centric event logs, we often utilize object-centric directly-follows graphs (Section 1.2) as part of the abstraction process. An example of such an abstraction is depicted in Listing 5. In this case, each type of object within the log has a corresponding set of arcs in its directly-follows graph. These arcs illustrate the flow and sequence of activities involving that particular object type. However, similar to traditional directly-follows graphs, we must be mindful of the context window limitation. As a result, arcs with fewer occurrences may be omitted from the textual abstraction to maintain a manageable size. Regardless of this omission, the critical insight here is the pattern of activities and interactions concerning each object type. Like the previously discussed abstractions, the way in which these object-specific arcs are represented in the abstraction does not significantly affect how advanced large language models interpret them. As long as the arcs are clearly stated, the large language model can efficiently process and generate useful insights from them. This flexibility underlines the applicability and utility of advanced large language models in understanding and analyzing complex object-centric artifacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Textual Abstractions of Event Logs</head><p>Process variants provide a crucial view of a traditional event log by giving us a glimpse into the different paths or sequences of activities that cases may follow in a process. They can be textually abstracted and presented to a Large Language Model (LLM), as illustrated in Listing 6. Each variant is represented along with its frequency and average throughput time. This structure enables the LLM to understand both the variant's prevalence and the time typically required for its completion. Given the frequency-based ordering of the variants, it is possible to handle limitations imposed by the context window. If the number of process variants is large and exceeds the context window size, less frequent variants can be omitted from the textual abstraction. Despite this omission, the abstraction would still retain the most common patterns, which likely capture a substantial portion of the overall process behavior. The ability of advanced LLMs to understand different textual representations is particularly beneficial here. The representation of process variants does not have to adhere to a strict syntax. It could be a sequence of activities separated by symbols or a plain text description.</p><p>Listing 6: Textual abstraction of the process variants in Table <ref type="table">1</ref> (obtained using the method pm4py.llm.abstract variants). When dealing with traditional event logs (Section 1.1), which are essentially organized collections of events grouped into cases, we can utilize textual abstractions to distill the key features of a specific case, as shown in Listing 7. In this type of abstraction, we highlight the key attributes at the case level and provide a detailed list of all events associated with that case. Each event is principally characterized by an activity and a timestamp, but other event-level attributes can be included as necessary, providing a more detailed snapshot of each event. The crucial aspect of this textual abstraction is that it presents all necessary information to evaluate the progression of a specific case. Consequently, it enables the large language model to answer questions that pertain to a specific case in question, such as identifying any potential issues or irregularities within that case. This makes case-level textual abstraction a powerful tool for detailed, case-specific analysis in process mining.</p><p>Listing 7: Textual abstraction of Case 1 in Table <ref type="table">1</ref> (obtained using the method pm4py.llm.abstract case).</p><p>If I have a case with the following (case) attributes: concept:name = Case1 the case contains the following events (the activity of the event is reported first):</p><p>Activity A ( timestamp = 2023-07-13 09:00:00+00:00 ; @@case index = 0 ; @@index = 0 ; ) Activity B ( timestamp = 2023-07-13 09:15:00+00:00 ; @@case index = 0 ; @@index = 1 ; ) Activity C ( timestamp = 2023-07-13 09:30:00+00:00 ; @@case index = 0 ; @@index = 2 ; )</p><p>A traditional event log can also be translated into a matrix of numerical features (Section 1.4), a format often used in machine learning. Each row in this matrix represents a case from the event log, and each column, or feature, provides some quantitative characteristic of that case. The textual abstraction of this type of matrix can be illustrated as in Listing 8. For every feature in the matrix, we provide its support, i.e., the number of cases where this feature is present or significant. Additionally, we supply quantiles of the feature values, giving a more detailed understanding of the distribution of these values. These aspects combined allow us to understand the relevance and descriptive power of each feature. Given the potential breadth of this kind of matrix, it is essential to consider the context window limitation when producing a textual abstraction. As a solution, one could decide to omit features that have a low support. Such a choice would ensure that the most impactful features, those that occur more frequently, are represented in the abstraction, providing a succinct yet representative snapshot of the event log's numerical features. This strategy makes this type of textual abstraction extremely valuable for a broad understanding of the event log's characteristics from a numerical perspective.</p><p>Listing 8: Textual abstraction of features extracted from the event log presented in Table <ref type="table">3</ref> (obtained using the method pm4py.llm.abstract log features).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Given the following features:</head><p>Value 'Activity A' for Event Attribute 'concept:name': number of non-zero values:</p><p>3 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Value 'Activity C' for Event Attribute 'concept:name': number of non-zero values:</p><p>2 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Value 'Activity B' for Event Attribute 'concept:name': number of non-zero values:</p><p>2 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Value 'Activity D' for Event Attribute 'concept:name': number of non-zero values:</p><p>1 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Succession 'Activity A' -&gt; 'Activity B' for the Values of the Attribute 'concept:</p><p>name': number of non-zero values: 2 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Succession 'Activity C' -&gt; 'Activity D' for the Values of the Attribute 'concept:</p><p>name': number of non-zero values: 1 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Succession 'Activity B' -&gt; 'Activity C' for the Values of the Attribute 'concept:</p><p>name': number of non-zero values: 1 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Succession 'Activity A' -&gt; 'Activity C' for the Values of the Attribute 'concept:</p><p>name': number of non-zero values: 1 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0}</p><p>Similar to the abstraction of traditional event logs, object-centric event logs can also be textually abstracted (Section 1.1), as exemplified in Listing 9. In an object-centric event log, each event is characterized not only by an activity and a timestamp, as in traditional event logs, but also by a set of related objects. These objects extend the dimensionality of the event log, providing more nuanced and contextually rich information about each event. The textual abstraction of an object-centric event log essentially reflects this richer structure. Each event is paired with its associated objects, hence providing a thorough picture of the specific process instance that the event belongs to.</p><p>However, due to the typically large size of object-centric event logs, a direct abstraction of the entire log could easily exceed the context window limitation of the large language model. To address this issue, it is advisable to execute the textual abstraction against a specific process execution (as in Listing 9), which can be a connected component of related objects, rather than the entire log. This approach allows for localized question answering on a given process execution, ensuring that the resulting prompts are meaningful and contextually appropriate while staying within the context window limitation. The ability to abstract and question specific process executions provides an extra level of flexibility when investigating process behaviours. It can help to unveil patterns or anomalies that are localized to specific instances of the process, contributing to a more granular understanding of the process dynamics.</p><p>Listing 9: Textual abstraction of the connected component in Table <ref type="table">2</ref> containing {Order1, Item1, Item2, Invoice1} (obtained using the method pm4py.llm.abstract ocel). As with traditional event logs, object-centric event logs can also be transformed into a matrix of numerical features (Section 1.4), each representing a unique aspect of the process. These features often delve deeper, exploring the lifecycles of individual objects or interactions between them within the event log's graph structure. The textual abstraction of such features is presented in Listing 10, with each feature detailed by its support and quantiles of its values, mirroring the approach used for traditional logs. However, due to the increased complexity and the larger number of features that object-centric event logs can offer, dealing with the context window limitation of Large Language Models can be more challenging. The primary strategy here is to focus on the most relevant features -those with the highest support. This prioritization helps to manage the amount of information fed into the LLM, ensuring that the most significant features are included, while those with less support can be omitted to fit within the context window. This approach allows for an effective trade-off between information detail and the size constraints imposed by the LLMs.</p><p>Listing 10: Textual abstraction of the features for the 'Orders' object type of the object-centric event log presented in Table <ref type="table">2</ref> (obtained using the method pm4py.llm.abstract ocel features).</p><p>Beforehand, a bit of notions. Given an object-centric event log, the object interaction graph connects objects that are related in at least an event. The object descendants graph connects objects related in at least an event, when the lifecycle of the second object starts after the lifecycle of the first. The object inheritance graph connects objects when there an event that ends the lifecycle of the first object and starts the lifecycle of the second one. Given the following features: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Prompting Strategies</head><p>This section introduces three prompting strategies for utilizing large language models (LLMs) in the field of process mining: "direct answering," "multiprompt answering," and "generation of database queries." These strategies vary in complexity and are chosen based on the problem at hand. They make use of textual abstractions and questions, and leverage the capabilities of LLMs for hypothesis generation, result interpretation, and even SQL query formulation, providing an interactive and adaptive approach to process mining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Direct Answering</head><p>The "direct answering" strategy is the most straightforward prompting approach used with large language models in the context of process mining. This strategy involves formulating a prompt which combines a textual abstraction of a process mining artifact with a direct question related to it. Example questions might be "What are the bottlenecks of the process?" (starting from the process variants abstraction) or "What are the main anomalies?" (starting from the directly-follows graph abstraction).</p><p>It is important to note that, in this strategy, the output structure of the response is not predetermined. Rather, the large language model will generate a response in the form of free text. Consequently, this means that the user, while freed from the task of analyzing the event log themselves, must have sufficient background knowledge to interpret the answer correctly.</p><p>Another key factor for success with the direct answering strategy is the formulation of the question itself. It needs to be concise, clear, and well-structured to enable the large language model to provide a meaningful and relevant response. This strategy, therefore, represents a delicate balance between user expertise, question formulation, and the interpretability of the model's responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Multi-Prompt Answering</head><p>In certain scenarios, more complex process mining tasks require a series of distinct prompts, each involving different abstractions and questions. This approach, known as multi-prompt answering, leverages the iterative nature of inquiry, where the answer to one question informs the formulation of the next. In this way, the user guides the large language model (LLM) through a sequence of steps to ultimately resolve the overarching process mining problem.</p><p>A classic example where the multi-prompt answering strategy is useful is in assessing fairness in process mining. Initially, a user might use a feature table abstraction to identify attributes that could potentially lead to discrimination.</p><p>Once the LLM provides this information, the user formulates a subsequent prompt to investigate if the process execution differs for cases belonging to the protected and non-protected groups. The second prompt is contingent on the results from the first one, as it is necessary to distinguish between cases before delving deeper into potential discrepancies in process execution.</p><p>In another example, the user might want to analyze process conformance. An initial prompt could be used to compare the process model to a log abstraction to identify non-conforming activities. Subsequent prompts could then be designed to examine why these non-conformities are occurring, perhaps by examining specific cases or focusing on particular process variants.</p><p>Multi-prompt answering is a powerful strategy, as it allows users to conduct a step-by-step, deep-dive analysis. However, it requires careful formulation of prompts and the ability to interpret and act on the LLM responses to guide the inquiry effectively. Therefore, it demands more user engagement than the direct answering strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Generation of Database Queries</head><p>The third strategy is "generation of database queries", which is particularly useful for complex process mining problems that are too intricate to be directly abstracted or solved by the large language model (LLM). Questions like "What is the average throughput time when activity B occurs more than one day after the start of the case?" or "Measure the correlation between throughput time and rework in the case" fall into this category.</p><p>In these situations, the LLM can be leveraged to generate SQL queries based on the user's initial natural language inquiry. These generated queries can then be executed against the event log, enabling complex data analysis without the user having to manually construct the intricate SQL statements.</p><p>Yet, this strategy's potential goes beyond translating natural language questions into SQL queries. It can also be used to generate hypotheses about the event log, derived from certain abstractions like process variants or log features. For instance, the user can present the LLM with such an abstraction and ask it to formulate an hypothesis about the event log expressed as a SQL query.</p><p>Once the SQL query (representing the hypothesis) is executed and the results are obtained, the LLM can then be employed again to evaluate if the original hypothesis holds true. Should the initial hypothesis be invalidated, the LLM is capable of formulating alternative hypotheses, which can then be transformed into SQL queries and tested against the data. This iterative method, which encompasses generating hypotheses, testing them, and re-assessing based on the outcomes, allows for a more in-depth exploration and understanding of the underlying processes. This approach significantly expands the scope of possible investigations that can be conducted using the LLM.</p><p>Nevertheless, while this method can streamline complex query generation and hypothesis testing, it does call for a specific set of skills on the part of the user. While the LLM can assist in generating complex queries and hypotheses, the responsibility of result interpretation and subsequent steps of analysis falls on the user. Thus, a certain degree of analytical acumen and domain knowledge is necessary for this approach to be fully effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Tool Support</head><p>In this section, we delve into the tool support available for conducting process mining tasks with large language models. pm4py Berti et al (2019), short for Process Mining for Python, is a versatile and comprehensive library that supports the entire spectrum of process mining applications, ranging from data loading and pre-processing, to process discovery, conformance checking, and enhancement. This suite of functionality enables practitioners and researchers to extract valuable insights from event logs and use them for optimizing and monitoring real-world processes. pm4py is developed from the Fraunhofer FIT process mining group and is fully documented at the address <ref type="url" target="https://pm4py.fit.fraunhofer.de">https://pm4py.  fit.fraunhofer.de</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Abstraction Provided pm4py.llm.abstract dfg()</p><p>Provides the DFG abstraction of a traditional event log pm4py.llm.abstract variants()</p><p>Provides the variants abstraction of a traditional event log pm4py.llm.abstract log attributes() Provides the abstraction of the attributes/columns of the event log pm4py.llm.abstract log features()</p><p>Provides the abstraction of the machine learning features obtained from an event log pm4py.llm.abstract case()</p><p>Provides the abstraction of a case (collection of events) pm4py.llm.abstract ocel()</p><p>Provides the abstraction of an objectcentric event log (list of events and objects) pm4py.llm.abstract ocel ocdfg()</p><p>Provides the abstraction of an objectcentric event log (OC-DFG) pm4py.llm.abstract ocel features()</p><p>Provides the abstraction of an objectcentric event log (features for ML) pm4py.llm.abstract event stream() Provides an abstraction of the (last) events of the stream related to a traditional event log pm4py.llm.abstract petri net()</p><p>Provides the abstraction of a Petri net pm4py.llm.abstract log skeleton()</p><p>Provides the abstraction of a log skeleton model</p><p>Table <ref type="table">6</ref>: Methods for various types of abstractions available in pm4py.</p><p>A significant development in version 2.7.5 of pm4py is the integration with Large Language Models (LLM), bolstering the tool's capacity for analysis and understanding of process data. This integration enables pm4py to offer a range of abstractions for process data and models, as detailed in Table <ref type="table">6</ref>. More features will be introduced in pm4py 2.7.6. Each method in this module provides a different view or representation of the process data, facilitating diverse avenues for exploration and analysis.</p><p>In addition to these abstractions, pm4py 2.7.5 allows for direct interaction with LLM through specific methods such as pm4py.llm.openai query that provides a more detailed view of complex processes. Object-centric process mining expands the traditional case-centric perspective, allowing for the consideration of multiple interacting objects in a process, thus enabling a more nuanced understanding of process dynamics.</p><p>The LLM integration in pm4py embraces this object-centric perspective, as demonstrated in the example given in Listing 12. The script loads an objectcentric event log (OCEL) and then uses two specific abstraction methods tailored for this type of data. The method abstract ocel ocdfg is used to generate an abstraction of the Object-Centric Directly Follows Graph (OC-DFG), a representation that captures the relationships between the different activities and objects in the log. This abstraction is then used to create a query for the LLM, asking for unusual relationships in the process graph. The method abstract ocel features is used to generate an abstraction of the features of a specific type of object (in this example, "order") in the OCEL. This abstraction is then used to create another query for the LLM, asking for odd feature values.</p><p>These examples showcase the potential of using LLM in conjunction with object-centric process mining. The intricate process insights offered by objectcentric logs, coupled with the rich interpretative capabilities of large language models, provide practitioners and researchers with powerful tools to uncover hidden process knowledge and drive informed process decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Assessment</head><p>In this section, we examine the ability of large language models, specifically Bard and GPT-4, to understand, generate, and answer queries related to process mining tasks. The considered models and their unique characteristics are discussed in Section 4.1. We also outline the specific event logs leveraged in this assessment in Section 4.2.</p><p>We delve into the models' capabilities in the realm of direct answering to process mining queries in Section 4.3, where we assess their ability to respond directly to various types of prompts. This exploration is then extended in Section 4.4, where we investigate the models' capacity for providing answers across multiple prompts, encapsulating more complex interactions.</p><p>Finally, we evaluate the models' aptitude in generating database queries from user prompts in Section 4.5. This involves assessing the ability of these models to not just understand a prompt, but to translate that understanding into SQL queries, a crucial aspect in the context of data analysis.</p><p>By comprehensively assessing these aspects, we aim to gauge the practicality and potential of these large language models in process mining tasks, seeking to illuminate areas of strength as well as identify opportunities for further research and improvement. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Considered Large Language Models</head><p>This section provides an examination of the two advanced LLMs currently leveraged in the field of process mining: GPT-4, developed by OpenAI, and Google Bard, brought forward by Google AI. Both models are the product of extensive training on vast datasets comprised of a diverse range of text and code, and exhibit remarkable capabilities in a variety of tasks.</p><p>GPT-4 is a large language model (LLM) developed by OpenAI. It is a powerful tool that can be used for a variety of tasks, including text generation, translation, and question answering. GPT-4 is trained on a massive dataset of text and code, which allows it to generate text that is both coherent and grammatically correct.</p><p>Google Bard is a large language model developed by Google AI. It is similar to GPT-4 in terms of its capabilities, but it is trained on a different dataset of text and code. This difference in training data means that Google Bard has different strengths and weaknesses than GPT-4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Considered Event Logs</head><p>In this study, we focus on several real-world process event logs to explore and evaluate the capabilities of large language models in the domain of process mining. These event logs encapsulate diverse fields, such as road traffic fine management, hospital case management, and business travel expenses, offering a breadth of scenarios to test the adaptability and accuracy of the language model. The event logs employed in this research are described in detail below.  </p><formula xml:id="formula_2">X X X X X X Hospital X X X X X X Lending X X X X X Renting X X X X X X</formula><p>• Road Traffic Fine Management Process<ref type="foot" target="#foot_1">foot_1</ref> : real-life event log of an information system managing road traffic fines in an Italian municipality. • BPI Challenge 2020 (Domestic Declarations)<ref type="foot" target="#foot_2">foot_2</ref> : the travel expense process consists of an employee's submission, approval by the travel administration, then by the budget owner and supervisor, and possibly a director.</p><p>The process concludes with a trip or a payment request. There are two types of trips: domestic and international. Domestic trips do not need prior approval, allowing employees to ask for cost reimbursement afterward. • Sepsis Cases Event Log<ref type="foot" target="#foot_3">foot_3</ref> : the dataset is an anonymized real-life event log of sepsis cases from a hospital, where sepsis is a life-threatening condition often resulting from an infection. Each case represents a patient's journey through the hospital, with events captured by the hospital's Enterprise Resource Planning (ERP) system. The events cover a range of different activities, and a multitude of data attributes are recorded such as the group responsible for the activity, test results, and checklist information. While event timestamps have been randomized, the time interval between events within a case remains unchanged. • Conformance Checking Challenge 2019<ref type="foot" target="#foot_4">foot_4</ref> : This past version of the conformance checking challenge was centered around a process involved in medical training. Specifically, it revolved around how medical students were taught to place a central venous catheter (CVC) using ultrasound guidance. The CVC procedure involves inserting a tube into a large vein, a process critical for administering fluids or medicines to patients, among other applications. For assessment of the multi-prompt answering strategy, we also use the event logs provided in <ref type="bibr">Pohl and Berti (2023)</ref> and described in <ref type="bibr">Pohl et al (2023)</ref>, including:</p><p>• Hiring event logs: these logs chronicle a complex recruitment process with various stages of evaluation and decision-making. The applicant's journey can be as simple as a straightforward rejection or as elaborate as multi-step screening culminating in a job offer, contingent on a host of influencing factors. • Hospital event logs: this dataset portrays a patient's journey through a hospital system, starting from the initial check-in at the Emergency Room or Family Department. It progresses through phases of medical examination, diagnosis, and treatment. It's worth noting that unsuccessful treatments often necessitate repeat examinations and interventions, illustrating the cyclical nature of healthcare delivery. • Lending event logs: these logs detail a loan application process starting from the scheduling of an initial appointment. It traverses several steps including validation of provided information and underwriting, leading to either loan approval or denial. Further requirements, such as the involvement of a co-signer or an assessment of collateral, may be needed. Some cases may experience direct appointment refusal, highlighting the process's variability based on applicants' individual financial circumstances. • Renting event logs: these logs present a comprehensive rental process that begins with a property viewing request and can end with a contract termination. Between these endpoints, stages such as preliminary vetting, property viewing, decision-making, and possibly, intensive screening occur. If successful, a rental agreement is initiated, with possible outcomes ranging from eviction due to late payments to voluntary contract termination by tenants. It's important to note that not all applications advance to the property viewing phase. The degree of discrimination exhibited in the logs varies across different domains, offering researchers an opportunity to explore tangible real-world situations. Table <ref type="table" target="#tab_7">9</ref> furnishes fundamental statistics for the log collection, and Table <ref type="table" target="#tab_8">10</ref> elaborates on the sensitive attributes. It's important to note that the selection of attributes pertaining to fairness can be a subject of debate; hence, we welcome discussions to enhance our grasp of fairness within the realm of process mining. Detailed descriptions of each log's attributes and process have been provided to facilitate the identification of potential instances of discrimination. The event logs provided also include the ground truth concerning the classification of cases -whether they belong to the protected group or not. This inclusion enables a comparison between actual case classifications, which are based on the sensitive attributes, and the actual ground truth. Therefore, the capacity to evaluate the accuracy of case categorization into protected and non-protected groups is significantly enhanced.</p><p>In our exploration of object-centric process mining using large language models, we utilized several publicly accessible logs available at <ref type="url" target="https://www.ocel-standard.org">https://www.  ocel-standard.org</ref>. Specifically, two simulated object-centric event logs were chosen for this analysis:</p><p>• the 'Order Management' event log, which can be accessed directly at <ref type="url" target="https://www.ocel-standard.org/1.0/running-example.jsonocel.zip">https://www.ocel-standard.org/1.0/running-example.jsonocel.zip</ref>. This log contains the object types 'orders', 'items', and 'packages', all of which were retained for our assessment. • the 'Recruiting' event log, available at <ref type="url" target="https://www.ocel-standard.org/1.0/recruiting.jsonocel.zip">https://www.ocel-standard.org/1.  0/recruiting.jsonocel.zip</ref>. In this log, we focused on the 'applications' and 'offers' object types.</p><p>By leveraging these specific logs, we aimed to evaluate how effectively large language models like Bard and GPT-4 could handle complex, object-centric process mining tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Direct Answering</head><p>In this section, we conduct an evaluation of the ability of advanced large language models, specifically Bard and GPT-4, to respond effectively to process mining queries, given the required abstraction. Our assessments of Bard and GPT-4 with regards to traditional process mining and event logs are documented in Table <ref type="table" target="#tab_9">11</ref>.</p><p>In the table, each query is assigned a unique code, and the appropriate acceptance criteria for the responses generated by the large language models are stipulated. Furthermore, each query is examined across four distinct event logs, namely Road Traffic, BPI Challenge 2020, Sepsis, and CCC19.</p><p>Observably, both Bard and GPT-4 demonstrate commendable performance when dealing with descriptive queries such as TQ1, TQ2, TQ3, and TQ5. Furthermore, these large language models exhibit a fair understanding of procedural and declarative models, demonstrating capabilities in tasks like play-out and conformance checking, albeit with certain constraints.</p><p>In particular, GPT-4 displayed a satisfactory level of competency across the diverse range of queries, albeit with some restrictions pertaining to medical processes. Therefore, it is suggested that further refinement and training might be beneficial in enhancing the capability of these models in the realm of process mining. OQ5 Could you identify interesting aspects for the analysis of the process? Some aspects to investigate are correctly identified from the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OCEL Features √ √</head><p>In Table <ref type="table" target="#tab_10">12</ref>, we evaluate the performance of large language models in tackling object-centric process mining tasks. Considering the relatively uncomplicated nature of the event logs used for this assessment, both models -Bard and GPT-4 -demonstrate notable proficiency across all tasks.</p><p>To provide a comprehensive understanding of their capabilities, we document a selection of responses generated by these models in Listing 13, Listing 14, Listing 15, and Listing 16. These examples serve as illustrative evidence of the substantial potential these models exhibit in responding effectively to a diverse set of queries within the realm of object-centric process mining.</p><p>Listing 13: Description of the Road Traffic process by GPT-4.</p><p>From the given data, it appears that this process describes the system of issuing, paying, and appealing fines, possibly within the context of a legal system, law enforcement agency, or a governmental body. The different steps represent actions taken in the process and the transitions between steps. I'll describe each step briefly:</p><p>Create Fine: This is the initial step where a fine is created. This could be due to a traffic violation, noncompliance with regulations, etc. Send Fine: The fine is then sent to the offender. This could be through mail, email, or other means. Insert Fine Notification: A record of the fine notification sent to the offender is inserted, probably in some database or record-keeping system. Add Penalty: If the fine is not paid within a certain time period, a penalty might be added to the initial amount. Send for Credit Collection: If the offender doesn't pay the fine and the added penalty, the fine might be sent for credit collection. A collection agency might be involved at this point. Payment: This is when the offender pays the fine. This might be done in full, or in parts (as suggested by the Payment -&gt; Payment frequency). Insert Date Appeal to Prefecture: The offender can appeal the fine to a higher authority, possibly a prefecture.</p><p>The date of this appeal is recorded. Send Appeal to Prefecture: The appeal is formally sent to the prefecture. Receive Result Appeal from Prefecture: The response or result from the prefecture regarding the appeal is received. Notify Result Appeal to Offender: The result of the appeal is then notified to the offender. Appeal to Judge: If unsatisfied with the result from the prefecture, the offender might appeal to a judge. Send Fine (again): In some cases, it seems like the fine might be sent again to the offender.</p><p>The frequency indicates the number of times the transition from one step to the next occurs, while the performance might be indicating the time taken for each transition in milliseconds (though it's not clear from the provided data). The process appears to loop at several points, with possibilities of appeal and repeated notifications or payments. It also seems to have multiple end points including payment, credit collection, or appeal to a judge.</p><p>Listing 14: Description of the Road Traffic process by Google Bard.</p><p>The process begins with the creation of a fine. The fine can be paid in full, or the offender can choose to appeal the fine. If the offender appeals the fine, they must first send a notification of appeal to the prefecture. The prefecture then reviews the appeal and sends a decision to the offender. If the decision is not in the offender's favor, they can appeal the decision to a judge. The judge will then review the appeal and make a final decision. The data shows that the most common outcome is for the offender to pay the fine in full. However, a significant number of offenders also choose to appeal the fine. Of those who appeal, the majority are unsuccessful. However, a small number of offenders are successful in having their fines overturned. The data also shows that the process of appealing a fine can be expensive. The offender must pay a fee to send the notification of appeal to the prefecture, and they may also have to pay legal fees if they choose to appeal the decision to a judge. Overall, the data shows that the process of appealing a fine can be a lengthy and expensive process. However, for those who are successful, it can be worth the effort.</p><p>Here are some additional insights that can be drawn from the data:</p><p>-The most common reason for appealing a fine is that the offender believes that the fine was unfair.</p><p>-The most common outcome of an appeal is that the fine is upheld.</p><p>-The success rate of appeals is relatively low.</p><p>-The cost of appealing a fine can be significant.</p><p>The data can be used to improve the process of appealing fines. For example, the data could be used to identify the factors that are most likely to lead to a successful appeal. The data could also be used to develop a more streamlined and efficient appeals process.</p><p>Listing 15: Root cause analysis on the BPI Challenge 2020 event log by GPT-4.</p><p>From the process variants and the frequency and performance statistics provided, there are a few key steps that could be causing performance issues in the process:</p><p>-Rejection by ADMINISTRATION or SUPERVISOR: Variants where the declaration is rejected by the Administration or Supervisor tend to have a higher performance number, which indicates more time or resources consumed in the process. This could be due to the time taken to review the declaration, the process to handle rejection, or the time spent to correct and resubmit the declaration. -Re-submission by EMPLOYEE: After a declaration is rejected, it is often resubmitted by the employee. This step will naturally add to the overall time of the process, as the employee will need to correct the issue that caused the rejection and then re-submit the declaration. -Approval by PRE APPROVER, BUDGET OWNER or SUPERVISOR: Variants that include additional approval steps (by a PRE APPROVER, BUDGET OWNER, or SUPERVISOR) also have higher performance numbers, indicating that these steps are adding to the time taken for the process. This could be due to time-consuming review processes or waiting times for approval. -Missing Approval: There are few cases where declarations are rejected due to missing approvals. This adds an additional step and increases the performance of the process. -Multi-step Processes: Variants with multiple steps, such as those that include rejections, resubmissions, and multiple approvals, show much higher performance numbers. This suggests that processes with multiple stages are taking much longer and consuming more resources.</p><p>Solutions to these issues might include streamlining the approval process, providing better training or resources to reduce the number of rejections, or implementing a more efficient system for handling re-submissions. Identifying and addressing these root causes could lead to significant improvements in the performance of the process.</p><p>Listing 16: Root cause analysis on the order management event log by Google Bard.</p><p>Sure, here are some of the root causes of the performance issues in the process:</p><p>-Long wait times for items to be picked. The "pick item" event has the highest frequency of all events, but the duration of this event is also relatively high. This suggests that there may be bottlenecks in the process of picking items, such as a lack of staff or inefficient picking procedures. -High number of out-of-stock items. The "item out of stock" has a relatively high frequency, which suggests that there are a significant number of items that are not in stock when customers place orders. This can lead to delays in the order fulfillment process and customer dissatisfaction. -Long wait times for packages to be delivered. The "send package" event has a relatively high duration, which suggests that there may be bottlenecks in the process of shipping packages. This could be due to a lack of shipping resources, inefficient shipping procedures, or delays in the shipping process.</p><p>To address these performance issues, the company could consider the following:</p><p>-Improve the efficiency of the picking process. This could be done by increasing the number of staff available for picking, optimizing the picking procedures, or using automation to help with the picking process. -Reduce the number of out-of-stock items. This could be done by improving the inventory management process, working with suppliers to ensure that items are in stock, or offering alternative products to customers when items are out of stock. -Reduce the wait time for packages to be delivered. This could be done by increasing the number of shipping resources, optimizing the shipping procedures, or working with shipping partners to improve the shipping process.</p><p>By addressing these performance issues, the company can improve the customer experience and increase its efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Multi-Prompt Answering</head><p>In our fairness assessment, we employ the multi-prompt strategy, primarily aiming to discern whether GPT-4 and Bard can accurately identify the protected group. For this purpose, SQL queries were generated through the large language model, utilizing prompts that encapsulate the attributes of the log and their corresponding characterization. An exemplar script that generates such prompts is available at <ref type="url" target="https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/01_1_protected_group_identification.py">https://github.com/pm4py/pm4py-core/  blob/priv/examples/llm/01 1 protected group identification.py</ref>. The aforementioned queries for two event logs are delineated in Figure <ref type="figure">5</ref>. Upon analysis, we observe that GPT-4's queries display a more encompassing view of the behavior considered as protected. Conversely, Bard's queries precisely target a specific subset of cases that are presumably exposed to discrimination.</p><p>Listing 17: SQL query provided by GPT-4 to identify the protected group in the hiring log high.xes.gz event log.</p><p>SELECT * FROM dataframe WHERE "case:citizen" = 'False' OR "case:gender" = 'False' OR "case:german speaking" = 'False' OR "case:religious" = 'False';</p><p>Listing 18: SQL query provided by Bard to identify the protected group in the hiring log high.xes.gz event log.</p><p>SELECT * FROM dataframe WHERE "case:citizen" = 'False' AND "case:gender" = 'False'</p><p>Listing 19: SQL query provided by GPT-4 to identify the protected group in the renting log high.xes.gz event log.</p><p>SELECT * FROM dataframe WHERE "case:citizen" = 'False' OR "case:gender" = 'False' OR "case:german speaking" = 'False' OR "case:married" = 'False';</p><p>Listing 20: SQL query provided by Bard to identify the protected group in the renting log high.xes.gz event log.</p><p>SELECT * FROM dataframe WHERE "case:gender" = 'False' AND "case:german speaking" = ' False'</p><p>Fig. <ref type="figure">5</ref>: SQL queries generated by Bard and GPT-4 to identify the protected groups in the considered event logs.</p><p>Subsequently, our focus shifts towards those event logs that signify a substantial degree of discrimination. To assess the classification performance on these logs, we employ an exemplar script accessible at <ref type="url" target="https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/01_2_protected_group_query.py">https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/01 2  protected group query.py</ref>. The resulting classification quality of GPT-4 and Bard is presented in Table <ref type="table" target="#tab_11">13</ref> and <ref type="table" target="#tab_12">Table 14</ref>. While Bard demonstrates high precision, it is hindered by a low recall and true negative rate, suggesting that it may fail to identify a considerable number of cases where potential discrimination might have taken place. On the other hand, GPT-4, despite exhibiting lower precision, boasts a high recall and true negative rate. This highlights GPT-4's capability to label a larger number of cases as potentially discriminated, hence reducing the occurrence of false negatives.</p><p>Having established a set of cases as 'protected' via GPT-4 and Bard, we now shift our focus towards assessing procedural fairness. The objective here is to uncover any process discrepancies that might hint at discrimination. To achieve this, we craft prompts embodying the process variants abstraction of both 'protected' and 'non-protected' cases. These prompts are then fed into the large language model with a request to discern the differences.</p><p>To ensure a fair and effective comparison, the 'protected' group, as per the ground truth contained within the simulated event logs, is taken into consideration. This approach is demonstrated in the example script accessible at <ref type="url" target="https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/02_group_fairness_factors.py">https://github.com/pm4py/pm4py-core/blob/priv/examples/llm/02  group fairness factors.py</ref>.</p><p>Listing 21: Procedural differences between the 'protected' and 'non-protected' group identified by GPT-4 in the hiring log high.xes.gz event log.</p><p>Here are the main differences I can identify from your process variant descriptions, taking into account the order of steps, frequency of each variant, and performance (assumed to be the time taken for each process variant).</p><p>-Earlier Application Rejection: The most common process variant for the 'protected' group is "Hand In Job Application -&gt; Application Rejected" with the highest frequency of 873. This suggests that the ' protected' group is often rejected right after submitting their job applications, skipping the telephonic screening or any further steps. This scenario does not occur as often for the 'unprotected' group, suggesting possible bias in application reviews. -Differences in Interview Steps: The 'unprotected' group seems to undergo more comprehensive interview steps including a "Coding Interview", "ML Interview", "Frontend Interview", "Behavioral Interview", and a double "Make Job Offer" step. These steps appear less frequently and later in the 'protected' group's process variants. -Performance Time: The performance time, which might refer to the time taken for each process variant, seems to be generally higher for the 'protected' group compared to the 'unprotected' group. This could indicate that the job application process takes longer for the 'protected' group, which could be seen as an unfair burden. -Frequency of Extensive Background Checks: The 'protected' group undergoes "Extensive Background Check" more frequently and earlier in the process than the 'unprotected' group. This could be indicative of bias, as it seems the 'protected' group is subjected to more rigorous checks more often. -Job Offers: The 'unprotected' group has more process variants leading to a job offer. This could suggest bias in the final decision-making process.</p><p>In conclusion, these discrepancies could be indicative of biases or systemic issues within the application process. Further analysis and understanding of the reasons behind these discrepancies would be needed to determine if they truly represent unfair treatment or if there are other factors at play.</p><p>Listing 22: Procedural differences between the 'protected' and 'non-protected' group identified by Google Bard in the hiring log high.xes.gz event log.</p><p>Sure, I can help you with that. Here are the main differences between the process variants for the protected and unprotected groups:</p><p>-The protected group is more likely to have their application rejected at the initial stage, before any interviews have taken place. This is evident in the fact that there are more process variants for the protected group that end in "Application Rejected" at the "Hand In Job Application" or "Telephonic Screening" stage. -The unprotected group is more likely to progress to the later stages of the interview process, including the coding interview, ML interview, and behavioral interview. This is evident in the fact that there are more process variants for the unprotected group that end in "Make Job Offer" at the "Coding Interview", "ML Interview", or "Behavioral Interview" stage. -The protected group is more likely to be rejected after the behavioral interview. This is evident in the fact that there are more process variants for the protected group that end in "Application Rejected" at the " Behavioral Interview" stage.</p><p>These differences suggest that the protected group may be facing discrimination in the job application process. Specifically, they may be being rejected at an earlier stage, even though they may be just as qualified as the unprotected group. Additionally, they may be being rejected after the behavioral interview, even though they may have performed well in the interview. It is important to note that these are just some of the differences between the process variants for the protected and unprotected groups. There may be other differences that are not evident in the data. However, the differences that I have identified suggest that the protected group may be facing discrimination in the job application process.</p><p>Refer to Listing 21 and Listing 22 for GPT-4 and Bard's respective responses pertaining to the hiring event log. Similarly, for the renting event log, GPT-4 and Bard's responses can be found in Listing 23 and Listing 24 respectively.</p><p>Listing 23: Procedural differences between the 'protected' and 'non-protected' group identified by GPT-4 in the renting log high.xes.gz event log.</p><p>Based on the given information, here are some differences that stand out between the 'protected' and ' unprotected' groups in terms of the rental process:</p><p>-Frequency and Extent of Rejection: It appears that in both groups, the rejection of prospective tenants is a common process variant. However, the 'unprotected' group faces a more frequent rejection after the " Screen Prospective Tenant" step without extensive screening, compared to the 'protected' group. -Paperwork and Screening Process: The 'protected' group more often goes through extensive paperwork and screening process, which includes steps like "Hand In The Paperwork", "Check Paperwork", "Screen Prospective Tenant", and "Extensive Screening". The 'unprotected' group, on the other hand, often seems to get rejected before reaching these steps or even without the extensive screening process. -Contract and Renting: When it comes to signing contracts, moving in, and starting to pay rent, the ' unprotected' group seems to have a somewhat easier path. There are several process variants for the ' unprotected' group where they get to sign the contract and move in without undergoing the 'Extensive Screening' step, which isn't the case for the 'protected' group. -Execution Time: The 'protected' group's processes generally take longer, as indicated by the higher ' performance' values, which could suggest a more extensive or stringent screening process.</p><p>These differences could be indicative of different levels of scrutiny or bias against the 'protected' group, although the provided data does not give explicit reasons for these differences. It is important to further investigate these observations to confirm any potential unfair treatment. As with any analysis of this sort , it's crucial to keep in mind the context and potential confounding factors that might affect the comparison between these two groups.</p><p>Listing 24: Procedural differences between the 'protected' and 'non-protected' group identified by Google Bard in the renting log high.xes.gz event log.</p><p>Sure, I can help you with that. Here are the main differences between the process variants for the protected and unprotected groups:</p><p>-The protected group is more likely to be rejected at the initial stage, before any paperwork has been submitted. This is evident in the fact that there are more process variants for the protected group that end in "Reject Prospective Tenant" at the "Apply for Viewing Appointment" or "Set Appointment" stage.</p><p>-The unprotected group is more likely to progress to the later stages of the process, including the screening, contract signing, and move-in stages. This is evident in the fact that there are more process variants for the unprotected group that end in "Sign Contract" or "Move In". -The protected group is more likely to cancel their apartment after moving in. This is evident in the fact that there are more process variants for the protected group that end in "Tenant Cancels Appartment".</p><p>These differences suggest that the protected group may be facing discrimination in the rental process. Specifically, they may be being rejected at an earlier stage, even though they may be just as qualified as the unprotected group. Additionally, they may be being rejected after moving in, even though they may be good tenants. It is important to note that these are just some of the differences between the process variants for the protected and unprotected groups. There may be other differences that are not evident in the data. However, the differences that I have identified suggest that the protected group may be facing discrimination in the rental process. Here are some additional thoughts on the matter:</p><p>-The protected group may be being rejected at an earlier stage because they are being subjected to more stringent screening criteria. For example, they may be being required to provide more documentation or to undergo more extensive background checks. -The protected group may be being rejected after moving in because they are being subjected to more scrutiny by their landlords. For example, they may be being more likely to be reported for minor infractions or to be evicted for non-payment of rent.</p><p>It is important to investigate these differences further to determine whether they are the result of discrimination. If they are, then steps should be taken to ensure that the protected group is not being discriminated against.</p><p>Both large language models perform admirably, pinpointing differences in the control-flow and time perspectives. These variances in control-flow correlate with the outcome of a case, the presence of rework, and the number of events in the case. That said, GPT-4's response stands out for being more comprehensive compared to Bard's.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Generation of Database Queries</head><p>What is the average throughput time when activity 'Send Fine' occurs more than 50 days after the start of the case?</p><p>Can you provide me a DuckDB SQL query. You should use the EPOCH function of DuckDB to get the timestamp from the date.</p><p>The data is stored in a Pandas dataframe where each row is an event having the provided attributes (so there are no separate table containing the variant). The dataframe is called "dataframe".</p><p>Please consider the following information: the case identifier is called "case:concept:name", the activity is stored inside the attribute "concept:name", the timestamp is stored inside the attribute "time:timestamp ", the resource is stored inside the attribute "org:resource". There is not a variant column but that can be obtained as concatenation of the activities of a case. There is not a duration column but that can be obtained as difference between the timestamp of the first and the last event.</p><p>Prompt executed against both large language models.</p><p>WITH case starts AS ( SELECT "case:concept:name", MIN("time:timestamp") AS start timestamp FROM dataframe GROUP BY "case:concept:name" ), fine after 50 days cases AS ( SELECT df."case:concept:name", EPOCH(df."time:timestamp") -EPOCH(cs.start timestamp) AS duration FROM dataframe AS df JOIN case starts AS cs ON df."case:concept:name" = cs."case:concept:name" WHERE df."concept:name" = 'Send Fine' AND (EPOCH(df."time:timestamp") -EPOCH(cs.start timestamp)) &gt; (50 * 24 * 60 * 60) ) SELECT AVG(duration) FROM fine after 50 days cases Correct response from GPT-4. SELECT AVG(duration) AS average throughput time FROM (SELECT case id, CONCAT(activity, '-', resource) AS variant, EPOCH(timestamp) AS timestamp, (timestamp -MIN(timestamp)) AS duration FROM dataframe WHERE activity = 'Send Fine' AND timestamp -MIN(timestamp) &gt; 50 * 86400) AS t</p><p>Wrong response from Bard.</p><p>Fig. <ref type="figure">6</ref>: SQL query generation comparison between GPT-4 and Bard for the "What is the average throughput time when activity 'Send Fine' occurs more than 50 days after the start of the case?" query executed against the Road Traffic event log.</p><p>In our research, we are investigating how large language models can formulate process queries in mainstream SQL language. Our primary focus lies on two prominent models -Bard and GPT-4 -and their ability to translate user-provided natural language queries into executable SQL statements.</p><p>Furthermore, we are interested in how adept these models are at spontaneously generating hypotheses based on an event log. The models are given basic abstractions such as the list of attributes and process variants within the log. For our analysis, we utilize DuckDB SQL language, a choice motivated by its seamless compatibility with the event log structure used by pm4py.</p><p>In the present state of affairs, it is evident that some amount of domain knowledge is indispensable to ensure correct query formulation. This includes: I want to check the average rework for cases below and above the average throughput time.</p><p>Can you provide me a DuckDB SQL query. You should use the EPOCH function of DuckDB to get the timestamp from the date.</p><p>The data is stored in a Pandas dataframe where each row is an event having the provided attributes (so there are no separate table containing the variant). The dataframe is called "dataframe".</p><p>Please consider the following information: the case identifier is called "case:concept:name", the activity is stored inside the attribute "concept:name", the timestamp is stored inside the attribute "time:timestamp ", the resource is stored inside the attribute "org:resource". There is not a variant column but that can obtained as concatenation of the activities of a case. There is not a duration column but that can be obtained as difference between the timestamp of the first and the last event.</p><p>Prompt executed against both large language models.</p><p>WITH case times AS ( SELECT "case:concept:name", EPOCH(MAX("time:timestamp")) -EPOCH(MIN("time:timestamp")) AS throughput time FROM dataframe GROUP BY "case:concept:name" ), case reworks AS ( SELECT "case:concept:name", COUNT( * ) -COUNT(DISTINCT "concept:name") AS rework FROM dataframe GROUP BY "case:concept:name" ), cases AS ( SELECT ct."case:concept:name", ct.throughput time, cr.rework FROM case times AS ct JOIN case reworks AS cr ON ct."case:concept:name" = cr."case:concept:name" ), average throughput time AS ( SELECT AVG(throughput time) AS avg throughput FROM cases ) SELECT AVG(CASE WHEN c.throughput time &lt; att.avg throughput THEN c.rework END) AS avg rework below average, AVG(CASE WHEN c.throughput time &gt; att.avg throughput THEN c.rework END) AS avg rework above average FROM cases AS c, average throughput time AS att Correct response from GPT-4. SELECT case id, avg rework, avg throughput time, variant FROM (SELECT case id, AVG(rework) AS avg rework, AVG(duration) AS avg throughput time, CONCAT(activity) AS variant FROM dataframe GROUP BY case id) AS t WHERE avg throughput time &lt;&gt; (SELECT AVG(duration) FROM dataframe )</p><p>Wrong response from Bard.</p><p>Fig. <ref type="figure">7</ref>: SQL query generation comparison between GPT-4 and Bard for the "I want to check the average rework for cases below and above the average throughput time." query executed against the Road Traffic event log.</p><p>• Knowledge of SQL, such as the functions needed to calculate timestamps.</p><p>• An understanding of process mining concepts, such as how to compute a case's throughput time or how to derive the process variant from a list of activities.</p><p>• Awareness of the event log's key attributes, such as the column that identifies the case, the activity, and the timestamp.</p><p>• Knowledge of the variable name that the query should target. While these prerequisites may require specialized knowledge, they are instrumental in ensuring the accuracy and relevance of the SQL queries generated by the large language models.</p><p>In our study, we endeavored to assess the ability of large language models to convert natural language queries into SQL. Two distinct queries were used for this purpose on the Road Traffic event log.:</p><p>1. What is the average throughput time when activity 'Send Fine' occurs more than 50 days after the start of the case? (Refer to Figure <ref type="figure">6</ref> for the full query and the corresponding responses from GPT-4 and Bard). 2. I want to check the average rework for cases below and above the average throughput time (Refer to Figure <ref type="figure">7</ref> for the full query and the corresponding responses from GPT-4 and Bard). Our analysis reveals that, given sufficient domain knowledge, GPT-4 has an impressive capability to translate natural language queries into accurate SQL Bard, on the other hand, appears to have significant difficulty making sense of the provided information, often failing to generate executable SQL queries. This discrepancy underscores the importance of adequate domain understanding for successful natural language processing tasks in process mining.</p><p>Listing 25: Prompt used for the automatic generation of hypotheses. 297.0} article empty: 290 quantiles: {0.0: 7.0, 0.25: 7.0, 0.5: 157.0, 0.75: 157.0, 1.0: 181.0} expense empty: 312 quantiles: {0.0: 0.0, 0.25: 10.0, 0.5: 11.0, 0.75: 14.0625, 1.0: 30.0} paymentAmount empty: 332 quantiles: {0.0: 5.6, 0.25: 33.6, 0.5: 37.25, 0.75: 53.0, 1.0: 275.0} totalPaymentAmount empty: 232 quantiles: {0.0: 0.0, 0.25: 0.0, 0.5: 0.0, 0.75: 36.</p><p>0, 1.0: 275.0} vehicleClass empty: 290 values: (A; freq. 98) (M; freq. 2) concept:name empty: 0 values: (Create Fine; freq. 100) (Send Fine; freq. 78) ( Payment; freq. 58) (Insert Fine Notification; freq. 57) (Add penalty; freq. 57) (Send for Credit Collection; freq. 36) (Send Appeal to Prefecture; freq. 1) ( Receive Result Appeal from Prefecture; freq. 1) (Notify Result Appeal to Offender; freq. 1) (Insert Date Appeal to Prefecture; freq. 1) org:resource empty: 290 values: (541; freq. 8) (538; freq. 6) (537; freq. 6) (559; freq. 4) (555; freq. 4) ...... can you formulate some hypothesis on the given process? please also formulate for every hypothesis a SQL query. Can you provide me a DuckDB SQL query. You should use the EPOCH function of DuckDB to get the timestamp from the date.</p><p>The data is stored in a Pandas dataframe where each row is an event having the provided attributes (so there are no separate table containing the variant). The dataframe is called "dataframe". Please consider the following information: the case identifier is called "case:concept :name", the activity is stored inside the attribute "concept:name", the timestamp is stored inside the attribute "time:timestamp", the resource is stored inside the attribute "org:resource". There is not a variant column but that can be obtained as concatenation of the activities of a case. There is not a duration column but that can be obtained as difference between the timestamp of the first and the last event.</p><p>To explore the potential of large language models in autonomously formulating hypotheses about event data, we posed a specific prompt to both . This prompt was formulated such that it encouraged the models to generate hypotheses, starting from the knowledge of the attributes and the process variants present in the data.</p><p>Here are some hypotheses generated by GPT-4: 1. The majority of cases conclude with the payment of fines after the addition of a penalty. This suggests that the imposition of a penalty may be a decisive factor prompting payment. The corresponding SQL query formulated by GPT-4, along with the results derived from its execution, are depicted in Figure <ref type="figure">8</ref>. 2. The process of appealing to the prefecture does not appear to be a common practice. This indicates that offenders rarely dispute their fines. The provided SQL query for this hypothesis, along with the subsequent results, can be viewed in Figure <ref type="figure">9</ref>. 3. There may be a correlation between the amount of fines and the frequency of credit collections, with higher fines potentially leading to an increase in credit collection instances. This could be attributed to the difficulty in paying larger fines. The SQL query and results corresponding to this hypothesis are presented in Figure <ref type="figure">10</ref>. Bard's generated hypotheses included the following: 1. The most common process variant is "Create Fine -→ Send Fine -→ Insert Fine Notification -→ Add penalty -→ Send for Credit Collection". 2. The average payment amount for cases that traverse the complete process appears to be higher compared to cases that are concluded prematurely. 3. The longest durations to complete are typically associated with cases that involve an appeal. Both large language models generated valid hypotheses. However, a critical distinction arises from their ability to translate these hypotheses into executable SQL queries. While GPT-4 demonstrated this capability effectively, Bard did not manage to formulate corresponding SQL queries, emphasizing the advantage of incorporating explicit domain knowledge into the language model.</p><p>SELECT COUNT( * ) AS Cases With Penalty Before Payment FROM ( SELECT "case:concept:name", MIN("time:timestamp") as MinTime After Penalty FROM dataframe WHERE "concept:name" = 'Add penalty' GROUP BY "case:concept:name" ) as subquery1 JOIN dataframe ON dataframe."case:concept:name" = subquery1."case:concept:name" AND dataframe."time: timestamp" &gt; subquery1.MinTime After Penalty WHERE dataframe."concept:name" = 'Payment'; SQL query generated by GPT-4. Cases With Penalty Before Payment 22426 Result obtained after executing the SQL query. If we calculate the percentage of total cases that this number represents, we get: Percentage = (Cases With Penalty Before Payment / Total Cases) * 100 = (22426 / 150370) * 100 = Approximately 14.9%</p><p>This indicates that approximately 14.9% of all cases involve a penalty being added before payment.</p><p>However, the hypothesis stated, "The majority of fines are not paid until a penalty is added." The data doesn't seem to support this hypothesis as less than half (only about 14.9%) of the cases have a penalty added before payment.</p><p>So, based on the provided data, Hypothesis 1 is not supported.</p><p>Validity of the hypothesis assessed by GPT-4.</p><p>Fig. <ref type="figure">8</ref>: Usage of GPT-4 to verify the hypothesis number 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>The field of process mining is not isolated, but intersects with various domains such as database technologies, natural language processing (NLP), and the use of large language models. Additionally, it relies heavily on domain knowledge for effective task execution. In the subsequent sections, we explore these intersections and dependencies, providing an overview of the state-of-the-art in these domains and their relevance to process mining. We delve into the interaction of database technologies with process mining (Section 5.1), the intersection of process mining and NLP (Section 5.2), and the importance of domain knowledge in process mining tasks (Section 5.3). This is followed by a thorough examination of the current state of large language models (Section 5.4) and their application within the realm of Business Process Management (Section 5.5). This examination helps illuminate the context and behind our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Database Technologies for Process Mining</head><p>Database technologies play a crucial role in process mining, helping manage the increasing amounts of process-related data. They provide ways to extract and analyze this data, leading to valuable insights. In this section, we delve into several of these technologies and their contributions to process mining. The book Polyvyanyy (2022) considers the recognition and management of core techniques for retrieving and manipulating process-related artifacts. These core techniques are deemed reusable across various contexts and use cases such as process compliance, standardization, and monitoring, among others. By focusing on these reusable techniques, their aim is to increase efficiency and streamline the application of process querying across various projects and disciplines. Another approach <ref type="bibr" target="#b40">Polyvyanyy et al (2017)</ref> proposes a framework to guide the creation of process querying methods. This framework serves as a blueprint for managing repositories of executed and designed processes and their relationships. This approach is instrumental in facilitating strategic decision-making, as well as laying the groundwork for the next generation of Business Intelligence platforms.</p><p>The paper <ref type="bibr" target="#b43">Schönig et al (2016)</ref> delve into a more specific solution, introducing a mining approach that works directly on relational event data through conventional SQL queries. By leveraging the power of database technologies, this approach is able to efficiently mine data without limiting the detection of certain control-flow constraints, thus proving to be fast and effective.</p><p>In <ref type="bibr" target="#b8">Baader and Krcmar (2018)</ref>, the challenging task of fraud detection in large datasets contained in a SQL database by combining process mining with red flag-based approaches is tackled. This combined technique promises a lower rate of false positives, thereby improving the accuracy of fraud detection.</p><p>Another consideration in the process mining field is the extraction of event logs from databases, which is not a trivial task and demands substantial domain knowledge <ref type="bibr" target="#b35">de Murillas et al (2019)</ref>. In response to this, a meta model is proposed to integrate both process and data perspectives in a highly flexible manner, allowing for multiple views on the database at any given moment.</p><p>The approach desribed in <ref type="bibr" target="#b21">Esser and Fahland (2021)</ref> put forward a novel data model for multi-dimensional event data based on labeled property graphs. This model allows the storing of structural and temporal relations in an integrated, graph-based data structure. Such a system can manage complex, multi-dimensional event data efficiently.</p><p>A unique and highly specialized process querying language, the Celonis Process Query Language (PQL), is presented in <ref type="bibr" target="#b49">Vogelgesang et al (2022)</ref>. This language, designed specifically for business users, translates process-related business questions into queries, which are then executed on a custom-built query engine. With a wide range of operators and a syntax inspired by SQL, Celonis PQL showcases an effective adaptation of querying language for process-related inquiries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Process Mining and NLP</head><p>In recent years, significant advancements have been made in the field of process mining, with a particular focus on making this technology more accessible to non-technical users. For instance, <ref type="bibr" target="#b10">Barbieri et al (2022)</ref> proposed a natural language querying interface aimed at democratizing process mining technology. Their reference architecture integrated classic natural language processing techniques such as entity recognition and semantic parsing with an abstract logical representation for process mining queries. The architecture was interfaced with a commercial tool called Everflow, thus enabling users to retrieve process mining insights through questions in plain English. This approach greatly simplifies the process mining experience for line-of-business professionals.</p><p>Building upon this work, <ref type="bibr" target="#b31">Kobeissi et al (2023)</ref> also acknowledged the necessity of a user-friendly process data querying interface. They recognized the lack of a query language targeted at domain analysts, who might lack experience with database technologies, and therefore proposed a natural language interface. This interface, which uses graph-based storage techniques, interprets a user's natural language query and constructs a corresponding structured query over the stored event data. This solution is particularly beneficial for analysts who wish to explore process execution data without in-depth knowledge of database technologies.</p><p>Semantic considerations have also been integrated into process mining, with a focus on anomaly detection. van der Aa et al (2021) proposed a method of anomaly detection in process mining that uses the natural language associated with events to identify semantically inconsistent execution patterns. This approach, which contrasts with traditional frequency-based techniques, contributes to a more meaningful identification of potential anomalies. By automatically extracting business objects and actions from textual labels of events and comparing these against a process-independent knowledge base, the authors effectively identify anomalies when process behavior does not align with the semantics.</p><p>In the realm of chatbot technology, <ref type="bibr" target="#b29">Kecht et al (2023)</ref> highlighted the importance of the capability of chatbots to learn and adhere to organizations' business processes. They developed an approach that quantifies chatbots' ability to learn business processes using standardized process mining metrics. This approach was demonstrated on a dataset of customer service conversations from three companies on Twitter, showing how it can quantify a chatbot's ability to learn not only the overall business process but also specific variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Domain Knowledge in Process Mining Tasks</head><p>Domain knowledge provides a wealth of insights that can augment the application of process mining techniques. One of the pivotal works in this context is presented in <ref type="bibr" target="#b44">Schuster et al (2022)</ref>. The study acknowledges that, while automated filtering of event data is a significant contributor to obtaining better process models, it may often be overly rigorous, leading to the removal of relevant data. To mitigate this, the authors introduce a new group of discovery algorithms that leverage domain knowledge in conjunction with event data. This synergistic approach is structured systematically via a taxonomy that classifies and compares existing strategies, offering a comprehensive review of domain knowledge-exploiting process discovery methodologies.</p><p>In the paper <ref type="bibr" target="#b45">Schuster et al (2023)</ref>, the authors introduce Cortado, a software tool designed specifically for interactive process discovery, a vital branch within process mining. Process discovery involves the data-driven exploration of operational processes. By analyzing event data that record historical process executions, process discovery algorithms are able to generate process models that elucidate the interplay between various activities. Such models become indispensable artifacts used across multiple process mining techniques. However, conventional process discovery methods often function like a black-box approach and may produce models of poor quality from event data. This is where Cortado steps in, taking a novel approach to process discovery by allowing users to progressively learn and refine process models from event data in an interactive manner. Through this approach, Cortado successfully leverages domain knowledge and data-derived insights to develop more nuanced process models.</p><p>Furthering the notion of domain knowledge incorporation, the research in <ref type="bibr" target="#b20">Dixit et al (2015)</ref> addresses the necessity of leveraging domain expertise to refine discovered process models. The authors introduce a modification algorithm that adjusts a discovered process model based on domain knowledge. This work stands as a significant stride towards enhancing process discovery by ensuring that the outputs align more closely with domain expert knowledge, thereby fostering a balance between data-driven and expertise-guided process discovery.</p><p>Lastly, the paper in <ref type="bibr" target="#b9">Baier et al (2014)</ref> presents an approach to align the levels of abstraction in event logs with business activities using extracted domain knowledge. The authors' method allows for n:m relations between events and activities and supports concurrency, addressing common issues encountered when attempting to abstract event logs to match business activities. This research provides a critical bridge between low-level event data and higherlevel business process activities, facilitating a more meaningful interpretation of discovered process models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Large Language Models</head><p>In the rapidly progressing field of natural language processing (NLP), one of the most significant developments of recent years has been the advent of large language models (LLMs). These models, such as BERT, GPT-2, GPT-3, and T5, represent a transformative shift in the domain, harnessing the power of deep learning and the wealth of available linguistic data to accomplish a broad spectrum of tasks. This subsection provides an overview of the genesis and evolution of these influential models, along with a focus on their computational and reasoning capabilities. Furthermore, we explore the motivation and progression of specific LLMs like ChatGPT as potent question-answering systems across multiple prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">The Genesis of Large Language Models</head><p>The field of Natural Language Processing (NLP) has been primarily concerned with understanding and generating human language. Early attempts at language modeling were based on statistical approaches, like n-gram models, which consider a fixed number of previous words to predict the next word in a sentence. However, these models suffer from the curse of dimensionality and fail to capture long-term dependencies in text.</p><p>The introduction of neural network-based approaches, such as feed-forward neural probabilistic language models <ref type="bibr" target="#b22">Gangireddy et al (2014)</ref> and recurrent neural networks (RNNs) <ref type="bibr" target="#b25">Jaech et al (2016)</ref>, was a significant leap forward. These models can theoretically capture arbitrarily long sequences and represent more complex syntactic and semantic relationships. However, in practice, RNNs and their variants (e.g., LSTM, GRU) struggle with long-term dependencies due to issues like vanishing and exploding gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Birth of Transformer Models</head><p>The limitations of RNNs were largely overcome by the advent of the Transformer architecture, introduced in the paper <ref type="bibr" target="#b47">Vaswani et al (2017)</ref>. The Transformer model is based on self-attention mechanisms and foregoes recurrence entirely. It allows for parallelizable computation and better handling of long-range dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.3">BERT, GPT-2, and T5</head><p>BERT (Bidirectional Encoder Representations from Transformers), introduced by Google in 2018, is a Transformer-based model trained on a large corpus of text data. Unlike previous models, BERT <ref type="bibr" target="#b18">Devlin et al (2019)</ref> considers context from both directions (left and right of a word) in all layers, giving it a deeper sense of language context and flow.</p><p>OpenAI introduced GPT-2 (Generative Pretrained Transformer 2) in 2019<ref type="foot" target="#foot_8">foot_8</ref> , focusing on generating human-like text. GPT-2 differs from BERT in its training objective. While BERT is a bidirectional model, GPT-2 is unidirectional (or causal), meaning it predicts the next word based on the preceding words, making it suitable for text generation tasks.</p><p>T5 (Text-to-Text Transfer Transformer)<ref type="foot" target="#foot_9">foot_9</ref> , introduced by Google in 2019, adopted a unified text-to-text approach where every NLP task is cast as a text generation problem, making the model versatile across multiple tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.4">ChatGPT and Its Motivation</head><p>ChatGPT is a variant of the GPT model developed by OpenAI. It is specifically fine-tuned for generating conversational responses, serving as a powerful tool for tasks like drafting emails, writing code, answering questions, tutoring, language translation, and even simulating characters for video games. The model was trained using Reinforcement Learning from Human Feedback (RLHF), using a dataset of dialogues where AI trainers provided both sides of a conversation and sometimes had access to model-written suggestions.</p><p>The motivation behind ChatGPT was to build an AI system that can generate useful and coherent responses over multiple conversational turns, instead of focusing on individual responses. This has involved addressing challenges such as providing detailed responses, maintaining the context of a conversation, and ensuring that the model doesn't generate harmful or misleading outputs. Despite these challenges, ChatGPT exemplifies the potential of language models in making substantial contributions to many areas of life and work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.5">Computing and Reasoning Capabilities</head><p>Large language models like BERT, GPT-3, and T5, have revolutionized the field of natural language processing with their capabilities to understand and generate human-like text. The ability to predict contextually relevant words, translate languages, and even code comes from these models' capacity to identify patterns in extensive textual data. They have been trained on enormous datasets and, as a result, carry within them a broad range of knowledge, from trivial facts to complex concepts.</p><p>From a computational perspective, these models are capable of more than just text generation and comprehension. They can perform mathematical computations, solve equations, and even tackle problems involving logic and reasoning <ref type="bibr" target="#b15">Bommasani et al (2021)</ref>, all based on the patterns learned during their training phase. While it's true that these models can simulate reasoning through the recognition of data patterns <ref type="bibr" target="#b17">Clark et al (2020)</ref>, this is different from the way humans reason. These models don't possess consciousness or understanding; instead, they generate outputs based on statistical patterns. However, it's worth noting that the "reasoning" exhibited by these models, despite its fundamental difference from human cognition, is impressive and has wide-ranging practical applications.</p><p>Large language models are powerful tools, capable of tackling diverse tasks, but they do have limitations. They lack the ability to access real-time knowledge beyond their training data, and their capability to verify information is limited. Nevertheless, they are a testament to the progress in the field and the potential of future developments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Large Language Models and Business Process Management</head><p>This subsection explores the promising potential and ongoing advancements of Large Language Models (LLMs), their application in Business Process Management (BPM), and the challenges that need to be addressed to effectively utilize these models in the BPM context. Large language models (LLMs), such as GPT-3, have shown remarkable capabilities in a broad array of natural language processing (NLP) tasks, extending their usefulness beyond text generation into more specialized fields, including business process management (BPM). As detailed in <ref type="bibr" target="#b16">Busch et al (2023)</ref>, these LLMs have been effectively utilized for predictive process monitoring and process extraction from text. However, the application of such models typically demands fine-tuning, a process that requires an extensive amount of suitable training data. One innovative approach to bypass this necessity is prompt engineering, which exploits the pre-training of LLMs without the need for additional fine-tuning. This paper outlines a research agenda for incorporating prompt engineering into BPM, thereby broadening the capabilities of LLMs within this discipline.</p><p>Moreover, the study presented in <ref type="bibr" target="#b48">Vidgof et al (2023)</ref> emphasizes the lack of systematic investigation into the opportunities offered by LLMs in BPM. Notwithstanding the impressive progress LLMs have made on various tasks, their application to the BPM lifecycle remains less explored. This research foregrounds several BPM tasks and highlights six research directions that call for attention when using LLMs, providing usage guidelines for practitioners.</p><p>In <ref type="bibr" target="#b30">Klievtsova et al (2023)</ref>, the authors address the rising interest in the use of chatbots, like ChatGPT, for Business Process Management (BPM) applications. The authors aim to systematically assess existing chatbots for their capacity to support conversational process modelling, a critical function in process-oriented capabilities. They commence by identifying application scenarios across the process life cycle and then conduct a systematic literature review on conversational process modelling. The outcome of this review is a taxonomy that serves as an input for pinpointing application scenarios for conversational process modelling. These scenarios include the paraphrasing and improvement of process descriptions. The authors evaluate these application scenarios for existing chatbots using a real-world test set derived from the higher education domain. This test set comprises process descriptions, their corresponding process models, and an evaluation of the model quality. The authors leverage the insights from the literature review and the scenario analyses to provide practical implications for the usage and potential avenues for further development of conversational process modelling.</p><p>In our previous work <ref type="bibr" target="#b14">Berti et al (2023b)</ref>, we performed a first exploration of the usage of Large Language Models (LLMs) in the domain of process mining.</p><p>A key challenge we addressed was the size constraints that limited the amount of data we could feed into the LLM. To overcome this, we first proposed a methodology to abstract information from standard process mining artifacts. This abstraction allowed us to distill complex data into a more concise format that was manageable for the LLM. Secondly, we developed strategic prompts that guided the LLMs to generate insightful and relevant responses from the abstracted inputs. However, we did not cover more advanced abstractions (machine learning features, object-centric event logs/process models, . . . ) or multi-prompt strategies. Also, the evaluation was limited to the GPT-4 large language model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Fig.4: Example object-centric directly-follows graph computed on the objectcentric log contained in Table2. Different annotations (i.e., frequency and performance) are computed<ref type="bibr" target="#b11">Berti and van der Aalst (2023)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc>If I have a process with flow: Activity A -&gt; Activity B ( frequency = 2 performance = 1350.0 ) Activity C -&gt; Activity D ( frequency = 1 performance = 900.0 ) Activity B -&gt; Activity C ( frequency = 1 performance = 900.0 ) Activity A -&gt; Activity C ( frequency = 1 performance = 1800.0 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>If I have a process with the following process variants: Activity A -&gt; Activity C -&gt; Activity D ( frequency = 1 performance = 2700.0 ) Activity A -&gt; Activity B -&gt; Activity C ( frequency = 1 performance = 1800.0 ) Activity A -&gt; Activity B ( frequency = 1 performance = 1800.0 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><figDesc>related objects: Invoice2, Item3, Order2 ) timestamp: 2023-07-13 09:30:00 Activity A ( related objects: Invoice2, Item3, Order2 ) timestamp: 2023-07-13 10:00:00 Activity B ( related objects: Invoice2, Item4, Order2 ) timestamp: 2023-07-13 10:30:00 objects:Invoice2 object type: Invoices ( lifecycle start: 2023-07-13 09:30:00 ; lifecycle end: 2023-07-13 10:30:00 ; lifecycle duration: 3600.0 ) Item3 object type: OrderItems ( lifecycle start: 2023-07-13 09:30:00 ; lifecycle end: 2023-07-13 10:00:00 ; lifecycle duration: 1800.0 ) Item4 object type: OrderItems ( lifecycle start: 2023-07-13 10:30:00 ; lifecycle end: 2023-07-13 10:30:00 ; lifecycle duration: 0.0 ) Order2 object type: Order ( lifecycle start: 2023-07-13 09:30:00 ; lifecycle end: 2023-07-13 10:30:00 ; lifecycle duration: 3600.0 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><figDesc>Duration of the lifecycle of the object: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 900.0, 0.25: 900.0, 0.5: 1800.0, 0.75: 2925.0, 1.0: 3600.0} Number of unique activities in the lifecycle of the object: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 2.0, 0.25: 2.0, 0.5: 2.5, 0.75: 3.0, 1.0: 3.0} Number of events in the lifecycle of the object: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 2.0, 0.25: 2.0, 0.5: 2.5, 0.75: 3.0, 1.0: 3.0} Number of objects ending their lifecycle together with the current object: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 2.0, 0.25: 2.0, 0.5: 2.0, 0.75: 2.25, 1.0: 3.0} Number of objects starting their lifecycle together with the current object: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 2.0, 0.25: 2.75, 0.5: 3.0, 0.75: 3.0, 1.0: 3.0} Start timestamp of the lifecycle of the object: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 1689238800.0, 0.25: 1689240150.0, 0.5: 1689243300.0, 0.75: 1689246900.0, 1.0: 1689249600.0} Completion timestamp of the lifecycle of the object: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 1689239700.0, 0.25: 1689243075.0, 0.5: 1689246450.0, 0.75: 1689249150.0, 1.0: 1689250500.0} Number of occurrences of the activity Activity A: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Number of objects related in the object interaction graph: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 3.0, 0.25: 3.0, 0.5: 3.0, 0.75: 3.0, 1.0: 3.0} Number of object of type OrderItems related to the current object in the object interaction graph: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 2.0, 0.25: 2.0, 0.5: 2.0, 0.75: 2.0, 1.0: 2.0} Number of object of type Invoices related to the current object in the object interaction graph: number of non-zero values: 4 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Number of occurrences of the activity Activity B: number of non-zero values: 3 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Frequency of the path "Activity A" -&gt; "Activity B" in the lifecycle of the object: number of non-zero values: 3 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Number of occurrences of the activity Activity C: number of non-zero values: 2 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Number of occurrences of the activity Activity D: number of non-zero values: 1 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Number of objects which precede the current object in the object descendants graph: number of non-zero values: 1 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Number of objects which follow the current object in the object inheritance graph: number of non-zero values: 1 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0} Number of objects which follow the current object in the object descendants graph : number of non-zero values: 1 ; quantiles of the non-zero: {0.0: 1.0, 0.25: 1.0, 0.5: 1.0, 0.75: 1.0, 1.0: 1.0}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>If I have the following process variants: Create Fine -&gt; Send Fine -&gt; Insert Fine Notification -&gt; Add penalty -&gt; Send for Credit Collection ( frequency = 36 performance = 53746600.0 ) Create Fine -&gt; Payment ( frequency = 22 performance = 809181.8181818182 ) ...... and attributes in the log: time:timestamp empty: 0 quantiles: {0.0: Timestamp('2000-03-14 23:00:00+0000', tz='UTC'), 0.25: Timestamp('2003-03-05 16:45:00+0000', tz='UTC'), 0.5: Timestamp('2005-12-21 11:00:00+0000', tz='UTC'), 0.75: Timestamp('2009-01-18 23:00:00+0000', tz='UTC'), 1.0: Timestamp ('2013-04-23 22:00:00+0000', tz='UTC')} amount empty: 233 quantiles: {0.0: 21.0, 0.25: 33.6, 0.5: 38.0, 0.75: 68.77, 1.0:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 :</head><label>8</label><figDesc>Fundamental statistics of the real-life event logs used in the assessment.</figDesc><table><row><cell>Event Log</cell><cell cols="2">Number of Events Number of Cases</cell><cell cols="2">Number of Variants Number of Activities</cell></row><row><cell>Road Traffic</cell><cell>561470</cell><cell>150370</cell><cell>231</cell><cell>11</cell></row><row><cell>BPI Challenge 2020</cell><cell>56437</cell><cell>10500</cell><cell>99</cell><cell>17</cell></row><row><cell>Sepsis</cell><cell>15214</cell><cell>1050</cell><cell>846</cell><cell>16</cell></row><row><cell>Conformance Checking Challenge 2019</cell><cell>1394</cell><cell>20</cell><cell>20</cell><cell>29</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9 :</head><label>9</label><figDesc>Fundamental statistics of the event logs used for fairness evaluation.</figDesc><table><row><cell>Event Log</cell><cell cols="4">Number of Events Number of Cases Number of Variants Number of Activities</cell></row><row><cell>hiring log high-xes.gz</cell><cell>63869</cell><cell>10000</cell><cell>386</cell><cell>12</cell></row><row><cell>hiring log low-xes.gz</cell><cell>72094</cell><cell>10000</cell><cell>296</cell><cell>12</cell></row><row><cell>hiring log medium-xes.gz</cell><cell>69054</cell><cell>10000</cell><cell>382</cell><cell>12</cell></row><row><cell>hospital log high-xes.gz</cell><cell>69528</cell><cell>10000</cell><cell>80</cell><cell>10</cell></row><row><cell>hospital log low-xes.gz</cell><cell>70037</cell><cell>10000</cell><cell>106</cell><cell>10</cell></row><row><cell>hospital log medium-xes.gz</cell><cell>70124</cell><cell>10000</cell><cell>77</cell><cell>10</cell></row><row><cell>lending log high-xes.gz</cell><cell>58822</cell><cell>10000</cell><cell>41</cell><cell>12</cell></row><row><cell>lending log low-xes.gz</cell><cell>60746</cell><cell>10000</cell><cell>31</cell><cell>12</cell></row><row><cell>lending log medium-xes.gz</cell><cell>58668</cell><cell>10000</cell><cell>33</cell><cell>12</cell></row><row><cell>renting log high-xes.gz</cell><cell>89972</cell><cell>10000</cell><cell>496</cell><cell>16</cell></row><row><cell>renting log low-xes.gz</cell><cell>96440</cell><cell>10000</cell><cell>508</cell><cell>16</cell></row><row><cell>renting log medium-xes.gz</cell><cell>105555</cell><cell>10000</cell><cell>610</cell><cell>16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10 :</head><label>10</label><figDesc>Sensitive attributes in the supplied event log dataset.</figDesc><table><row><cell>Domain</cell><cell>Age</cell><cell>Citizenship</cell><cell>German Proficiency</cell><cell>Gender</cell><cell>Religion</cell><cell>Years of Education</cell><cell>Underlying Condition</cell><cell>Private Insurance</cell></row><row><cell>Hiring</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 11 :</head><label>11</label><figDesc>Assessment of large language models' capabilities on traditional event logs/process models.</figDesc><table><row><cell>Question</cell><cell>Acceptance Criteria for the Answer(s)</cell><cell>Textual Abstraction Used</cell><cell>Road Traffic</cell><cell cols="2">BPI Challenge 2020</cell><cell></cell><cell>Sepsis</cell><cell>CCC19</cell></row><row><cell></cell><cell></cell><cell>GPT-4</cell><cell>Bard</cell><cell>GPT-4</cell><cell>Bard</cell><cell>GPT-4</cell><cell>Bard</cell><cell>GPT-4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 12 :</head><label>12</label><figDesc>Assessment of large language models' capabilities on object-centric event logs.</figDesc><table><row><cell>Question</cell><cell>Acceptance Criteria for the Answer(s)</cell><cell>Textual Abstraction Used</cell><cell cols="2">Order Management</cell><cell></cell><cell>Recruiting</cell></row><row><cell>OQ1 Could you provide a description of the process</cell><cell>The description reflects the process and its steps.</cell><cell>OC-DFG</cell><cell>GPT-4 √</cell><cell>Bard √</cell><cell>GPT-4 √</cell><cell>Bard √</cell></row><row><cell>underlying this data? OQ2 Could you identify the main anomalies in this</cell><cell>Some anomalies are correctly identified from the data.</cell><cell>OC-DFG</cell><cell>√</cell><cell>√</cell><cell>√</cell><cell>√</cell></row><row><cell>data according to your domain knowledge of the pro-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cess? OQ3 Could you identify the root causes of the perfor-</cell><cell>Some root causes for performance issues are correctly</cell><cell>OC-DFG</cell><cell>√</cell><cell>√</cell><cell>√</cell><cell>X</cell></row><row><cell>mance issues in the process? OQ4 Could you identify the main anomalies in this</cell><cell>identified from the data. Some anomalies are correctly identified from the data.</cell><cell>Process Execution</cell><cell>√</cell><cell>√</cell><cell>√</cell><cell>√</cell></row><row><cell>data according to your domain knowledge of the pro-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cess?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 13 :</head><label>13</label><figDesc>Quality of the classification done by GPT-4 between the 'protected' and 'non-protected' groups.</figDesc><table><row><cell>Event Log</cell><cell>TP</cell><cell>FP</cell><cell>FN</cell><cell>TN</cell><cell>Precision</cell><cell>Recall</cell><cell>True Neg. Rate</cell></row><row><cell>hiring log high</cell><cell>1507</cell><cell>606</cell><cell cols="2">1512 6375</cell><cell>0.72</cell><cell>0.50</cell><cell>0.80</cell></row><row><cell>hospital log high</cell><cell cols="4">1105 1089 1417 6389</cell><cell>0.50</cell><cell>0.44</cell><cell>0.82</cell></row><row><cell>lending log high</cell><cell>1501</cell><cell>688</cell><cell cols="2">1500 6391</cell><cell>0.69</cell><cell>0.50</cell><cell>0.81</cell></row><row><cell>renting log high</cell><cell cols="4">1068 1056 1914 5962</cell><cell>0.50</cell><cell>0.35</cell><cell>0.75</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 14 :</head><label>14</label><figDesc>Quality of the classification done by GPT-4 between the 'protected' and 'non-protected' groups. The excellent recall and true negative rate should be noticed.</figDesc><table><row><cell>Event Log</cell><cell>TP</cell><cell>FP</cell><cell>FN</cell><cell>TN</cell><cell>Precision</cell><cell>Recall</cell><cell>True Neg. Rate</cell></row><row><cell>hiring log high</cell><cell cols="2">2977 5768</cell><cell>42</cell><cell>1213</cell><cell>0.34</cell><cell>0.98</cell><cell>0.97</cell></row><row><cell>hospital log high</cell><cell cols="2">2922 6395</cell><cell>88</cell><cell>595</cell><cell>0.31</cell><cell>0.97</cell><cell>0.87</cell></row><row><cell>lending log high</cell><cell cols="2">2923 4555</cell><cell>78</cell><cell>2444</cell><cell>0.39</cell><cell>0.97</cell><cell>0.96</cell></row><row><cell>renting log high</cell><cell cols="2">2716 6749</cell><cell>266</cell><cell>269</cell><cell>0.29</cell><cell>0.91</cell><cell>0.50</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Available at the address https://github.com/pm4py/pm4py-core/blob/release/tests/input data/running-example.bpmn</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://doi.org/10.4121/uuid:270fd440-1057-4fb9-89a9-b699b47990f5</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://doi.org/10.4121/uuid:3f422315-ed9d-4882-891f-e180b5b4feb5</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://data.4tu.nl/articles/ /12707639/1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://doi.org/10.4121/uuid:c923af09-ce93-44c3-ace0-c5508cf103ad</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>√ √ X √ X</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p>√ √ √ √TQ6 Could you identify the root causes of the performance issues in the process? Some root causes for performance issues are correctly identified from the data.Process Variants√ X √ X X X √ XTQ7 Can you provide me a trace allowed by the process model?The provided trace is allowed from the procedural model.Petri net√ X √ X X X X XTQ8 Can you explain why this trace is not allowed by the process model?A valid explanation about the unconformity is provided.Petri net√ √ √ X √ X X XTQ9 Can you provide me a trace allowed by the process model?The provided trace is allowed from the declarative model.DECLARE √ √ √ X</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p>Temporal Profile√ √ X X X XTQ12 Could you identify interesting aspects for the analysis of the process? Some aspects to investigate are correctly identified from the data.Log Features√ X √ X √ X X X</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_8"><p>https://github.com/openai/gpt-2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_9"><p>https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Functionality pm4py.llm.openai query() Executes a prompt against OpenAI, returning the response as string</p><p>Table <ref type="table">7</ref>: Method for interacting directly with the LLM APIs available in pm4py.</p><p>(Table <ref type="table">7</ref>). This function enables users to directly execute prompts against OpenAI's language models, obtaining textual responses that can be further analyzed or used in subsequent processes.</p><p>Listing 11: Example usage of the pm4py's LLM integration on traditional process mining objects A sample usage of pm4py's LLM integration is shown in Listing 11, where the abstract variants method is used to retrieve the variants of an event log. Subsequently, the Petri net discovered from the event log is abstracted using abstract petri net, and both of these abstractions are used to construct prompts for querying an LLM.</p><p>Listing 12: Example usage of the pm4py's LLM integration on object-centric process mining objects import pm4py ocel = pm4py.read ocel("tests/input data/ocel/example log.jsonocel") q1 = "\n\nWhat are the strangest relationships in this graph?" print(pm4py.llm.abstract ocel ocdfg(ocel) + q1) q2 = "\n\nWhat are the strangest features' values?" print(pm4py.llm.abstract ocel features(ocel, "order") + q2)</p><p>A distinct advantage of the pm4py tool is its support for object-centric process mining, a relatively recent advancement in the process mining field SELECT COUNT(DISTINCT "case:concept:name") AS Cases With Appeal FROM dataframe WHERE "concept:name" = 'Insert Date Appeal to Prefecture' OR "concept:name" = 'Send Appeal to Prefecture' OR "concept:name" = 'Receive Result Appeal from Prefecture' OR "concept:name" = 'Notify Result Appeal to Offender';</p><p>SQL query generated by GPT-4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cases With Appeal 4204</head><p>Result obtained after executing the SQL query.</p><p>With the total number of cases being 150,370 and the number of cases that include an appeal to the prefecture being 4,204, we can calculate the percentage of cases that involve an appeal to the prefecture. This indicates that only around 2.8% of all cases involve an appeal to the prefecture.</p><p>Given that this is a relatively small proportion, the data does seem to support Hypothesis 3 that the process of appealing to the prefecture is not common, implying that offenders don't often dispute their fines.</p><p>Validity of the hypothesis assessed by GPT-4.</p><p>Fig. <ref type="figure">9</ref>: Usage of GPT-4 to verify the hypothesis number 2.</p><p>SELECT AVG(dataframe.amount) as Average Fine, subquery1.Ending Action FROM ( SELECT "case:concept:name", MAX("time:timestamp") as MaxTime, "concept:name" as Ending Action FROM dataframe WHERE "concept:name" IN ('Send for Credit Collection', 'Payment') GROUP BY "case:concept:name", "concept:name" ) as subquery1 JOIN dataframe ON dataframe."case:concept:name" = subquery1."case:concept:name" GROUP BY subquery1.Ending Action;</p><p>SQL query generated by GPT-4. Result obtained after executing the SQL query.</p><p>Yes, the data appears to support Hypothesis 4. The average fine for cases that end with 'Send for Credit Collection' (74.13) is higher than the average fine for cases that end with 'Payment' (52.00).</p><p>This suggests that higher fines are more likely to lead to credit collections, possibly because they are more difficult for individuals to pay. However, it's important to note that this is an observational finding and may not imply causation. Other factors might also contribute to a case ending in credit collection.</p><p>Further statistical analysis could be conducted to quantify the strength of this relationship and control for potential confounding variables.</p><p>Validity of the hypothesis assessed by GPT-4. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Natural language-based detection of semantic execution anomalies in event logs</title>
		<author>
			<persName><forename type="first">H</forename><surname>Van Der Aa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rebmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Leopold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf Syst</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page">101824</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">for modeling business processes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Aagesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krogstie</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-45100-3_10</idno>
		<idno>BPMN 2.0</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-45100-310" />
	</analytic>
	<monogr>
		<title level="m">Handbook on Business Process Management 1, Introduction, Methods, and Information Systems</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Vom Brocke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Rosemann</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="219" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The application of petri nets to workflow management</title>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<idno type="DOI">10.1142/S0218126698000043</idno>
		<ptr target="https://doi.org/10.1142/S0218126698000043" />
	</analytic>
	<monogr>
		<title level="j">J Circuits Syst Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="66" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-662-49851-4</idno>
		<ptr target="https://doi.org/10.1007/978-3-662-49851-4" />
		<title level="m">Process Mining -Data Science in Action</title>
		<meeting>ess Mining -Data Science in Action</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Second Edition</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Workflow mining: Discovering process models from event logs</title>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A ;</forename><surname>Berti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weijters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maruster</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2004.47</idno>
		<ptr target="https://doi.org/10.1109/TKDE.2004.47" />
	</analytic>
	<monogr>
		<title level="m">FI-2020-1946 van der Aalst WMP</title>
		<imprint>
			<date type="published" when="2004">2020. 2004</date>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="page" from="1128" to="1142" />
		</imprint>
	</monogr>
	<note>Discovering object-centric petri nets Fundam Informaticae</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">IEEE 1849: The XES standard: The second IEEE standard sponsored by IEEE computational intelligence society [society briefs]</title>
		<author>
			<persName><forename type="first">G</forename><surname>Acampora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vitiello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bnd</forename><surname>Stefano</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCI.2017.2670420</idno>
		<ptr target="https://doi.org/10.1109/MCI.2017.2670420" />
	</analytic>
	<monogr>
		<title level="j">IEEE Comput Intell Mag</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="4" to="8" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A framework for extracting and encoding features from object-centric event data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levich</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-20984-0_3</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-20984-03" />
	</analytic>
	<monogr>
		<title level="m">Service-Oriented Computing -20th International Conference, ICSOC 2022</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Troya</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Medjahed</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Piattini</surname></persName>
		</editor>
		<meeting><address><addrLine>Seville, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-11-29">2022. November 29 -December 2, 2022</date>
			<biblScope unit="page" from="36" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Defining cases and variants for object-centric event data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schmitz</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICPM57379.2022.9980730</idno>
		<ptr target="https://doi.org/10.1109/ICPM57379.2022.9980730" />
	</analytic>
	<monogr>
		<title level="m">th International Conference on Process Mining, ICPM 2022</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Burattin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Polyvyanyy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Weber</surname></persName>
		</editor>
		<meeting><address><addrLine>Bolzano, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022-10-23">2022b. October 23-28, 2022</date>
			<biblScope unit="page" from="128" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reducing false positives in fraud detection: Combining the red flag approach with process mining</title>
		<author>
			<persName><forename type="first">G</forename><surname>Baader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Krcmar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Account Inf Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bridging abstraction layers in process mining</title>
		<author>
			<persName><forename type="first">T</forename><surname>Baier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mendling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weske</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf Syst</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="123" to="139" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Verification of quantitative temporal compliance requirements in process descriptions over event logs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Madeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stroeh</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-34560-9_25</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-34560-925" />
	</analytic>
	<monogr>
		<title level="m">Advanced Information Systems Engineering -35th International Conference, CAiSE 2023</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Indulska</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Reinhartz-Berger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cetina</surname></persName>
		</editor>
		<meeting><address><addrLine>Zaragoza, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022. 2023. June 12-16, 2023</date>
			<biblScope unit="page" from="417" to="433" />
		</imprint>
	</monogr>
	<note>Journal of Intelligent Information Systems pp 1-30 A natural language querying interface for process mining</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">OC-PM: analyzing object-centric event logs and process models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Berti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10009-022-00668-w</idno>
		<ptr target="https://doi.org/10.1007/s10009-022-00668-w" />
	</analytic>
	<monogr>
		<title level="j">Int J Softw Tools Technol Transf</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Process mining for python (pm4py): Bridging the gap between process-and data science</title>
		<author>
			<persName><forename type="first">A</forename><surname>Berti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Van Zelst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Van</forename><surname>Der Aalst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename></persName>
		</author>
		<ptr target="https://ceur-ws.org/Vol-2374/paper4" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Conference on Process Mining (ICPM 2019)</title>
		<meeting>the 1st International Conference on Process Mining (ICPM 2019)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="13" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">a) Graph-based feature extraction on object-centric event logs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pdf Berti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Herforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Qafari</surname></persName>
		</author>
		<idno type="DOI">10.1007/s41060-023-00428-2</idno>
		<ptr target="https://doi.org/10.1007/s41060-023-00428-2" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Data Science and Analytics URL</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">) Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study</title>
		<author>
			<persName><forename type="first">A</forename><surname>Berti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2307.02194</idno>
		<idno>CoRR abs/2307.02194</idno>
		<ptr target="https://arxiv.org/abs/2307.02194" />
		<imprint>
			<date type="published" when="2023">2023b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">On the opportunities and risks of foundation models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<idno>CoRR abs/2108.07258</idno>
		<ptr target="https://arxiv.org/abs/2108.07258" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Just tell me: Prompt engineering in business process management</title>
		<author>
			<persName><forename type="first">K</forename><surname>Busch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rochlitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sola</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-34241-7_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-34241-71" />
	</analytic>
	<monogr>
		<title level="m">Enterprise, Business-Process and Information Systems Modeling -24th International Conference, BPMDS 2023, and 28th International Conference, EMMSAD 2023</title>
		<title level="s">Lecture Notes in Business Information Processing</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Van Der Aa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Bork</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Proper</surname></persName>
		</editor>
		<meeting><address><addrLine>Zaragoza, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023-06-12">2023. June 12-13, 2023</date>
			<biblScope unit="volume">479</biblScope>
			<biblScope unit="page" from="3" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transformers as soft reasoners over language</title>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2020/537</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2020/537" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020. ijcai.org</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Bessiere</surname></persName>
		</editor>
		<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020. ijcai.org</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3882" to="3890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06-02">2019. June 2-7, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semantics and analysis of business process models in BPMN</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Dijkman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dumas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ouyang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.infsof.2008.02.006</idno>
		<ptr target="https://doi.org/10.1016/j.infsof.2008.02.006" />
	</analytic>
	<monogr>
		<title level="j">Inf Softw Technol</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1281" to="1294" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Enhancing process mining results using domain knowledge</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jcam</forename><surname>Buijs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<idno>CEUR-WS.org</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Symposium on Data-driven Process Discovery and Analysis</title>
		<meeting>the 5th International Symposium on Data-driven Process Discovery and Analysis</meeting>
		<imprint>
			<publisher>SIMPDA</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="79" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-dimensional event data in graph databases</title>
		<author>
			<persName><forename type="first">S</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fahland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Data Semant</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="109" to="141" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Feed forward pre-training for recurrent neural network language models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Gangireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Renals</surname></persName>
		</author>
		<idno type="DOI">10.21437/Interspeech.2014-561</idno>
		<ptr target="https://doi.org/10.21437/Interspeech.2014-561" />
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH 2014, 15th Annual Conference of the International Speech Communication Association</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Meng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Ma</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-09-14">2014. September 14-18, 2014</date>
			<biblScope unit="page" from="2620" to="2624" />
		</imprint>
		<respStmt>
			<orgName>ISCA</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">OCEL: A standard for object-centric event logs</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Ghahfarokhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Trends in Database and Information Systems -ADBIS 2021</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Bellatreche</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Dumas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Karras</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Proceedings</title>
		<author>
			<persName><forename type="first">Simpda</forename><surname>Doing</surname></persName>
		</author>
		<author>
			<persName><surname>Madeisd</surname></persName>
		</author>
		<author>
			<persName><surname>Megadata</surname></persName>
		</author>
		<author>
			<persName><surname>Caons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Estonia</forename><surname>Tartu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-85082-1_16</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-85082-116" />
	</analytic>
	<monogr>
		<title level="m">Doctoral Consortium and Workshops</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">August 24-26, 2021</date>
			<biblScope unit="page" from="169" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Domain adaptation of recurrent neural networks for natural language understanding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
		<idno type="DOI">10.21437/Interspeech.2016-1598</idno>
		<ptr target="https://doi.org/10.21437/Interspeech.2016-1598" />
	</analytic>
	<monogr>
		<title level="m">17th Annual Conference of the International Speech Communication Association</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Morgan</surname></persName>
		</editor>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09-08">2016. 2016. September 8-12, 2016</date>
			<biblScope unit="page" from="690" to="694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evaluating trace encoding methods in process mining</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Junior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ceravolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Damiani</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-70650-0_11</idno>
		<idno>978-3-030-70650-0 11</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">From Data to Models and Back -9th International Symposium, DataMod 2020, Virtual Event</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Bowles</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Broccia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nanni</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020-10-20">2020. October 20, 2020</date>
			<biblScope unit="page" from="174" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Process mining using BPMN: relating event logs and process models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Kalenkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Lomazova</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10270-015-0502-0</idno>
		<ptr target="https://doi.org/10.1007/s10270-015-0502-0" />
	</analytic>
	<monogr>
		<title level="j">Softw Syst Model</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1019" to="1048" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Discovering high-level BPMN process models from event data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Kalenkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Burattin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Leoni</surname></persName>
		</author>
		<idno type="DOI">10.1108/BPMJ-02-2018-0051</idno>
		<ptr target="https://doi.org/10.1108/BPMJ-02-2018-0051" />
	</analytic>
	<monogr>
		<title level="j">Bus Process Manag J</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="995" to="1019" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Quantifying chatbots&apos; ability to learn business processes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Egger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kratsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf Syst</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page">102176</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Conversational process modelling: State of the art, applications, and implications in practice</title>
		<author>
			<persName><forename type="first">N</forename><surname>Klievtsova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Benzin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kampik</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2304.11065</idno>
		<idno>CoRR abs/2304.11065</idno>
		<ptr target="https://arxiv.org/abs/2304.11065" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Natural language querying of process execution data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kobeissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Assy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gaaloul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf Syst</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page">102227</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discovering blockstructured process models from event logs -A constructive approach</title>
		<author>
			<persName><forename type="first">Sjj</forename><surname>Leemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fahland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-38697-8_17</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-38697-817" />
	</analytic>
	<monogr>
		<title level="m">eds) Application and Theory of Petri Nets and Concurrency -34th International Conference, PETRI NETS 2013</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Colom</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Desel</surname></persName>
		</editor>
		<meeting><address><addrLine>Milan, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013-06-24">2013. June 24-28, 2013</date>
			<biblScope unit="volume">7927</biblScope>
			<biblScope unit="page" from="311" to="329" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A general process mining framework for correlating, predicting and clustering dynamic behavior based on event logs</title>
		<author>
			<persName><forename type="first">M</forename><surname>De Leoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dees</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.is.2015.07.003</idno>
		<ptr target="https://doi.org/10.1016/j.is.2015" />
	</analytic>
	<monogr>
		<title level="j">Inf Syst</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="235" to="257" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">User-guided discovery of declarative process models</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Maggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<idno type="DOI">10.1109/CIDM.2011.5949297</idno>
		<ptr target="https://doi.org/10.1109/CIDM.2011" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Computational Intelligence and Data Mining, CIDM 2011, part of the IEEE Symposium Series on Computational Intelligence</title>
		<meeting>the IEEE Symposium on Computational Intelligence and Data Mining, CIDM 2011, part of the IEEE Symposium Series on Computational Intelligence<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011-04-11">2011. 2011. April 11-15, 2011</date>
			<biblScope unit="page" from="192" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Connecting databases with process mining: a meta model and toolset</title>
		<author>
			<persName><forename type="first">Egl</forename><surname>De Murillas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Reijers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Van</forename><surname>Der Aalst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Softw Syst Model</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1209" to="1247" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">From BPMN process models to BPEL web services</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dumas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahm</forename><surname>Hofstede</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICWS.2006.67</idno>
		<ptr target="https://doi.org/10.1109/ICWS.2006.67" />
	</analytic>
	<monogr>
		<title level="m">2006 IEEE International Conference on Web Services (ICWS 2006)</title>
		<meeting><address><addrLine>Chicago, Illinois, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2006-09">2006. September 2006</date>
			<biblScope unit="page" from="285" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Pohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berti</forename><forename type="middle">A</forename></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.8059488</idno>
		<ptr target="https://doi.org/10.5281/zenodo.8059488" />
		<title level="m">Un)Fair Process Mining Event Logs</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>published on 2023-06-23</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Discrimination-aware process mining: A discussion</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Qafari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-27815-0_8</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-27815-08" />
	</analytic>
	<monogr>
		<title level="m">Process Mining Workshops -ICPM 2022 International Workshops</title>
		<title level="s">Lecture Notes in Business Information Processing</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Montali</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Senderovich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Weidlich</surname></persName>
		</editor>
		<meeting>ess Mining Workshops -ICPM 2022 International Workshops<address><addrLine>Bozen-Bolzano, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-10-23">2022. October 23-28, 2022</date>
			<biblScope unit="volume">468</biblScope>
			<biblScope unit="page" from="101" to="113" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">A collection of simulated event logs for fairness assessment in process mining</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Qafari</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2306.11453</idno>
		<idno>CoRR abs/2306.11453</idno>
		<ptr target="https://arxiv.org/abs/2306.11453" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Process querying: Enabling business intelligence through query-based process analytics</title>
		<author>
			<persName><forename type="first">A ;</forename><surname>Polyvyanyy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Springer Polyvyanyy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Process Querying Methods</title>
		<meeting>ess Querying Methods</meeting>
		<imprint>
			<date type="published" when="2017">2022. 2017</date>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="41" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fairness-aware process mining</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Qafari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-33246-4_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-33246-411" />
	</analytic>
	<monogr>
		<title level="m">On the Move to Meaningful Internet Systems: OTM 2019 Conferences -Confederated International Conferences: CoopIS, ODBASE, C&amp;TC 2019</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Panetto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Debruyne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hepp</surname></persName>
		</editor>
		<meeting><address><addrLine>Rhodes, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-10-21">2019. October 21-25, 2019</date>
			<biblScope unit="page" from="182" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Case level counterfactual reasoning in process mining</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Qafari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename><surname>Van Der Aalst</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-79108-7_7</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-79108-77" />
	</analytic>
	<monogr>
		<title level="m">Intelligent Information Systems -CAiSE Forum 2021</title>
		<title level="s">Lecture Notes in Business Information Processing</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Nurcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Korthaus</surname></persName>
		</editor>
		<meeting><address><addrLine>Melbourne, VIC, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021-06-28">2021. June 28 -July 2, 2021</date>
			<biblScope unit="volume">424</biblScope>
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient and customisable declarative process mining with SQL</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schönig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rogge-Solti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cabanillas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Information Systems Engineering</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="290" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Utilizing domain knowledge in data-driven process discovery: A literature review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Van Zelst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Van</forename><surname>Der Aalst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Ind</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Cortado: A dedicated process mining tool for interactive process discovery</title>
		<author>
			<persName><forename type="first">D</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Van Zelst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Van</forename><surname>Der Aalst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wmp</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.softx.2023.101373</idno>
		<ptr target="https://doi.org/10.1016/j.softx.2023.101373" />
	</analytic>
	<monogr>
		<title level="j">SoftwareX</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">101373</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Temporal conformance checking at runtime based on time-infused process models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Stertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mangler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rinderle-Ma</surname></persName>
		</author>
		<idno>CoRR abs/2008.07262</idno>
		<ptr target="https://arxiv.org/abs/2008.07262" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/hash/3" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">2017. 2017. December 4-9, 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
	<note>Guyon I, von Luxburg U f5ee243547dee91fbd053c1c4a845aa-Abstract.html</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Large language models for business process management: Opportunities and challenges</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vidgof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bachhofner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mendling</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2304.04309</idno>
		<idno>CoRR abs/2304.04309</idno>
		<ptr target="https://arxiv.org/abs/2304.04309" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Celonis PQL: A query language for process mining</title>
		<author>
			<persName><forename type="first">T</forename><surname>Vogelgesang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ambrosy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Becher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Process Querying Methods</title>
		<meeting>ess Querying Methods</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="377" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Flexible heuristics miner (FHM)</title>
		<author>
			<persName><forename type="first">Ajmm</forename><surname>Weijters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jts</forename><surname>Ribeiro</surname></persName>
		</author>
		<idno type="DOI">10.1109/CIDM.2011.5949453</idno>
		<ptr target="https://doi.org/10.1109/CIDM.2011.5949453" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Computational Intelligence and Data Mining, CIDM 2011, part of the IEEE Symposium Series on Computational Intelligence</title>
		<meeting>the IEEE Symposium on Computational Intelligence and Data Mining, CIDM 2011, part of the IEEE Symposium Series on Computational Intelligence<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011-04-11">2011. 2011. April 11-15, 2011</date>
			<biblScope unit="page" from="310" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A generic framework for trace clustering in process mining</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zandkarimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rehse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Soudmand</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICPM49681.2020.00034</idno>
		<ptr target="https://doi.org/10.1109/ICPM49681.2020.00034" />
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Process Mining, ICPM 2020</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Van Dongen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Montali</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Wynn</surname></persName>
		</editor>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020-09">2020. October 4-9, 2020</date>
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

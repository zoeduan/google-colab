<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Algorithmic Ghost in the Research Shell: Large Language Models and Academic Knowledge Creation in Management Research</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nigel</forename><surname>Williams</surname></persName>
							<email>nigel.williams@port.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Stanislav</forename><surname>Ivanov</surname></persName>
							<email>stanislav.ivanov@vumk.eu</email>
						</author>
						<author>
							<persName><forename type="first">Dimitrios</forename><surname>Buhalis</surname></persName>
							<email>dbuhalis@bournemouth.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Systems and People</orgName>
								<orgName type="department" key="dep2">Faculty of Business and Law</orgName>
								<orgName type="institution" key="instit1">The School of Organisations</orgName>
								<orgName type="institution" key="instit2">University of Portsmouth</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Varna University of Management</orgName>
								<address>
									<addrLine>13A Oborishte str.</addrLine>
									<postCode>9000</postCode>
									<settlement>Varna</settlement>
									<country key="BG">Bulgaria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Business School</orgName>
								<orgName type="institution">Zangador Research Institute</orgName>
								<address>
									<postCode>9010</postCode>
									<settlement>Varna</settlement>
									<country key="BG">Bulgaria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Bournemouth University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Algorithmic Ghost in the Research Shell: Large Language Models and Academic Knowledge Creation in Management Research</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">51A5D434F8921EBB9C299FFEFD3C21BE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>large language models</term>
					<term>knowledge creation</term>
					<term>management research</term>
					<term>ChatGPT</term>
					<term>GPT-3</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper looks at the role of large language models in academic knowledge creation based on a scoping review (2018 to January 2023) of how researchers have previously used the language model GPT to assist in the performance of academic knowledge creation tasks beyond data analysis. These tasks include writing, editing, reviewing, dataset creation and curation, which have been difficult to perform using earlier ML tools. Based on a synthesis of these papers, this study identifies pathways for a future academic research landscape that incorporates wider usage of large language models based on the current modes of adoption in published articles as a CoWriter, Research Assistant and Respondent. The paper concludes with a research and practice agenda for management knowledge creation based on the wider adoption of Large Language models. The paper's focus is on understanding the nature of the current usage of GPT to perform academic tasks. As such, it does not describe the challenges and problems of large language models. It does also not speculate about the extent to which they present machine intelligence or consciousness.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Artificial Intelligence (AI) has been defined as the research and design of creating machines that simulate human intelligence to perform actions or intellectual tasks <ref type="bibr" target="#b38">(Müller and Bostrom, 2016)</ref>. This paper will define AI simply as "computer systems that perform tasks requiring cognition tasks autonomously". This is similar to earlier definitions <ref type="bibr" target="#b46">(Russell, 2010)</ref>.</p><p>Emerging phenomena can often be overlooked in management research as they are poorly defined with unclear conceptual concepts and limited empirical data <ref type="bibr">(Yadav, 2018)</ref>. Large Language models like GPT, however, have growth drivers that suggest that they are worthy of researcher attention and specifically, their impact on academic knowledge production should be identified at this early stage of adoption.</p><p>Previous academic research in business and management have identified the potential for machine learning analytics to change the nature of theorising in business and management reseach <ref type="bibr" target="#b29">(Leavitt, Schabram, Hariharan &amp; Barnes, 2021)</ref>. Large Language models such as GPT, however, can go further to influence the nature of academic knowledge production itself in this domain. Management research is primarily based on empirical quantitative and qualitative studies done by small teams of researchers which may be difficult to replicate <ref type="bibr" target="#b5">(Block, Fisch, Kanwal, Lorenzen, &amp; Schulze, 2022)</ref>. As a result, the domain can be influenced by tools that can simulate human created text in a manner that experimental or lab based work would not. The area therefore requires examination which is the purpose of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">AI transformations</head><p>AI in the Business and management domain research has taken two main perspectives. The first is as an analytical approach: AI tools identify insights, using classification or modelling of complex dynamic data. AI analytical approaches enable the direct examination of "mixed" data, such as data collected from social media that can combine text, images and video (Al-Smadi, Jaradat, Al-Ayyoub, and Jararweh, 2017). These approaches have been used to examine the meaning of text <ref type="bibr" target="#b35">(Martinez-Torres, and Toral, 2019)</ref>, identify market segments via geographical data <ref type="bibr" target="#b45">(Rodríguez, Semanjski, Gautama, Van de Weghe and Ochoa, 2018)</ref> and emergent visual representations from photographs <ref type="bibr" target="#b61">(Zhang, Chen, and Li, 2019)</ref>. The second stream of research examines the impact of AI on organisational activity. Research has examined the extent to which AI can be applied in service operations <ref type="bibr" target="#b36">(Meyer, Cohen, and Nair, 2020)</ref>.</p><p>Machine learning (ML) is the dominant approach to implementing artificial intelligence in computer systems <ref type="bibr" target="#b13">(Ghahramani, 2015)</ref>. Neural Network approaches use a combination of machine learning algorithms configured as layers of nodes, which process inputs of data or outputs from previous nodes <ref type="bibr" target="#b44">(Pourgholamali, Kahani, Bagheri and Noorian, 2017)</ref>. A subset of these approaches, Language models are combinations of neural networks trained by predicting blanked-out words in texts <ref type="bibr">(Otter, Medina and Kalita, 2018 )</ref> using a technique called Transformer, which allows for parallel training on multiple processors. Examples of such models include Google's BERT and OpenAI's GPT (Generative Pre-Trained).</p><p>The latter, GPT combines transformers with other machine learning models <ref type="bibr" target="#b54">(Vig, 2019)</ref>. The current iteration, GPT-3 has 175 billion parameters. GPT-3 can recognise grammar, essay structure, and writing genre based on the analysis of very large text datasets. It can be retrained on small datasets to perform tasks such as summarisation and question answering which cannot be done by statistical, unsupervised or supervised learning techniques. GPT-3 can be deployed using natural language prompts that apply the software's rich representations of language on itself to configure its internal neural networks.</p><p>In practice, users of GPT can create statements or prompts that describe knowledge tasks. That may include tasks such as "write an academic abstract on Y topic for X journal". This is translated by the program into required software actions that result in text generation, transformation and summarisation to produce a final output. On November 30 th 2022, an adapted version of GPT was launched via a simple to use chat interface. ChatGPT, as it is known has been trained using Reinforcement Learning with Human Feedback. ChatGPT has grown to 30 million users in two months, faster than many other digital products (<ref type="url" target="https://www.nytimes.com/2023/02/03/technology/chatgpt-openai-artificial-intelligence.html">https://www.nytimes.com/2023/02/03/technology/chatgpt-openai-artificial- intelligence.html</ref>).</p><p>Researchers have begun to use GPT as not merely an analytical tool but a contributor to the academic knowledge creation process as it can assist with core tasks of research such as identifying potential academic contributions, forming and prioritising ideas <ref type="bibr" target="#b11">(Du, Kim, Raheja, Kumar &amp; Kang, 2022)</ref>. To date, researchers in education <ref type="bibr" target="#b2">(Baidoo-Anu &amp; Owusu Ansah, 2023)</ref>, medicine <ref type="bibr" target="#b49">(Shen,Heacock, Elias, Hentel, Reig, Shih, &amp; Moy, 2023)</ref>, and tourism <ref type="bibr" target="#b9">(Carvalho &amp; Ivanov, 2023)</ref>, among others, are examing the impact of the adoption of LLMs in their domains.</p><p>Research, however, has not yet explored the potential for AI to change the underlying practices of academic knowledge creation. The exponential growth of data processing power has led to advances in AI, including self-supervised neural models, that can learn powerful representations from large-scale unstructured data such as text without human supervision. In this manner, they can go beyond analysis by applying these representations to generate outputs in the form of text, audio, images and video <ref type="bibr" target="#b56">(Weisz,Muller, He, &amp; Houde, 2023)</ref>. For example, in 2019 Springer published the first academic book written by AI <ref type="bibr" target="#b59">(Writer, 2019)</ref>.</p><p>Like other types of digital products, GPT, has catalysed an online community of knowledge and practices <ref type="bibr" target="#b55">(Van de Vrande, De Jong, Vanhaverbeke, &amp; De Rochemont, 2009)</ref>. This community provides advice on how to utilize software applications in addition to offical support <ref type="bibr" target="#b10">(Cosentino, Izquierdo, and Cabot 2017)</ref>. Growth in available advice will make core tools more accessible to non-technical individuals, supporting increased adoption even if core technical functionality does not change.</p><p>GPT and other language models are poised to be embedded in consumer word processing and other applications (<ref type="url" target="https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/)">https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/</ref>). This can only ensure that the number of users, including academics, will perform knowledge-creation tasks using these tools. Improved language models are under development which are designed to overcome the limitations of existing offerings (<ref type="url" target="https://www.datacamp.com/blog/what-we-know-gpt4">https://www.datacamp.com/blog/what-we-know-gpt4</ref>). Combined, these drivers suggest that their impact on knowledge creation will continue to grow. This paper makes an initial contribution based on a scoping review (2018 to January 2023) of how researchers have previously used the language model GPT to assist in the performance of academic knowledge creation tasks beyond the analysis of data. These tasks include writing, editing, reviewing, dataset creation and curation, which have been difficult to perform using earlier ML tools form the basis of creating research outputs, which underpin academic impact, knowledge exchange with industry and educational experiences. Based on a synthesis of these papers, we identify pathways for a future academic research landscape that incorporates wider usage of large language models based on the current modes of adoption in published articles as a CoWriter, Research Assistant and Respondent. The paper concludes with a research and practice agenda for management knowledge creation based on the wider adoption of Large Language models. The paper's focus is on understanding the nature of the current usage of GPT to perform academic tasks. As such, it does not describe the challenges and problems of large language models. It does also not speculate about the extent to which they present machine intelligence or consciousness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>This research takes the form of a scoping study, a type of literature review that aims to identify sources of evidence in a research area. Unlike systematic reviews, scoping reviews do not focus on a welldefined question and tend to address broader topics in an emerging area <ref type="bibr" target="#b6">(Brogaard, 2021)</ref>. Scoping studies can provide an initial overview of an area that has not been reviewed before. Given the nature of the approach, the research questions tend to be broad and can include non-peer-reviewed articles, which may limit the robustness of the findings <ref type="bibr" target="#b42">(Pham, Rajić, Greig, Sargeant, Papadopoulos &amp; McEwen, 2014)</ref>. This scoping review was created to identify research was done that examines the use of GPT as in scholarly knowledge production beyond the analysis of data to support the creation of outputs. We identify academic tasks as belonging to the broad categories identified in Table <ref type="table" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Finalise knowledge development approach</head><p>Determine the approach (literature review, secondary or primary data analysis) required to create an academic contribution. Design approach protocol and perform exploratory evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Perform knowledge development activity</head><p>Adapt analysis protocol, and document decisions made and findings. Identify academic and industry implications of findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Create initial research communication artefact</head><p>Complete output (paper, presentation), and submit to outlet. Adapted from <ref type="bibr" target="#b19">Hope, Downey, Etzioni, Weld &amp; Horvitz (2022)</ref>.</p><p>Records were first identified using the search term GPT, GPT-2 and GPT-3 and academic tasks from table 1 using Scopus, Google Scholar and Semantic Scholar from 2018 to Jan 2023. To limit the search results, the articles had to mention academic tasks, including academic writing, literature summary, text generation, and experiment design. Abstracts were screened by two academics using the platform Rayyan.ai to remove duplicates and remove irrevelant studies. This left 182 studies to be examined in detail for eligibility and were removed if they did not focus on one or more of the categories identified in Table <ref type="table" target="#tab_0">1</ref>. Figure <ref type="figure">1</ref> provides an overview of the knowledge search and identification of the final subset of articles.</p><p>Records identified from Scopus, Google Scholar Semantic Scholar and Arxiv search using Publish or Perish (973)</p><p>Records after duplicates removed using Rayyan.ai (591)</p><p>Records Screened (591)</p><p>Full Text Articles to be assessed for Eligibility (182)</p><p>Records Excluded Irrelevant (409)</p><p>Full Text Articles were excluded if they did not focus on academic knowledge creation (Table <ref type="table" target="#tab_0">1</ref>)</p><p>Studies included in Synthesis ( <ref type="formula">22</ref>) Table <ref type="table">2</ref> 4. Findings: GPT in Academic Knowledge production GPT, like other large language models have a number of impacts on academic knowledge creation. While large language models have been available for some time, previous versions required programming knowledge in order to obtain full benefit of usage. The public availability of GPT via a chat interface has enabled non-programmers to access these advanced tools, thus leading to the democratisation of academic knowledge creation. There is also an exponential increase in available advice on how to create prompts to be able to get the best possible output for a wide variety of tasks. Table <ref type="table">2</ref> summarizes how GPT has been employed for academic knowledge-creation tasks.</p><p>Table 2: Papers Type Title and Reference Classification Preprint Srivastava, M. (2023, January 9). A Day in the Life of ChatGPT as a researcher: Sustainable and Efficient Machine Learning -A Review of Sparsity Techniques and Future Research Directions. <ref type="url" target="https://doi.org/10.31219/osf.io/e9p3g">https://doi.org/10.31219/osf.io/e9p3g</ref> GPT as Cowriter Preprint Uchendu, A., Le, T., &amp; Lee, D. (2022). Attribution and Obfuscation of Neural Text Authorship: A Data Mining Perspective. arXiv preprint arXiv:2210.10488. GPT as Cowriter Journal article Leippold, M. (2022). Thus spoke GPT-3: Interviewing a large-language model on climate finance. Finance Research Letters, 103617. GPT as Cowriter Preprint Liew, A., &amp; Mueller, K. (2022). Using Large Language Models to Generate Engaging Captions for Data Visualizations. arXiv preprint arXiv:2212.14047. GPT as Cowriter Preprint Liyanage, V., Buscaldi, D., &amp; Nazarenko, A. (2022). A benchmark corpus for the detection of automatically generated text in academic publications. arXiv preprint arXiv:2202.02013. GPT as Cowriter Journal article Nowak-Gruca, A. J. (2022). Could an Artificial Intelligence be a Ghostwriter?. Journal of Intellectual Property Rights (JIPR), 27(1), 25-37. GPT as Cowriter Journal article Illia, L., Colleoni, E., &amp; Zyglidopoulos, S. (2023). Ethical implications of text generation in the age of artificial intelligence. Business Ethics, the Environment &amp; Responsibility, 32(1), 201-210. GPT as Cowriter Journal article Alarie, B., &amp; Cockfield, A. (2021). Will machines replace us?: Machine-authored texts and the future of scholarship. Law, Technology and Humans, 3(2), 5-11. GPT as Cowriter Conference paper Tallón-Ballesteros, A. J. (2020). Exploring the potential of GPT-2 for generating fake reviews of research papers. Fuzzy Systems and Data Mining VI: Proceedings of FSDM, 331, 390. GPT as Cowriter Journal article Pavlik, J. V. (2023). Collaborating With ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media GPT as Cowriter Type Title and Reference Classification Education. Journalism &amp; Mass Communication Educator, 10776958221149577. Conference paper Sekulić, I., Aliannejadi, M., &amp; Crestani, F. (2022, February). Evaluating mixed-initiative conversational search systems via user simulation. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining (pp. 888-896). GPT as Respondent Conference paper Hämäläinen, P., Tavast, M., &amp; Kunnari, A. (2022, March). Neural Language Models as What If?-Engines for HCI Research. In 27th International Conference on Intelligent User Interfaces (pp. 77-80). GPT as Respondent Conference paper Tavast, M., Kunnari, A., &amp; Hämäläinen, P. (2022, March). Language Models Can Generate Human-Like Self-Reports of Emotion. In 27th International Conference on Intelligent User Interfaces (pp. 69-72). GPT as Respondent Conference paper Meyer, S., Elsweiler, D., Ludwig, B., Fernandez-Pichel, M., &amp; Losada, D. E. (2022, July). Do We Still Need Human Assessors? Prompt-Based GPT-3 User Simulation in Conversational AI. In Proceedings of the 4th Conference on Conversational User Interfaces (pp. 1-6). GPT as Respondent Journal article Salehi, P., Hassan, S. Z., Lammerse, M., Sabet, S. S., Riiser, I., Røed, R. K., ... &amp; Riegler, M. A. (2022). Synthesising a talking child avatar to train interviewers working with maltreated children. Big Data and Cognitive Computing, 6(2), 62. GPT as Respondent Preprint Horton, J. J. (2023). Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?. arXiv preprint arXiv:2301.07543. GPT as Respondent Journal article Jaimovitch-López, G., Ferri, C., Hernández-Orallo, J., Martínez-Plumed, F., &amp; Ramírez-Quintana, M. J. (2022). Can language models automate data wrangling?. Machine Learning, 1-30. GPT as Research Assistant Journal article Hernandez, I., &amp; Nie, W. (2022). The AI-IP: Minimising the guesswork of personality scale item development through artificial intelligence. Personnel Psychology. GPT as Research Assistant Journal article Lee, P., Fyffe, S., Son, M., Jia, Z., &amp; Yao, Z. (2022). A Paradigm Shift from "Human Writing" to "Machine Generation" in Personality Test Development: an Application of State-of-the-Art Natural Language Processing. Journal of Business and Psychology, 1-28. GPT as Research Assistant Preprint Ye, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., ... &amp; Kong, L. (2022). Zerogen: Efficient zero-shot GPT as Research Assistant Type Title and Reference Classification learning via dataset generation. arXiv preprint arXiv:2202.07922. Conference paper Bellan, P., Dragoni, M., &amp; Ghidini, C. (2022). Experiment Maker: a Tool to create Experiments with GPT-3 easily. EKAW'22: Companion Proceedings of the 23rd International Conference on Knowledge Engineering and Knowledge Management, September 26-29, 2022, Bozen-Bolzano, IT GPT as Research Assistant Journal article Kansteiner, W. (2022). Digital doping for historians: can history, memory, and historical theory be rendered artificially intelligent? History and Theory.<ref type="url" target="https://doi.org/10.1111/hith.12282">https://doi.org/10.1111/hith.12282</ref> GPT as Research Assistant</p><p>Three themes emerged from the literature: 1) GPT as a Co-Writer in which the tool was deployed to complete academic outputs (paper, presentation) to scan and evaluate current academic research, identify and prioritise possible research directions. 2) GPT as a Research Assistant determines the approach (literature review, secondary or primary data analysis) required to create academic contribution; designs approach protocol and performs exploratory evaluation; performs evaluation or analysis; documents decisions made and findings; identifies academic and industry implications of findings. 3) GPT as a Respondent in which GPT was used as a source of simulated respondents and systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">GPT as a Co-Writer</head><p>Previous Natural Language Generation (NLG) software systems followed rule-based systems. Large Language models learn representations from large text collections, in the case of GPT, 175 billion parameters. The use of these tools can enable researchers to synthesise related work as well as expand the exploration of problem spaces to adjacent and parallel fields <ref type="bibr" target="#b0">(Alarie and Cockfield, 2021)</ref>. Many management phenomena are examined differently in different fields and even related fields. The use of GPT (Table <ref type="table">2</ref>) to summarise and synthesise knowledge can enable research teams at the initial stage to deploy arguments based on developments in parallel domains in business and management or broadly across the social sciences.</p><p>Researchers have speculated on the role of GPT as a disguised ghost-writer in academic research <ref type="bibr">(Srivastava, 2022)</ref>. Although some software applications already exist (e.g. <ref type="url" target="https://writer.com/ai-">https://writer.com/ai-</ref>content-detector/), text created by AI is difficult to detect, and formal response requires the coordination of multiple technological and social institutions in order to establish acceptable use of text generation <ref type="bibr">(Illia, Colleoni and Zyglidopoulos, 2022)</ref>. As these models become bigger, the act of Authorship Attribution (human or machine becomes more difficult (Nowak-Gruca, 2022). The introduction of ChatGPT forced many academic publishers to adopt formal policies towards AI-generated text and AI authorship of academic publications. The consensus is that GPT or other LLM cannot be a co-author and must be treated as a tool. Moreover, the use of AI to generate texts needs to be explicitly acknowledged but the human authors take full responsibility for the manuscript's content.</p><p>In addition to core academic texts, GPT has been used to create academic peer review reports (Bartoli and Medvet, 2020). In both cases, the team adapted the model to academic domains by training them on domain-specific text so that they can create outputs in the required format and style. The rate of knowledge production is increasing and in many domains, the number of papers that are available on a weekly or monthly basis frequently exceeds the capacity of individual researchers to meaningfully absorb. There are also potential modalities of fraud based on the creation of fake review reports <ref type="bibr" target="#b53">(Uchendu, Le and Lee, 2022)</ref>. Since reviewers are anonymous, review reports for papers can be generated without attribution, that may be used to reduce trust in the academic process. These tools also have indirect impacts. For researchers who depend on public text sources to generate outputs, such as social media these tools may pose a problem as they will be an increasing amount of fake reviews and posts on online platforms <ref type="bibr" target="#b25">(Karanjai, 2022)</ref>. In both cases we will have knowledge being created by tools that do not have a mind, worldview or perspective and are simply presenting words based on statistical inference rather than on meaning.</p><p>Far more dangerous are the use of these tools to create false or misleading information from external actors, which may result increased amount of academic hoaxes (Al-Khatib &amp; Teixeira da Silva, 2016). These frauds have been popular where politically motivated actors create fake articles in an attempt to show academic biases and flaws <ref type="bibr" target="#b43">(Piedra, 2019)</ref>. The ability to generate plausible text in the style of targeted journals as well as plausible data sets will increase the volume of these hoaxes and academia will have to create enhanced ways of identifying these hoaxes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">GPT as a research assistant</head><p>This stream of research (Table <ref type="table">2</ref>) identifies the potential for these tools to support literature search, data preparation, transformation and synthesis tasks performed by academics. For synthesis, these tools can create summaries of existing text, including examination of arguments <ref type="bibr" target="#b0">(Alarie &amp; Cockfield, 2021;</ref><ref type="bibr" target="#b21">Illia, Colleoni, &amp; Zyglidopoulos, 2023)</ref>. Data quality improvement by actions such as cleaning and curation are critical for computational analyses of large datasets. Attempts have been made to utilise machine learning approaches to automate this process, but they face limitations of determining relavance and can result in errors. Due to the complex nature, a significant amount of this work is done via crowdsourcing or hiring of data cleaning staff. Academics have used GPT to perform tasks that require domain knowledge on unstructured data, including cleaning, formatting and exploratory analysis (Jaimovitch-López, Ferri, Hernández-Orallo, Martínez-Plumed &amp; Ramírez-Quintana, 2022). GPT has been able to identify required elements in text, fill in data that is missing using a semantic approach, learn transformation functions and identify anomalies in multimodal data sets given a few examples from researchers. In this way, they automate data preprocessing tasks in a manner that can shape subsequent research by reducing the time to apply multiple transformation approaches which can support a greater range of analytical tasks <ref type="bibr">(De Bie et al, 2022)</ref>.</p><p>In addition to tasks on unstructured data, GPT has been used to support conventional quantitative and qualitative analyses. For the former, GPT has been used to create items for scale development by generating a large number of options which were then refined using stated researcher priorities <ref type="bibr" target="#b17">(Hernandez &amp; Nie, 2022)</ref>. Scale development is a complex research task that can be limited by the team's capacity for identifying potential items, creating appropriate descriptions, ensuring validity and identifying correlations among items. GPT outputs were found to be equivalent to those created using traditional approaches <ref type="bibr" target="#b17">(Hernandez &amp; Nie, 2022)</ref>.</p><p>GPT has also been used as an approach to explore research options. The tool has been used to examine potential respondent behaviour and interactions by querying it's internal text representations.</p><p>In contrast to traditional data collection approaches, GPT was able to support the development of qualitative and quantitative data collection as well as enable researchers in order to explore confactual what if questions <ref type="bibr">(Hämäläinen, Tavast, &amp; Kunnari, 2022)</ref>. In this way, GPT was used to improve research methodology, not simply perform analyses. Even further, in ZeroGen, GPT was used to create a subset of itself, called a tiny task model (TAM) to perform specific types of analyses when an existing machine learning model did not exist <ref type="bibr" target="#b60">(Ye, Gao, Li, Xu, Feng, Wu, &amp; Kong, 2022)</ref>. Unlike previous approaches, the model did not require external training data in order to create a tool that could analyse specific types of data. In this area, GPT has also been used recursively on itself to design large language experiments <ref type="bibr" target="#b3">(Bellan, Dragoni, &amp; Ghidini, 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">GPT as Respondent</head><p>GPT has itself become a respondent to create papers. Without any additional data sources, researchers have queried GPT on perspective on issues such as climate change to identify biases or dominant perspectives in its internal language model <ref type="bibr" target="#b31">(Leippold, 2022)</ref>. GPT has also acted as a respondent to interview questions in traditional academic research <ref type="bibr" target="#b22">(Iskender, 2023)</ref>.</p><p>GPT has also been acted as a participant in experiments, replacing crowdsourced workers in computing and economics research <ref type="bibr" target="#b3">(Bellan, Dragoni, and Ghidini, 2022)</ref>. In the former, GPT has acted as a surrogate user in a conversational search system to ask questions of a given information system and evaluate the usefulness of the answers <ref type="bibr">(Meyer, Elsweiler, Ludwig, Fernandez-Pichel &amp; Losada, 2022)</ref>.</p><p>In the latter, GPT has been used to replicate findings from famous economic experiments <ref type="bibr" target="#b20">(Horton, 2023)</ref>.</p><p>While GPT does not have a worldview, it may exhibit emergent behaviour based on its training data. These idiosyncrasies are not seen as a limitation but as a benefit for researchers seeking to explore complex behaviours. In this way, GPT can provide simulated responses to questions of emotions that a rich descriptions but are entirely synthetic. These responses can be used to enrich existing datasets or to provide a basis for comparison to extend theoretical work <ref type="bibr" target="#b60">(Ye et al., 2022)</ref>. This is of particular value where few respondents are available or respondents may be unresponsive. In this mode, GPT has been used to create simulated responders for sensitive topics that allow researchers to explore these areas without causing harm <ref type="bibr" target="#b48">(Salehi et al., 2022)</ref>. These respondents need not be individuals as group interactions can also be modelled <ref type="bibr" target="#b16">(Hamilton 2023</ref>). However, this means that the studies that are based on simulated responses and emotions do not evaluate actual human perceptions and emotions; hence, the validity of the findings of such papers will be limited to the AI domain and they should not be generalised to humans. A related stream of research identifies the biases of Chat GPT as a respondent on specific subjects. The tool has been used to answer Positive and Negative Affect Schedule (PANAS) items <ref type="bibr" target="#b30">(Lee, Fyffe, Son, Jia and Yao, 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.0">Discussion and Research Agenda</head><p>Large language models like GPT create new capacities and constraints to Business and Management academics involved in research output creation. The above themes suggest that LLMs like GPT can increase the capacity of academic teams to perform research. Management academic researchers are increasingly required to provide knowledge that is not just rigorous but impactful <ref type="bibr" target="#b57">(Wickert et al., 2021)</ref>. Management research has been criticised for having a gap between researchers and practitioners, as managers rarely read articles in top management journals due to their theoretical nature with limited practical value <ref type="bibr" target="#b27">(Kieser, Nicolai, &amp; Seidl, 2015)</ref>. Additionally, the focus is on publishing in highly ranked/high-impact journals to increase institutional status with financial and reputational benefits. By increasing the capacity of researchers to deliver research, Large Language models may enable the field to enact its societal responsibilities by being able to generate rigorous impactful research. This benefit may be tempered by the increasing volume of outputs from researchers using simulated outputs in order to meet institutional status requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Large Language Models and Academic Capacity Expansion</head><p>The use of these tools to summarise and synthesise knowledge can enable research teams at the initial stage to gain some insight into methodological and theoretical developments in parallel domains in business and management or broadly across the social sciences. By expanding the exploration of the problem space, academic contributions could be based on a broader conceptual base range. In this way academic silos can be broken down by conceptual frameworks enriched by contributions from parallel fields <ref type="bibr" target="#b41">(Pavlik, 2023)</ref>. In areas where there may a limited number of respondents, such as niche populations or difficult populations, these tools can be used to help refine data collection instruments or to generate simulated data <ref type="bibr" target="#b48">(Salehi, Hassan, Lammerse, Sabet, Riiser, Røed &amp; Riegler, 2022)</ref>. However, in the, the validity of such studies might be questionable and new modes of verification in addition to conceptual validity and triangulation must be created to examine the validity of computer generated responses.</p><p>Large language models provide the opportunity to create new types of outputs based on syntesis of extant research. These technologies can be applied as as a precursor to or a supplement to a systematic literature review. The rate of scholarly production is ever increasing <ref type="bibr">(World Bank, n.d.)</ref> and academics may find it difficult to keep up with the body of knowledge <ref type="bibr" target="#b24">(Johann, Raabe, &amp; Rauhut, 2022)</ref>. Furthermore, articulating a distinct academic contribution may require academics to summarise and synthesise different bodies of knowledge, which can be difficult <ref type="bibr" target="#b33">(Lindgreen, Di Benedetto, Clarke, Evald, Bjørn-Andersen &amp; Lambert, 2021)</ref>. The use of these language models as initial summarisation tools in their research assistant role may be of value. Instead of narrowing down to a small number of articles for synthesis, researchers can explore broader questions based on contributions that are embedded in different types of knowledge. This can create a new type of systematic integrated review that extends the current manual approach using the summarization capabilities of these tools <ref type="bibr" target="#b12">(Elsbach &amp; van Knippenberg, 2020)</ref>.</p><p>The second new type of output may be based on prompt programming. Researchers have published articles that combine text, code and data (Hildebrand, Efthymiou, Busquet, Hampton, Hoffman, &amp; Novak, 2020). The way in which GPT is accessed is via prompting which may be a series of instructions that can be increasingly refined to provide feedback to the model <ref type="bibr" target="#b62">(Zhou, Muresanu, Han, Paster, Pitis, Chan &amp; Ba, 2022)</ref>. Future papers may include a structured description of prompts and responses along with a recording of text generation in real time to enable replication of research.</p><p>Future academic outputs may be based on entirely new methodologies facilitated by GPT. Netnography, for example, adapted the idea of ethnography to online communities and interactions <ref type="bibr" target="#b28">(Kozinets, 2020)</ref>. Language models may be used in a similar manner to query themselves in a new form of ethnography. In this case, the "respondent" is an aggregated body of statistical patterns derived from online text and the researcher is querying statistical patterns in the text to gain some insight into what common knowledge or widely held perspectives are on a given topic or area. When prompted by the authors, ChatGPT suggested such netnographic approach to be named "AI-based netnography" ot "AI-driven netnography".</p><p>GPT can also be prompted to act in different rules and can be used to extend existing analyses that may require the creation of narratives from a distinct population that is difficult to access <ref type="bibr" target="#b48">(Salehi et al., 2022)</ref>. In this role, they may also be a distinct form of social simulation. Existing simulation models use agent-based modelling or system dynamics to model associations among numerical variables. A large language model does not need such an abstraction and can directly simulate interactions among simulated characters that it creates <ref type="bibr" target="#b16">(Hamilton, 2023)</ref>. This may be a new way of performing social simulation activities that is not based on simplification of a problem, but on simulating scenarios based on a richer form of qualitative description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Large Language Models and Academic Capacity Constraints</head><p>The use of these tools can increase the power of technological companies over academic knowledge production. The development of large language models is funded by very large commercial organisations and are not public goods <ref type="bibr" target="#b4">(Bender, Gebru, McMillan-Major &amp; Shmitchell, 2021)</ref>. The information provided to these tools via researcher usage help train the systems to improve knowledge creation <ref type="bibr" target="#b41">(Pavlik, 2023)</ref>. Increasing the use of these tools in academic publications allows them to become better at creating academic writing which ironically will increase their power over knowledge production. For researchers who rely on technological companies for data access, changes in the terms of service can force cancellation of planned initiatives, in drastic cases affecting an entire subdomain of research <ref type="bibr" target="#b7">(Bruns, 2019)</ref>. Further, as large language models are inscrutable, they may embed training dataset biases on outputs, indirectly shaping academic research <ref type="bibr" target="#b20">(Horton, 2023)</ref>.</p><p>For researchers who depend on public text sources to generate outputs such as social media these tools may pose a as they will be an increasing amount of fake reviews and posts on online platforms. The problem of fake data will be a major one since academics, students and public can create plausible sounding data using simple prompts for interviews or take existing data sets and modify them quite simply to create a plausible seeming data set that is then analysed and presented as if it were collected from real individuals (Tallón-Ballesteros, 2020). The increasing reliance of academics on platforms such as Mechanical Turk is another potential concern since these respondents may also use large language models in order to generate responses to be paid for surveys or experimental participation <ref type="bibr">(Tavast, Kunnari, &amp; Hämäläinen, 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Concluding remarks</head><p>Large Language Models are taking academia like a storm. While there are many fears about them, there are significant benefits in terms of knowledge creation. New research methodology, increased output, better quality of the research output, and new insights and only some of the potential impacts of these technologies on academic knowledge creation. One thing to remember is that LLMs are nothing else but tools, sophisticated but yet tools. They do not have consciousness and cannot take responsibility for the written text. Therefore, they cannot be listed as co-authors of academic publications. However, they can assist in all stages of the research process, making it more effective and efficient. Hence, in the future, researchers may not go the way of horses <ref type="bibr" target="#b8">(Brynjolffson &amp; McAfee, 2015)</ref> but rather researchers that utilise AI (in this case LLMs) will outperform researchers that do not on traditional metrics. Thus, LLMs may be a source of competitive advantage in academia and skills to use LLMs will be part of researchers' near future core competences. Research methods modules at universities will need to incorporate LLM-based research methodologies and skills in order to equip the future researchers with the necessary research skills. As the LLMs develop, so will the researchers in a co-evolution game that has no end or winner but fuzzy rules, evolution path and knowledge cocreation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Categories of Academic TasksIdentify the nature of gaps in existing work (insufficient research, overlooked area, emerging area in need of empirical work or synthesis) and identify potential academic contribution from the planned study. Identify potential outlet for publication.</figDesc><table><row><cell>Academic Task</cell><cell>Summary</cell></row><row><cell>Identify area of focus</cell><cell>Scanning and evaluating current academic research</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Alarie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cockfield</surname></persName>
		</author>
		<title level="m">Will machines replace us?: Machine-authored texts and the future of scholarship. Law, Technology and Humans</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="5" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stings, hoaxes and irony breach the trust inherent in scientific publishing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Khatib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Teixeira Da Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Publishing Research Quarterly</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="208" to="219" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Baidoo-Anu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Owusu Ansah</surname></persName>
		</author>
		<idno>SSRN 4337484</idno>
		<title level="m">Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Experiment Maker: a Tool to create Experiments with GPT-3 easily. EKAW&apos;22: Companion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bellan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dragoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ghidini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Knowledge Engineering and Knowledge Management</title>
		<meeting>the 23rd International Conference on Knowledge Engineering and Knowledge Management<address><addrLine>Bozen-Bolzano, IT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022-09-26">2022. September 26-29, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shmitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<date type="published" when="2021-03">2021, March</date>
			<biblScope unit="page" from="610" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Replication studies in top management journals: An empirical investigation of prevalence, types, outcomes, and impact</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Block</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lorenzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schulze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Review Quarterly</title>
		<imprint>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Innovative outcomes in public-private innovation partnerships: a systematic review of empirical evidence and current challenges</title>
		<author>
			<persName><forename type="first">L</forename><surname>Brogaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public Management Review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="135" to="157" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">After the &apos;APIcalypse&apos;: Social media platforms and their fight against critical scholarly research</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bruns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information, Communication &amp; Society</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1544" to="1566" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Will Humans Go the Way of Horses? Labor in the Second Machine Age</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolffson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcafee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foreign Affairs</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="8" to="14" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ChatGPT for tourism: applications, benefits, and risks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ivanov</surname></persName>
		</author>
		<idno type="DOI">10.1108/TR-02-2023-0088</idno>
		<ptr target="https://doi.org/10.1108/TR-02-2023-0088" />
	</analytic>
	<monogr>
		<title level="j">Tourism Review</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A systematic mapping study of software development with GitHub</title>
		<author>
			<persName><forename type="first">V</forename><surname>Cosentino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L C</forename><surname>Izquierdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cabot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="7173" to="7192" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Raheja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.03685</idno>
		<title level="m">Read, Revise, Repeat: A System Demonstration for Human-in-the-loop Iterative Text Revision</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Creating high-impact literature reviews: An argument for &apos;integrative reviews</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Elsbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Van Knippenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Management Studies</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1277" to="1289" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Probabilistic machine learning and artificial intelligence</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">452</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Grace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Salvatier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dafoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Evans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08807</idno>
		<title level="m">When will AI exceed human performance? Evidence from AI experts</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural Language Models as What If?-Engines for HCI Research</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hämäläinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tavast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kunnari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th International Conference on Intelligent User Interfaces</title>
		<imprint>
			<date type="published" when="2022-03">2022. March</date>
			<biblScope unit="page" from="77" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Hamilton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.05327</idno>
		<title level="m">Blind Judgement: Agent-Based Supreme Court Modelling With GPT</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The AI-IP: Minimising the guesswork of personality scale item development through artificial intelligence</title>
		<author>
			<persName><forename type="first">I</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nie</surname></persName>
		</author>
		<idno type="DOI">10.1111/peps.12543</idno>
	</analytic>
	<monogr>
		<title level="j">Personnel Psychology</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gazing into Clever Hans machines</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hernández-Orallo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="172" to="173" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Hope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.02007</idno>
		<title level="m">A Computational Inflection for Scientific Discovery</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Horton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.07543</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ethical implications of text generation in the age of artificial intelligence</title>
		<author>
			<persName><forename type="first">L</forename><surname>Illia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Colleoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zyglidopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Business Ethics, the Environment &amp; Responsibility</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="201" to="210" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Holy or Unholy? Interview with Open AI&apos;s ChatGPT</title>
		<author>
			<persName><forename type="first">A</forename><surname>Iskender</surname></persName>
		</author>
		<idno type="DOI">10.54055/ejtr.v34i.3169?fbclid=IwAR2aQHqs3wE8BLSQT1hSQ-qIr1EdRJiZnHFFRfywGGbqm6YBYOS-rerX-uY</idno>
		<ptr target="https://doi.org/10.54055/ejtr.v34i.3169" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Tourism Research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">3414</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Can language models automate data wrangling</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jaimovitch-López</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ferri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hernández-Orallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Martínez-Plumed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Ramírez-Quintana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Under pressure: The extent and distribution of perceived pressure among scientists in Germany</title>
		<author>
			<persName><forename type="first">D</forename><surname>Johann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Raabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rauhut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Austria, and Switzerland. Research Evaluation</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="385" to="409" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Targeted Phishing Campaigns using Large Scale Language Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Karanjai</surname></persName>
		</author>
		<idno type="DOI">10.48550/arxiv.2301.00665</idno>
		<ptr target="https://doi.org/10.48550/arxiv.2301.00665" />
		<imprint>
			<date type="published" when="2022-02-03">2022. 3 February 2023</date>
		</imprint>
	</monogr>
	<note>arXiv, available at</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Kansteiner</surname></persName>
		</author>
		<idno type="DOI">10.1111/hith.12282</idno>
		<ptr target="https://doi.org/10.1111/hith.12282" />
		<title level="m">Digital doping for historians: can history, memory, and historical theory be rendered artificially intelligent? History and Theory</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The practical relevance of management research: Turning the debate on relevance into a rigorous scientific research program</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nicolai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academy of Management annals</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="143" to="233" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Kozinets</surname></persName>
		</author>
		<title level="m">Netnography: The essential guide to qualitative social media research</title>
		<imprint>
			<publisher>Sage</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ghost in the machine: On organisational theory in the age of machine learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Leavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schabram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Barnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academy of Management Review</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="750" to="777" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Paradigm Shift from &quot;Human Writing&quot; to &quot;Machine Generation&quot; in Personality Test Development: an Application of State-of-the-Art Natural Language Processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fyffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business and Psychology</title>
		<imprint>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Thus spoke GPT-3: Interviewing a large-language model on climate finance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Leippold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Finance Research Letters</title>
		<imprint>
			<biblScope unit="page">103617</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Using Large Language Models to Generate Engaging Captions for Data Visualizations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.14047</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">How to define, identify, and measure societal value</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lindgreen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Di Benedetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Evald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bjørn-Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Lambert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Industrial Marketing Management</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="1" to="A13" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A benchmark corpus for the detection of automatically generated text in academic publications</title>
		<author>
			<persName><forename type="first">V</forename><surname>Liyanage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Buscaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nazarenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.02013</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A machine learning approach for the identification of the deceptive reviews in the hospitality sector using unique attributes and sentiment orientation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D R</forename><surname>Martinez-Torres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Toral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tourism Management</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="393" to="403" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">From automats to algorithms: the automation of services using artificial intelligence</title>
		<author>
			<persName><forename type="first">C</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Service Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="161" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Paraphrase identification and semantic text similarity analysis in Arabic news tweets using lexical, syntactic, and semantic features</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jaradat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Mahmoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jararweh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="640" to="652" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Future progress in artificial intelligence: A survey of expert opinion</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bostrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fundamental issues of artificial intelligence</title>
		<imprint>
			<biblScope unit="page" from="555" to="572" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Could an Artificial Intelligence be a Ghostwriter?</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Nowak-Gruca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intellectual Property Rights (JIPR)</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="37" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A survey of the usages of deep learning for natural language processing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Otter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="604" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Collaborating With ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Pavlik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>Journalism &amp; Mass Communication Educator</publisher>
			<biblScope unit="page">10776958221149577</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A scoping review of scoping reviews: advancing the approach and enhancing the consistency</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Greig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Sargeant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mcewen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research synthesis methods</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="371" to="385" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The gift of a hoax</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Piedra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Qualitative Social Work</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="152" to="158" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Embedding unstructured side information in product recommendation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pourgholamali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kahani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Noorian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Commerce Research and Applications</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="70" to="85" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised hierarchical clustering approach for tourism market segmentation based on crowdsourced mobile phone data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Semanjski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gautama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Van De Weghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ochoa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">2972</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Artificial intelligence a modern approach</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Pearson Education, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Evaluating mixed-initiative conversational search systems via user simulation</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sekulić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aliannejadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Fifteenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022-02">2022, February</date>
			<biblScope unit="page" from="888" to="896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Synthesising a talking child avatar to train interviewers working with maltreated children</title>
		<author>
			<persName><forename type="first">P</forename><surname>Salehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lammerse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Riiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Røed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big Data and Cognitive Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">62</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">ChatGPT and Other Large Language Models Are Double-edged Swords</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Heacock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Elias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Hentel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="page">230163</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Srivastava</surname></persName>
		</author>
		<idno type="DOI">10.31219/osf.io/e9p3g</idno>
		<ptr target="https://doi.org/10.31219/osf.io/e9p3g" />
		<title level="m">A Day in the Life of ChatGPT as a researcher: Sustainable and Efficient Machine Learning -A Review of Sparsity Techniques and Future Research Directions</title>
		<imprint>
			<date type="published" when="2009">2023. January 9</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Exploring the potential of GPT-2 for generating fake reviews of research papers. Fuzzy Systems and Data Mining VI: Proceedings of FSDM</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Tallón-Ballesteros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="page">390</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Language Models Can Generate Human-Like Self-Reports of Emotion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tavast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kunnari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hämäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th International Conference on Intelligent User Interfaces</title>
		<imprint>
			<date type="published" when="2022-03">2022. March</date>
			<biblScope unit="page" from="69" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Uchendu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.10488</idno>
		<title level="m">Attribution and Obfuscation of Neural Text Authorship: A Data Mining Perspective</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">A multiscale visualization of attention in the transformer model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05714</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<author>
			<persName><forename type="first">V</forename><surname>Van De Vrande</surname></persName>
		</author>
		<author>
			<persName><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Vanhaverbeke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rochemont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Open innovation in SMEs: Trends, motives and management challenges</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="423" to="437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Weisz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Houde</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.05578</idno>
		<title level="m">Toward General Design Principles for Generative AI Applications</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Management research that makes a difference: Broadening the meaning of impact</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wickert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Doh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Prescott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prencipe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Management Studies</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="297" to="320" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Scientific and technical journal articles 2000-2018</title>
		<ptr target="https://data.worldbank.org/indicator/IP.JRN.ARTC.SC" />
		<imprint>
			<publisher>World Bank</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Lithium-Ion Batteries. A Machine-Generated Summary of Current Research</title>
		<author>
			<persName><forename type="first">B</forename><surname>Writer</surname></persName>
		</author>
		<ptr target="https://link.springer.com/content/pdf/10.1007%2F978-3-030-16800-1.pdf" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Academy of Marketing Science</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Yadav</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="361" to="365" />
			<date type="published" when="2018">2019. 2018</date>
			<publisher>Springer</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
	<note>Making emerging phenomena a research priority</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Zerogen: Efficient zero-shot learning via dataset generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2202.07922</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Discovering the tourists&apos; behaviors and perceptions in a tourism destination by analysing photos&apos; visual content with a computer deep learning model: The case of Beijing</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tourism Management</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="595" to="608" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Muresanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Paster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.01910</idno>
		<title level="m">Large language models are human-level prompt engineers</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ranking LLMs by compression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-06-20">20 Jun 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Peijia</forename><surname>Guo</surname></persName>
							<email>guopeijia0929@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics</orgName>
								<orgName type="institution">Northwest University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ziguang</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haibo</forename><surname>Hu</surname></persName>
							<email>huhaibo22@mails.ucas.ac.cn</email>
							<affiliation key="aff2">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chao</forename><surname>Huang</surname></persName>
							<email>chuang@ict.ac.cn</email>
							<affiliation key="aff2">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ming</forename><surname>Li</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
							<email>rzhang@nwu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics</orgName>
								<orgName type="institution">Northwest University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yiheng</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tianle</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Siyuan</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jiayue</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuanyuan</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jiaming</forename><surname>Tian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Antong</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mengshen</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhengliang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zihao</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lin</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dajiang</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ning</forename><surname>Qiang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dingang</forename><surname>Shen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tianming</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bao</forename><forename type="middle">2023</forename><surname>Ge</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Mao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yufei</forename><surname>Cui</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tei-Wei</forename><surname>Kuo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chun</forename><surname>Jason</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ing</forename><surname>Bao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mohammad</forename><surname>Bavarian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeff</forename><surname>Belgum</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ir- Wan</forename><surname>Bello</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jake</forename><surname>Berdine</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Bernadett-Shapiro</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Berner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lenny</forename><surname>Bogdonoff</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oleg</forename><surname>Boiko</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Madelaine</forename><surname>Boyd</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anna-Luisa</forename><surname>Brakman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Greg</forename><surname>Brock- Man</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tim</forename><surname>Brooks</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Miles</forename><surname>Brundage</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Button</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rosie</forename><surname>Campbell</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Cann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Brittany</forename><surname>Carey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chelsea</forename><surname>Carlson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rory</forename><surname>Carmichael</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Brooke</forename><surname>Chan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Che</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fotis</forename><surname>Chantzis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Derek</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sully</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ruby</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ben</forename><surname>Chess</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chester</forename><surname>Cho</surname></persName>
						</author>
						<author>
							<persName><roleName>Hyung</roleName><forename type="first">Casey</forename><surname>Chu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Won</forename><surname>Chung</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dave</forename><surname>Cummings</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeremiah</forename><surname>Currier</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yunxing</forename><surname>Dai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tarun</forename><surname>Goel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Gogineni</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rapha</forename><surname>Goh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Gontijo- Lopes</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Shanghai Institute for Mathematics and Interdisciplinary Sciences</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Morgan</forename><surname>Gordon</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Scott</forename><surname>Grafstein</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan</forename><surname>Gray</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joshua</forename><surname>Greene</surname></persName>
						</author>
						<author>
							<persName><roleName>Shixiang</roleName><forename type="first">Shane</forename><surname>Gross</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yufei</forename><surname>Gu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Guo</surname></persName>
							<email>chriszggz@gamil.com</email>
						</author>
						<author>
							<persName><forename type="first">Jesse</forename><surname>Hallacy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeff</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuchen</forename><surname>Harris</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mike</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Johannes</forename><surname>Heaton</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Heidecke</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alan</forename><surname>Hesse</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wade</forename><surname>Hickey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Hickey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Brandon</forename><surname>Hoeschele</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kenny</forename><surname>Houghton</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shengli</forename><surname>Hsu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xin</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joost</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shantanu</forename><surname>Huizinga</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shawn</forename><surname>Jain</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joanne</forename><surname>Jain</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Angela</forename><surname>Jang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Roger</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Haozhun</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Denny</forename><surname>Jin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shino</forename><surname>Jin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Billie</forename><surname>Jomoto</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hee- Woo</forename><surname>Jonn</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tomer</forename><surname>Jun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Łukasz</forename><surname>Kaftan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ali</forename><surname>Kaiser</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ingmar</forename><surname>Ka- Mali</surname></persName>
						</author>
						<author>
							<persName><surname>Kanitscheider</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shirish</forename><surname>Nitish</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tabarak</forename><surname>Keskar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Logan</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kilpatrick</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christina</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yongjik</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><forename type="middle">Hendrik</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jamie</forename><surname>Kirch- Ner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matt</forename><surname>Kiros</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Knight</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Łukasz</forename><surname>Kokotajlo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Kondraciuk</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aris</forename><surname>Kondrich</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kyle</forename><surname>Kon- Stantinidis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gretchen</forename><surname>Kosic</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vishal</forename><surname>Krueger</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Kuo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ikai</forename><surname>Lampe</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Teddy</forename><surname>Lan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jade</forename><surname>Leike</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Leung</surname></persName>
						</author>
						<author>
							<persName><roleName>Chak</roleName><forename type="first">Ming</forename><surname>Levy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rachel</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Molly</forename><surname>Lim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Stephanie</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mateusz</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Theresa</forename><surname>Litwin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan</forename><surname>Lopez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Patricia</forename><surname>Lowe</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anna</forename><surname>Lue</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kim</forename><surname>Makanju</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sam</forename><surname>Malfacini</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Todor</forename><surname>Manning</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yaniv</forename><surname>Markov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bianca</forename><surname>Markovski</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Katie</forename><surname>Martin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Mayer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bob</forename><surname>Mayne</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Scott</forename><forename type="middle">Mayer</forename><surname>Mcgrew</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christine</forename><surname>Mckinney</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Mcleavey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jake</forename><surname>Mcmillan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Mcneil</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aalok</forename><surname>Medina</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jacob</forename><surname>Mehta</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Luke</forename><surname>Menick</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrey</forename><surname>Metz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pamela</forename><surname>Mishchenko</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vinnie</forename><surname>Mishkin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Evan</forename><surname>Monaco</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Morikawa</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tong</forename><surname>Mossing</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mira</forename><surname>Mu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oleg</forename><surname>Murati</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Murk</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ashvin</forename><surname>Mély</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Reiichiro</forename><surname>Nair</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rajeev</forename><surname>Nakano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arvind</forename><surname>Nayak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><surname>Neelakantan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hyeonwoo</forename><surname>Ngo</surname></persName>
						</author>
						<author>
							<persName><surname>Noh</surname></persName>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Cory Decareaux</orgName>
								<orgName type="institution" key="instit2">Thomas Degry</orgName>
								<orgName type="institution" key="instit3">Noah Deutsch</orgName>
								<address>
									<addrLine>Damien Deville Sheila Dunning Adrien Ecoffet Atty Eleti Tyna Eloundou David Farhi Liam Fedus Simón Posada Fishman Juston Forte</addrLine>
									<settlement>Arka Dhar David Dohan Steve Dowling Niko Felix</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Isabella Ful- ford</orgName>
								<address>
									<settlement>Leo Gao</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Elie Georges</orgName>
								<address>
									<addrLine>Christian Gibson</addrLine>
									<settlement>Vik</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ranking LLMs by compression</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-06-20">20 Jun 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">47B19B0951B094682DC16B0B7BBB14AB</idno>
					<idno type="arXiv">arXiv:2406.14171v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Meta-Radiology, 1(2):100017</term>
					<term>Inbal Magar and Roy Schwartz</term>
					<term>2022</term>
					<term>Data contamination: From memorization to exploitation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We conceptualize the process of understanding as information compression, and propose a method for ranking large language models (LLMs) based on lossless data compression. We demonstrate the equivalence of compression length under arithmetic coding with cumulative negative log probabilities when using a large language model as a prior, that is, the pretraining phase of the model is essentially the process of learning the optimal coding length. At the same time, the evaluation metric compression ratio can be obtained without actual compression, which greatly saves overhead. In this paper, we use five large language models as priors for compression, then compare their performance on challenging natural language processing tasks, including sentence completion, question answering, and coreference resolution. Experimental results show that compression ratio and model performance are positively correlated, so it can be used as a general metric to evaluate large language models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, the rapid development of LLMs has brought earth-shaking changes to the field of natural language processing (NLP) <ref type="bibr" target="#b15">(Radford et al., 2019;</ref><ref type="bibr">Zhao et al., 2023;</ref><ref type="bibr">Liu et al., 2023)</ref>. LLMs are advanced language models pretrained on tens of gigabytes of data without tuning on data for specific tasks. These large models can directly complete various NLP tasks, and even become a milestone technology towards general artificial intelligence (AGI). Currently, LLMs are being studied more and more widely in various fields, such as education and research (Rahman and <ref type="bibr" target="#b16">Watanobe, 2023)</ref>, medicine and healthcare <ref type="bibr" target="#b19">(Thirunavukarasu et al., 2023;</ref><ref type="bibr" target="#b2">Cascella et al., 2023)</ref>, etc., and their performance evaluation methods are becoming more and more important. <ref type="bibr" target="#b3">Chang et al. (2024)</ref> showed that researchers always scrutinize the capabilities of AI models or algorithms through evaluation using specific and challenging tasks, so the evaluation metrics are outlined from the perspective of the evaluation tasks. The metrics are diverse, such as Exact Match (EM), F1-score, ROUGE, etc., and many are set for specific tasks, making it difficult to uniformly evaluate the performance of the model on different tasks. In addition, contamination of training and test data can also lead to biased evaluation results <ref type="bibr">(Magar and Schwartz, 2022)</ref>, making it impossible to verify whether NLP progress is achieved through better language understanding or better data utilization. Various limitations lead to the lack of a unified LLMs evaluation standard.</p><p>Therefore, we consider the process of model training and learning itself and prove the equivalence of the model pre-training goal and the compression length under arithmetic coding, indicating that compression is closely related to model performance, and then use the compression ratio as a general metric to measure the model's generalization ability in different scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Language Models Evaluation</head><p>Currently, performance evaluation of LLMs is mainly achieved through benchmark tests, including diverse tasks, standardized datasets and comprehensive evaluation metrics. The purpose is to establish a systematic and standardized evaluation framework.</p><p>In 2019, <ref type="bibr" target="#b23">Wang et al. (2019)</ref> introduced the General Language Understanding Evaluation Benchmark (GLUE), a multi-task evaluation platform for measuring the performance of natural language understanding models. It contains nine tasks, covering various types such as text classification, text similarity evaluation, natural language Inference, question answering, etc. A recent study <ref type="bibr" target="#b12">Laskar et al. (2023)</ref> evaluated ChatGPT across 140 tasks and an-alyze 255K responses it generates in these datasets, laying the foundation for deploying ChatGPT-like LLMs in real-world applications. More recently, <ref type="bibr">OpenAI et al. (2024)</ref> tested GPT-4 on a diverse set of benchmarks, including 34 simulating exams that were originally designed for humans. Benchmark test is very important for evaluating the performance of language models and promoting research progress, but limited coverage tasks, data contamination <ref type="bibr" target="#b1">(Brown et al., 2020;</ref><ref type="bibr" target="#b13">Li, 2023)</ref>, and huge overhead are all challenges and limitations faced in this process. In order to solve these problems, we propose compression ratio based on lossless data compression, a general evaluation metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Neural Compression</head><p>The goal of data compression is to reduce the representation size while retaining valid information. Our LLMs-based compressor uses neural networks for data compression and belongs to the neural compression category. Current research in neural compression largely benefits from advances in deep generative modeling <ref type="bibr" target="#b25">(Yang et al., 2023)</ref>, such as GANs <ref type="bibr" target="#b6">(Goodfellow et al., 2014)</ref>, VAEs <ref type="bibr" target="#b17">(Rezende and Mohamed, 2015)</ref>, and autoregressive models <ref type="bibr" target="#b22">(Van Den Oord et al., 2016)</ref>. With the development of deep neural networks, lossless text compression has also ushered in new progress. <ref type="bibr" target="#b7">Goyal et al. (2018)</ref> proposed DeepZip, a lossless compressor based on neural networks, consisting of two main modules: RNN and arithmetic coding. It achieves higher compression ratio than GZIP. <ref type="bibr" target="#b0">Bellard (2019)</ref> proposed a lossless compressor based on LSTM, which is simple to describe and has reasonable memory consumption compared to compressors that provide a similar compression ratio. Recent advancements, such as TRACE, a fast transformer-based general-purpose lossless compressor <ref type="bibr">(Mao et al., 2022)</ref>, achieves an overall speedup of approximately 3x while maintaining a compression ratio comparable to state-of-the-art compressors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">LLMs based Arithmetic Coding for Compression</head><p>Shannon's fundamental theorem of coding states that <ref type="bibr" target="#b18">(Shannon, 1948)</ref>, given messages randomly generated from a model, it is impossible to encode them into less bits (on average) than the entropy of that model, thus defining a lower bound Algorithm 1 Arithmetic Coding 1:</p><formula xml:id="formula_0">Input: t 0:n := t 0 t 1 • • • t n ∈ T n+1 . 2: I 0 low = 0, I 0 high = 1 3: for t i , i = 1, 2, • • • , n, n + 1 do 4: range = I i-1 high -I i-1 low 5: I i low ← I i-1 low + range * F i (t i ) 6: I i high ← I i-1 low + range * (F i (t i ) + P i (t i )) 7: end for 8: Output: [I n+1 low , I n+1 high ).</formula><p>for lossless compression. Arithmetic coding is an entropy coding algorithm. <ref type="bibr" target="#b9">Huang et al. (2023)</ref> proposed an entropy-based compressor that integrated generative pre-trained transformer into adaptive arithmetic coding, highlighting the potential of pretrained LLMs as powerful priors in compression.</p><p>In this paper, we integrate LLMs into adaptive arithmetic coding for compression, with the aim of representing data according to the probability of output to reduce its overall size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LLMs as Entropy Models</head><p>Considering text data, first use a tokenizer to convert the text into a data stream t 1:n</p><formula xml:id="formula_1">:= t 1 t 2 • • • t n ∈ T n of length n,</formula><p>where T is LLM vocabulary, a finite set of tokens. The empty sequence is denoted as ε. Let ϕ represents LLM, where ϕ(t 1:(i-1) ) = P i (t i |t 1 , t 2 , • • • , t i-1 ), i ≥ 2 means modeling the next token t i through the previous i -1 tokens t 1:(i-1) , and we get its probability distribution P i . In order to obtain the distribution for P 1 , add an EOS (End of Sentence) token at the beginning of the text as t 0 . For each token t i , the associated P i acts as the entropy model, guiding the encoder to allocate fewer bits to high-frequency tokens and more bits to low-frequency tokens, thereby improving compression efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coding Process</head><p>The range for the data stream is the interval [0, 1) before anything is transmitted. As each token is processed, the cumulative distribution functions F i (t i ) and P i (t i ) are calculated according to ϕ(t 0:(i-1) ). Then narrow the interval to the part assigned to that token:</p><formula xml:id="formula_2">I i low = I i-1 low + (I i-1 high -I i-1 low ) * F i (t i ), I i high = I i-1 low + (I i-1 high -I i-1 low ) * (F i (t i ) + P i (t i ))</formula><p>Adaptive arithmetic coding using LLM is shown in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Equivalence of Model Pre-training Goal and Compression Length</head><p>It is well established that compression and prediction are essentially equivalent <ref type="bibr" target="#b4">(Delétang et al., 2023)</ref>. In this way, compression and LLMs are closely linked. We mathematically prove the equivalence of model pre-training goal and compression length. Then we present a novel method for evaluating LLMS based on lossless compression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-training Optimization Goals for LLMs</head><p>The loss function, also known as the objective function, measures the difference between the probability distribution predicted by the model and the true distribution. Model training is to reduce the loss function through continuous iteration, thereby optimizing model performance.</p><p>We continue to consider the data stream above</p><formula xml:id="formula_3">t 1:n := t 1 t 2 • • • t n ∈ T n . The true distribution of data Q is the sequence of probability mass func- tions Q n : T n → (0, 1], for all n ∈ N , satisfy- ing the constraint Q n (t 1:n ) = s∈T Q n+1 (t 1:n s),</formula><p>where Q 0 (ε) := 1. The meaning can be clearly seen from the parameters of Q, so we omit the subscript of Q.</p><p>Now we have the true distribution Q of the data and the probability distribution P predicted by the LLMs. The pre-training Optimization Goals for LLMs is to make P closer to Q, which can elicit the definition of relative entropy, that is, Kullback-Leibler Divergence:</p><formula xml:id="formula_4">D KL (Q||P ) = n i=1 (Q i log 2 Q i ) - n i=1 (Q i log 2 P i ) The previous term n i=1 (Q i • log 2 Q i )</formula><p>is the inverse of the entropy of the true distribution Q, which is constant.</p><p>The last term</p><formula xml:id="formula_5">-n i=1 (Q i • log 2 P i )</formula><p>is the definition of cross entropy, represented by H(Q, P ). Gibbs inequality states that (Gibbs, 1878): D KL (Q||P ) ≥ 0, the equality sign is true if and only if Q i = P i , ∀i. Therefore, in order to make the probability distribution P closer to the true distribution Q, that is, to minimize the value of cross entropy. It further illustrates that cross entropy can be used as the loss function, and minimizing cross entropy is the goal of optimizing the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Negative Log Probability as Compression Length</head><p>The goal of lossless compression is to encode a data stream t 1:n sampled from a true distribution Q into a minimum length bit stream, while ensuring that the original sequence can be recovered through decoding. In practice, Q is usually unknown, so we approximate Q through the probability distribution P predicted by the LLMs ϕ. During arithmetic coding, the length of the interval I i is equal to I i-1 * P i (t i ). For the sequence t 1:n , starting from the initial interval of length 1, the final encoded interval length is n i=1 P i (t i ), so the number of bits required to represent this final interval (i.e. message t 1:n ) is n i=1 -log 2 P i (t i ). This reveals a direct way to approximate the compression length without having to perform the compression method exactly. So the expected number of bits we get is</p><formula xml:id="formula_6">E t∼Q [ n i=1 -log 2 P i (t i )]</formula><p>, that is the cross entropy H(Q, P ).</p><p>Therefore, in the process of achieving lossless compression, minimizing the expected length of the encoded data stream is equivalent to minimizing cross entropy. At this point, the equivalence of model pre-training goal and compression length has been proven. Furthermore, we can use compression ratio as a unified criterion for evaluating LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>The experiment consists of four key parts: the calculation of the compression ratio and three natural language processing tasks, namely sentence completion, question answering and coreference resolution. We use a total of five LLMs as compressor priors, but the proposed method is not limited to these models. This method can be applied to more advanced LLMs as long as the predicted probabilities can be obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Calculation of Compression Ratio</head><p>First, we select the Text8 dataset to calculate the compression ratio of the compressor. The Text8 dataset is a large corpus extracted from the English Wikipedia. After some simple preprocessing, the text content covers various topics and fields. It is a general dataset for language modeling.</p><p>We split the read Text8 file by spaces and obtain a list containing all words. Then every 200 words are divided into a sublist, and the 200-length word fragment are converted into strings. The list of the first 10,000 strings is passed to the LLMs compressor as a parameter. The compression ratio calculation formula is as follows (in bits): Table 2: Performance on sentence completion .</p><formula xml:id="formula_7">compression ratio = original text</formula><p>The LLM compressors involved include LLaMA 2 7B released by Meta, Mistral 7B released by the Mistral AI team, OPT-IML 1.3B released by Facebook, and GPT-2-XL 1.5B and GPT-2 774M released by OpenAI. Their calculated compression ratios are shown in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sentence Completion</head><p>Sentence completion is designed to allow the computer to predict the missing parts based on the given context, so that the sentence becomes coherent and complete. We compare the performance of three large models, LLaMA 2 7B, Mistral 7B and GPT-2-XL 1.5B on the HellaSwag dataset, using accuracy as a metric. The results are shown in Table <ref type="table">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Question Answering</head><p>The goal of question answering is to enable the computer to understand the questions raised by users through semantic understanding and syntax analysis, and then generate answers that meet the requirements of the questions. Because any form of LLM evaluation can be seen as question answering or switch to this format, so it is a very important means for LLMs evaluation <ref type="bibr" target="#b8">(Guo et al., 2023)</ref>. We compare the performance of two large models, LLaMA 2 7B and OPT-IML 1.3B on the BoolQ dataset, using accuracy as a metric. The results are shown in Table <ref type="table" target="#tab_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LLM</head><p>Accuracy(%) LLaMA 2 7B 77.4 <ref type="bibr" target="#b20">(Touvron et al., 2023</ref>) OPT-IML 1.3B 61.5 <ref type="bibr" target="#b10">(Iyer et al., 2023)</ref>  Table 4: Performance on coreference resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Coreference Resolution</head><p>Coreference resolution is to identify the entities referred to by pronouns and noun phrases in the text. It has many practical applications in natural language processing, such as information extraction, text summarization, etc. Correct parsing of reference relationships can help computers better understand text. We compares the performance of two large models, GPT-2-XL 1.5B and GPT-2 774M on the Winograd Schema Challenge data set, using accuracy as a metric. The results are shown in Table <ref type="table">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Result Analysis</head><p>From the above experiments, it can be concluded that: the better data compression effect of LLM, the better its performance in natural language processing tasks. That is, there is a positive correlation between compression ratio and model performance.</p><p>When we can effectively compress data, it means that we have captured the key characteristics and patterns of the data. This is similar to finding patterns and redundancies in the data during the model learning process. So we can say that if a large language model achieves the best lossless compression on a dataset, it will often achieve the best generalization on other datasets.</p><p>Therefore, the experimental results further verify the theoretical conclusion of this paper: compression ratio can be used as a general metric to measure the performance of LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We proposed to rank LLMs through lossless data compression in this paper. Our method measures compression ratios as a metric for generalization. We demonstrate the equivalence of compression length under arithmetic coding and LLMs pretraining goal, saving the overhead of actual compression. This further illustrates that understanding is compression, demonstrated by our experiments across challenging downstream NLP tasks.</p><p>For NLP tasks, the experiments in this paper only used the open source version of the pre-trained language model, which was subject to computational constraints and scale limitations. Furthermore evaluation is not the end goal but the starting point. A mature evaluation system should not only provide conclusions about performance, but also provide analysis and guidance for future research and development, which is also our future research direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Statement</head><p>We take academic integrity and research independence very seriously. Here we would like to declare that parts of this paper overlap with a published paper. Overlaps include ideas presented, experimental methods. Information about the published paper is as follows:</p><p>• Title: Compression Represents Intelligence Linearly</p><p>• Author: Yuzhen Huang, Jinghan Zhang, Zifei Shan, Junxian He</p><p>• arXiv:2404.09937 [cs.CL]</p><p>• Submission date: April 15, 2024</p><p>When we began our work, we were unaware of the existence of this published paper. Our study began on December 2023, was completed on May 2024, and was submitted on June 20, 2024.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Compression ratios of different compressors.</figDesc><table><row><cell>length compressed text length</cell><cell>.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Performance on question answering.</figDesc><table><row><cell>LLM</cell><cell>Accuracy(%)</cell></row><row><cell>GPT-2-XL 1.5B</cell><cell>73.3 (Wu et al., 2023)</cell></row><row><cell>GPT-2 774M</cell><cell>69.2 (Trichelair et al., 2018)</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Fabrice</forename><surname>Bellard</surname></persName>
		</author>
		<ptr target="https://bellard.org/nncp/nncp.pdf" />
		<title level="m">Lossless data compression with neural networks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Evaluating the feasibility of chatgpt in healthcare: an analysis of multiple clinical and research scenarios</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Cascella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Montomoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentina</forename><surname>Bellini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Bignami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of medical systems</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A survey on evaluation of large language models</title>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jindong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaijie</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yidong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Grégoire</forename><surname>Delétang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anian</forename><surname>Ruoss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul-Ambroise</forename><surname>Duquenne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><surname>Catt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Genewein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Mattern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Grau-Moya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Wenliang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Aitchison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Orseau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.10668</idno>
		<title level="m">Language modeling is compression</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the equilibrium of heterogeneous substances</title>
		<author>
			<persName><forename type="first">Josiah</forename><surname>Willard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gibbs</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">96</biblScope>
			<biblScope unit="page" from="441" to="458" />
			<date type="published" when="1878">1878</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Deepzip: Lossless data compression using recurrent neural networks</title>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kedar</forename><surname>Tatwawadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Shubham Chandak, and Idoia Ochoa</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Zishan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renren</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bojian</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.19736</idno>
		<title level="m">Evaluating large language models: A comprehensive survey</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Approximating human-like fewshot learning with gpt-based compression</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiying</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.06942</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Opt-iml: Scaling language model instruction meta learning through the lens of generalization</title>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakanth</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Simig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punit</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian O'</forename><surname>Horo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Pereyra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Albert Q Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Bamford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>De Las Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianna</forename><surname>Bressand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><surname>Saulnier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.06825</idno>
		<title level="m">Mistral 7b</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A systematic study and comprehensive evaluation of chatgpt on benchmark datasets</title>
		<author>
			<persName><forename type="first">Md</forename><surname>Tahmid Rahman Laskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mizanur</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Amran Hossen Bhuiyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><forename type="middle">Xiangji</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">An open source data contamination report for llama series models</title>
		<author>
			<persName><forename type="first">Yucheng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.17589</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Cullen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Keefe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Pachocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Paino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashley</forename><surname>Palermo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giambattista</forename><surname>Pantuliano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Parascandolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emy</forename><surname>Parish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Parparita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filipe</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>De Avila Belbute Peres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><surname>Ponde De Oliveira</surname></persName>
		</author>
		<author>
			<persName><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michelle</forename><surname>Pokorny</surname></persName>
		</author>
		<author>
			<persName><surname>Pokrass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vitchyr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tolly</forename><surname>Pong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alethea</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raul</forename><surname>Proehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cameron</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kendra</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Rimbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bob</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henri</forename><surname>Rotsted</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Roussez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Saltarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shibani</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heather</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schnurr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyla</forename><surname>Selsam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toki</forename><surname>Sheppard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Sherbakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shoker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Szymon</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Sidor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddie</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Simens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Sitkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Sohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Sokolowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felipe</forename><forename type="middle">Petroski</forename><surname>Staudacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalie</forename><surname>Such</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Summers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolas</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madeleine</forename><forename type="middle">B</forename><surname>Tezak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amin</forename><surname>Tillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Tootoonchian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preston</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Tuggle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Turley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><surname>Felipe Cerón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Uribe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Vallone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Vijayvergiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><forename type="middle">Jay</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akila</forename><surname>Cj Weinmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welihinda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayi</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lilian</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Wiethoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Willner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Wolrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherwin</forename><surname>Workman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rowan</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marvin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. 2024. Gpt-4 technical report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Chatgpt for education and research: Opportunities, threats, and strategies</title>
		<author>
			<persName><forename type="first">Md</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafizer</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Watanobe</surname></persName>
		</author>
		<idno type="DOI">10.3390/app13095783</idno>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1530" to="1538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName><forename type="first">Claude</forename><surname>Elwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shannon</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Bell system technical journal</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="379" to="423" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Large language models in medicine</title>
		<author>
			<persName><forename type="first">Arun</forename><surname>James Thirunavukarasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darren</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeng</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kabilan</forename><surname>Elangovan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Fang Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Ting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature medicine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1930" to="1940" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasmine</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288</idno>
	</analytic>
	<monogr>
		<title level="m">Open foundation and fine-tuned chat models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">How reasonable are common-sense reasoning tasks: A case-study on the winograd schema challenge and swag</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Trichelair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Emami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackie</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kit</forename><surname>Cheung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.01778</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pixel recurrent neural networks</title>
		<author>
			<persName><forename type="first">Aäron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1747" to="1756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Muhammad Abdul-Mageed, and Alham Fikri Aji</title>
		<author>
			<persName><forename type="first">Minghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdul</forename><surname>Waheed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyu</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.14402</idno>
	</analytic>
	<monogr>
		<title level="m">Lamini-lm: A diverse herd of distilled models from large-scale instructions</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">An introduction to neural data compression. Foundations and Trends® in Computer Graphics and Vision</title>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Mandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="113" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Kun</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqian</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beichen</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zican</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiyang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zikang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><surname>Wen</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>2023. A survey of large language models</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

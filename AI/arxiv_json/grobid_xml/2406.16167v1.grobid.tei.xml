<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy in Large Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-06-23">23 Jun 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Harish</forename><forename type="middle">Tayyar</forename><surname>Madabushi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Josh</forename><surname>Openai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Steven</forename><surname>Achiam</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sandhini</forename><surname>Adler</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lama</forename><surname>Agarwal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ilge</forename><surname>Ahmad</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Florencia</forename><surname>Akkaya</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Diogo</forename><surname>Leoni</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Janko</forename><surname>Almeida</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sam</forename><surname>Altenschmidt</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shyamal</forename><surname>Alt- Man</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Red</forename><surname>Anadkat</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Igor</forename><surname>Avila</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Suchir</forename><surname>Babuschkin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Valerie</forename><surname>Balaji</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Balcom</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Haim- Ing</forename><surname>Baltescu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mohammad</forename><surname>Bao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeff</forename><surname>Bavarian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ir- Wan</forename><surname>Belgum</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jake</forename><surname>Bello</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Berdine</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Bernadett-Shapiro</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lenny</forename><surname>Berner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oleg</forename><surname>Bogdonoff</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Madelaine</forename><surname>Boiko</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anna-Luisa</forename><surname>Boyd</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Greg</forename><surname>Brakman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tim</forename><surname>Brock- Man</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Miles</forename><surname>Brooks</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Brundage</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Trevor</forename><surname>Button</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rosie</forename><surname>Cai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Campbell</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Brittany</forename><surname>Cann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chelsea</forename><surname>Carey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rory</forename><surname>Carlson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Brooke</forename><surname>Carmichael</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Che</forename><surname>Chan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fotis</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Derek</forename><surname>Chantzis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sully</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ruby</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ben</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chester</forename><surname>Chess</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Casey</forename><surname>Cho</surname></persName>
						</author>
						<author>
							<persName><roleName>Hyung</roleName><forename type="first">Won</forename><surname>Chu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dave</forename><surname>Chung</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeremiah</forename><surname>Cummings</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yunxing</forename><surname>Currier</surname></persName>
						</author>
						<author>
							<persName><surname>Dai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tarun</forename><surname>Goel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Gogineni</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rapha</forename><surname>Goh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Gontijo- Lopes</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Morgan</forename><surname>Gordon</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Scott</forename><surname>Grafstein</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan</forename><surname>Gray</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joshua</forename><surname>Greene</surname></persName>
						</author>
						<author>
							<persName><roleName>Shixiang</roleName><forename type="first">Shane</forename><surname>Gross</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yufei</forename><surname>Gu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Guo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jesse</forename><surname>Hallacy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeff</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuchen</forename><surname>Harris</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mike</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Johannes</forename><surname>Heaton</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Heidecke</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alan</forename><surname>Hesse</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wade</forename><surname>Hickey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Hickey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Brandon</forename><surname>Hoeschele</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kenny</forename><surname>Houghton</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shengli</forename><surname>Hsu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xin</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joost</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shantanu</forename><surname>Huizinga</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shawn</forename><surname>Jain</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joanne</forename><surname>Jain</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Angela</forename><surname>Jang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Roger</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Haozhun</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Denny</forename><surname>Jin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shino</forename><surname>Jin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Billie</forename><surname>Jomoto</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hee- Woo</forename><surname>Jonn</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tomer</forename><surname>Jun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Łukasz</forename><surname>Kaftan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ali</forename><surname>Kaiser</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ingmar</forename><surname>Ka- Mali</surname></persName>
						</author>
						<author>
							<persName><surname>Kanitscheider</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shirish</forename><surname>Nitish</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tabarak</forename><surname>Keskar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Logan</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kilpatrick</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christina</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yongjik</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><forename type="middle">Hendrik</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jamie</forename><surname>Kirch- Ner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matt</forename><surname>Kiros</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Knight</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Łukasz</forename><surname>Kokotajlo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Kondraciuk</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aris</forename><surname>Kondrich</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kyle</forename><surname>Kon- Stantinidis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gretchen</forename><surname>Kosic</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vishal</forename><surname>Krueger</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Kuo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ikai</forename><surname>Lampe</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Teddy</forename><surname>Lan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jade</forename><surname>Leike</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Leung</surname></persName>
						</author>
						<author>
							<persName><roleName>Chak</roleName><forename type="first">Ming</forename><surname>Levy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rachel</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Molly</forename><surname>Lim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Stephanie</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mateusz</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Theresa</forename><surname>Litwin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan</forename><surname>Lopez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Patricia</forename><surname>Lowe</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anna</forename><surname>Lue</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kim</forename><surname>Makanju</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sam</forename><surname>Malfacini</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Todor</forename><surname>Manning</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yaniv</forename><surname>Markov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bianca</forename><surname>Markovski</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Katie</forename><surname>Martin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Mayer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bob</forename><surname>Mayne</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Scott</forename><forename type="middle">Mayer</forename><surname>Mcgrew</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christine</forename><surname>Mckinney</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Mcleavey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jake</forename><surname>Mcmillan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Mcneil</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aalok</forename><surname>Medina</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jacob</forename><surname>Mehta</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Luke</forename><surname>Menick</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrey</forename><surname>Metz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pamela</forename><surname>Mishchenko</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vinnie</forename><surname>Mishkin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Evan</forename><surname>Monaco</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Morikawa</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tong</forename><surname>Mossing</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mira</forename><surname>Mu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oleg</forename><surname>Murati</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Murk</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ashvin</forename><surname>Mély</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Reiichiro</forename><surname>Nair</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rajeev</forename><surname>Nakano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arvind</forename><surname>Nayak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><surname>Neelakantan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hyeonwoo</forename><surname>Ngo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Long</forename><surname>Noh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cullen</forename><surname>Ouyang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jakub</forename><surname>O'keefe</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alex</forename><surname>Pachocki</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joe</forename><surname>Paino</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ashley</forename><surname>Palermo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Giambat</forename><surname>Pantuliano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Carl</forename><surname>Ross</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bob</forename><surname>Rotsted</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Henri</forename><surname>Roussez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nick</forename><surname>Ry- Der</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mario</forename><surname>Saltarelli</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ted</forename><surname>Sanders</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Heather</forename><surname>Schmidt</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Schnurr</surname></persName>
						</author>
						<author>
							<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Selsam</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kyla</forename><surname>Sheppard</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Toki</forename><surname>Sherbakov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jessica</forename><surname>Shieh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sarah</forename><surname>Shoker</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Szymon</forename><surname>Sidor</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Sigler</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maddie</forename><surname>Simens</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jordan</forename><surname>Sitkin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ian</forename><surname>Sohl</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Sokolowsky</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Natalie</forename><surname>Staudacher</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Clemens</forename><surname>Winter</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Samuel</forename><surname>Wolrich</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hannah</forename><surname>Wong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lauren</forename><surname>Workman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sherwin</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kai</forename><surname>Xiao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tao</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sarah</forename><surname>Yoo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qim- Ing</forename><surname>Yuan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marvin</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shengjia</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tianhao</forename><surname>Zheng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Juntang</forename><surname>Zhuang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">William</forename><surname>Zhuk</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Barret</forename><forename type="middle">2024</forename><surname>Zoph</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The University of Bath</orgName>
								<address>
									<settlement>Bath</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Cory Decareaux</orgName>
								<orgName type="institution" key="instit2">Thomas Degry</orgName>
								<orgName type="institution" key="instit3">Noah Deutsch</orgName>
								<address>
									<addrLine>Damien Deville Sheila Dunning Adrien Ecoffet Atty Eleti Tyna Eloundou David Farhi Liam Fedus Simón Posada Fishman Juston Forte</addrLine>
									<settlement>Arka Dhar David Dohan Steve Dowling Niko Felix</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Isabella Ful- ford</orgName>
								<address>
									<settlement>Leo Gao</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Elie Georges</orgName>
								<address>
									<addrLine>Christian Gibson</addrLine>
									<settlement>Vik</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Filipe de Avila Belbute Peres</orgName>
								<orgName type="institution">tista Parascandolo</orgName>
								<address>
									<addrLine>Emy Parparita Alex Passos Mikhail Pavlov Andrew Peng Adam Perel- man</addrLine>
									<settlement>Joel Parish</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Elizabeth Proehl</orgName>
								<orgName type="institution">Michael Petrov</orgName>
								<address>
									<addrLine>Henrique Ponde de Oliveira Pinto Poko- rny Michelle Pokrass Vitchyr H. Pong Tolly Pow- ell Alethea Power Boris Power Raul Puri Alec Radford Jack Rae, Aditya Ramesh Cameron Raymond</addrLine>
									<settlement>Michael</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">Ilya Sutskever</orgName>
								<orgName type="institution" key="instit1">Francis Real</orgName>
								<orgName type="institution" key="instit2">Kendra Rimbach</orgName>
								<orgName type="institution" key="instit3">Fe- lipe Petroski Such</orgName>
								<orgName type="institution" key="instit4">Natalie Summers</orgName>
								<address>
									<addrLine>Jie Tang</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">Nikolas Tezak</orgName>
								<address>
									<addrLine>Madeleine B. Thompson, Phil Tillet</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">Amin Tootoonchian</orgName>
								<address>
									<addrLine>Preston Tuggle</addrLine>
									<settlement>Elizabeth Tseng Nick Turley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="institution">Jerry Tworek</orgName>
								<address>
									<addrLine>Juan Fe- lipe Cerón Uribe Andrea Vallone Arun Vijayvergiya, Chelsea Voss Carroll Wainwright Alvin Wang Jonathan Ward Jason Wei, CJ Weinmann Akila Welihinda Peter Welinder Ji- ayi Weng Lilian Weng Matt Wiethoff</addrLine>
									<settlement>Justin Jay Wang Ben Wang Dave Willner</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy in Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-06-23">23 Jun 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">842E02FE8C1B740CB469AC04150DA653</idno>
					<idno type="arXiv">arXiv:2406.16167v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a novel extension to Retrieval Augmented Generation with the goal of mitigating factual inaccuracies in the output of large language models. Specifically, our method draws on the cognitive linguistic theory of frame semantics for the indexing and retrieval of factual information relevant to helping large language models answer queries. We conduct experiments to demonstrate the effectiveness of this method both in terms of retrieval effectiveness and in terms of the relevance of the frames and frame relations automatically generated. Our results show that this novel mechanism of Frame Semantic-based retrieval, designed to improve Retrieval Augmented Generation (FS-RAG), is effective and offers potential for providing data-driven insights into frame semantics theory. We provide open access to our program code and prompts 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction, Motivation and Context</head><p>Large language models (LLMs), despite their significant capabilities and widespread adoption have the inherent tendency to generate plausible sounding, yet inaccurate, output. This phenomenon, referred to as "hallucinations," has been a significant stumbling block in the widespread deployment of these solutions <ref type="bibr" target="#b7">(Ji et al., 2023)</ref>. Hallucinations themselves are not limited to factual inaccuracies, and include other modes of failure, including the incorrect interpretation of input prompts and errors in logical inference. However, factual hallucinations are particularly important to address as the retrieval of incorrect facts is particularly hard to recover from and can neutralise and make irrelevant all other improvements.</p><p>The capabilities of LLMs typically improve with an increase in their "size," which is a combination of a model's parameters and the size of the pretraining corpus. Until recently, this was seen by some as being evidence that further scaling would eventually address the shortcomings of LLMs, including hallucinations. For example, LLMs were claimed to develop "emergent abilities": specifically, it was believed that LLMs, when scaled to several billion parameters developed capabilities including those required to solve tasks requiring reasoning in humans, thus indicative that they were developing reasoning skills <ref type="bibr">(Wei et al., 2022b)</ref>. More recent work, however, has shown that this is not the case and that LLMs instead develop a single capability, which they leverage to solve tasks <ref type="bibr" target="#b9">(Lu et al., 2023)</ref>. This capability, called "in-context learning," is, roughly put, the ability of models to solve a particular task based on a few examples provided in the prompt <ref type="bibr" target="#b1">(Brown et al., 2020;</ref><ref type="bibr" target="#b2">Chowdhery et al., 2023)</ref>. <ref type="bibr" target="#b9">(Lu et al., 2023)</ref> further suggest that the process of instructional fine-tuning LLMs to understand instructions <ref type="bibr">(Wei et al., 2022a)</ref>, enables models to leverage the same "in-context" abilities even in the absence of examples. This finding indicates that further scaling, while providing improved instruction following abilities, will not grant modes the broader capacity to for general reasoning.</p><p>The fact that LLMs are not likely to develop the ability to reason has profound implications to work on improving them, including to mitigating hallucinations. It implies that we must explore alternative approaches. This is especially the case when it comes to factual hallucinations as the 'parametric memory' in LLMs is orders of magnitude smaller than the pre-training data <ref type="bibr" target="#b7">(Ji et al., 2023)</ref>. As such, they must necessarily use some method of compressing their pre-training data. Without the ability to distinguish between the information that is relevant and what is not relevant in their pre-training data, their method of compression defaults to be the memorisation of frequent information and the learning of statistical patterns and trends to repre-sent the less frequent information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Retrieval Augmented Generation</head><p>Given this context, it isn't surprising that Retrieval Augmented Generation, or RAG, which involves the inclusion of relevant information to the prompt has been so successful <ref type="bibr" target="#b8">(Lewis et al., 2020)</ref>. It provides a viable mechanism of offloading information retrieval (IR) demands and instead focuses on using the LLM as a mechanism of analysing and processing data based on explicit instructions. It should be noted that analysing and processing data through explicit instructions is precisely what models excel at through in-context learning. Importantly, RAG also provides a solution to another of LLMs' problems, which is the outdating of knowledge. By incorporating the latest information, RAG prevents the need for further training for even minor knowledge updates to the LLM which is clearly infeasible <ref type="bibr" target="#b14">(Shuster et al., 2021)</ref>.</p><p>However, RAG comes with its own shortcomings. RAG transfers the problem of mitigating factual hallucinations to one of retrieving information relevant to answering a query <ref type="bibr" target="#b6">(Gao et al., 2024)</ref>. While LLMs can handle some noise in the retrieved context provided, a dramatic increase in noise unsurprisingly leads to deteriorating performance of models. The retrieval of information relevant to answering a query is non-trivial as such information is not always likely to be semantically related to the query. This problem becomes even more important when the query requires reasoning over multiple facts each of which are progressively semantically further from the query. Overall, the fact that logically connected information is not always semantically similar makes existing keyword and semantic similarity based search and IR systems poorly suited for the specific IR requirements of LLMs.</p><p>Existing mechanisms of dealing with this problem in information retrieval typically involve using LLMs themselves to solve this problem. Broadly, there are two ways of doing this: the first involves the use of LLMs to decompose the query into sub-queries each of which require less complex reasoning <ref type="bibr">(Patel et al., 2022;</ref><ref type="bibr" target="#b18">Zhou et al., 2023)</ref>, and the second involves the use of LLMs to generate intermediary reasoning steps, called chain of thought <ref type="bibr">(Wei et al., 2022c</ref>), to answer the query. These intermediary steps are then used to generate IR search queries and the resultant facts are fed back to an LLM to generate a response <ref type="bibr" target="#b13">(Shao et al., 2023)</ref>. While these methods show some promise, the problem with them is clear: they are yet another opaque mechanism the failure of which will be hard to fix. In fact, we might be able to improve these systems be fine-tuning models to perform this task. However, such a solution is only going to further obfuscate the process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Contributions</head><p>To address these concerns we propose a novel, transparent, and mutable storage and retrieval system for the mitigation of factual hallucinations in LLMs. This solution is based on theoretical insights from cognitive linguistics, specifically frame semantics. Specifically, this work makes the following contributions:</p><p>1. We propose a novel, transparent, and mutable storage and retrieval system for the mitigation of factual hallucinations in LLMs which is based on theoretical insights from frame semantics. We call this system FS-RAG.</p><p>2. We show the effectiveness of our method by experimenting on a closed domain question answering. Specifically, our method of storage and retrieval provides a significant boost over both treditional search systems and, significantly, also outperforms an LLM based search system wherein we generate search terms using a Language Model.</p><p>3. We show that our method has the significant additional advantage of being interpretable, and thus having the potential to provide datadriven insights to the theory of frame semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Frame Semantics</head><p>Given the context provided earlier, it is evident that only the most frequently occurring factual information from pre-training is explicitly retained in LLMs. Less frequently occurring facts are not explicitly stored and instead the model has access to only statistical approximations. Given that the exact information stored is not explicit and also different for models of different scale and training regimes, the only way to get around hallucination is to explicitly provide LLMs with all but the most common information The effectiveness of RAG provides an easy mechanism for including such information. However, as mentioned previously, the effectiveness of this method hinges on the nontrivial task of retrieving relevant information.</p><p>We propose that this mechanism can be found in the concept of Frame Semantics in cognitive linguistics, which purportedly facilitate human understanding of words by allowing us to recall pertinent information.</p><p>Frame semantics <ref type="bibr" target="#b5">(Fillmore et al., 2006</ref>) is a theory of linguistic meaning that emphasises that the meanings of words are best understood by the semantic and conceptual "frames" or "schemas" within which they function. A frame is a cognitive structure that helps individuals understand and perceive the world around them, enabling them to organise knowledge based on typical situations, actions, or common experiences. In linguistics, a frame influences how the meanings of words are interpreted in different contexts. For example, the word "sell" invokes a commercial transaction frame involving a seller, a buyer, an item being sold, and an agreed price and helps to predict and explain the use of other related words and the roles they play within the same context. FrameNet <ref type="bibr" target="#b0">(Baker et al., 1998)</ref> is an online database based on frame semantics, with the goal to catalogue English words and their associated semantic frames, defining the various roles and relations in a frame and illustrating these with example sentences. Each "frame" in FrameNet captures a specific type of event, relation, or entity and the roles associated with it. For example, the COMMERCE_SELL frame in FrameNet includes roles for the seller, the buyer, the goods being sold, and is annotated to be inherited by the frame RENTING_OUT and as a "perspective on" the frame COMMERCE_GOODS-TRANSFER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Frame Semantic RAG</head><p>This section provides an overview of Frame Semantic RAG (FS-RAG), the proposed mechanism of storing and indexing factual information to aid effective retrieval for the mutation of hallucinations in LLMs. In evaluating our mechanism of retrieval we make use of Entailment Bank, <ref type="bibr" target="#b3">(Dalvi et al., 2021)</ref>, which comprises science questions from school years 4 to 6, along with relevant facts and "entailment trees".</p><p>Consider Table 1, which presents an example from the Entailment-Bank dataset. The original task involves building an entailment tree to answer questions and consists of three tasks at different lev-</p><p>Question How might eruptions affect plants? Associated Facts F1: eruptions emit lava; F2: eruptions produce ash clouds; F3: plants have green leaves; F4: plant producers die without sunlight; F5: ash clouds block sunlight. Inference Steps F2 + F5 implies I1: eruptions block sunlight; F4 + I1 implies I2: eruptions can cause plants to die. Answer eruptions can cause plants to die. Table 1: An example question from Entailment Bank and associated factoids. Language models find it significantly easier to generate the required entailment trees when presented with all relevant facts. However, the fact that the retrieval of relevant facts is non-trivial motivates a frame semantics based mechanism for indexing and search facts relevant to answering questions.</p><p>els of difficulty: a) Task 1 presents the model with all relevant facts and requires only the construction of the entailment tree; b) Task 2 requires the model to perform the same task, but with 15 to 25 distractors included; c) Task 3 involves first extracting the relevant facts from the entire corpus before constructing the entailment tree. The authors find that even a relatively small model, T5-11B <ref type="bibr" target="#b10">(Raffel et al., 2020)</ref>, can perform relatively well on Tasks 1 and 2, when fine-tuned. Task 3, they find, is much harder highlighting the importance of efficient retrieval. We direct the reader to the results section of <ref type="bibr" target="#b3">(Dalvi et al., 2021)</ref> for details.</p><p>Overall, these results reinforce our earlier points: Retrieval is non-trivial and improving retrieval has the potential to significantly boost model performance. In the example presented above, using search terms derived just from the question (e.g. "eruption") including more complex combinations (e.g. "eruption and plants") may not effectively retrieve relevant information. Additionally, if the search terms are too broad, it can cause the retrieval of a significant number of irrelevant facts. Both the lack of relevant facts and a large number of unrelated facts can hinder the model's performance.</p><p>This work is motivated by the hypothesis that we can significantly narrow the search space if we index facts-stored as plain text-according to the frames they invoke and use the frames associated with the question along with the relations between frames to retrieve relevant facts. To test our hypothesis, we focus our experiments on the retrieval of relevant facts.</p><p>In the above example, the FrameNet frames associated with the question could include: a) SURVIV-ING, which captures situations requiring endurance in a dangerous situation and includes annotations of the frame element "Dangerous_situation"; and b) CAUSE_HARM, which describes a situation where an 'agent' injures a 'victim'. Our frame-based mechanism additionally allows the exploitation of the relations between frames to traverse the hierarchical interconnections between frames. This method approximates reasoning steps, enabling the retrieval of facts that are logically connected, even if they are not semantically similar. Within the limited scope of a single task, this work shows a significant improvement in retrieval (recall) using frames when compared to traditional search based baseline, and when compared to retrieval using search terms generated by LLMs, thus verifying the feasibility of this approach. Finally, we use the adaptability of state of the art LLMs to develop helper-LLMs that generate sets of frames, which we then evaluate and compare for their effectiveness in retrieving relevant information. Expanding these methods has the potential to provide, for the first time, data-driven insights that can be used to refine the theory of frame semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Settings</head><p>In this section, we describe the experiments we conduct to test the hypothesis that frame based indexing and search is a more effective mechanism than keyword based indexing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task</head><p>Our choice of the specific task is motivated by the observation that LLMs can perform reasonably well when provided with relevant facts alongside some distractors. However, as described in the previous section, the retrieval of these relevant facts poses a significant challenge. Therefore, we focus on the task of retrieving relevant factoids for answering questions in Entailment Bank. Specifically, we focus on the information extraction subtask required in Task 3 described in Section 3. Notice that the effective retrieval of facts would simplify Task 3 to Task 2, the task of building entailment trees given the relevant facts and some distractors. Given how effective T5-11B, which, by current standards consists of relatively few parameters, is on Task 2, simplifying Task 3 to Task 2 provides a template for solving tasks based exclusively on retrieved facts, which would in turn help with the mitigation of factual hallucinations in LLMs. We slightly modify Task 3 by constructing the corpus of facts that we extract from using all the facts required by any question across the relevant data split, instead of the complete text book corpus which is harder to process. Regardless, we evaluate frame semantic retrieval and the baselines on exactly the same set of questions and facts to ensure a fair comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Empirical Evaluation Metrics</head><p>Given the nature of our task, we select Retrieval@k as our evaluation metric. The average length of entailment trees in the Entailment Bank dataset 7.6 with very few having more than 10. Given that Task 2 (described previously in Section 3) includes between 15 and 25 distractors, we test our methods using Retrieval@k for k ∈ 35, 40, 45. Success in this setting will demonstrate that our retrieval mechanism can effectively simplify Task 3, which requires retrieval from the entire corpus, into Task 2, which involves building entailment trees based on relevant facts and a few distractors. Recall that models perform significantly better on Task 2 than on Task 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>We use two different baselines to compare the effectiveness of frame semantic indexing and retrieval against. The first, is a simple keyword match baseline and is chosen due to our emphasis on interpretability and ease of correction. Being able to understand why a system retrieves certain facts enables refinement of the system by reassigning facts to different clusters or index buckets. This level of transparency is not possible with more opaque methods, such as dense vector-based retrieval. Since frame semantic retrieval implicitly provides interpretable we choose a baseline that is similarly transparent. We first generate search terms by feeding the relevant question to RAKE <ref type="bibr" target="#b12">(Rose et al., 2010)</ref>, a tool for extracting search terms, which is known to be effective. We then perform a simple string match to extract all factoids that contain the keywords.</p><p>The second baseline we use is not directly comparable as it is not interpretable. This consists of using an LLM to generate relevant search terms and is included so we might compare frame semantic retrieval to a rough analogue of question decomposition, a standard mechanism used in RAG as described above. Both baselines can be boosted using several techniques. For example, we do not generate chain of thoughts before generating the search terms using GPT-4, which is likely to improve the effectiveness of the resultant search terms. This is because the purpose of this work is not create a mechanism that outperforms existing methods, but to establish the feasibility of the frame semantic indexing and retrieval process which has the advantage of being interpretable and being based on cognitive linguistic theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Frame Semantic Retrieval: Methods and Qualitative Analysis</head><p>In this section we detail the methods used for frame semantic indexing and retrieval. Given that one of objectives is to maintain interpretability and to to potentially provide data-driven insights to the theory of frame semantics, we perform a qualitative analysis of the outputs of each of the stages. An empirical evaluation of the effectiveness of these methods is presented next, in Section 6.</p><p>The mechanism of retrieving information based on frame semantics consists of three distinct stages: The first is a pre-processing step, which involves indexing all relevant factoids based on between two and four of the most prominent frames that they invoke. The second and third steps are performed when answering a question at inference time and involve identifying the single most important frame associated with the question (the question frame), and frames associated with the question frame, which are likely to be associated with factoids relevant to answering the original question but separated by one or more logical steps. The most important parts of the prompts associated with each of these steps along with example outputs are presented in Table <ref type="table">2</ref>. The complete prompts, including prior versions we experimented with, are included in the supplementary data uploaded with this paper. In all cases, we prompt <ref type="bibr">GPT-4 (Ope-nAI et al., 2024)</ref> using a temperature of 0 to ensure reproducible results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Frame Identification</head><p>There are two difficulties in identifying the frames associated with facts or questions. The first is the necessity to define a complete set of frames, and the second is the linking of these frames to the relevant fact or question. Our exploratory experiments of using FrameNet as a definitive source of all frames which we use to compare against facts and questions from Entailment Bank, showed that FrameNet is inadequate for this purpose. Specifically, the approximately 1,200 frames indexed on FrameNet have two significant shortcomings. The first is FrameNet's focus on 'trigger' words to identify frames is problematic. This emphasis on individual trigger words, likely influenced by the tools available at the time of FrameNet's inception, overlooks the fact that a sentence, as a whole, might invoke a frame that is difficult to identify through trigger words alone, which themselves can be challenging to extract within sentences. The second is the fact that the frames available within FrameNet cover a limited set of domains, which overlap minimally with the frames that are appropriate for the Entailment Bank dataset.</p><p>To address these issues, we bootstrap the creation of frames using an LLM, specifically GPT-4. We prompt GPT-4 to generate frames relevant to the input fact or question, allowing us to organically expand our set of frames. We use in-context examples, selected from the training set, to enable the model to better output relevant frames. The complete prompts, including prior versions we experimented with, are included in the supplementary data uploaded with this paper. We start with an empty 'frame set' and iteratively generate frames associated with facts and questions. For each fact or question, the frames output by GPT-4 are compared with the existing frames previously generated (or none in the initial instances). This comparison is also done with the help of GPT-4. We first extract 5 frames, whose frame names are most semantically similar to that of the newly generated frame. This is done using sentence BERT <ref type="bibr" target="#b11">(Reimers and Gurevych, 2019)</ref>, an effective semantic similarity metric that originally relied on BERT <ref type="bibr" target="#b4">(Devlin et al., 2019)</ref>, but now makes use of custom contextual embeddings. We then prompt GPT-4 to determine if the newly generated frame must be added to the frame set.</p><p>As an example, GPT-4, when prompted to generate frames related to the factoid "the gravitational</p><p>Task Prompt Output Example Frame Identification Facts are indexed by the the frames they invoke During Inference, relevant facts are extracted based on frames invoked by the question and additional frames that are related.</p><p>What is the single/two most important frame, based on the theory of frame semantics, relevant for answering the question/fact below. Do not include frames about answering questions or reasoning, that is implied. Do not include frames which are metaphorical. Ensure the the name of the frame is as descriptive as possible. Output a single frame and join words in the frame by underscores. Output nothing but the name of the frame. Question 1: How does the appearance of a constellation change during the night? Answer 1: celestial_motion . . . Problem: Question Problem: &lt;QUESTION&gt; Answer Problem: Input Question: Tides, such as those along the coast of Massachusetts, are caused by gravitational attractions acting on Earth. Why is the gravitational attraction of the Moon a greater factor in determining tides than the gravitational attraction of the much larger Sun? Output Frame:</p><p>GRAVITA-TIONAL_INFLUENCE Check if the new frame must be added to the frame set</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Used during inference</head><p>The following question has been tagged with the single frame listed.</p><p>Is this frame significantly different from existing frames listed and should it be added as a new frame? Respond with True if it is significantly different otherwise False. Respond with True and False only. Example Question: From Earth, the Sun appears brighter than any other star because the Sun is the Example Tagged Frame:proximity Example Existing Frames 2: CELES-TIAL_MOTION Example Answer: True . . . Question Problem: &lt;INPUT QUESTION&gt; Tagged Frame Problem: &lt;INPUT NEW FRAME&gt; Existing Frames Problem: &lt;INPUT EXIST-ING FRAME&gt; Answer Problem: Input Question:Melinda learned that days in some seasons have more daylight hours than in other seasons. Which season receives the most hours of sunlight in the Northern Hemisphere? Input Frame Assigned: SEA-SONAL_VARIATION_IN_DAYLIGHT Input List of Existing Frames: DAYLIGHT_VARIATION, SEA-SONAL_ADAPTATION, SEA-SONAL_BEHAVIOR, SEASONAL_CHANGE, SEASONAL_VARIATION Output (Add SEA-SONAL_VARIATION_IN_DAYLIGHT to Frame Set?): False Action Taken: Question tagged with DAY-LIGHT_VARIATION Identifying Frame Relations Used during inference Listed below is a single frame relevant to a question. List those frames which are most likely to be associated with the facts required for answer this question. These frames are based on the theory of frame semantics. Do not include frames about answering questions or reasoning, that is implied. Do not include frames which are metaphorical. [. . . ] Example Question 1: Stars are organized into patterns called constellations. One constellation is named Leo. Which statement best explains why Leo appears in different areas of the sky throughout the year? Example Question Frame: CELES-TIAL_MOTION Example Output Frames: CON-STELLATION_CLASSIFICATION, STAR_CLASSIFICATION, CELES-TIAL_MOTION Problem Question : &lt;QUESTION&gt; Problem Question Frame : &lt;FRAME&gt; Problem Output Frames: Input Question: Which measurement is best expressed in light-years? Input Question Frame: DIS-TANCE_IN_ASTRONOMY Output set of Frames Related to Question Frame: CELESTIAL_DISTANCE, ASTRO-NOMICAL_UNIT, SPATIAL_MEASUREMENT</p><p>Table 2: Prompts and associated outputs for each step in frame based indexing and retrieval.</p><p>pull of the sun on earth's oceans causes the tides," might generate GRAVITATIONAL INFLUENCE and TIDAL MOVEMENT. These frames are compared against the existing frames and the frame GRAVI-TATIONAL INFLUENCE might be replaced by the similar frame GRAVITATIONAL ATTRACTION already in our frame set. If a similar frame is not found, the original frame is added to the frame set. This same process is then used to generate frames associated with questions. We find that this method is sub-optimal and that GPT-4 is a poor judge of identifying frames which are truly different form those already in the frame set. As such, we always augment the original set of frames with five frames whose names are most semantically similar to the original. See also Table <ref type="table">2</ref> for more examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Frame Relations</head><p>We call the overlap between the frames invoked by a question and those invoked by the facts necessary for answering that question a first-order frame overlap. This first-order overlap is not sufficient to extracting all facts that are relevant to answering a question. As such, we require a means of identifying relations between frames, so we can expand the set of relevant frames to include those which are related to the original, as a proxy for the reasoning process. This is in addition to the expansion using semantic similarity described previously.</p><p>Instead of importing definitions of frame relations, for example from FrameNet, we generate these relations using a data-driven approach. Specifically, we extract questions and associated facts from the training data. We then assign frames to both the questions and the facts using the methods described previously. The frames associated with the questions and the corresponding facts are assumed to hold a latent relation, which we use to generate similar frame relations at the time of answering questions. This is done by prompting GPT-4 with the relevant question and the frame associated with the frame and requiring GPT-4 to generate frames relevant to answering the question. Row three of Table <ref type="table">2</ref> presents the prompt and an example output of this step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Qualitative Analysis</head><p>A qualitative analysis of resultant frames and frame relations demonstrate the surprising effectiveness of this method. Table <ref type="table">2</ref> presents some of the frames and frame relations automatically generated using the methods described above. The results are far from perfect, but are interesting from the perspectives of the diversity and adaptability they present. It is important to note that these results are achieved though prompting alone. Given that LLMs, such as GPT-4, are unlikely to be designed to solve tasks such as this, it is not surprising that there is much room for improvement, although the results demonstrate the feasibility of this method. Overall, we believe that bootstrapping these methods-by first manually refining a dataset generated through prompting, then iteratively training models specifically for this task, and subsequently using that model to generate more data-is an effective way to scale these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Empirical Evaluation</head><p>In addition to the qualitative analysis we present an empirical evaluation of the frame semantic retrieval methods described above. We compare the performance of frame semantic retrieval to the two search based baselines described in Section 4.3. We present the results in Table <ref type="table">3</ref>. Overall, we find that frame semantic retrieval outperforms both the simple search based baseline and the baseline where search terms are generated using GPT-4 by a significant margin. Recall that we test our methods using Retrieval@k for k ∈ 35, 40, 45 to take into account the fact that this allows us to demonstrate that our retrieval mechanism can effectively simplify Task 3, which requires retrieval from the entire corpus, into Task 2, which involves building entailment trees based on relevant facts and a few distractors.</p><p>While our results are not perfect, frame semantic indexing and retrieval has one significant advantage. It is the fact that each stage of the process can be improved by fine-tuning LLMs for the specific purpose. In addition, the transparent nature of this process, which outputs frames at each stage, allows for the analysis and 'debugging' of each stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>This work presents a novel mechanism for the indexing and retrieval of facts relevant for answering specific questions with the purpose of mitigating factual hallucinations in LLMs. This work demonstrates the feasibility and effectiveness of this method in both retrieval and the automatic generation of frames which, when scaled to multiple tasks, has the potential to provide data-driven insights to the theory of Frame Semantics.</p><p>We believe that this work provides a template</p><p>Recall@ RAKE Search (Baseline 1) GPT-4 Search (Baseline 2) Frame Semantic Retrieval (our method) @35 0.330 0.385 0.439 @40 0.333 0.390 0.464 @45 0.338 0.396 0.473</p><p>Table <ref type="table">3</ref>: Recall at k between 35 and 45 comparing frame semantic retrieval to search based retrieval where the search terms are generated using a traditional keyword based method (RAKE) and using GPT-4. It is notable that frame semantic retrieval performs significantly better than both baselines across all selected values of k.</p><p>for effectively integrating cognitive linguistics and LLM research, benefiting both fields. In future work, we intend to first create models that are specifically fine-tuned to perform each of the tasks described above, specifically frame generation, frame identification and frame relation identification. In addition, we indent to extend this work to multiple tasks so as to establish its effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>This work presents a novel method of indexing and retrieval of facts specifically for the purpose of ensuring that LLMs reason over retrieved, and therefore correct facts, thereby mitigating factual hallucinations in LLMs. Our experiments are based on a single task in a specific domain. As a proof of concept of a novel method that is based on cognitive linguistic theory, these experiments are effective in showcasing the feasibility of this method. However, demonstrating the effectiveness of this method on multiple tasks is required for a more rigorous test, which we leave to future work. Additionally, our experiments, however, do not extend to testing LLMs for reduced hallucinations -prior work implies that improved retrieval will indeed lead to reduced hallucinations, but it is left to future work to rigorously test this.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/H-TayyarMadabushi/A-Frame-Semantics-based-approach-for-Improved-Factual-Accuracyin-Large-Language-Models</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Berkeley FrameNet project</title>
		<author>
			<persName><forename type="first">Collin</forename><forename type="middle">F</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">B</forename><surname>Lowe</surname></persName>
		</author>
		<idno type="DOI">10.3115/980845.980860</idno>
	</analytic>
	<monogr>
		<title level="m">36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="86" to="90" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Alec Radford, Ilya Sutskever, and Dario Amodei</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
	<note>Language models are few-shot learners</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Palm: Scaling language modeling with pathways</title>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kensen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Vinodkumar Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiner</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anselm</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunipa</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><surname>Omernick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Dai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thanumalayan</forename><surname>Sankaranarayana Pillai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marie</forename><surname>Pellat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aitor</forename><surname>Lewkowycz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Erica</forename><surname>Moreira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Zongwei</forename><surname>Zhou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Brennan</forename><surname>Saeta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mark</forename><surname>Diaz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michele</forename><surname>Catasta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kathy</forename><surname>Meier-Hellstern</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Douglas</forename><surname>Eck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Noah</forename><surname>Fiedel</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">240</biblScope>
			<biblScope unit="page" from="1" to="113" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Explaining answers with entailment trees</title>
		<author>
			<persName><forename type="first">Bhavana</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengnan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leighanna</forename><surname>Pipatanangkura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.585</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Online and Punta Cana, Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7358" to="7370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><surname>Fillmore</surname></persName>
		</author>
		<title level="m">Frame semantics. Cognitive linguistics: Basic readings</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="373" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Retrieval-augmented generation for large language models: A survey</title>
		<author>
			<persName><forename type="first">Yunfan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kangxiang</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinliu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxi</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haofen</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Survey of hallucination in natural language generation</title>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nayeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rita</forename><surname>Frieske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiezheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Etsuko</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno type="DOI">10.1145/3571730</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Retrieval-augmented generation for knowledgeintensive nlp tasks</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heinrich</forename><surname>Küttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9459" to="9474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Are emergent abilities in large language models just in-context learning? Pruthvi Patel, Swaroop Mishra, Mihir Parmar, and Chitta Baral. 2022. Is a question decomposition unit all we need?</title>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Bigoulaeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachneet</forename><surname>Sachdeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harish</forename><surname>Tayyar Madabushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.emnlp-main.302</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="4553" to="4569" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using Siamese BERTnetworks</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic keyword extraction from individual documents</title>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Cowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text mining: applications and theory</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy</title>
		<author>
			<persName><forename type="first">Zhihong</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeyun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.findings-emnlp.620</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="9248" to="9274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Retrieval augmentation reduces hallucination in conversation</title>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spencer</forename><surname>Poff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.320</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<meeting><address><addrLine>Punta Cana</addrLine></address></meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3784" to="3803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>International Conference on Learning Representations</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Emergent abilities of large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Survey Certification</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Least-to-most prompting enables complex reasoning in large language models</title>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

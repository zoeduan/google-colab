<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Utilizing Large Language Models for Natural Interface to Pharmacology Databases</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hong</forename><surname>Lu</surname></persName>
							<email>honglu@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Chuan</forename><surname>Li</surname></persName>
							<email>chuanl@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Yinheng</forename><surname>Li</surname></persName>
							<email>yinhengli@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Zhao</surname></persName>
							<email>zhaojie@microsoft.com</email>
						</author>
						<title level="a" type="main">Utilizing Large Language Models for Natural Interface to Pharmacology Databases</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4025A29A17F73D822A39A16B98577805</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The drug development process necessitates that pharmacologists undertake various tasks, such as reviewing literature, formulating hypotheses, designing experiments, and interpreting results. Each stage requires accessing and querying vast amounts of information. In this abstract, we introduce a Large Language Model (LLM)-based Natural Language Interface designed to interact with structured information stored in databases. Our experiments demonstrate the feasibility and effectiveness of the proposed framework. This framework can generalize to query a wide range of pharmaceutical data and knowledge bases.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Numerous databases are commonly used in pharmacology <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref>, encompassing various properties of biological entities (such as genes, proteins, drugs, phenotypes, and diseases) and their relationships. Simple queries might involve retrieving GO terms for a specific protein, while complex queries could necessitate analyzing diseases associated with the dysregulation of a genetic pathway. However, formulating SQL queries and comprehending these databases can be challenging and time-consuming for pharmacologists <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4]</ref>. In this work, we study employing Large Language Models (LLMs) to develop a natural language interface that enables pharmacologists to query public or private databases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHOD</head><p>As illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, our end-to-end Question Answering (QA) system allows users to ask natural language questions, which are then translated into SQL queries by GPT-4. Using these queries, the SQL database retrieves relevant information from the databases. Our system employs an in-house Named Entity Recognition (NER) model, followed by an entity linker built on Cognitive Search. Detected entities are replaced with their type-aware placeholders. The GPT-4 powered SQL generator facilitates schema linking, question decomposition, Chain-of-Thought, and self-correction of the generated SQL query.</p><p>In addition to the QA system, there is a separate question generation pipeline. This pipeline serves two purposes: generating a synthetic dataset to evaluate the QA model and providing incontext demonstrations for few-shot QA. This dual functionality ensures that the system is effective, accurate, and user-friendly, streamlining the research process and enhancing data exploration efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>We evaluated our solution using both synthetic and realistic questions. Our synthetic dataset comprises 60 single-hop questions and 204 two-hop questions, based on the knowledge graph of entities. Domain experts reviewed these generated questions to ensure their quality and relevance. Furthermore, our realistic dataset includes 50 question-answer pairs curated by experts who are unaware of the database schema. This dataset represents the system's effectiveness and applicability to real-world scenarios, further demonstrating its practical utility.</p><p>We utilize PrimeKG <ref type="bibr" target="#b0">[1]</ref> as the knowledge graph, which comprehensively includes 10 types of entities and 30 types of relations with over 8 million edges, aggregated from 20 bio-medical data sources. We employ Exact Match (EM) and F1-score as evaluation metrics. To assess the importance of each module, we conducted an ablation test and evaluated model performance on the realistic dataset with and without named entity recognition (NER) or self-correction (Table1). This test highlights the significance of both modules. Our model also demonstrated reasonable performance on synthetic questions (Table2). The results indicate that NER is a bottleneck and confirm that two-hop reasoning can be more challenging for LLMs. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The proposed framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Realistic dataset ablation results. "-" denotes removing NER (using oracle entity names) or self-correction (SC).NER -SC 0.375 0.399 0.792 0.797</figDesc><table><row><cell>Setting</cell><cell cols="2">ChatGPT</cell><cell cols="2">GPT-4</cell></row><row><cell></cell><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell></row><row><cell>Full</cell><cell cols="4">0.396 0.433 0.708 0.712</cell></row><row><cell>-NER</cell><cell cols="4">0.458 0.491 0.792 0.797</cell></row><row><cell>-SC</cell><cell cols="4">0.313 0.316 0.708 0.712</cell></row><row><cell>-</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Evaluation on the synthetic dataset.</figDesc><table><row><cell>LLM</cell><cell>Setting</cell><cell>single-hop EM F1</cell><cell>two-hop EM F1</cell><cell>Overall EM F1</cell></row><row><cell>GPT-4</cell><cell cols="4">Full Full -NER 0.700 0.746 0.458 0.483 0.513 0.543 0.450 0.496 0.320 0.343 0.378 0.350</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Building a knowledge graph to enable precision medicine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
			<publisher>Sci Data</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A knowledge graph based question answering method for medical domain</title>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PeerJ Comput Sci</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Knowledge Transfer between Structured and Unstructured Sources for Complex Question Answering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>In SUKI</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pourreza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rafiei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.11015[cs.CL]arXiv:2307.15717v1[cs.CL]26</idno>
		<imprint>
			<date type="published" when="2023-07">2023. Jul 2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

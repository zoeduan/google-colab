<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Katikapalli</forename><surname>Subramanyam</surname></persName>
							<email>kalyan@akmmusai.pro</email>
							<affiliation key="aff0">
								<orgName type="institution">Akmmus AI</orgName>
								<address>
									<region>Trichy</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
							</affiliation>
						</author>
						<title level="a" type="main">A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">01C578E7D5B09B7E467E7F343FDC2D65</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Large Language Models</term>
					<term>GPT-3</term>
					<term>ChatGPT</term>
					<term>GPT-4</term>
					<term>Transformers</term>
					<term>Survey</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models (LLMs) are a special class of pretrained language models obtained by scaling model size, pretraining corpus and computation. LLMs, because of their large size and pretraining on large volumes of text data, exhibit special abilities which allow them to achieve remarkable performances without any task-specific training in many of the natural language processing tasks. The era of LLMs started with OpenAI's GPT-3 model, and the popularity of LLMs is increasing exponentially after the introduction of models like ChatGPT and GPT4. We refer to GPT-3 and its successor OpenAI models, including ChatGPT and GPT4, as GPT-3 family large language models (GLLMs). With the ever-rising popularity of GLLMs, especially in the research community, there is a strong need for a comprehensive survey which summarizes the recent research progress in multiple dimensions and can guide the research community with insightful future research directions. We start the survey paper with foundation concepts like transformers, transfer learning, self-supervised learning, pretrained language models and large language models. We then present a brief overview of GLLMs and discuss the performances of GLLMs in various downstream tasks, specific domains and multiple languages. We also discuss the data labelling and data augmentation abilities of GLLMs, the robustness of GLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with multiple insightful future research directions. To summarize, this comprehensive survey paper will serve as a good resource for both academic and industry people to stay updated with the latest research related to GPT-3 family large language models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Large Language Models (LLMs), the recent buzz in Artificial Intelligence, have garnered a lot of attention in both academic and industry circles with their remarkable performances in most of the natural language processing (NLP) tasks. These models are essentially deep learning models, specifically transformer-based, pretrained on large volumes of text data and then aligned to human preferences using meta-training. Pretraining provides universal language knowledge to the model <ref type="bibr" target="#b0">[1]</ref>, while meta-training aligns the model to act based on the user's intentions. Here user's intention includes both explicit intentions, like following instructions, and implicit intentions, like maintaining truthfulness and avoiding bias, toxicity, or any harmful behaviour <ref type="bibr" target="#b1">[2]</ref>. Large language models (LLMs) are a special class of pretrained language models obtained by scaling model size, pretraining corpus and computation. For downstream task usage, pretrained language models leverage supervised learning paradigm, which involves task-specific fine-tuning and hundreds or thousands of labelled instances <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>. LLMs leverage in-context learning (ICL), a new learning paradigm which doesn't require task-specific fine-tuning and a large number of labelled instances <ref type="bibr" target="#b3">[4]</ref>. LLMs treat any NLP task as a conditional text generation problem and generate the desired text output just by conditioning on the input prompt, which includes task description, test input and optionally, a few examples. Figure <ref type="figure">1</ref> shows the evolution of artificial intelligence from machine learning to large language models.</p><p>In the beginning, NLP systems are predominantly rule-based. These rule-based models are built on top of domain expert-framed rules. As manual rule framing is a laborious, expensive process and also requires frequent changes, rules-based models are gradually replaced by machine models, which learn the rules automatically from the training data and completely avoid manual rule framing <ref type="bibr" target="#b0">[1]</ref>. However, machine learning models require human intervention in the form of domain experts for feature engineering. The evolution of dense text vector representation models like Word2Vec <ref type="bibr" target="#b4">[5]</ref>, Glove <ref type="bibr" target="#b5">[6]</ref>, FastText <ref type="bibr" target="#b6">[7]</ref> and the advancement of computer hardware like GPUs, NLP systems are built using traditional deep learning models like CNN <ref type="bibr" target="#b7">[8]</ref>, RNN <ref type="bibr" target="#b8">[9]</ref>, LSTM <ref type="bibr" target="#b9">[10]</ref>, GRU <ref type="bibr" target="#b10">[11]</ref>, Seq2Seq <ref type="bibr" target="#b11">[12]</ref> and Attention-based Seq2Seq models <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. However, the drawbacks of these models like the inability to (i) capture long-term dependencies and (ii) leverage GPUs fully because of sequential processing (except in the case of CNN), resulted in the evolution of advanced deep learning models like Transformers <ref type="bibr" target="#b14">[15]</ref>, which are fully attention based without any recurrent and convolution layers.</p><p>Inspired by the success of image-pretrained models <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b17">[18]</ref> built on top of transfer learning and large convolution models, the research community focused on building pretrained language models (PLMs) like BERT <ref type="bibr" target="#b18">[19]</ref> and GPT-1 <ref type="bibr" target="#b19">[20]</ref> with transformers as the backbone and pretrained based on a new learning paradigm called self-supervised learning <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. Unlike traditional deep learning models and vanilla transformers, which require training from scratch for downstream usage, pretrained language models can be easily adapted to downstream tasks with fine-tuning. The huge success of BERT and GPT-1 models triggered the development of other pretrained language models like RoBERTa, XLNet <ref type="bibr" target="#b22">[23]</ref>, ELECTRA <ref type="bibr" target="#b23">[24]</ref>, ALBERT <ref type="bibr" target="#b24">[25]</ref>, DeBERTa <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, GPT-2 <ref type="bibr" target="#b27">[28]</ref>, T5 <ref type="bibr" target="#b28">[29]</ref>, BART <ref type="bibr" target="#b29">[30]</ref> etc.</p><p>Although PLMs have many advantages compared to traditional deep learning and vanilla transformer models, they still suffer from drawbacks like the inability to generalize to unseen tasks without task-specific training. So, the research community focused on developing more advanced models like large language models which can generalize to unseen tasks without any taskspecific training. The era of LLMs started with GPT-3 <ref type="bibr" target="#b3">[4]</ref>, and the success of GPT-3 inspired the development of other LLMs like PaLM <ref type="bibr" target="#b30">[31]</ref>, Chinchilla <ref type="bibr" target="#b31">[32]</ref>, GLaM Fig. <ref type="figure">1</ref>: Evolution of artificial intelligence from machine learning to large language models. <ref type="bibr" target="#b32">[33]</ref>, LaMDA <ref type="bibr" target="#b33">[34]</ref>, Gopher <ref type="bibr" target="#b34">[35]</ref>, Megatron-Turing NLG <ref type="bibr" target="#b35">[36]</ref> <ref type="bibr" target="#b180">[181]</ref>, BLOOM <ref type="bibr" target="#b36">[37]</ref>, Galactica <ref type="bibr" target="#b37">[38]</ref>, OPT <ref type="bibr" target="#b38">[39]</ref>, LLaMA <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref> etc. The popularity of LLMs is increasing exponentially after the recent launch of Open AI's models like ChatGPT and GPT-4 <ref type="bibr" target="#b41">[42]</ref>. For example, ChatGPT has garnered millions of users within a few weeks of its launch. Because of the ability to generalize to unseen tasks based on the task description and a few examples without requiring any task-specific training, just like humans, LLMs can be considered as a baby step towards Artificial General Intelligence <ref type="bibr" target="#b42">[43]</ref>. In this survey paper, we mainly focus on Open AI LLMs like GPT-3 models, GPT-3.5 models (InstructGPT, ChatGPT etc.) and GPT-4, which we refer to as GPT-3 family large language models (GLLMs). This survey paper provides a comprehensive review of research works related to GLLMs in multiple dimensions.</p><p>Contributions. The key contributions of this survey paper are</p><p>• First survey paper to present a comprehensive review of GPT-3 family large language models (GLLMs) in multiple dimensions covering more than 350 recent research papers. • We discuss various foundation concepts like transformers, transfer learning, self-supervised learning, pretrained language models and large language models. • We discuss GPT-3 family large language models in detail, starting from GPT-3 to the latest ChatGPT and GPT-4. • We discuss the performances of GLLMs in various downstream tasks and present a thorough discussion on the data labelling, and data augmentation abilities of GLLMs. • We discuss the robustness and the evaluation abili-ties of GLLMs.</p><p>• We present multiple insightful future research directions which will guide the research community to improve the performances of GLLMs further. Comparison with existing surveys. The existing survey papers provide a review of large language models <ref type="bibr" target="#b43">[44]</ref> and the relevant concepts like in-context learning <ref type="bibr" target="#b44">[45]</ref>, evaluation <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref>, alignment with human values <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref>, safety and trustworthiness <ref type="bibr" target="#b49">[50]</ref>, reasoning <ref type="bibr" target="#b50">[51]</ref>, challenges and applications <ref type="bibr" target="#b51">[52]</ref>, LLM compression <ref type="bibr" target="#b52">[53]</ref> and multi-modal LLMs <ref type="bibr" target="#b53">[54]</ref>. For example, Zhao et al. <ref type="bibr" target="#b43">[44]</ref> are the first to provide a comprehensive of large language models. Unlike Zhao et al. <ref type="bibr" target="#b43">[44]</ref>, the other existing survey papers focus on specific concepts of LLMs. For example, the survey papers written by Dong et al. <ref type="bibr" target="#b44">[45]</ref>, Chang et al. <ref type="bibr" target="#b45">[46]</ref>, Wang et al. <ref type="bibr" target="#b47">[48]</ref> and Huang et al. <ref type="bibr" target="#b50">[51]</ref> focus on in-context learning, evaluation of LLMs, alignment of LLMs with human values and reasoning ability of LLMs respectively. Similarly, the survey papers written by Yin et al. <ref type="bibr" target="#b53">[54]</ref> and Huan et al. <ref type="bibr" target="#b49">[50]</ref> provide a review of multi-modal LLMs and the safety and trustworthiness of LLMs, respectively. However, there is no existing survey paper which provides a comprehensive survey of GPT-3 family large language models. With the ever-rising popularity of GPT-3 family large language models like GPT-3, InstructGPT, ChatGPT, GPT-4 etc. and a lot of research works using these models, there is a strong need for a survey paper which focuses exclusively on GPT-3 family large language models.</p><p>Papers collection. For this survey paper, we gathered over 350 research papers that appeared online in the period of June 2020 to September 2023. Initially, we selected GLLMs like GPT-3, InstructGPT, Codex and GPT-4 papers as seed papers and collected all the citing papers. We also collected papers from popular venues like ACL, EMNLP, COLING, AAAI, ICML, ICLR, NeurIPS etc and popular databases like Google Scholar and ScienceDirect using the keywords GPT-3, ChatGPT, GPT-3.5, Instruct-GPT, Codex and GPT-4. After removing the duplicate papers, we did a manual review to arrive at a final set of over 350 relevant research papers.</p><p>Survey paper organization. The survey paper is organized as follows: Section 2 presents a brief overview of various foundation concepts like transformers, transfer learning, self-supervised learning, pretrained language models and large language models. Section 3 presents GPT-3 family large language models in detail, starting from GPT-3 to the latest ChatGPT and GPT-4. Sections 4, 5, and 6 discuss the performances of GLLMs in various downstream tasks, specific domains and multilingual scenarios, respectively. Section 7 presents the data labelling and data augmentation abilities of GLLMs. Section 8 discusses various research works presenting approaches to detect text generated by GLLMs. Sections 9 and 10 discuss the robustness and evaluation abilities of GLLMs, respectively. Section 11 presents multiple insightful future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">FOUNDATION CONCEPTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Transformer</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Traditional Deep Learning Models</head><p>Before the evolution of the transformer model, most of the research in natural language processing involved deep learning models like multi-layer perceptron (MLP), convolutional neural network (CNN), recurrent neural network (RNN), long short-term memory (LSTM) network, gated recurrent unit (GRU), sequence-to-sequence and attention-based sequence-to-sequence <ref type="bibr" target="#b54">[55]</ref>. MLP is a feed-forward neural network with three or more layers (input layer, one or more hidden layers, and output layer), and the neurons in these layers are fully connected. MLPs are easy to understand and simple to implement. However, as MLPs ignore the sequence information and struggle to capture the semantic relationships, these models are subsequently replaced by advanced models like CNN and RNN. CNN, originally developed to process images, is also explored for natural language processing tasks by treating text as a one-dimensional image <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b55">[56]</ref>. CNNs can learn local features (n-grams) effectively using convolution layers but struggle to capture long-term dependencies. RNNs evolved as a deep learning model exclusively to process sequential data like text, time series, etc <ref type="bibr" target="#b8">[9]</ref>. RNNs can handle input with varying lengths and process sequential data by maintaining a hidden state to capture the context from previous inputs. However, RNNs suffer from vanishing gradients problems and struggle to capture long-term dependencies. LSTM <ref type="bibr" target="#b9">[10]</ref> and GRU <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b56">[57]</ref> evolved as advanced RNN variants to address the issues with the vanilla RNN model. The gating mechanism in these models helps to regulate the flow of information along the sequence and retain the most important information. Compared to LSTM, which includes three gates (input, forget and output gates), GRU is more parameter efficient as it includes only two gates, namely the input and the reset gates.</p><p>RNN and its variants like LSTM and GRU expect the input and output sequences to be the same length. However, in the case of natural language generation tasks like machine translation, text summarization, etc., the input and output sequences can be of different lengths. So, the researchers introduced the sequence-tosequence (Seq2Seq) model to handle tasks with different input and output sequence lengths <ref type="bibr" target="#b11">[12]</ref>. The Seq2Seq model is originally developed for machine translation and later explored for other NLP tasks. The Seq2Seq model consists of an encoder and decoder based on RNN, LSTM or GRU to process the input sequence and generate the output sequence. The encoder processes the input sequence to generate a fixed-size context vector based on which the decoder generates the output sequence. However, the fixed-size context vector fails to encode the entire information in the input sequence, especially when the input sequence is long <ref type="bibr" target="#b12">[13]</ref>. The attention mechanism is introduced to address this issue, allowing the decoder to focus on the relevant input tokens at each decoding step <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. However, as the encoder and decoder of the Seq2Seq model are based on RNN and its variants, the Seq2Seq model suffers from vanishing gradients and struggles to capture long-term dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Drawbacks of Traditional Deep Learning Models</head><p>Here are the drawbacks of traditional deep learning models</p><p>• Lack of sequence and semantic understanding -MLPs ignore sequence information, treating all input tokens as independent. Moreover, MLPs can learn statistical patterns but struggle to capture semantic information in the input sequence. • Computationally expensive -CNNs require a large number of parameters to achieve good results. Although LSTM and GRU address the limitations of vanilla RNNs to some extent, these models include a gating mechanism which significantly increases the number of model parameters. The large number of parameters makes these models computationally expensive to train and use. • Vanishing gradients -RNN suffer from vanishing gradients problem. Although LSTM and GRU address this problem to some extent, these models also suffer from vanishing gradient problem and have difficulties in capturing long-term dependencies. • Sequential Computation -RNN and its variants process the input sequence token by token, i.e. sequentially. This sequential computation is a bottleneck for these models to leverage parallel computing capability in advanced computing hardware like GPUs and TPUs. This sequential computation also slows down training and inference processes, especially for long sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Transformer Description</head><p>The transformer model evolved as an effective alternative to traditional deep learning models and addressed most associated issues <ref type="bibr" target="#b14">[15]</ref>. In no time, the transformer model, with its novel and efficient architecture, gained a lot of popularity and became a de facto choice for building pretrained language models and large language models using self-supervised learning paradigm <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b43">[44]</ref>.</p><p>The key ingredient behind the massive success of the transformer model is its self-attention mechanism. The self-attention mechanism allows the transformer model to process the input sequence without using recurrent or convolution layers. This attention mechanism also allows the model to effectively capture long-range dependencies in the input sequence, making it highly effective for natural language understanding and generation tasks.</p><p>The transformer consists of encoder and decoder components. The encoder processes the input text using a stack of encoder layers and then produces rich contextualized vector representations for each token in the input sequence, which are later used by the decoder. Each encoder layer consists of a self-attention mechanism and a feedforward neural network. The self-attention mechanism adds contextual information to the token vectors by allowing each token to attend to all other input tokens, and this helps the model to capture long-term dependencies better. After the self-attention mechanism, the token vectors are passed through a feedforward neural network, which introduces non-linearity and further transforms the representations. In this way, each encoder layer applies self-mechanism and feed-forward network to add more contextual information to the token vector representations.</p><p>The decoder receives the output from the last encoder layer and processes it sequentially by applying a stack of layers, with each decoder layer having masked self-attention, encoder-decoder self-attention and feedforward neural network. The masked self-attention allows each token to attend to the previously generated tokens only and prevents the model from attending to future tokens. The encoder-decoder self-attention allows the decoder to attend to the encoded input sequence and helps the decoder focus on relevant input sequence tokens to generate the output tokens.</p><p>The self-attention mechanism in the Transformer uses multiple attention heads, which allow the model to learn different aspects of relationships between tokens and encode more contextual information in the token representations. The encoder and decoder layers also include the embedding layer, residual connections and layer normalization. The embedding layer transforms input tokens into vector representations where each vector representation encodes both the meaning and position information. The residual connections and layer normalization are applied after the self-attention mechanism and feed-forward network. Residual connection avoids vanishing gradients and ensures a smooth flow of gradients, while layer normalization is applied to normalize the token representations and stabilize training. Apart from the embedding layer and stack of decoder layers, the decoder also includes an output layer. The output layer is nothing but a softmax layer that assigns probabilities to each token in the vocabulary, indicating the likelihood of each token being the next word in the generated sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Transfer Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Why Transfer Learning?</head><p>Although machine learning models tasted some success, these models require feature engineering, which is a laborious and expensive process involving human intervention in the form of domain experts <ref type="bibr" target="#b0">[1]</ref>. Deep learning models, essentially a subset of machine learning, don't require feature engineering as deep learning models learn features during training. Over the years, deep learning witnessed the evolution of various models like multi-layer perceptron (MLP), convolution neural networks (CNN), recurrent neural networks (RNN), long short-term memory networks (LSTM), gated recurrent unit networks (GRU), encoder-decoder networks, encoder-decoder with attention networks and recently transformers <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b58">[59]</ref>. Even though deep learning models eliminated the requirement of manual feature engineering and achieved significant progress, the main drawback with these models is the requirement of a large amount of labelled data to achieve good results. Along with developing various deep learning models, the research community also focused on developing high-quality datasets for various tasks <ref type="bibr" target="#b59">[60]</ref>. However, manual data annotation is a time-consuming, expensive and laborious process. Additionally, when there is a change in the data distribution, it is essential to re-train deep learning models with new labelled data to maintain good performances <ref type="bibr" target="#b60">[61]</ref>. To reduce the costs, the research community focused on how to effectively train deep learning models with limited labelled data. Transfer learning evolved as one of the effective solutions to train deep learning models with limited labelled data <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b60">[61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">What is Transfer Learning?</head><p>Transfer Learning in the context of artificial intelligence involves existing knowledge transfer from one task (or domain) to another different but related task (or domain) <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b60">[61]</ref>. Transfer learning avoids training a model from scratch and helps improve the model's performance on the target task (or domain) by leveraging already existing knowledge. Transfer learning is largely based on the idea that when two tasks (or domains) are similar, the knowledge from the source task (or domain) with sufficient data can be used to enhance the performance of the Fig. <ref type="figure">2</ref>: Real-life examples of knowledge transfer (transfer learning). Examples are inspired from <ref type="bibr" target="#b57">[58]</ref> target task (or domain) with limited data. For example, consider the task of sentiment analysis of reviews of different products. It is highly expensive to annotate large data separately for each product. In such cases, transfer learning helps to adapt the model trained on one product reviews to perform well on other product reviews without requiring large labelled data <ref type="bibr" target="#b61">[62]</ref>.</p><p>Transfer learning draws inspiration from human beings, i.e., human beings can do new tasks without or with few examples just by reusing previously gained knowledge <ref type="bibr" target="#b59">[60]</ref>. Figure <ref type="figure">2</ref> illustrates real-life examples of knowledge transfer (transfer learning). For example, a person who can cycle can learn to ride a bike quickly with less effort. This is because riding a cycle and a bike involves a lot of common things like handling the balance, etc. Similarly, a person familiar with C programming language can learn Python programming language easily. This is because both C and Python are programming languages and share many common concepts. So, due to the ability to reuse the existing knowledge and train the target models with limited data, transfer learning evolved as a promising learning paradigm and eventually played a crucial role in the evolution of advanced deep learning models like pretrained language models <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref> and the recent large language models. Overall, the advantages of transfer learning are</p><p>• Transfer learning helps to reduce the requirement of labelled data. (Data efficiency) • Transfer learning avoids training models from scratch by providing a good initialization from existing related models. (Faster training and development) • Transfer learning helps to enhance the performance on the target task (or domain) by reusing existing knowledge. (Enhance target task performance) • Transfer learning is explored across AI areas like</p><p>computer vision, natural language processing, and speech processing. (Versatile) In conclusion, transfer learning is a powerful learning paradigm in artificial intelligence that has benefits regarding data efficiency, speed, performance, adaptability, and real-world practicality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Transfer Learning vs Other Learning Paradigms</head><p>Along with transfer learning, the other learning paradigms that evolved to address large labelled data requirements are semi-supervised learning <ref type="bibr" target="#b62">[63]</ref> and multitask learning <ref type="bibr" target="#b63">[64]</ref>. Semi-supervised learning is a learning paradigm in artificial intelligence that uses labelled and unlabelled data to train models <ref type="bibr" target="#b62">[63]</ref>. As semi-supervised learning uses labelled and unlabelled data, it lies between unsupervised and supervised learning paradigms. As semi-supervised learning uses only a small amount of labelled data, it reduces the amount of labelled data required, like transfer learning. However, unlike transfer learning, where the distribution of source and target tasks can be different, in semi-supervised, the distribution of labelled and unlabelled data should be the same <ref type="bibr" target="#b57">[58]</ref>. Multi-task learning is a learning paradigm which focuses on enhancing the performance of a group of tasks by leveraging the interconnections between the tasks and learning them simultaneously <ref type="bibr" target="#b62">[63]</ref>. Unlike multi-task learning, which simultaneously learns all the tasks, transfer learning first learns the source task and then transfers the knowledge to the target task. In multitask learning, the focus is generally on all the tasks, while transfer learning focuses more on the target task <ref type="bibr" target="#b60">[61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Self-Supervised Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Why Self-Supervised Learning?</head><p>The main drawback with traditional deep learning models like CNN is the requirement of training from scratch. Training from scratch requires a large amount of labelled data. Data labelling is not only expensive but also a time-consuming and laborious process, which eventually makes the model development expensive. To reduce the requirement of labelled data and make the model development process less expensive, the computer vision research community focused on developing models like VGGNet <ref type="bibr" target="#b16">[17]</ref>, AlexNet <ref type="bibr" target="#b15">[16]</ref> and GoogleNet <ref type="bibr" target="#b17">[18]</ref> on top of large CNNs, transfer learning and supervised learning. These models are pretrained on a large number of labelled images from ImageNet dataset <ref type="bibr" target="#b64">[65]</ref> using supervised learning, and then adapted to downstream Fig. <ref type="figure">3</ref>: Illustration of self-supervised learning paradigm.</p><p>tasks. These pretrained models avoid training downstream models from scratch by providing a good initialization. Moreover, downstream models initialized from pretrained models converge faster and achieve good results even with limited labelled data <ref type="bibr" target="#b59">[60]</ref>.</p><p>Inspired by the huge success of pretrained image models, the NLP research community focused on developing pretrained language models <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b59">[60]</ref>. However, the main challenge here is the use of supervised learning at scale to pretrain language models. This is because supervised learning at scale requires huge volumes of labelled data, which is almost impossible to obtain in many cases because of highly expensive annotation costs. Besides high annotation costs, supervised learning also suffers from generalization errors and spurious correlations <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b21">[22]</ref>. Self-supervised learning with the ability to automatically generate the labels and make use of unlabelled data evolved as an effective alternative to supervised learning to pretrain language models at scale <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">What is Self-Supervised Learning?</head><p>Self-supervised learning, a promising learning paradigm in artificial intelligence, helps models from different modalities like language, speech or image to learn background knowledge from large volumes of unlabeled data <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. Unlike supervised learning, which relies on large volumes of labelled data, self-supervised learning pretrains the models at scale based on the pseudo supervision offered by one or more pretraining tasks. Here, the pseudo supervision stems from the labels, which are automatically generated without human intervention based on the description of the pretraining task. In general, self-supervised learning involves one or more pretraining tasks <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Moreover, the efficiency of selfsupervised learning is heavily influenced by the choice of pretraining task <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>.</p><p>Figure <ref type="figure">3</ref> presents the self-supervised learning paradigm. In the pretraining phase, the labels are automatically generated based on the description of pretraining tasks, and the models learn universal knowledge using the pseudo supervision offered by one or more pretraining tasks. Pretraining helps the models to gain strong background knowledge, which allows the models to provide a good initialization to downstream models. The initialization from pretrained models enhances the downstream models in terms of generalization, performance, and robustness and makes them data efficient. After pretraining, pretrained language models can be easily adapted to downstream tasks with limited labelled data, and large language models can be used to solve downstream tasks using in-context learning without any task-specific fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Evolution of Self-Supervised Learning</head><p>Figure <ref type="figure">4</ref> shows the evolution of self-supervised learning in natural language processing from embedding models to the recent large language models. The evolution of self-supervised learning in natural language processing happened in three stages, namely embedding models, pretrained language models and large language models. Initially, self-supervised learning is explored to develop non-contextual embedding models (e.g. Word2Vec <ref type="bibr" target="#b4">[5]</ref>, FastText <ref type="bibr" target="#b6">[7]</ref>), followed by sentence embedding (e.g. Sent2Vec <ref type="bibr" target="#b65">[66]</ref>) and contextual embedding models (e.g. ELMo <ref type="bibr" target="#b66">[67]</ref>). The quest to develop pretrained models motivated NLP researchers to explore self-supervised learning to develop pretrained language models <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b59">[60]</ref>. As pretrained language models cannot generalize to NLP tasks without fine-tuning, the NLP research community focused on developing large language models using self-supervised learning at a large scale <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b39">[40]</ref>- <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b67">[68]</ref>. To summarize, self-supervised is undergoing a rapid evolution and is also treated as a significant element in achieving near human-level intelligence <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Self-Supervised Learning vs Other Learning Paradigms</head><p>Self-supervised learning, with its exceptional ability to make use of unlabelled data at scale, evolved as an alternative to supervised learning to pretrain models. However, self-supervised learning has similarities and dissimilarities with supervised learning <ref type="bibr" target="#b0">[1]</ref>. Both selfsupervised and supervised provide supervision. How-Fig. <ref type="figure">4</ref>: Evolution of self-supervised learning in natural language processing. ever, unlike supervised learning, which offers supervision based on human-labelled data, self-supervised learning offers supervision based on automatically generated data. Supervised learning is mostly used to train downstream models with task-specific data, while selfsupervised learning is used to train pretrained models to offer good initialization to downstream models. Similarly, self-supervised learning has similarities and dissimilarities with unsupervised learning <ref type="bibr" target="#b0">[1]</ref>. Both selfsupervised learning and unsupervised learning make use of unlabelled data without requiring any labelled data. However, unlike self-supervised learning, which focuses on learning rich data representations using pseudo supervision, the main focus of unsupervised learning is to identify the hidden patterns in the data without any supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Pretrained Language Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Overview</head><p>Deep learning witnessed the evolution of several models, from convolution neural networks to the latest transformers <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b58">[59]</ref>. Transformer addressed drawbacks of traditional deep learning models like convolutional neural network, recurrent neural network and its variants and achieved significant progress <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b68">[69]</ref>. However, transformer and traditional deep learning models suffer from one major drawback: training from scratch, which requires large volumes of labelled data and makes model development expensive. Inspired by the success of pretrained image models like VGGNet <ref type="bibr" target="#b16">[17]</ref>, AlexNet <ref type="bibr" target="#b15">[16]</ref> and GoogleNet <ref type="bibr" target="#b17">[18]</ref> in computer vision, NLP researchers focused on developing pretrained models for natural language processing based on transformers and self-supervised learning <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b69">[70]</ref>. Pretrained language models are advanced deep learning models essentially transformer-based, pretrained on large volumes of text data and can be adapted to downstream tasks with limited labelled data. Along with transformer model, self-supervised learning and transfer learning are key concepts which make pretrained language models possible <ref type="bibr" target="#b0">[1]</ref> (refer Figure <ref type="figure">5</ref>). The era of pretrained language models started with GPT-1 <ref type="bibr" target="#b19">[20]</ref> and BERT <ref type="bibr" target="#b18">[19]</ref> models. The massive success of BERT and GPT-1 models triggered the development of other pretrained language models like RoBERTa <ref type="bibr" target="#b70">[71]</ref>, XLNet <ref type="bibr" target="#b22">[23]</ref>, ELECTRA <ref type="bibr" target="#b23">[24]</ref>, ALBERT <ref type="bibr" target="#b24">[25]</ref>, DeBERTa <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, GPT-2 <ref type="bibr" target="#b27">[28]</ref>, T5 <ref type="bibr" target="#b28">[29]</ref>, BART <ref type="bibr" target="#b29">[30]</ref>, PEGASUS <ref type="bibr" target="#b71">[72]</ref> etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Evolution of Pretrained Language Models</head><p>The evolution of pretrained language models happened along three dimensions: encoder-based models, decoderbased models and encoder-decoder based models <ref type="bibr" target="#b0">[1]</ref>. Encoder-based models consist of an embedding layer and stack of encoder layers, with each encoder layer having self-attention and feed-forward networks. Encoderbased models are primarily used for natural language understanding tasks like text classification, entity extraction, relation extraction, etc. Some of the popular encoder-based pretrained language models are BERT, RoBERTa, XLNet, ALBERT, ELECTRA, DeBERTa, etc. Decoder-based models consist of an embedding layer and a stack of decoder layers, with each decoder layer having self-attention, masked self-attention and feedforward networks. Decoder-based models are used for both natural language understanding and generation tasks. Some of the popular decoder-based pretrained language models are GPT-1, GPT-2 etc. Encoder-decoder based models consist of both encoder and decoder modules. In general, encoder-decoder based models are used for natural language generation tasks like machine translation, text summarization, etc., while some are explored for both natural language understanding and generation tasks. Some of the popular encoder-decoder based models are T5, BART, PEGASUS, M2M100, NLLB, etc.</p><p>After the massive success of pretrained language models in the English language, the research community started to develop multilingual pretrained language models <ref type="bibr" target="#b72">[73]</ref> and pretrained language models for non-English languages <ref type="bibr" target="#b0">[1]</ref>. Some of the popular multilingual pretrained language models are mBERT <ref type="bibr" target="#b18">[19]</ref>, mT5 <ref type="bibr" target="#b73">[74]</ref>, mBART <ref type="bibr" target="#b74">[75]</ref>, IndicBERT <ref type="bibr" target="#b75">[76]</ref>, XLM <ref type="bibr" target="#b76">[77]</ref>, XLM-R <ref type="bibr" target="#b77">[78]</ref>, mDeBERTa <ref type="bibr" target="#b25">[26]</ref> etc. As the performance of general domain pretrained language models is limited in domain-Fig. <ref type="figure">5</ref>: Key ingredients in the evolution and success of pretrained language models. specific tasks <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, the research community focused on developing pretrained language models for specific domains like social media <ref type="bibr" target="#b78">[79]</ref>, <ref type="bibr" target="#b79">[80]</ref>, finance <ref type="bibr" target="#b80">[81]</ref>- <ref type="bibr" target="#b82">[83]</ref>, legal <ref type="bibr" target="#b83">[84]</ref>, <ref type="bibr" target="#b84">[85]</ref>, coding <ref type="bibr" target="#b85">[86]</ref>- <ref type="bibr" target="#b87">[88]</ref>, healthcare <ref type="bibr" target="#b88">[89]</ref>- <ref type="bibr" target="#b90">[91]</ref> etc., As pretrained language models have millions of parameters which make model fine-tuning and deployment expensive, compact pretrained language models like Dis-tilBERT <ref type="bibr" target="#b91">[92]</ref>, TinyBERT <ref type="bibr" target="#b92">[93]</ref>, MobileBERT <ref type="bibr" target="#b93">[94]</ref>, MiniLM <ref type="bibr" target="#b94">[95]</ref>etc., are developed. As pretrained language models have a limited context length which limits the performance on long sequences, long-sequence pretrained language models like LongFormer <ref type="bibr" target="#b95">[96]</ref>, BigBird <ref type="bibr" target="#b96">[97]</ref> etc., are developed. Pretrained language models encode only the universal language knowledge available in the pretraining corpus and lack valuable knowledge available in ontologies. So, the research community developed ontology-enriched models like SapBERT <ref type="bibr" target="#b97">[98]</ref>, UmlsBERT <ref type="bibr" target="#b98">[99]</ref>, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Large Language Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Overview</head><p>The pretrained language models, starting from GPT-1 <ref type="bibr" target="#b19">[20]</ref>, BERT <ref type="bibr" target="#b18">[19]</ref> models to the latest DeBERTa <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, achieved significant progress and also reduced the amount of labelled data required to train the task-specific models <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Pretrained language models follow the paradigm "pretrain then fine-tune", i.e., the model is pretrained first and then adapted to downstream tasks by fine-tuning. As task-specific fine-tuning is mandatory to adapt the pretrained language model to downstream tasks, pretrained language models cannot generalize to unseen downstream tasks without task-specific finetuning. Moreover, task-specific fine-tuning requires labelled data and creates a separate copy of the pretrained language model for each downstream NLP task, increasing the model development and deployment costs <ref type="bibr" target="#b0">[1]</ref>.</p><p>Pretrained language models are treated as narrow AI systems as they are adapted through fine-tuning and then used for specific downstream tasks. However, the main focus of the research community is to develop artificial general intelligence systems <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b99">[100]</ref> which are not narrowly focused on specific tasks but have the ability for general problem-solving and can handle even the unseen tasks by utilizing the existing knowledge like human beings. The NLP researchers observed that the performance of pretrained language models can be enhanced further through scaling along three dimensions: pretraining computation, pretraining data and model size <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b70">[71]</ref>. Large size allows the models to capture more nuanced language patterns, which in turn enhances their ability to understand and generate text, while large pretraining data helps the model to learn from a wider range of text. The promising results from scaling and the quest to build artificial general intelligence systems motivated NLP researchers to build much bigger and bigger models, which eventually resulted in the evolution of GPT-3 and its successor models <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b30">[31]</ref>- <ref type="bibr" target="#b32">[33]</ref>. Learning paradigms like transfer learning and self-supervised learning make large language models possible, but scaling makes these models powerful.</p><p>The research community coined a new phrase, "large language models", to refer to GPT-3 and its successor large models to differentiate these models from small pretrained language models <ref type="bibr" target="#b43">[44]</ref>. Large language models (LLMs) are a special class of pretrained language models obtained by scaling model size, pretraining corpus and computation as showin in Figure <ref type="figure">6</ref>. Large language models (LLMs) are essentially deep learning models, specifically transformer-based, pretrained on large volumes of text data and aligned to human preferences using meta-training. Pretraining provides universal language knowledge to the model <ref type="bibr" target="#b0">[1]</ref>, while meta-training aligns the model to act based on the user's intentions. Here, the user's intention includes explicit intentions, like following instructions, and implicit intentions, like maintaining truthfulness and avoiding bias, toxicity, or harmful behaviour <ref type="bibr" target="#b1">[2]</ref>.</p><p>Because of their large size and pretraining on large volumes of text data, LLMs exhibit special abilities referred to as emerging abilities <ref type="bibr" target="#b100">[101]</ref>, <ref type="bibr" target="#b101">[102]</ref>, allowing them to achieve remarkable performances without any taskspecific training in many natural language processing tasks. For downstream task usage, pretrained language models leverage supervised learning paradigm, which involves task-specific fine-tuning and hundreds or thousands of labelled instances <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>. LLMs leverage incontext learning (ICL), a new learning paradigm that doesn't require task-specific fine-tuning and many la-Fig. <ref type="figure">6</ref>: Key ingredients in the evolution and success of large language models. belled instances <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b44">[45]</ref>. LLMs treat any NLP task as a conditional text generation problem and generate the desired text output by conditioning on the input prompt, including task description, test input and optionally, a few examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Evolution of Large Language Models</head><p>The evolution of large language models happened along two dimensions: closed-source LLMs and open-source LLMs. The era of LLMs roughly started with GPT-3. Following the success of GPT-3, Open AI developed successor models like InstructGPT <ref type="bibr" target="#b1">[2]</ref>, Codex <ref type="bibr" target="#b102">[103]</ref>, Chat-GPT and GPT-4 <ref type="bibr" target="#b41">[42]</ref>. Google introduced models like GLaM <ref type="bibr" target="#b32">[33]</ref>, PaLM <ref type="bibr" target="#b30">[31]</ref>, PaLM2 <ref type="bibr" target="#b67">[68]</ref>, LaMDA <ref type="bibr" target="#b33">[34]</ref> and Bard. DeepMind developed models like Gopher <ref type="bibr" target="#b34">[35]</ref>, Chinchilla <ref type="bibr" target="#b31">[32]</ref>, AlphaCode <ref type="bibr" target="#b103">[104]</ref> and Sparrow <ref type="bibr" target="#b104">[105]</ref>. Companies like Baidu, AI21 labs and Amazon developed the models Ernie 3.0 Titan <ref type="bibr" target="#b105">[106]</ref>, Jurassic-1 <ref type="bibr" target="#b106">[107]</ref> and AlexaTM <ref type="bibr" target="#b107">[108]</ref>, respectively. Although the performances of closed-source LLMs are impressive, the main drawback with these models is that they are behind the paywalls, i.e., their weights are not publicly available, only some of them are accessible only through the APIs offered by the respective companies, and the model usage is charged based on the tokens processed and generated.</p><p>To address this issue, the research community focused on developing open-source LLMs with publicly available weights. Some of the popular open-source LLMs are OPT <ref type="bibr" target="#b38">[39]</ref>, OPT-IML <ref type="bibr" target="#b108">[109]</ref>, Galactica <ref type="bibr" target="#b37">[38]</ref>, LLaMA <ref type="bibr" target="#b39">[40]</ref>, LLaMA2 <ref type="bibr" target="#b40">[41]</ref> and Falcon. The performances of these open-source LLMs are on par with closed-source LLMs. Moreover, in some cases, open-source LLMs outperform closed-source LLMs. For example, Galactica beats closedsource LLMs like GPT-3, Chinchilla and PaLM. Inspired by the success of open-source LLMs in the English language, the research community focused on developing multilingual and bilingual LLMs. BLOOM <ref type="bibr" target="#b36">[37]</ref> and BLOOMZ <ref type="bibr" target="#b109">[110]</ref> are examples of multilingual LLMs, JAIS <ref type="bibr" target="#b110">[111]</ref> (English and Arabic), GLM <ref type="bibr" target="#b111">[112]</ref> (English and Chinese) and FLM-101B <ref type="bibr" target="#b112">[113]</ref> (English and Chinese) are examples of bilingual LLMs.</p><p>The success of closed and open-source LLMs in the general domain triggered the development of domainspecific LLMs like FinGPT <ref type="bibr" target="#b113">[114]</ref> and BloombergGPT <ref type="bibr" target="#b114">[115]</ref> in the finance domain, MedPaLM <ref type="bibr" target="#b115">[116]</ref> and Med-PaLM2 <ref type="bibr" target="#b116">[117]</ref> in the healthcare domain and StarCoder <ref type="bibr" target="#b117">[118]</ref>, CodeLlaMa <ref type="bibr" target="#b118">[119]</ref>, CodeGen <ref type="bibr" target="#b119">[120]</ref> and CodeGen2 <ref type="bibr" target="#b120">[121]</ref> in the coding domains. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GPT-FAMILY LARGE LANGUAGE MODELS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>Open AI, an AI company established in 2015, focused on building generative models. The Open AI researchers initially explored RNNs for developing generative language models <ref type="bibr" target="#b121">[122]</ref>. Inspired by the huge success of the transformer model and its ability to capture long-term dependencies, Open AI researchers leveraged the transformer decoder to build GPT-1 (117M parameters), the first-ever transformer-based pretrained language model <ref type="bibr" target="#b19">[20]</ref>. GPT-1 introduced a new paradigm, "pretrain and fine-tune", to develop downstream task models effectively. Originally, the "pretrain and fine-tune" paradigm was introduced by Dai et al. <ref type="bibr" target="#b122">[123]</ref> and then explored by Howard and Ruder <ref type="bibr" target="#b123">[124]</ref> to build language models for text classification. However, unlike Radford et al. <ref type="bibr" target="#b19">[20]</ref> work, these research works build language models based on LSTM, which lacks parallelization ability and has difficulties in capturing long-term dependencies. Radford et al. <ref type="bibr" target="#b19">[20]</ref> used casual language modeling as a pretraining task to pretrain the GPT-1 model. The casual language modeling pretraining task involves generating the next token based on the previous tokens. GPT-1 achieved SOTA results in 9 out of 12 NLP tasks <ref type="bibr" target="#b19">[20]</ref>. Fig. <ref type="figure">7</ref>: Open AI journey starting from GPT-1 to the latest GPT-4. Fig. <ref type="figure">8</ref>: GPT-3 family large language models (GLLMs) starting from GPT-3 series to the latest GPT-4. Here, SFT stands for supervised fine-tuning, and RLHF stands for reinforcement learning from human feedback. Here, raw represents that the model is just pretrained and is not aligned using SFT or RLHF. Here, RLHF-Chat represents that the model is aligned using RLHF and optimized for chat.</p><p>Inspired by the success of GPT-1, Open AI researchers introduced the GPT-2 model to push the results further <ref type="bibr" target="#b27">[28]</ref>. The GPT-2 model is pretrained on the Web-Text corpus (40B text), which is much larger than the Books corpus used to pretrain the GPT-1 model. The authors developed four versions of the GPT-2 model with varying parameters: 117M, 345M, 762M and 1.5B. The authors observed that the perplexity decreases with an increase in the model's size, and even for the largest version of 1.5B, the decrease in perplexity did not exhibit saturation. This revealed that GPT-2 underfitted the pretraining dataset, and extending the training duration could have further reduced perplexity. This observation triggered the insight that "developing even larger language models will decrease the perplexity further and enhance natural language understanding and generation capabilities". The insights gained from the GPT-1 and GPT-2 models laid a strong foundation for the evolution of the GPT-3 family large language models, including the latest models like ChatGPT and GPT-4. Figure <ref type="figure">7</ref> shows the journey of Open AI starting from GPT-1 to the latest GPT-4 and Figure <ref type="figure">8</ref> shows the GPT-3 family large language models starting from GPT-3 series to the latest GPT-4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">GPT-3 Models</head><p>The experiment results of GPT-2 showed that increasing the model size further reduces the perplexity, and the model with more parameters achieves better results than the models with fewer parameters. This observation motivated Open AI researchers to train much bigger GPT models, which eventually resulted in the introduction of the GPT-3 model <ref type="bibr" target="#b3">[4]</ref>. GPT-3 model contains 175B parameters and is 100 times bigger than its predecessor model, GPT-2. Moreover, the GPT-3 model is trained over a corpus with the text from multiple sources like webpages, Wikipedia and books, unlike GPT-1 and GPT-2 models, which are pretrained over corpora with the text from books and webpages, respectively. Scaling in three dimensions: pretraining data, model size, and pretraining computation allows the GPT-3 model to learn more from large volumes of texts from different sources, which eventually empowers the model to handle unseen tasks without any task-specific training. Unlike GPT-1 and GPT-2 models, which leverage supervised learning to do downstream tasks, GPT-3 leverages training-free in-context learning. In-context learning is a new learning paradigm that is training-free and solves the downstream tasks by using knowledge encoded in the model parameters <ref type="bibr" target="#b44">[45]</ref>. In-context learning accepts prompts as input where the input prompt consists of task descriptions, optimally few examples and other instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">GPT-3.5 Models</head><p>Two main drawbacks of the GPT-3 model are (i) GPT-3 is not trained over code data, and hence, it lacks complex reasoning abilities like solving math problems <ref type="bibr" target="#b43">[44]</ref>, and (ii) GPT-3 model struggles to follow user instructions and sometimes generate harmful text <ref type="bibr" target="#b1">[2]</ref>. These two drawbacks are addressed by GPT-3.5 models. Brown et al. <ref type="bibr" target="#b3">[4]</ref> observed that GPT-3 can generate simple programs, although it is not specifically trained for generating code. The Open AI researchers triggered by this observation introduced Codex <ref type="bibr" target="#b102">[103]</ref>, an exclusive GLLM for coding tasks. Codex is developed by fine-tuning a GPT model with 12B parameters over publicly available Github code. Moreover, it is observed that GPT models explicitly trained over code data exhibit better reasoning capabilities.</p><p>During pretraining, the GPT-3 model is optimized based on the casual language modeling objective, which involves predicting the next word based on the previous words. In-context learning during inference can be viewed as conditional text generation, where the model generates the output by conditioning on the given prompt. The model performs text generation during pretraining and inference, but it does vanilla text generation during pretraining and conditional text generation during inference. During pretraining, the model conditions on the previous words and generates the next word, i.e., vanilla text generation. However, during incontext learning, the model conditions on the prompt and generates the answer rather than generating the next words, i.e., conditional text generation. So, there is a gap between pretraining and in-context learning at inference. Due to this, in many cases during inference, the GPT-3 model fails to understand the given prompt and tends to generate the next words.</p><p>The pretraining corpus of the GPT-3 model includes some amount of text with undesired qualities like misinformation, abuse, hate, sexism, etc., due to which the model sometimes generates harmful text. To enhance complex reasoning ability, the instruction following ability and reduce the harmful text generation, GPT-3.5 models are developed by fine-tuning GPT-3 models over code data and then aligned using supervised fine-tuning (SFT) or reinforcement learning from human feedback (RLHF) <ref type="bibr" target="#b1">[2]</ref>. For example, the text-davinci-002 model is developed by fine-tuning the GPT-3 model (text-davinci) over code data to get code-davinci-002, which is further aligned using SFT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">ChatGPT and GPT-4</head><p>GPT-3 models are capable of understanding and generating natural language, while GPT-3.5 models are capable of understanding and generating both natural language and code. However, both GPT-3 and GPT-3.5 models are not chat optimized. This drawback is addressed by ChatGPT (GPT-3.5-turbo) and GPT-4 <ref type="bibr" target="#b41">[42]</ref> models. Open AI introduced ChatGPT in November 2022. With extraordinary conversational abilities, ChatGPT, ChatGPT has garnered millions of users within a few weeks of its launch. Following ChatGPT, Open AI released the GPT-4 model in March 2023, which can handle both text and image inputs. Apart from generating text with human-like fluency, these models further pushed the results in many natural language processing tasks. The performance of these models in downstream tasks and specific domains is discussed in detail in Sections 4 and 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PERFORMANCE OF GLLMS IN DOWN-STREAM TASKS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Text Classification</head><p>Overview. Text Classification is one of the fundamental tasks in natural language processing <ref type="bibr" target="#b144">[145]</ref>. It involves assigning label(s) from a predefined set of labels to a given piece of text. Here, the piece of text can be a phrase, sentence, paragraph or even a document. Many of the natural language processing problems, like offensive language identification, stance detection, sentiment analysis, hate speech detection, etc., are approached as text classification. Text Classification can be binary, multi-class or multi-label.</p><p>In the case of text classification, the large language model is prompted with a task description, a predefined set of labels, examples (optional) and the test input. Here, task description, a predefined set of labels and examples constitute the context. The model understands what actually the task is from the context and then assigns the most appropriate label(s) to the given test input. The additional inputs, like examples in the context, enrich the prompt with more information which allows the model to understand the task better and then perform better.</p><p>Paper Task(s) GLLMs Explored Prompt Settings Domain(s) Language(s) SOTA Results [125] Stance Detection ChatGPT ZS, FS Social Media English No [126] Stress Detection, Depression Detection , Suicidal Detection ChatGPT ZS Social Media English No [127] Mental Health Analysis Tasks ChatGPT ZS Social Media English No [128] Sentiment Analysis ChatGPT ZS, FS Social Media English, Chinese No [129] Stock Prediction based on Sentiment Analysis ChatGPT ZS Finance English No [130] Computational Social Science Tasks GPT-3, ChatGPT ZS Social Media English No [131] Genre Identification ChatGPT ZS General English, Slovenian No [132] Sentiment Analysis, Misinformation Detection ChatGPT</p><p>Research works exploring GLLMs for text classification. The recent works explored GLLMs like GPT-3, GPT-3.5 ChatGPT and GPT-4 for various text classification problems like sentiment analysis <ref type="bibr" target="#b127">[128]</ref>, <ref type="bibr" target="#b128">[129]</ref>, <ref type="bibr" target="#b131">[132]</ref>, <ref type="bibr" target="#b133">[134]</ref>, <ref type="bibr" target="#b135">[136]</ref>, <ref type="bibr" target="#b141">[142]</ref>, <ref type="bibr" target="#b143">[144]</ref>, stance detection <ref type="bibr" target="#b124">[125]</ref>, intent classification <ref type="bibr" target="#b142">[143]</ref>, mental health analysis <ref type="bibr" target="#b125">[126]</ref>, <ref type="bibr" target="#b126">[127]</ref>, hate speech detection <ref type="bibr" target="#b138">[139]</ref>, <ref type="bibr" target="#b139">[140]</ref>, misinformation detection <ref type="bibr" target="#b131">[132]</ref>, paraphrase detection <ref type="bibr" target="#b133">[134]</ref>, news classification <ref type="bibr" target="#b135">[136]</ref>, natural language inference <ref type="bibr" target="#b133">[134]</ref>, <ref type="bibr" target="#b136">[137]</ref>, <ref type="bibr" target="#b137">[138]</ref>etc. The evaluation is done in zero and few-shot settings using different prompting strategies like chainof-thought (CoT) <ref type="bibr" target="#b124">[125]</ref>, <ref type="bibr" target="#b126">[127]</ref>, <ref type="bibr" target="#b133">[134]</ref>, <ref type="bibr" target="#b136">[137]</ref>, <ref type="bibr" target="#b137">[138]</ref>, <ref type="bibr" target="#b140">[141]</ref>, <ref type="bibr" target="#b143">[144]</ref>, self-question prompting (SQP) <ref type="bibr" target="#b137">[138]</ref>, clue and reasoning prompting (CARP) <ref type="bibr" target="#b143">[144]</ref> etc. Most of the research works focused on English datasets, except a few research works focused on other languages like Chinese <ref type="bibr" target="#b127">[128]</ref>, Slovenian <ref type="bibr" target="#b130">[131]</ref>, Indonesian <ref type="bibr" target="#b131">[132]</ref>, Javanese <ref type="bibr" target="#b131">[132]</ref>, and Buginese <ref type="bibr" target="#b131">[132]</ref>. A brief summary of research works exploring GLLMs for various text classification problems is presented in Table <ref type="table">1</ref>.</p><p>Most of the research works showed that compared to direct prompting, advanced prompting strategies help the model to achieve better results. This is because advanced prompting involves generating intermediate outputs, which in turn guide the model in generating the correct final output. Zhang et al. <ref type="bibr" target="#b124">[125]</ref> explored the ChatGPT model with direct and chain-of-thought prompting for stance detection in tweets in zero and few-shot settings. Experiment results on three datasets showed that one-shot chain of thought prompting outperforms zero-shot direct prompting and also achieves near state-of-the-art results. Yang et al. <ref type="bibr" target="#b126">[127]</ref> designed emotion-enhanced CoT prompting to combine emotion information with the power of CoT prompting for mental health analysis tasks. Experiments on five different mental health analysis tasks showed that ChatGPT with emotion-enhanced CoT outperforms other prompting strategies. Overall, ChatGPT outperforms traditional deep learning models like CNN and RNN but still lags behind task-specific fine-tuned models. Wu et al. <ref type="bibr" target="#b136">[137]</ref> explored models like GPT-4 and ChatGPT for radiology natural language inference task. The authors reported that GPT-4 with IRSA prompting strategy outperforms ChatGPT in both zero and few-shot settings. IRSA stands for Instruction Response Semantic Alignment. IRSA prompting strategy is almost the same as direct prompting except that in the case of IRSA prompting, the model is instructed to give the labels "contain" and "not contain" instead of "entailment" and "not entailment", just to reduce the complexity. Wang et al. <ref type="bibr" target="#b137">[138]</ref> evaluated the performances of the latest LLMs like GPT-3.5, GPT-4, and Bard models on text classification tasks like natural language inference and document classification in the healthcare domain. The GPT-4 model with the newly designed self-question prompting (SQP) outperforms other models in both zero and few-shot settings. The SQP strategy involves identifying the key elements of input, generating questions and answers related to the key elements, and then using them to generate the final output. Parikh et al. <ref type="bibr" target="#b142">[143]</ref> showed that the performance of the GPT-3 model for intent classification in zeroshot settings can be enhanced by including intent class descriptions in the prompt.</p><p>Some of the research works demonstrated that GPT-3 family large language models can outperform taskspecific fine-tuned models <ref type="bibr" target="#b130">[131]</ref>, <ref type="bibr" target="#b133">[134]</ref> and domainspecific LLMs <ref type="bibr" target="#b135">[136]</ref>. Kuzman et al. <ref type="bibr" target="#b130">[131]</ref> showed that ChatGPT outperforms fine-tuned XLM-R model in the task of automatic genre identification in the English language. Zhong et al. <ref type="bibr" target="#b133">[134]</ref> compared the performances of ChatGPT and fine-tuned models based on base and large versions of BERT and RoBERTa models on tasks like natural language inference, sentiment analysis and paraphrase identification. The results showed that Chat-GPT outperforms both base and large fine-tuned models by a large margin in the case of natural language inference task. Li et al. <ref type="bibr" target="#b135">[136]</ref> evaluated the performances of general LLMs like ChatGPT and GPT-4 and domainspecific LLMs like BloombergGPT on tasks like finance news classification and sentiment analysis. In the case of finance news classification, GPT-4 outperforms all other LLMs, including the domain-specific BloombergGPT model. In all the above discussed research works, the performance of GLLMs is impressive but still lags behind SOTA results. Sun et al. <ref type="bibr" target="#b143">[144]</ref> showed that it is possible to achieve SOTA results in text classification tasks with the newly designed clue And reasoning prompting (CARP) prompting strategy. CARP involves a progressive reasoning approach for handling complex linguistic phenomena, and it involves three steps: finding clues based on input, generating reasoning steps based on the input and the generated clues, and then arriving at the final output based on the input, generated clues and reasoning steps. Experiment results showed that the results are impressive as InstructGPT with CARP prompting strategy using just 16 examples achieves SOTA results on four text classification datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Information Extraction</head><p>Overview. Information Extraction (IE) in natural language processing involves extracting structured data like entities, relationships and events from unstructured text data <ref type="bibr" target="#b163">[164]</ref>. Transforming unstructured text data into structured data enables efficient data processing, knowledge discovery, decision making and enhances information retrieval and search. Information extraction involves a number of tasks like entity typing, entity extraction, relation classification, relation extraction, event detection, event argument extraction and event extraction <ref type="bibr" target="#b152">[153]</ref>. Entity typing (ET) involves classifying identified named entity mentions into one of the predefined entity types <ref type="bibr" target="#b164">[165]</ref>. Named Entity Recognition (NER) or Entity Extraction (EE) involves identifying entity mentions and then assigning them to appropriate entity types <ref type="bibr" target="#b165">[166]</ref>. Relation classification (RC) involves identifying the semantic relationship between the given two target entities in a sentence <ref type="bibr" target="#b166">[167]</ref>. Relation Extraction (RE) involves extracting the entities and then classifying the semantic relationship between the two target entities, i.e., involves entity extraction followed by relation classification <ref type="bibr" target="#b167">[168]</ref>. Event Detection (ED) aims to identify and categorize words or phrases that trigger events <ref type="bibr" target="#b168">[169]</ref>. Event Argument Extraction (EAE) involves identifying event arguments, i.e., entities involved in the event and then classifying their roles <ref type="bibr" target="#b169">[170]</ref>. Event Extraction (EE) aims to extract both the events and the involved entities, i.e., it involves event detection followed by event argument extraction <ref type="bibr" target="#b170">[171]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research works expoloring GLLMs for information extraction tasks</head><p>The recent works explored GPT-3 family large language models for various information extraction tasks like entity typing <ref type="bibr" target="#b152">[153]</ref>, entity extraction <ref type="bibr" target="#b135">[136]</ref>, <ref type="bibr" target="#b137">[138]</ref>, <ref type="bibr" target="#b145">[146]</ref>- <ref type="bibr" target="#b148">[149]</ref>, <ref type="bibr" target="#b152">[153]</ref>, <ref type="bibr" target="#b157">[158]</ref>- <ref type="bibr" target="#b159">[160]</ref>, <ref type="bibr" target="#b161">[162]</ref>, relation classification <ref type="bibr" target="#b137">[138]</ref>, <ref type="bibr" target="#b148">[149]</ref>, <ref type="bibr" target="#b152">[153]</ref>- <ref type="bibr" target="#b155">[156]</ref>, <ref type="bibr" target="#b162">[163]</ref>, relation extraction <ref type="bibr" target="#b147">[148]</ref>, <ref type="bibr" target="#b150">[151]</ref>- <ref type="bibr" target="#b152">[153]</ref>, <ref type="bibr" target="#b157">[158]</ref>, <ref type="bibr" target="#b160">[161]</ref>, <ref type="bibr" target="#b161">[162]</ref>, event classification <ref type="bibr" target="#b152">[153]</ref>, event argument extraction <ref type="bibr" target="#b152">[153]</ref> and event extraction <ref type="bibr" target="#b147">[148]</ref>, <ref type="bibr" target="#b149">[150]</ref>, <ref type="bibr" target="#b152">[153]</ref>, <ref type="bibr" target="#b157">[158]</ref>. The evaluation is done in zero and few-shot settings using different prompting strategies like chain-of-thought (CoT) <ref type="bibr" target="#b137">[138]</ref>, <ref type="bibr" target="#b151">[152]</ref>, <ref type="bibr" target="#b155">[156]</ref>, <ref type="bibr" target="#b160">[161]</ref>, self-verification <ref type="bibr" target="#b158">[159]</ref>, self-question prompting (SQP) <ref type="bibr" target="#b137">[138]</ref>, event ranking (ER) <ref type="bibr" target="#b151">[152]</ref> etc. Most of the research works focused on English datasets, except a few research works focused on other languages like Chinese <ref type="bibr" target="#b147">[148]</ref>. A brief summary of research works exploring GLLMs for various information extraction tasks is presented in Table <ref type="table">2</ref>.</p><p>Hu et al. <ref type="bibr" target="#b146">[147]</ref> demonstrated the performance of Chat-GPT in extracting clinical entities like problem, treatment, and test can be enhanced by including additional information about entity types like synonyms and subtypes in the prompt. Wei et al. <ref type="bibr" target="#b147">[148]</ref> proposed ChatIE, a two-stage framework for information extraction, with each stage implemented as a multi-turn question answering. This two-stage framework helps the model break complex IE tasks into sub-tasks which allows the</p><p>Paper Task(s) GLLMs Explored Prompt Settings Domain(s) Language(s) SOTA Results [146] Entity Extraction ChatGPT ZS General English No [147] Entity Extraction GPT-3, ChatGPT ZS Healthcare English No [148] Entity Extraction, Event Extraction, Relation Extraction ChatGPT ZS General English, Chinese No [149] Entity Extraction, Relation Classification GPT-3 FS Healthcare English No [150] Event Extraction ChatGPT FS General English No [151] Protein-Protein Interaction Extraction GPT-3, ChatGPT and GPT-4 ZS Healthcare English No [152] Temporal Relation Extraction ChatGPT ZS General English No [153] Entity Typing, Entity Extraction, Relation Classification, Relation Extraction, Event Detection, Event Argument Extraction, Event Extraction ChatGPT ZS General English No [154] Temporal Relation Classification, Causal Relation Classification, Discourse Relation Classification ChatGPT ZS, FS General English No [155] Relation Classification GPT-3.5 FS General, Scientific Literature English Yes [156] Relation Classification GPT-3.5 FS General, Scientific Literature English Yes [157] Entity Extraction GPT-3.5, ChatGPT ZS General English No [135] Entity Extraction, Relation Extraction GPT-3, GPT-3.5, ChatGPT ZS, FS General, Social Eedia English No [158] Entity Extraction, Relation Extraction and Event Detection InstructGPT FS General English Yes [159] Entity Extraction GPT-3 FS General English No [138] Entity Extraction, Relation Classification GPT-3.5, GPT-4 ZS, FS Healthcare English No [160] Entity Extraction GPT-3 ZS General English No [161] Relation Extraction GPT-3 FS General, Healthcare English No [136] Entity extraction ChatGPT, GPT-4 FS Finance English No [162] Entity Extraction, Relation Extraction GPT-3, Codex FS General, Scientific Literature English No [163] Relation Classification GPT-3.5, ChatGPT ZS General English No TABLE 2. Summary of research works exploring GLLMs for information extraction tasks. Here ZS represents zero-shot, and FS represents few-shot. model to perform better. Results showed that ChatGPT used with the ChatIE framework outperforms vanilla ChatGPT by a large margin of more than 18 points. Gutierrez et al. [149] enhanced the performance of the GPT-3 model for entity extraction and relation classification by using techniques like contextual calibration [172] to reduce bias and kNN-based demonstration selection. Gao et al. [150] examined the performance of ChatGPT for event extraction in few-shot settings. The model is prompted with task descriptions, definitions of event types, positive and negative examples, and test input. The authors reported that including negative examples decreases the performance of the model, which is in line with other existing works [173]. The possible reason for this is that the model misunderstands negative examples as positive examples. Rehana et al. [151] explored GPT-3 family models like GPT-3, ChatGPT and GPT-4 for protein-protein interaction extraction. It is reported that including normalized protein names in the prompt enhances the performance of the model. However, finetuned PubMedBERT model outperforms GPT-4 model with an F1-score of 86.47.</p><p>Yuan et al. <ref type="bibr" target="#b151">[152]</ref> demonstrated that advanced prompting strategies like event ranking and chain-of-thought improve the performance of ChatGPT compared to vanilla prompting in temporal relation extraction. However, ChatGPT lags behind traditional neural networks like LSTM and fine-tuned pre-trained language models, which indicates the toughness of the temporal relation extraction task. Wang et al. <ref type="bibr" target="#b137">[138]</ref> evaluated the performances of the latest LLMs like GPT-3.5, GPT-4, and Bard models on entity extraction and relation classification in the clinical domain. Experiment results showed that GPT-4 with self-question prompting outperforms other LLMs on most of the datasets. Li et al. <ref type="bibr" target="#b161">[162]</ref> compared the performances of both natural language and code LLMs like GPT-3 and Codex using natural language and code style prompts. Experiment results showed that (i) Codex outperforms GPT-3 model and moderately sized fine-tuned models and (ii) Codex model with natural language or code style prompt outperforms GPT-3 model (iii) Code style prompts achieves better results in case of both Codex and GPT-3 models. The possible explanation for this is Codex which is pretrained over large volumes of code, encode structured code information which is useful for IE tasks as IE tasks involve structured outputs. Zhang et al. <ref type="bibr" target="#b162">[163]</ref> proposed the QA4RE framework, which frames relation extraction as a questionanswering problem. In the QA4RE framework, the sentence serves as context, and the relation types serve as options from which the LLMs choose. Experiment results showed that the proposed approach improves the performance of ChatGPT and GPT-3.5 models by a good margin in relation extraction.</p><p>Some of the research works <ref type="bibr" target="#b154">[155]</ref>, <ref type="bibr" target="#b155">[156]</ref>, <ref type="bibr" target="#b157">[158]</ref> demonstrated that GPT-3 family models can achieve SOTA results in information extraction tasks. Wan et al. <ref type="bibr" target="#b155">[156]</ref> achieved SOTA results in relation extraction with the GPT-RE framework. GPT-RE framework overcomes the drawbacks in existing works using entity-aware demonstration retrieval based on fine-tuned model and gold label-induced reasoning. The use of representations from fine-tuned relation model for demonstration selection is more effective as they naturally include entity and relation information. Ma et al. <ref type="bibr" target="#b157">[158]</ref> proposed a "filter then rerank" approach to use both fine-tuned models and LLMs to take advantage of the strengths of both models for few-shot information extraction. Here finetuned model acts as a filter while LLM acts as a re-ranker. The proposed approach achieves SOTA results with an average improvement of over 2 points in the F1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Question Answering</head><p>Overview. Question Answering (QA) is an important natural language processing task which deals with the development of algorithms to understand and interpret user queries in natural language and then deliver accurate responses <ref type="bibr" target="#b173">[174]</ref>, <ref type="bibr" target="#b174">[175]</ref>. The main aim of question answering systems is to enhance human-computer interaction, i.e., QA systems avoid the use of complex commands and allow the user to interact with machines in a more natural way through natural language queries. For example, popular AI assistants like Amazon Alexa 1 , Google Assistant 2 and Apple Siri 3 rely on QA to provide accurate answers to user queries. The option of interaction through natural language queries enhances the reach of technology to a broader audience. QA can be treated as a fine-grained version of information retrieval <ref type="bibr" target="#b175">[176]</ref>, and the demand for QA systems is increasing day by day because of the ability to generate answers which are accurate, relevant and short.</p><p>Research works exploring GLLMs for question answering tasks. The NLP research community explored GLLMs for question answering in various domains like education <ref type="bibr" target="#b176">[177]</ref>, <ref type="bibr" target="#b183">[184]</ref>, news <ref type="bibr" target="#b179">[180]</ref>, healthcare <ref type="bibr" target="#b137">[138]</ref>, <ref type="bibr" target="#b181">[182]</ref>, <ref type="bibr" target="#b182">[183]</ref>, <ref type="bibr" target="#b184">[185]</ref>, <ref type="bibr" target="#b185">[186]</ref>, <ref type="bibr" target="#b189">[190]</ref>, <ref type="bibr" target="#b190">[191]</ref>, <ref type="bibr" target="#b192">[193]</ref>, <ref type="bibr" target="#b194">[195]</ref>, social media <ref type="bibr" target="#b134">[135]</ref>, coding <ref type="bibr" target="#b186">[187]</ref>, legal <ref type="bibr" target="#b187">[188]</ref>, <ref type="bibr" target="#b193">[194]</ref>, finance <ref type="bibr" target="#b135">[136]</ref> and scientific literature <ref type="bibr" target="#b188">[189]</ref>. Most of the research works focused on the English language, except a few research works focusing on languages like Portuguese <ref type="bibr" target="#b176">[177]</ref>, Japanese <ref type="bibr" target="#b190">[191]</ref>, <ref type="bibr" target="#b194">[195]</ref> and Chinese <ref type="bibr" target="#b192">[193]</ref>. As advanced prompting methods allow GLLMs to perform well, some of the research works investigated the effectiveness of advanced prompting strategies like chainof-thought <ref type="bibr" target="#b137">[138]</ref>, <ref type="bibr" target="#b176">[177]</ref>, <ref type="bibr" target="#b177">[178]</ref>, <ref type="bibr" target="#b182">[183]</ref>, <ref type="bibr" target="#b188">[189]</ref>, <ref type="bibr" target="#b194">[195]</ref>, selfquestion prompting <ref type="bibr" target="#b137">[138]</ref>, <ref type="bibr" target="#b192">[193]</ref> and holistically thought <ref type="bibr" target="#b192">[193]</ref> for question answering. Table <ref type="table">3</ref> presents a summary of research works exploring GLLMs for question answering across various domains and languages.</p><p>Zheng et al. <ref type="bibr" target="#b180">[181]</ref> studied the shortcomings of Chat-GPT in answering complex open-domain questions and found errors related to understanding, factual accuracy, specificity, and logical reasoning. They also analyzed the importance of knowledge memorization, recall, and reasoning abilities in addressing these failures. The authors demonstrated that providing the model with external knowledge, cues for knowledge recall, and guidance for logical reasoning can enhance its ability to provide more accurate answers. Samaan et al. <ref type="bibr" target="#b181">[182]</ref> examined the accuracy of ChatGPT in answering questions related to Bariatric surgery. The authors reported that ChatGPT correctly answered 131 questions from 151 questions, i.e., ChatGPT achieves an accuracy of 86.8%. The impressive performance of ChatGPT shows that it can serve as an additional information resource in addition to healthcare professionals and reduce their burden in answering patient questions. Holmes et al. <ref type="bibr" target="#b182">[183]</ref> compared the performances of GLLMs like ChatGPT, GPT-4 with other LLMs like Bard, BLOOMZ and medical physicists in answering related questions to Radiation Oncology Physics. The performance of GPT-4 is very impressive as the model outperforms medical physicists and other LLMs like ChatGPT, Bard and BLOOMZ. The performance of GPT-4 is further enhanced using CoT prompting, i.e., the model is prompted to arrive at the answer after stepby-step reasoning. Nori et al. <ref type="bibr" target="#b184">[185]</ref> performed a comprehensive evaluation of the GPT-4 model on medical question answering in zero and few-shot settings. For evaluation, the authors used six datasets: two related to the United States Medical License Examination (USMLE) exam and four from the MultiMedQA benchmark <ref type="bibr" target="#b115">[116]</ref>. The performance of GPT-4 is very impressive as it outperforms not only general LLM like GPT-3.5 but also medical domain-specific LLM like Med-PaLM <ref type="bibr" target="#b115">[116]</ref>. Moreover, on USMLE exam datasets, GPT-4 model score is 20 points more than the passing score.</p><p>Hamidi et al. <ref type="bibr" target="#b185">[186]</ref> evaluated ChatGPT and Claude Paper Task(s) GLLMs Explored Prompt Settings Domain(s) Language(s) SOTA Results [177] Admission Exam Question Answering GPT-3.5, ChatGPT, GPT-4 ZS, FS Education Brazilian Portuguese No [178] Knowledge-based Complex Question Answering GPT-3, GPT-3.5, ChatGPT ZS General Multiple languages No [179] Knowledge-based Visual Question Answering GPT-3 ZS General English Yes [180] Tabular Question Answering GPT-3 ZS, FS News English No [181] Open Domain Question Answering ChatGPT ZS General English No [182] Bariatric Surgery Question Answering ChatGPT ZS Healthcare English No [183] Radiation Oncology Physics Question Answering ChatGPT, GPT-4 ZS Healthcare English No [184] Computer Science Question Answering ChatGPT ZS Education English No [185] Medical Question Answering GPT-3.5, GPT-4 ZS, FS Healthcare English No [186] Patient-specific Question Answering ChatGPT ZS Healthcare English No [132] Question Answering ChatGPT ZS General English Yes [157] Boolean Question Answering ChatGPT ZS General English No [133] Multiple Choice Question Answering ChatGPT ZS General, Social Media English No [135] Question Answering GPT-3, GPT-3.5, ChatGPT ZS, FS General English No [187] Multiple Choice Code Question Answering GPT-3.5 ZS Coding English No [188] Bar Exam Question Answering GPT-3.5 ZS Legal English No [189] Multi-Document Question Answering GPT-3.5 FS General, Scientific Literature English No [190] Plastic Survey Exam Question Answering ChatGPT ZS Healthcare English No [191] Japanese Medical Exam Question Answering GPT-3.5, GPT-4 FS Healthcare Japanese No [136] Financial Question Answering ChatGPT, GPT-4 ZS Finance English No [138] Medical Question Answering GPT-3.5, GPT4 ZS, FS Healthcare English No [192] Multiple Choice Question Answering GPT-3, Codex, InstructGPT ZS General English No [193] Medical Conversational Question Answering GPT-3, InstructGPT ZS Healthcare English, Chinese No [194] Question Answering GPT-3 ZS Multiple domains including Legal and Health English No [195] Japanese Medical Exam Question Answering GPT-3, ChatGPT, GPT-4 FS Healthcare Japanese No TABLE 3. Summary of research works exploring GLLMs for question answering tasks. Here ZS represents zero-shot, and FS represents few-shot.</p><p>in answering patient-specific medical questions from MIMIC-III clinical notes. Experiment results demonstrated that the performances of both models are promising as these models display significant levels of coherence, accuracy, coverage and relevance in their answers. Li et al. <ref type="bibr" target="#b135">[136]</ref> demonstrated that GPT4 achieves the best results for question answering in the finance domain and outperforms ChatGPT, domain-specific models like BloombergGPT, FinQANet and general LLMs like OPT (66B), and BLOOM (176B). Although the performance of GLLMs is impressive in zero and few-shot settings in multiple choice question answering, these models still lag behind SOTA results. The main reason for this is the use of cloze prompts. In cloze prompts, the model is prompted with only question without answer options, so the model generates the answers just by conditioning on the question. Robinson et al. <ref type="bibr" target="#b191">[192]</ref> proposed a new prompting strategy called multiple choice prompt which prompts the model with question and answer options so that the model generates the answer by conditioning on both question and answer options. Evaluation on 20 datasets showed that multiple-choice prompt helps GLLMs to achieve near SOTA results. Some of the research works explored the effectiveness of GLLMs in answering exam questions from various domains. Nunes et al. <ref type="bibr" target="#b176">[177]</ref> investigated the performances of GLLMs like GPT-3.5, ChatGPT and GPT-4 in answering questions from the Brazilian university admission exam. Here all the questions are in Brazilian Portuguese language. The authors explored different prompting strategies like vanilla (zero-shot and fewshot) and CoT (few-shot). The authors observed that GPT-4 outperforms all other models by a large margin of over 11 points and achieves the best results with CoT prompting in few-shot settings. Joshi et al. <ref type="bibr" target="#b183">[184]</ref> evaluated ChatGPT in answering undergraduate-level computer science exam questions. For the evaluation, the authors gathered (i) questions from various computer science subjects like data structures, operating systems, machine learning and database management systems, (ii) questions from the GATE exam and (iii) programming questions from the Leetcode website. The results showed that ChatGPT is inconsistent in answering the questions, so students are not advised to rely on ChatGPT completely for their assignments and exams. Bommarito et al. <ref type="bibr" target="#b187">[188]</ref> examined the ability of OpenAI's text-davinci-003 (GPT-3.5) model in answering multiple choice questions from the Bar Exam. Interestingly, human participants with extensive education and specialized training achieved a 68% accuracy rate, while the GPT-3.5 model achieved a lower accuracy rate of 50.3%. Gupta et al. <ref type="bibr" target="#b189">[190]</ref> evaluated how effective ChatGPT is in answering questions from plastic surgery inservice training examination. The authors reported that ChatGPT achieves an accuracy of 54.96% by correctly answering 242 questions. Tanaka et al. <ref type="bibr" target="#b190">[191]</ref> evaluated the performances of GLLMs like GPT-3.5 and GPT-4 in answering questions from the Japanese National Medical Licensing Examination (NMLE). Here the input includes sample examples, instructions to translate the question into English, and then summarizing the question before answering. The authors reported that GPT-4 achieves a score better than the minimum passing score, and further analysis showed that the incorrect answers are due to insufficient medical knowledge and insufficient information about the Japanese-specific medical system. Kasai et al. <ref type="bibr" target="#b194">[195]</ref> reported that GPT-4 outperforms other models and passes the Japanese national medical licensing exam in the last six years. Moreover, ChatGPT with English-translated prompts achieves better results than ChatGPT with Japanese prompts. This is because ChatGPT is predominantly trained over the English text corpus.</p><p>Some of the research works explored GLLMs for more challenging tasks in question answering like tabular question answering <ref type="bibr" target="#b179">[180]</ref>, knowledge-based complex question answering <ref type="bibr" target="#b177">[178]</ref>, multiple choice code question answering <ref type="bibr" target="#b186">[187]</ref>, multi-document question answering <ref type="bibr" target="#b188">[189]</ref> and conversational question answering <ref type="bibr" target="#b192">[193]</ref>. Srivastava et al. <ref type="bibr" target="#b179">[180]</ref> evaluated the effectiveness of GPT-3 for question answering on tabular data in zero and few-shot settings. Here the model is prompted with unstructured passage text, tabular data in JSON format, examples (in the case of few-shot) and the question. The authors reported that GPT-3 displayed its ability to successfully locate the table, comprehend its structure, and accurately access the relevant cells or passages of text in order to provide answers to the given questions. Savelka et al. <ref type="bibr" target="#b186">[187]</ref> evaluated the effectiveness of GPT-3.5 models in answering multiple-choice questions (MCQs), particularly those involving code snippets from programming courses. Experiment results showed that MCQs with code snippets have lower success rates compared to those without code, indicating a challenge in answering multiple-choice questions with code snippets. Pereira et al. <ref type="bibr" target="#b188">[189]</ref> presented Visconde, a novel framework based on the GPT-3.5 model to tackle multi-document question answering. Visconde follows a three-step process involving decomposition, retrieval, and aggregation. The decomposition phase uses the GPT-3.5 model in fewshot settings for question simplification, the retrieval stage uses the SOTA model to select the relevant text chunks, and the final aggregation phase uses the GPT-3.5 with few-shot CoT prompting to get the answer. The authors observed that CoT prompting, i.e., generating reasoning steps before generating the final answer, enhances the performance. Weng et al. <ref type="bibr" target="#b192">[193]</ref> enhanced the performance of GLLMs in answering medical conversational questions in English and Chinese using a novel prompt strategy called Holistically Thought (HoT). The HoT prompting strategy involves diffused thinking and focused thinking strategies to generate high-quality responses. Diffused thinking helps to generate various responses through diversified decoding, focused thinking generates a concise medical summary based on the dialogues and the final response is generated based on the dialogues, outputs of diffused thinking and focused thinking.</p><p>Unlike all the above discussed research works where the performances of GLLMs are just satisfactory but not SOTA, some of the research works <ref type="bibr" target="#b131">[132]</ref>, <ref type="bibr" target="#b178">[179]</ref> demonstrated that it is possible to achieve SOTA results for question answering task using GLLMs. For example, Yang et al. <ref type="bibr" target="#b178">[179]</ref> explored GPT-3 model for knowledgebased visual question answering. Knowledge-based visual question answering involves answering questions which require information which is not available in the input images. The authors propose a novel approach which uses GPT-3 as a knowledge source which is implicit and unstructured. Experiment results showed that the proposed approach achieves new SOTA results by outperforming existing approaches with a large margin of over 8 points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Machine Translation</head><p>Overview. Machine Translation (MT), an important task of natural language processing, deals with the development of models which can translate input text from the source language to the target language <ref type="bibr" target="#b208">[209]</ref>- <ref type="bibr" target="#b210">[211]</ref>. MT models receive the input text in the source language, understand the syntax and semantics of the input text and then generate the translation in the target language. So, a good machine translation model should possess strong natural language understanding and generation skills to generate quality translations. evolution of MT systems started with rule-based models followed by statistical and neural models <ref type="bibr" target="#b210">[211]</ref>. Rulebased MT systems are built on top of manually crafted syntactic and grammatical rules. As manually framing rules is heavily laborious and expensive, these systems are later replaced by statistical MT systems. Statistical MT systems use statistical models trained on bilingual data. With the evolution of deep learning models, the research community started to build neural machine translation (NMT) systems with the help of neural models <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b211">[212]</ref>. These neural models are essentially based on the encoder-decoder architecture, where the encoder understands the input sequence and encodes it into a vector, and the decoder, based on the encoder output, generates the output sequence auto-regressively. Some of the recent neural models used for translation are mBART-50 <ref type="bibr" target="#b212">[213]</ref>, M2M100 <ref type="bibr" target="#b213">[214]</ref>, NLLB200 <ref type="bibr" target="#b214">[215]</ref> etc.</p><p>Research works exploring GLLMs for machine translation. In recent times, GLLMs like ChatGPT and GPT-4 demonstrated remarkable performances in both natural language understanding and generation tasks. A good machine translation system requires strong natural language understanding and generation skills. As ChatGPT and GPT-4 possess strong natural language understanding and generation skills, the research community investigated the effectiveness of these models for machine translation across various domains like news <ref type="bibr" target="#b196">[197]</ref>, <ref type="bibr" target="#b198">[199]</ref>- <ref type="bibr" target="#b200">[201]</ref>, healthcare <ref type="bibr" target="#b196">[197]</ref>, <ref type="bibr" target="#b197">[198]</ref>, social media <ref type="bibr" target="#b197">[198]</ref>- <ref type="bibr" target="#b200">[201]</ref>, dialogue <ref type="bibr" target="#b198">[199]</ref>- <ref type="bibr" target="#b200">[201]</ref> and e-commerce <ref type="bibr" target="#b198">[199]</ref>, <ref type="bibr" target="#b199">[200]</ref>. Most of the research works focused on sentencelevel machine translation <ref type="bibr" target="#b131">[132]</ref>, <ref type="bibr" target="#b195">[196]</ref>- <ref type="bibr" target="#b199">[200]</ref>, <ref type="bibr" target="#b201">[202]</ref>, <ref type="bibr" target="#b203">[204]</ref>- <ref type="bibr" target="#b207">[208]</ref>, except a few research works focused on paragraphlevel machine translation <ref type="bibr" target="#b202">[203]</ref>, <ref type="bibr" target="#b203">[204]</ref> and document-level machine translation <ref type="bibr" target="#b198">[199]</ref>, <ref type="bibr" target="#b200">[201]</ref>. As advanced prompting methods allow GLLMs to perform well, some of the research works investigated the effectiveness of advanced prompting strategies like pivot <ref type="bibr" target="#b197">[198]</ref>, chain-of-thought <ref type="bibr" target="#b206">[207]</ref> and multi-aspect prompting and selection <ref type="bibr" target="#b205">[206]</ref>. Table <ref type="table" target="#tab_4">4</ref> presents a summary of research works exploring GLLMs for machine translation across various domains and languages.</p><p>Gu et al. <ref type="bibr" target="#b195">[196]</ref> proposed a novel approach based on ChatGPT to enhance the quality of translation from Japanese to Chinese by effectively handling attribute clauses using a pre-edit scheme. The proposed approach, which integrates the pre-edit scheme with a novel twostep prompting strategy, enhances the translation quality by more than 35%. Peng et al. <ref type="bibr" target="#b196">[197]</ref> explored the impact of temperature, task and domain information on the translation performance of ChatGPT. The authors showed that (i) ChatGPT performance degrades with an increase in temperature, and hence it is recommended to use a lower temperature (recommended is 0). and (ii) including task and domain information in the prompt enhances the performance of ChatGPT consistently for both high and low language translations. Zhu et al. <ref type="bibr" target="#b201">[202]</ref> evaluated the performance of ChatGPT and other LLMs like OPT, BLOOM and XGLM on 102 languages in 202 translation directions. The authors reported that ChatGPT comprehensively outperforms other LLMs but still lags behind neural machine translation models like NLLB in the majority of the translation directions. Further analysis showed three errors, namely hallucination, monotonic translation and off-target translation. Lyu et al. <ref type="bibr" target="#b202">[203]</ref> presented some interesting research directions with respect to using LLMs for machine translation. The presented interesting research directions include stylized machine translation, interactive machine translation and translation memory-based machine translation. Neural machine translation systems just focus on source-target text mapping, which results in a lot of errors. Unlike neural machine translation systems, the human translation process involves intermediate steps to ensure high translation quality. Inspired by the human translation process, He et al. <ref type="bibr" target="#b205">[206]</ref> proposed MAPS, which involves three steps: knowledge mining, knowledge integration and knowledge selection to generate quality translations. Extension evaluation of the WMT22 test set shows that MAPS improves the performance of models like GPT-3.5 and Alpaca and also addresses the hallucination issue by resolving 59% of hallucination errors.</p><p>In all the above discussed research works, the performances of GLLMs are just satisfactory but not on par or beyond the performances of commercial machine translation systems. Some of the research works <ref type="bibr" target="#b197">[198]</ref>- <ref type="bibr" target="#b200">[201]</ref>, <ref type="bibr" target="#b203">[204]</ref>, <ref type="bibr" target="#b204">[205]</ref>, <ref type="bibr" target="#b206">[207]</ref>, <ref type="bibr" target="#b207">[208]</ref> showed that it is possible to outperform commercial machine translation systems using GLLMs. For example, Jiao et al. <ref type="bibr" target="#b197">[198]</ref> investigated the translation capabilities of GLLMs like ChatGPT and GPT-4 and compared the performance with commercial systems like Google Translate, DeepL Translate and Tencent TranSmart. Extensive evaluation of multiple datasets showed that (i) the performance of GLLMs is on par with commercial systems in the case of high resources languages only, and (ii) the translation quality of low-resource languages can be enhanced using a novel pivot prompting strategy, which involves translating into high resource language before translating into the target low resource language. The naive prompts are unable to elicit the translation ability of ChatGPT fully. So, Gao et al. <ref type="bibr" target="#b199">[200]</ref> focused on developing advanced prompting strategies by including additional information like task information, domain information and syntactic information like PoS (parts of speech) tags. The authors showed that ChatGPT, with the proposed advanced prompting strategy, achieves promising results and even outperforms commercial systems like Google Translate and DeepL Translate. Wang et al. <ref type="bibr" target="#b200">[201]</ref> examined the performances of ChatGPT and GPT-4 for document-level machine translation and also compared the results with commercial systems from Google, DeepL and Tencent. The authors reported that GLLMs do well when the sentences in the document are combined and given at once to the model. Moreover, with this prompting strategy, both the GLLMs exhibit better performances than commercial machine translation systems according to human evaluation and also outperform most documentlevel neural machine translation methods in terms of d-BLEU scores. Karpinska et al. <ref type="bibr" target="#b203">[204]</ref> explored the GPT-3.5 model for paragraph-level machine translation. The authors experimented with three different prompting strategies, namely translating sentence by sentence in isolation, translating sentence by sentence in the presence of the rest of the paragraph and translating the entire paragraph at once. After extensive evaluation of 18 language pairs, including English and Japanese, the authors report that translating the entire paragraph at once outperforms other strategies and commercial systems like Google Translate. Raunak et al. <ref type="bibr" target="#b207">[208]</ref> examined the differences between the translations generated by GLLMs like GPT-3.5 and NMT systems like Microsoft Translator. The authors reported that GLLM generated translations are less literal, with better scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Keyphrase Generation</head><p>Overview. Keyphrase generation (KPG) involves generating a set of phrases that capture the main ideas of a document <ref type="bibr" target="#b224">[225]</ref>. The primary advantage of KPG over keyphrase extraction is the ability to generate both extractive and abstractive keyphrases. Keyphrase generation is approached as a sequence-to-sequence generation task <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b225">[226]</ref>, <ref type="bibr" target="#b226">[227]</ref> in the existing works. The current state-of-the-art model for keyphrase generation is, Key-BART <ref type="bibr" target="#b226">[227]</ref>, which is based on BART and trained using the text-to-text generation paradigm. Table <ref type="table" target="#tab_5">5</ref> presents a summary of research works exploring GLLMs for keyphrase generation.</p><p>Research works exploring GLLMs for keyphrase generation. Martinez et al. <ref type="bibr" target="#b215">[216]</ref> performed a comprehensive evaluation of ChatGPT as a keyphrase generator by evaluating its performance on six datasets using six candidate prompts. The authors reported that the results are promising, but ChatGPT struggles in the case of generating absent keyphrases. Song et al. <ref type="bibr" target="#b216">[217]</ref> evaluated ChatGPT on multiple datasets from news and scientific literature domains having both short and long documents. Experiment results showed that ChatGPT outperforms KeyBART <ref type="bibr" target="#b226">[227]</ref>, the SOTA model, on all the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Dialogue Tasks</head><p>Overview. Dialogue tasks in natural language processing (NLP) deal with understanding and generating humanlike conversations between machines and users <ref type="bibr" target="#b227">[228]</ref>. The main objective of these tasks is to enable machines to have conversations with humans in a natural way. These dialogue tasks are essential components of building effective conversational agents, which have a wide range of applications, including customer support TABLE 6. Summary of research works exploring GLLMs for various dialogue tasks. Here ZS represents zero-shot, and FS represents few-shot.</p><p>[228], <ref type="bibr" target="#b228">[229]</ref>.</p><p>Research works exploring GLLMs for dialogue tasks. The research community explored GLLMs like GPT-3, GPT-3.5 and ChatGPT for various dialogue tasks like dialogue summarization <ref type="bibr" target="#b156">[157]</ref>, <ref type="bibr" target="#b219">[220]</ref>, <ref type="bibr" target="#b220">[221]</ref> , dialogue question answering <ref type="bibr" target="#b223">[224]</ref>, emotion dialogue understanding and generation <ref type="bibr" target="#b218">[219]</ref>, dialogue state tracking <ref type="bibr" target="#b217">[218]</ref>, dialogue generation <ref type="bibr" target="#b131">[132]</ref>, and dialogue discourse analysis <ref type="bibr" target="#b222">[223]</ref>. Some of the research works explored LLMs for the evaluation of dialogue tasks <ref type="bibr" target="#b221">[222]</ref>. Most of the research works focused on general domain and English language datasets, except a few research works which focused on the medical domain <ref type="bibr" target="#b219">[220]</ref> and languages like Chinese <ref type="bibr" target="#b222">[223]</ref>, <ref type="bibr" target="#b223">[224]</ref>. Table <ref type="table">6</ref> presents a summary of research works exploring GLLMs for various dialogue tasks.</p><p>Pan et al. <ref type="bibr" target="#b217">[218]</ref> reported that ChatGPT exhibits better performance in dialogue state tracking compared to spoken language understanding. Further, the authors showed that the performance of ChatGPT can be enhanced by (i) using a multi-turn interactive prompt for dialogue state tracking and (ii) providing additional details like slot names, examples and descriptions for slot filling in spoken language understanding. Zhao et al. <ref type="bibr" target="#b218">[219]</ref> explored the emotion dialogue capabilities of ChatGPT by evaluating the model on five different tasks, namely emotion recognition, emotion cause recognition, dialogue act classification (emotion dialogue understanding), empathetic response generation and emotion support generation. It is reported that ChatGPT exhibits better performances in emotion dialogue generation compared to emotion dialogue understanding. Chintagunta et al. <ref type="bibr" target="#b219">[220]</ref> showed that the in-house model trained on GPT-3 generated summaries achieves performances comparable to when trained on human-generated summaries. Further, the in-house model trained on mixed summaries (human-generated and GPT-3 generated) achieves better performances than those trained on either one of the summaries.</p><p>Prodan et al. <ref type="bibr" target="#b220">[221]</ref> proposed a scoring system to choose the best examples for dialogue summarizing using few-shot GPT-3. The proposed scoring system enhances the quality of generated summaries with an 11% reduction in failures. Huynh et al. <ref type="bibr" target="#b221">[222]</ref> studied the impact of various aspects influencing the performance of LLMs as Dialog evaluators. The authors reported that the performance as a dialogue evaluator largely depends on the diversity and relevance of the datasets used for instruction tuning. Fan et al. <ref type="bibr" target="#b222">[223]</ref> investigated the effectiveness of ChatGPT for dialogue discourse analysis by evaluating its performance on three tasks, namely topic segmentation, discourse parsing and discourse relation recognition. ChatGPT's performance is promising in the case of topic segmentation, and CoT prompting enhances the performance. Wang et al. <ref type="bibr" target="#b223">[224]</ref> proposed a novel approach based on explicit CoT prompting and demonstration selection to answer dialogue questions in few-shot settings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Information Retrieval</head><p>Information retrieval (IR) involves accessing and retrieving relevant information from large volumes of data.</p><p>Here, the main objective is to provide users with the most relevant information by matching their queries to the content of documents and ranking them based on relevance <ref type="bibr" target="#b231">[232]</ref>. The process includes indexing, query formulation, search and retrieval, ranking, and presentation. Information retrieval is utilized in a wide range of fields, such as web search engines, digital libraries, e-commerce, healthcare, and scientific research <ref type="bibr" target="#b231">[232]</ref>. It plays a vital role in facilitating efficient and effective access to information in the modern digital era. Table <ref type="table" target="#tab_7">7</ref> presents a summary of research works exploring GLLMs for information retrieval. Sun et al. <ref type="bibr" target="#b229">[230]</ref> explored the effectiveness of GPT-3 family models like GPT-3, GPT-3.5, ChatGPT and GPT-4 for passage re-ranking in information retrieval. The results are promising as GPT-4 outperforms SOTA models like monoT5-3B <ref type="bibr" target="#b232">[233]</ref> on multiple benchmarks. Moreover, the compact model trained on ChatGPTgenerated data demonstrates superior performance compared to the monoT5-3B model when evaluated on the MS MARCO dataset in BEIR <ref type="bibr" target="#b233">[234]</ref> benchmark. The existing approaches for document retrieval employ dual dense encoders, which encode query and document independently, resulting in shallow interaction between query and document <ref type="bibr" target="#b234">[235]</ref>. To overcome this drawback, Ziems et al. <ref type="bibr" target="#b230">[231]</ref> proposed a novel approach which involves generating URLs using LLMs for document retrieval. The authors reported that document retrieval by generating URLs outperforms existing approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Recommendation Systems</head><p>Overview. Recommendation systems aim to reduce information overload and enhance the user experience by making relevant recommendations related to products or content based on user preferences and behaviour <ref type="bibr" target="#b235">[236]</ref>. In recent times, recommendation systems have gained immense popularity and are extensively utilized across a range of fields, such as entertainment, e-commerce, social media etc. For example, popular platforms like YouTube and Netflix use recommendation systems to suggest relevant videos and platforms like Amazon use recommendation systems to suggest relevant products to the user <ref type="bibr" target="#b236">[237]</ref>. The commonly used approaches for recommendation systems are based on collaborative filtering <ref type="bibr" target="#b237">[238]</ref>, content-based <ref type="bibr" target="#b238">[239]</ref> and knowledge-based <ref type="bibr" target="#b239">[240]</ref>. The performance of traditional recommendation systems is limited by a number of issues like cold-start problem, poor generalization across domains and lack of explainability <ref type="bibr" target="#b240">[241]</ref>, <ref type="bibr" target="#b241">[242]</ref>.</p><p>To overcome these drawbacks in traditional recommendation systems, recent works explored GPT-3 family large language models for various tasks in recommendation systems like next item prediction <ref type="bibr" target="#b242">[243]</ref>, rating prediction <ref type="bibr" target="#b240">[241]</ref>, <ref type="bibr" target="#b243">[244]</ref>, top-k predictions <ref type="bibr" target="#b240">[241]</ref>, direct recommendation <ref type="bibr" target="#b244">[245]</ref>, sequence recommendation <ref type="bibr" target="#b244">[245]</ref> and generating explanations <ref type="bibr" target="#b244">[245]</ref>. The evaluation is done in a variety of domains like movies <ref type="bibr" target="#b240">[241]</ref>, <ref type="bibr" target="#b242">[243]</ref>, <ref type="bibr" target="#b245">[246]</ref>- <ref type="bibr" target="#b248">[249]</ref>, news <ref type="bibr" target="#b245">[246]</ref>, books <ref type="bibr" target="#b243">[244]</ref>, <ref type="bibr" target="#b245">[246]</ref>, <ref type="bibr" target="#b246">[247]</ref>, music <ref type="bibr" target="#b245">[246]</ref>, <ref type="bibr" target="#b247">[248]</ref>, social media <ref type="bibr" target="#b249">[250]</ref>, beauty <ref type="bibr" target="#b244">[245]</ref>, and games <ref type="bibr" target="#b248">[249]</ref>. Table <ref type="table" target="#tab_8">8</ref> presents a summary of research works exploring GLLMs for recommendation systems.</p><p>Research works exploring GLLMs for recommendation systems. Wang et al. <ref type="bibr" target="#b242">[243]</ref> proposed a novel prompting strategy called "Next-Item Recommendation (NIR)" to recommend movies using GLLMs. The proposed prompting strategy involves a three-step process to capture the user's preferences, choose representative movies they have watched in the past, and provide a ranked list of ten recommended movies. Dai et al. <ref type="bibr" target="#b245">[246]</ref> reported that ChatGPT outperforms other GLLMs and is more effective with pair-wise and list-wise ranking compared to point-wise ranking. When it comes to balancing cost and performance, ChatGPT with listwise ranking outperforms both point-wise and pair-wise ranking approaches. ChatGPT demonstrates the potential for providing explanations for recommendations and addressing the challenges of the cold start problem. Gao et al. <ref type="bibr" target="#b240">[241]</ref> proposed Chat-REC, which leverages GLLMs to build conversational recommendation systems. The authors reported that Chat-REC performs well in tasks like top-k recommendations and zero-shot rating prediction. Moreover, Chat-REC enhances the conversational recommendation systems by making them more interactive and providing clear explanations.</p><p>Mysore et al. <ref type="bibr" target="#b249">[250]</ref> explored GLLMs like InstructGPT to generate synthetic data, and the experiment results showed that narrative-driven recommendation models trained on augmented datasets outperform LLM baselines and other approaches. Kang et al. <ref type="bibr" target="#b246">[247]</ref> evaluated GLLMs like GPT-3.5 and ChatGPT on user rating prediction in zero and few-shot settings. Based on the experimental findings on datasets from movies and book domains, the authors reported that traditional models that have access to user interaction data perform better  <ref type="bibr" target="#b244">[245]</ref> evaluated the performance of ChatGPT in five recommendation tasks, which include predicting ratings, direct recommendation, sequence recommendation, generating explanations, and summarizing reviews. Based on the evaluation of Amazon beauty datasets, the authors reported that (i) ChatGPT is much better in rating prediction compared to other tasks like direct and sequence recommendation. and (ii) ChatGPT achieves new SOTA results in generating explanations based on human evaluation. Hou et al. <ref type="bibr" target="#b248">[249]</ref> demonstrated that GLLMs possess strong potential for zero-shot ranking tasks, showcasing performance that is comparable to or even superior to traditional recommendation models. Here, the authors designed the prompts in a way that important information like candidate items, sequential interaction history and ranking instruction is included. Zhiyuli <ref type="bibr" target="#b243">[244]</ref> proposed BookGPT, a novel framework which leverages GLLMs like ChatGPT for book recommendation. Specifically, the performance of BookGPT is evaluated on three sub-tasks, namely the book rating task, book summary recommendation task and user rating recommendation task. The performance of BookGPT is promising in all three sub-tasks, and the performance increases with an increase in prompt examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Coding Tasks</head><p>Overview. Software engineering is a discipline which deals with designing, developing, testing, and maintaining software systems <ref type="bibr" target="#b271">[272]</ref>. To create software systems, software engineers use a variety of programming languages, development tools, and technologies. To aid software engineers and enhance their productivity, the research community focused on automating a number of coding tasks like code generation from natural language descriptions, code repair, code explanation gen-eration, code hints generation, code completion, code document generation, test cases generation, code vulnerability detection, code refactoring, etc. The evolution of pre-trained source code models has paved the way for achieving cutting-edge results across coding tasks <ref type="bibr" target="#b454">[455]</ref>. Some of the popular pretrained source code models are CodeBERT <ref type="bibr" target="#b85">[86]</ref>, CodeGPT <ref type="bibr" target="#b272">[273]</ref>, CoTexT <ref type="bibr" target="#b273">[274]</ref>, Graph-CodeBERT <ref type="bibr" target="#b274">[275]</ref>, CodeT5 <ref type="bibr" target="#b86">[87]</ref>, CodeT5+ <ref type="bibr" target="#b87">[88]</ref>, PLBART <ref type="bibr" target="#b275">[276]</ref>, PyCodeGPT <ref type="bibr" target="#b276">[277]</ref> etc. Inspired by the success of GLLMs in NLP tasks, the research community focused on assessing the performances of these models in coding tasks also.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research works exploring GLLMs for various coding tasks.</head><p>The research community explored GLLMs for coding tasks across various languages like Java <ref type="bibr" target="#b250">[251]</ref>, <ref type="bibr" target="#b251">[252]</ref>, <ref type="bibr" target="#b254">[255]</ref>, <ref type="bibr" target="#b259">[260]</ref>, <ref type="bibr" target="#b262">[263]</ref>, <ref type="bibr" target="#b263">[264]</ref>, <ref type="bibr" target="#b265">[266]</ref>, <ref type="bibr" target="#b266">[267]</ref>, <ref type="bibr" target="#b268">[269]</ref>, <ref type="bibr" target="#b269">[270]</ref>, Python <ref type="bibr" target="#b252">[253]</ref>, <ref type="bibr" target="#b253">[254]</ref>, <ref type="bibr" target="#b255">[256]</ref>- <ref type="bibr" target="#b257">[258]</ref>, <ref type="bibr" target="#b259">[260]</ref>, <ref type="bibr" target="#b261">[262]</ref>, <ref type="bibr" target="#b262">[263]</ref>, <ref type="bibr" target="#b264">[265]</ref>, <ref type="bibr" target="#b266">[267]</ref>, <ref type="bibr" target="#b267">[268]</ref>, <ref type="bibr" target="#b270">[271]</ref>, PHP <ref type="bibr" target="#b259">[260]</ref>, GO <ref type="bibr" target="#b259">[260]</ref>, Ruby <ref type="bibr" target="#b259">[260]</ref>, JavaScript <ref type="bibr" target="#b259">[260]</ref>, C <ref type="bibr" target="#b260">[261]</ref>, <ref type="bibr" target="#b267">[268]</ref>, C++ <ref type="bibr" target="#b258">[259]</ref>, <ref type="bibr" target="#b267">[268]</ref>, Julia <ref type="bibr" target="#b267">[268]</ref>, and MATLAB <ref type="bibr" target="#b267">[268]</ref>. Most of the research works focused on Python and Java languages, while a few research works focused on other languages like GO, PHP, GO, Ruby, JavaScript, C, C++, Julia and MATLAB. The assessment is done in zero and few-shot settings using mostly direct prompts. Table <ref type="table">9</ref> presents a summary of research works exploring GLLMs for various coding tasks. Some of the research works <ref type="bibr" target="#b252">[253]</ref>, <ref type="bibr" target="#b256">[257]</ref>, <ref type="bibr" target="#b258">[259]</ref>, <ref type="bibr" target="#b267">[268]</ref>, <ref type="bibr" target="#b268">[269]</ref> explored GLLMs for code generation task. Yeticstiren et al. <ref type="bibr" target="#b252">[253]</ref> compared various AI-assisted code generation tools like ChatGPT, Amazon's Code Whisperer and Github's Copilot on the Human Eval <ref type="bibr" target="#b102">[103]</ref> dataset. ChatGPT outperforms other tools by generating correct code 65.2% of the time, while the other tools generate correct code for a maximum of 46.3% of the time only. The test cases in existing datasets for code generation evaluation are limited in terms of quality and quantity. So, Liu et al. <ref type="bibr" target="#b256">[257]</ref> proposed EvaPlus, a new framework for automatic test case generation using ChatGPT and the traditional mutation approach. The authors use EvaPlus to develop HumanEvalPlus on the top of the HumanEval <ref type="bibr" target="#b102">[103]</ref> dataset. The au-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Paper</head><p>GLLMs Explored Task(s) Prompt Settings Language(s) SOTA Results <ref type="bibr" target="#b250">[251]</ref> ChatGPT few-shot.</p><p>thors reported that HumanEvalPlus can detect a lot of incorrectly generated code that was previously undetected. Nascimento et al. <ref type="bibr" target="#b258">[259]</ref> compared the quality of code generated by ChatGPT and software developers for competitive coding problems on the LeetCode platform using various evaluation metrics. The authors reported that ChatGPT exhibits better performance compared to novice programmers but is outperformed by experienced programmers. Kashefi et al. <ref type="bibr" target="#b267">[268]</ref> explored how effective ChatGPT is for generating code for numerical methods in five different programming languages: C, C++, Python, MATLAB and Julia. The authors observed that the results are promising but have some limitations which require further investigation. Destefanis et al. <ref type="bibr" target="#b268">[269]</ref> assessed the code generation ability of LLMs like Bard and GPT-3.5 by evaluating their performances in generating Java language code given the natural language descriptions. The authors observed that GPT-3.5 outperforms the Bard model by a large margin of more than 37%.</p><p>Some of the research works <ref type="bibr" target="#b262">[263]</ref>, <ref type="bibr" target="#b264">[265]</ref>, <ref type="bibr" target="#b266">[267]</ref>, <ref type="bibr" target="#b270">[271]</ref> explored GLLMs for code repair task. Prenner et al. <ref type="bibr" target="#b262">[263]</ref> explored the Codex model for automatic program repair in Python and Java programming languages. The authors observed that the performance of Codex is comparable to state-of-the-art methods. Moreover, the Codex model is slightly better at fixing errors in Python language compared to Java language. Kang et al. <ref type="bibr" target="#b266">[267]</ref> developed AutoSD, a novel framework for automatic program repair using GLLMs. The authors reported that the evaluation on three standard datasets showed that the proposed framework is on par with the baselines.</p><p>Unit tests generated using traditional approaches suffer from low readability <ref type="bibr" target="#b269">[270]</ref>. To address this drawback, some of the research works <ref type="bibr" target="#b263">[264]</ref>, <ref type="bibr" target="#b269">[270]</ref> explored GLLMs for test case generation. Siddiq et al. <ref type="bibr" target="#b263">[264]</ref> evaluated models like Codex and ChatGPT for unit test generation for Java code. Experiment results showed that Codex performs better with 80% coverage for the HumanEval dataset. However, both models perform poorly in the case of the SF110 benchmark, with less than 2% coverage. Yuan et al. <ref type="bibr" target="#b269">[270]</ref> designed a ChatGPT-based unit test generation framework called "Chat-Tester". The iterative test refiner helps Chat-Tester to generate better unit tests compared to vanilla ChatGPT. In all the above discussed research works, the performance of GLLMs in various coding tasks is promising but still lags behind SOTA results. Some of the research works <ref type="bibr" target="#b250">[251]</ref>, <ref type="bibr" target="#b253">[254]</ref>, <ref type="bibr" target="#b259">[260]</ref>, <ref type="bibr" target="#b261">[262]</ref>, <ref type="bibr" target="#b265">[266]</ref> demonstrated that GLLMs can achieve SOTA results in coding tasks. Xia et al. <ref type="bibr" target="#b250">[251]</ref> proposed ChatRepair, an automatic program repair tool based on ChatGPT. ChatRepair achieves remarkable performance, surpassing all the existing methods. It successfully resolves 114 and 48 bugs on Defects4j 1.2 and 2.0 <ref type="bibr" target="#b277">[278]</ref>, respectively, outperforming the previous best by 15 and 17 bugs, respectively. Khan et al. <ref type="bibr" target="#b259">[260]</ref> explored Codex, GPT-3 family model pretrained on natural and programming languages to automate code documentation generation. The evaluation results on six programming languages showed that Codex, with just one example, outperforms existing approaches by a large margin of 11.2%. Geng et al. <ref type="bibr" target="#b265">[266]</ref> explored Codex for code document generation and demonstrated that fewshot in-context learning with systematic demonstration selection helps the GPT-3 model to achieve new SOTA results on two standard datasets related to Java language.</p><p>Some of the research works <ref type="bibr" target="#b253">[254]</ref>, <ref type="bibr" target="#b254">[255]</ref>, <ref type="bibr" target="#b261">[262]</ref> explored advanced prompting like CoT, brainstorming, differential prompting, etc., for coding tasks. Liu et al. <ref type="bibr" target="#b254">[255]</ref> evaluated the code generation capabilities of ChatGPT by evaluating its performances on text-to-code and codeto-code generation tasks on CodeXGLUE <ref type="bibr" target="#b272">[273]</ref> datasets. The authors observed that advanced prompting strategies like CoT enhance the code generation capabilities of models like ChatGPT. Li et al. <ref type="bibr" target="#b261">[262]</ref> proposed Brainstorm, a new framework for code generation. Brainstorm involves three steps: brainstorming to generate diverse thoughts, thoughts selection to select the best thought using a ranking model and writing code to generate the code based on the problem statement and the best thought. The authors reported that the proposed framework helps ChatGPT to increase its performance by more than 50% and achieve new SOTA results on the Code-Contests <ref type="bibr" target="#b103">[104]</ref> benchmark. Li et al. <ref type="bibr" target="#b253">[254]</ref> showed that directly using ChatGPT to find failure-inducing test cases results in poor performances. So, the authors proposed a new prompting strategy called "Differential Prompting", which enables ChatGPT to achieve new SOTA results on the Quixbugs dataset <ref type="bibr" target="#b278">[279]</ref>. Differential Prompting involves program intention inference followed by two more steps: program generation and differential testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.10">Multimodal AI Tasks</head><p>Overview. Traditional AI systems are designed to handle data from a single modality such as text, image, audio or video. As real-world data is often multimodal, researchers focused on developing multi-modal AI systems which can leverage input data from multiple modalities to generate more accurate results. Multimodal AI systems leverage techniques from different areas of AI, like natural language processing, computer vision, speech processing etc., to process multi-modal input data effectively <ref type="bibr" target="#b279">[280]</ref>, <ref type="bibr" target="#b280">[281]</ref>. Multi-Modal AI systems can perform a variety of understanding and generation tasks like visual question answering <ref type="bibr" target="#b178">[179]</ref>, <ref type="bibr" target="#b281">[282]</ref>- <ref type="bibr" target="#b283">[284]</ref>,</p><p>text-to-image generation <ref type="bibr" target="#b284">[285]</ref>- <ref type="bibr" target="#b286">[287]</ref>, text-to-video generation <ref type="bibr" target="#b287">[288]</ref>, text-to-speech synthesis <ref type="bibr" target="#b288">[289]</ref>, speech-to-text synthesis <ref type="bibr" target="#b288">[289]</ref>, image captioning <ref type="bibr" target="#b289">[290]</ref> etc.</p><p>Research works exploring GLLMs for Multimodal AI tasks. After the huge success of LLMs in natural language generation and understanding tasks, the research community recently explored GPT-3 family models in multi-modal understanding and generation tasks in various combinations like image+language <ref type="bibr" target="#b178">[179]</ref>, <ref type="bibr" target="#b281">[282]</ref>- <ref type="bibr" target="#b286">[287]</ref>, <ref type="bibr" target="#b289">[290]</ref>- <ref type="bibr" target="#b297">[298]</ref>, video+language <ref type="bibr" target="#b287">[288]</ref>, <ref type="bibr" target="#b298">[299]</ref>, au-dio+language <ref type="bibr" target="#b299">[300]</ref>, <ref type="bibr" target="#b300">[301]</ref>. Most of the research works focused on general domain datasets, which some of the research works focused on specific domains like healthcare <ref type="bibr" target="#b289">[290]</ref>, <ref type="bibr" target="#b297">[298]</ref>. Table <ref type="table" target="#tab_9">10</ref> presents a brief summary of research works exploring GLLMs for various multimodal AI tasks.</p><p>Some of the research works developed multi-model AI systems for a specific task like action generation <ref type="bibr" target="#b290">[291]</ref>, knowledge-based visual question answering <ref type="bibr" target="#b178">[179]</ref>, <ref type="bibr" target="#b281">[282]</ref>- <ref type="bibr" target="#b283">[284]</ref>, x-ray report generation <ref type="bibr" target="#b289">[290]</ref>, named entity recognition <ref type="bibr" target="#b293">[294]</ref>, text-to-video generation <ref type="bibr" target="#b287">[288]</ref>, layout generation <ref type="bibr" target="#b295">[296]</ref>, text-to-image generation <ref type="bibr" target="#b286">[287]</ref>. Kalakonda et al. <ref type="bibr" target="#b290">[291]</ref> proposed GPT-3 based plug-and-play framework called Action-GPT for text-based action generation. Here, the authors generated multiple detailed body movement descriptions from the action phrases and then used them to generate actions. Shao et al. <ref type="bibr" target="#b281">[282]</ref> proposed Prophet, which avoids using an external knowledge base by using GPT-3 as an implicit knowledge base and includes vanilla visual question answering to provide answer heuristics to GPT-3. The answer heuristics, along with caption and question information, provide rich task-specific information to the GPT-3 model, which results in much better performances. Ranjit et al. <ref type="bibr" target="#b289">[290]</ref> proposed automatic x-ray report generation based on contrastively pretrained vision-language encoder and GPT-3 family models like GPT-3.5, ChatGPT and GPT-4. The contrastively pretrained encoder is used to encode input x-ray image into image vector embedding based on which the most similar sentences from the radiology report corpus are retrieved. The retrieved similar sentences form the context and allow LLM to generate a quality X-Ray report. Li et al. <ref type="bibr" target="#b293">[294]</ref> proposed PGIM, a two-stage approach which utilizes ChatGPT as an implicit knowledge base for multi-modal NER task. In the first stage, ChatGPT, when prompted with text descriptions of the image, generates the auxiliary knowledge. In the second stage, the downstream model receives the raw text and ChatGPT-generated auxiliary knowledge as input. The authors reported that the proposed approach outperforms existing SOTA approaches based on texttext and text-image paradigms.</p><p>Hong et al. <ref type="bibr" target="#b287">[288]</ref> proposed DirecT2V for text-to-video generation, which leverages GPT-4 model as a framelevel director. Here, the GPT-4 model generates descriptions for each frame based on a single prompt, and then the Text-to-Image model is used to generate frames based on these descriptions. <ref type="bibr">Feng</ref>  LayoutGPT, which leverages LLM and Layout-to-Image models to generate 2D and 3D planning layouts from text descriptions. Zhang et al. <ref type="bibr" target="#b286">[287]</ref> proposed "Control-GPT" based on LLMs and diffusion models for controllable text-to-image generation. Here, GPT-4 generates sketches based on Tikz code based on the text instructions, and then diffusion model generates realistic images with generated sketches and the text instructions as input. Here, the generated sketches help diffusion models to get a better idea about spatial relationships.</p><p>Some of the research works focused on developing multi-model AI systems which can handle multiple tasks <ref type="bibr" target="#b288">[289]</ref>, <ref type="bibr" target="#b291">[292]</ref>, <ref type="bibr" target="#b292">[293]</ref>, <ref type="bibr" target="#b294">[295]</ref>, <ref type="bibr" target="#b298">[299]</ref>, <ref type="bibr" target="#b301">[302]</ref>. As ChatGPT is trained on one data modality i.e., text data, ChatGPT can only handle text inputs and training models from scratch for vision-language tasks, is not a feasible option as it involves huge computation. So, Wu et al. <ref type="bibr" target="#b291">[292]</ref> developed Visual ChatGPT based on ChatGPT and various visual foundation models to handle 22 vision language tasks. Bhattacharya et al. <ref type="bibr" target="#b298">[299]</ref> proposed a novel three-stage approach to handle five video understanding tasks. The proposed approach involves transforming video into text stories and then using this text content for video understanding tasks. Hakimov et al. <ref type="bibr" target="#b294">[295]</ref> explored GPT-3 model for five vision language tasks, including four classifications and one question answering. Here the model is prompted with text description of the input image along with other elements like task instruction and similar examples. Huang et al. <ref type="bibr" target="#b288">[289]</ref> proposed Au-dioGPT, which allows ChatGPT to handle multiple audio understanding and generation tasks with the help of audio foundation models. Some of the research works explored GPT-3 family models for other tasks like data labelling <ref type="bibr" target="#b299">[300]</ref>, generating instructions <ref type="bibr" target="#b300">[301]</ref>, data generation <ref type="bibr" target="#b296">[297]</ref>, prompt editing <ref type="bibr" target="#b285">[286]</ref> and evaluation <ref type="bibr" target="#b284">[285]</ref> while developing multimodal AI systems. Mei et al. <ref type="bibr" target="#b299">[300]</ref> used ChatGPT to rewrite those noisy audio captions and developed Wav-Caps, an audio captions dataset of 400k instances. The authors reported that the models trained on WavCaps datasets achieve new SOTA results. Zhang et al. <ref type="bibr" target="#b300">[301]</ref> developed SpeechGPT and then do cross-modal instruction tuning to enhance its multi-model instruction following ability. Here, the authors use GPT-4 to generate the instructions for diverse tasks. Fan et al. <ref type="bibr" target="#b296">[297]</ref> proposed LaCLIP (Language augmented Contrastive Language-Image Pretraining), an extended version of CLIP which applies data augmentation to both text and image data to ensure that the model gets exposed to diversified texts during training. Here the data augmentation is performed using the open-source LLaMA model in fewshot settings, and the examples for LLaMA ICL are generated using ChatGPT. Zhu et al. <ref type="bibr" target="#b285">[286]</ref> explored GPT-3 and GPT-3.5 models for prompt editing in textto-image generation. The authors observed a potential reduction of 20-30% in the remaining edits required by implementing the prompt edits suggested by GPT-3 family models. Lu et al. <ref type="bibr" target="#b284">[285]</ref> proposed LLMScore, a new metric which can effectively capture both image and object-level compositionality for text-to-image generation evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.11">Machine Learning Tasks</head><p>Overview. Machine learning (ML) is an area of artificial intelligence (AI) that deals with the development of algorithms that can learn from data and make decisions <ref type="bibr" target="#b304">[305]</ref>. Even though machine learning algorithms are successfully used in various real-world applications, creating an effective ML solution for a new task can be difficult due to the numerous design choices involved. In recent times, AutoML has evolved as a solution to reduce the human effort involved in designing ML solutions <ref type="bibr" target="#b306">[307]</ref>. However, AutoML algorithms suffer from various drawbacks <ref type="bibr" target="#b304">[305]</ref>, like (i) the requirement of multiple rounds of trial-and-error, resulting in significant time consumption, (ii) starting the search for a new task from scratch, ignoring past experience gained from the previous tasks and (iii) many AutoML methods lack interpretability because of their black-box nature.</p><p>Research works exploring GLLMs to automate machine learning tasks. Inspired by the success of GLLMs in other tasks, the research community explored GLLMs as an alternative to AutoML to automate machine learning tasks <ref type="bibr" target="#b302">[303]</ref>- <ref type="bibr" target="#b305">[306]</ref>. Table <ref type="table" target="#tab_10">11</ref> presents a summary of research works exploring GLLMs to automate machine learning tasks. Zheng et al. <ref type="bibr" target="#b302">[303]</ref> explored how effective is GPT-4 for neural architecture search, i.e., designing optimal neural network configurations. The proposed approach involves two steps, namely (i) GPT-4 generates the optimal neural architecture based on the given problem statement, (ii) the generated configuration is evaluated, and for further refinement, the evaluation results along with the problem statement are passed to the model. This two-step process is repeated for a certain number of iterations to achieve the optimal configuration. Shen et al. <ref type="bibr" target="#b303">[304]</ref> proposed HuggingGPT to solve AI tasks with the help of GLLMs like ChatGPT and models in AI communities like Hugging Face. HuggingGPT involves four steps, namely task planning, model selection, task execution and response generation. The authors reported that HuggingGPT achieves promising results in solving AI tasks in language, vision and speech.</p><p>Zhang et al. <ref type="bibr" target="#b304">[305]</ref> proposed MLCopilot, which leverages the power of GLLMs to solve machine learning tasks. MLCopilot works in two stages, namely offline and online. The offline stage involves creating an experience pool from which GLLM is used to retrieve relevant knowledge. The online stage involves retrieving relevant examples from the experience pool, and then GLLM generates results based on the task description, relevant examples and knowledge. Zhang et al. <ref type="bibr" target="#b305">[306]</ref> proposed AutoML-GPT, which leverages the advanced GPT-4 GLLM to automatic machine learning tasks and reduces human efforts in building machine learning models. AutoML-GPT involves two stages. The first stage involves composing a prompt paragraph based on the model and data cards. The second stage involves performing the four crucial steps from data processing to training log prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.12">Planning</head><p>Overview. Many important industries, like finance and banking, often involve repetitive sequential tasks. These workflows, despite their significance, are typically not fully automated or formally defined. Recently, due to strong reasoning capabilities, the research community explored GLLMs for planning. Some of the research works <ref type="bibr" target="#b308">[309]</ref>, <ref type="bibr" target="#b310">[311]</ref> directly used LLMs for planning, while some of them <ref type="bibr" target="#b307">[308]</ref>, <ref type="bibr" target="#b309">[310]</ref> explored LLMs for planning extraction, which can then be used by automated systems.</p><p>Research works exploring GLLMs for planning. Table 12 presents a summary of research works exploring GLLMs for planning. Human models are crucial in facilitating human-robot interaction (HRI), as they empower robots to plan their behaviour based on the impact of their actions on individuals. As it is difficult to craft good human labels, Zhang et al. <ref type="bibr" target="#b308">[309]</ref> used the GPT-3.5 model (i) as zero-shot human models and also (ii) for planning in trust-related scenarios. Hu et al. <ref type="bibr" target="#b310">[311]</ref> proposed a novel prompting strategy called "Chain of Symbol" prompting to elicit better the planning abilities of large language models like InstructGPT and ChatGPT. Unlike CoT prompting, which uses natural language descriptions to represent complex environments, CoS prompting uses condensed symbols to represent them in intermediate reasoning steps. The authors reported that CoS prompting outperforms CoT prompting in both performance and efficiency.</p><p>There are usually natural language documents that describe the procedures for the company's employees. Plan extraction methods offer the opportunity to extract structured plans from these natural language descriptions of workflows <ref type="bibr" target="#b92">[93,</ref><ref type="bibr" target="#b94">95]</ref>. These extracted plans can</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Paper</head><p>Task(s) GLLMs Explored Prompt Settings Language(s) <ref type="bibr" target="#b302">[303]</ref> Neural Architecture Search GPT-4 ZS English <ref type="bibr" target="#b303">[304]</ref> Multiple AI tasks in language, speech and vision areas GPT-3.5, ChatGPT, GPT-4 FS English <ref type="bibr" target="#b304">[305]</ref> Machine Learning Tasks GPT-3.5 FS English <ref type="bibr" target="#b305">[306]</ref> Machine Learning Tasks GPT-4 FS English TABLE 12. Summary of research works exploring GLLMs for planning. Here ZS represents zero-shot, and FS represents few-shot.</p><p>then be used by automated systems. Olmo et al. <ref type="bibr" target="#b307">[308]</ref> explored the GPT-3 model for plan extraction in fewshot settings from the natural language descriptions of workflows and showed that GPT-3 model outperforms existing SOTA models in some cases. Xie et al. <ref type="bibr" target="#b309">[310]</ref> explored GPT-3.5 models to extract plans from natural language descriptions. The authors reported that the models are poor planners on their own, which is in line with the existing works <ref type="bibr" target="#b311">[312]</ref>- <ref type="bibr" target="#b313">[314]</ref> and are better at extracting plans from natural language. However, these models are sensitive to prompts and also struggle in the case of tasks involving spatial or numerical reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">PERFORMANCE OF GLLMS IN SPECIFIC DOMAINS</head><p>Apart from the general domain, natural language processing is also explored in specific domains like healthcare, finance, legal, social media, etc. Analyzing domainspecific texts is more challenging because of domainspecific terminology and abbreviations, complex language structures, etc. In domains like healthcare, finance and legal, domain experts use many words and abbreviations that are specific to the domain and not commonly found in general domain texts. In domains like social media, the texts are mostly authored by the general public using informal language and slang words. Moreover, social media texts are noisy, with many misspelt words, emojis, irregular grammar and abbreviations <ref type="bibr" target="#b314">[315]</ref>, <ref type="bibr" target="#b315">[316]</ref>.</p><p>Inspired by the success of pretrained language models like BERT, RoBERTa, ELECTRA, DeBERTa and T5 in the general domain, these models are also explored for domain-specific NLP tasks <ref type="bibr" target="#b0">[1]</ref>. However, the performance of general domain models is limited as these models are pretrained on general domain texts <ref type="bibr" target="#b80">[81]</ref>, <ref type="bibr" target="#b88">[89]</ref>, and fine-tuning alone cannot provide enough domain knowledge <ref type="bibr" target="#b0">[1]</ref>. So, the research community focused on developing domain-specific pretrained language models either by continual pretraining or pretraining from scratch <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Currently, domain-specific pretrained language models achieve state-of-the-art results in most tasks in specific domains like healthcare, finance, legal, social media, etc.</p><p>GPT-3 family large language models achieve impressive performances in most NLP tasks in zero and fewshot settings in the general domain. Surprisingly, these models outperform fine-tuned pretrained language models in some tasks and achieve state-of-the-art results <ref type="bibr" target="#b143">[144]</ref>, <ref type="bibr" target="#b154">[155]</ref>, <ref type="bibr" target="#b155">[156]</ref>, <ref type="bibr" target="#b157">[158]</ref>. Inspired by the massive success of GLLMs in the general domain, the research community explored GLLMs in specific domains to assess how good these models are in domain-specific NLP tasks. Moreover, an extensive evaluation of these models in domain-specific tasks helps to arrive at valuable insights that will guide the research community to improve the performance further and increase the usage of these models in domain-specific NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Healthcare Domain</head><p>The recent works explored GLLMs for a variety of clinical NLP tasks like question answering <ref type="bibr" target="#b116">[117]</ref>, <ref type="bibr" target="#b194">[195]</ref>, <ref type="bibr" target="#b316">[317]</ref>, <ref type="bibr" target="#b319">[320]</ref>, <ref type="bibr" target="#b321">[322]</ref>, <ref type="bibr" target="#b322">[323]</ref>, <ref type="bibr" target="#b325">[326]</ref>, <ref type="bibr" target="#b332">[333]</ref>, <ref type="bibr" target="#b334">[335]</ref>, <ref type="bibr" target="#b336">[337]</ref>, <ref type="bibr" target="#b337">[338]</ref>, <ref type="bibr" target="#b340">[341]</ref>, <ref type="bibr" target="#b341">[342]</ref>, text de-identification <ref type="bibr" target="#b317">[318]</ref>, dialogue summarization <ref type="bibr" target="#b318">[319]</ref>, <ref type="bibr" target="#b327">[328]</ref>, <ref type="bibr" target="#b329">[330]</ref>, named entity recognition <ref type="bibr" target="#b148">[149]</ref>, <ref type="bibr" target="#b320">[321]</ref>, relation extraction <ref type="bibr" target="#b320">[321]</ref>, text classification <ref type="bibr" target="#b137">[138]</ref>, <ref type="bibr" target="#b320">[321]</ref>, <ref type="bibr" target="#b325">[326]</ref>, <ref type="bibr" target="#b334">[335]</ref>, semantic similarity <ref type="bibr" target="#b320">[321]</ref>, <ref type="bibr" target="#b325">[326]</ref>, text simplification <ref type="bibr" target="#b323">[324]</ref>, <ref type="bibr" target="#b326">[327]</ref>, <ref type="bibr" target="#b342">[343]</ref>, relation classification <ref type="bibr" target="#b148">[149]</ref>, <ref type="bibr" target="#b325">[326]</ref>, text summarization <ref type="bibr" target="#b324">[325]</ref>, <ref type="bibr" target="#b330">[331]</ref>, natural language inference <ref type="bibr" target="#b136">[137]</ref>, <ref type="bibr" target="#b137">[138]</ref>, <ref type="bibr" target="#b325">[326]</ref>, <ref type="bibr" target="#b334">[335]</ref>, word sense disambiguation <ref type="bibr" target="#b328">[329]</ref>, biomedical evidence extraction <ref type="bibr" target="#b328">[329]</ref>, coreference resolution <ref type="bibr" target="#b328">[329]</ref>, medical status extraction <ref type="bibr" target="#b328">[329]</ref>, medical attribute extraction <ref type="bibr" target="#b328">[329]</ref>, synonym generation <ref type="bibr" target="#b333">[334]</ref>, clinical decision support <ref type="bibr" target="#b335">[336]</ref>, <ref type="bibr" target="#b339">[340]</ref> and diagnostic lists generation <ref type="bibr" target="#b338">[339]</ref> focused on English datasets, except a few focused on other languages like Japanese <ref type="bibr" target="#b194">[195]</ref>, <ref type="bibr" target="#b321">[322]</ref> and Chinese <ref type="bibr" target="#b322">[323]</ref>, <ref type="bibr" target="#b331">[332]</ref>, <ref type="bibr" target="#b332">[333]</ref>. Table <ref type="table" target="#tab_12">13</ref> presents a summary of research works exploring GLLMs for various NLP tasks in the healthcare domain.</p><p>Lyu et al. <ref type="bibr" target="#b342">[343]</ref> investigated the performance of Chat-GPT and GPT-4 models in the healthcare domain, specif-ically the radiology area, by evaluating their ability to simplify the content in radiology reports. Experiment results showed that (i) GPT-4 performs better than Chat-GPT. and (ii) optimized prompt with detailed instructions improves the performance for both models by a good margin. Antaki et al. <ref type="bibr" target="#b341">[342]</ref> evaluated the effectiveness of ChatGPT in answering Opthalmology questions.</p><p>The test set consists of both easy and moderate-level questions. Experiment results showed that ChatGPT achieves an average accuracy of 49.25%. Specifically, ChatGPT is able to answer the questions with good accuracy in general medicine. However, its performance in specific sub-areas of Opthalmology is worst. Gilson et al. <ref type="bibr" target="#b340">[341]</ref> evaluated GLLMs like GPT-3, GPT-3.5, and ChatGPT model in answering the medical questions in Step 1 and Step 2 exams of USMLE. Experiment results showed that ChatGPT outperforms the other two models by a good margin. Rao et al. <ref type="bibr" target="#b335">[336]</ref> demonstrated that ChatGPT performs better in the final diagnosis than in the initial diagnosis. This is because ChatGPT has access to more clinical data during the final diagnosis than the initial one.</p><p>Carpenter et al. <ref type="bibr" target="#b333">[334]</ref> demonstrated that GPT-3 can be used for the synonym generation for drugs of abuse. The authors query GPT-3 repeatedly for each drug to generate multiple synonyms, which are later filtered. The generated synonyms are then used to build a lexicon that is helpful for pharmacovigilance on social media platforms. Inspired by the success of the GPT-3 model for text summarization in the general domain, Shaib et al. <ref type="bibr" target="#b330">[331]</ref> explored the GPT-3 model for summarizing biomedical documents. Experiment results revealed that (i) GPT-3 performance is promising in the case of single document summarization and (ii) GPT-3 struggles to summarize the content from multiple biomedical documents. Nair et al. <ref type="bibr" target="#b329">[330]</ref> proposed a novel approach called "MEDSUM-ENT", a multi-stage framework for clinical dialogue summarization. The proposed method leverages the GPT-3 model through multiple intermediate calls to extract medical entities from the conversations. In the final step of summarization, the extracted entities, task instructions and in-context examples help the GPT-3 model to generate high-quality summaries. Based on the evaluation of radiology reports simplified by Chat-GPT, Jeblick et al. <ref type="bibr" target="#b326">[327]</ref> reported that ChatGPT-generated simplified radiology reports are not potentially harmful, complete and factually correct. However, further analysis reveals that some simplified reports contain factually incorrect sentences, potentially harmful paragraphs and a lack of essential medical findings.</p><p>Hirosawa et al. <ref type="bibr" target="#b338">[339]</ref> investigated the effectiveness of ChatGPT for clinical diagnosis by evaluating its ability to generate accurate diagnosis lists for clinical vignettes with common chief complaints. Experimental results showed that ChatGPT can generate diagnosis lists with good accuracy. However, the accuracy rate of ChatGPT is still less than the accuracy rate of physicians. Wang et al. <ref type="bibr" target="#b332">[333]</ref> evaluated the performance of the ChatGPT model in answering medical questions in the Chinese language. Here, ChatGPT is prompted with questions in both English and Chinese to avoid language barriers. Experimental results show that the performance of ChatGPT is much lower than the average performance of the medical students. For example, ChatGPT correctly answers 45.8% of questions, while the average answering rate of medical students is 67.9% in 2021.</p><p>Some of the research works demonstrated that domain-specific pretrained language models outperform GLLMs. Hernandez et al. <ref type="bibr" target="#b334">[335]</ref> compared the performance of the GPT-3 model with the performances of general and domain-specific pretrained language models on three healthcare NLP tasks: natural language inference, question answering and text classification. Experiment results showed that domain-specific pretrained language models achieve better results even though they are much smaller than GPT-3. Xu et al. <ref type="bibr" target="#b331">[332]</ref> introduced MedGPTEval, a benchmark to assess large language models in the healthcare domain. An extensive evaluation showed that domain-specific Chinese LLM outperforms general-purpose models like ChatGPT and ERNINE Bot. Singhal et al. <ref type="bibr" target="#b116">[117]</ref> introduced MedPaLM2, a healthcare domain-specific LLM obtained by domainspecific finetuning of the PaLM2 <ref type="bibr" target="#b67">[68]</ref> model. Experiment results showed that MedPaLM2 outperforms fewshot GPT-4 and achieves new state-of-the-art results on the MultiMedQA benchmark. Moradi et al. <ref type="bibr" target="#b325">[326]</ref> investigated the performances of BioBERT and GPT-3 in few-shot settings on five biomedical NLP tasks: text classification, natural language inference, question answering, relation extraction and semantic similarity. The authors observed that BioBERT and GPT-3 models underperform the model fine-tuned using full training data. Moreover, the BioBERT model outperforms GPT-3 in few-shot settings even though the BioBERT model is 514 times smaller than GPT-3.</p><p>Some research works showed that GLLMs can outperform domain-specific pretrained language models. Ma et al. <ref type="bibr" target="#b324">[325]</ref> proposed ImpressionGPT, a novel approach for summarizing radiology reports using ChatGPT. The proposed method involves dynamic prompt construction and iterative optimization to enhance the performance of ChatGPT further. Evaluation on two standard datasets showed that the proposed framework achieves new SOTA results outperforming fine-tuned models like ChestXrayBERT <ref type="bibr" target="#b347">[348]</ref>. Liu et al. <ref type="bibr" target="#b322">[323]</ref> introduced CMExam, a dataset with 60k+ multiple-choice medical questions in the Chinese language and evaluated GLLMs like GPT-3.5 and GPT-4 on answer prediction and answer reasoning tasks. The authors observed that GPT-4 achieves the best results for both tasks, outperforming GPT-3.5 and medical domain-specific Chinese LLMs like Huatuo <ref type="bibr" target="#b351">[352]</ref> and DoctorGLM <ref type="bibr" target="#b348">[349]</ref>. Chen et al. <ref type="bibr" target="#b320">[321]</ref> explored GLLMs like GPT-3.5 and GPT-4 on eight datasets spanning four tasks in zero and few-shot settings. The authors observed that fine-tuned PubMedBERT outperforms both the GLLMs in all the biomedical tasks except question answering. In the case of biomedical question answering, GPT-4 outperforms the fine-tuned PubMedBERT model by a large margin of <ref type="bibr" target="#b16">17</ref> Giorgi et al. <ref type="bibr" target="#b318">[319]</ref> explored models like Longformer Encoder-Decoder (LED) <ref type="bibr" target="#b95">[96]</ref> based on supervised finetuning and GLLMs like GPT-4 based on few-shot ICL for clinical dialogue summarization as a part of MEDIQA-Chat 2023 <ref type="bibr" target="#b349">[350]</ref> shared task. Here, the authors used Instructor <ref type="bibr" target="#b350">[351]</ref> to select the most similar examples for few-shot ICL. Experiment results based on automatic metrics like BERTScore and ROUGE demonstrated that GPT-4 not only outperforms the LED model but also achieves first rank in the shared task. For medical text de-identification, Liu et al. <ref type="bibr" target="#b317">[318]</ref> proposed a novel approach called "DeID-GPT", a two-step approach based on GLLMs. In the first step, HIPAA identifiers are included in the prompt. In the second step, GLLM receives the prompt and the medical record based on which the model generates the de-identified medical record having the personal information masked. The authors observed that GPT-4 outperforms not only ChatGPT but also fine-tuned models based on BERT, RoBERTa and ClinicalBERT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Legal Domain</head><p>The recent works explored GLLMs for a variety of legal NLP tasks like natural language inference <ref type="bibr" target="#b343">[344]</ref>, question answering <ref type="bibr" target="#b187">[188]</ref>, <ref type="bibr" target="#b346">[347]</ref>, <ref type="bibr" target="#b351">[352]</ref>, text generation <ref type="bibr" target="#b344">[345]</ref>, <ref type="bibr" target="#b346">[347]</ref> and text classification <ref type="bibr" target="#b345">[346]</ref>. Table <ref type="table" target="#tab_13">14</ref> presents a summary of research works exploring GLLMs for various NLP tasks in the legal domain. Bommarito et al. <ref type="bibr" target="#b187">[188]</ref> evaluated the performance of the GPT3.5 model in the legal domain by evaluating its ability to answer bar exam questions. The model answers the questions correctly at a rate of 50%, which is 25% more than the random guess baseline. However, the model performance is almost 18% less than the human performance, and overall model performance is below the passing threshold. Nguyen et al. <ref type="bibr" target="#b344">[345]</ref> presented LawGPT 1.0, the first-ever chatbot model based on GPT-3 for the legal domain. The GPT-3 model is pretrained on mostly generic corpus, so it lacks domain-specific knowledge. To add domain-specific knowledge, LawGPT is developed by fine-tuning the GPT-3 model on the law corpus. Experimental results showed that LawGPT 1.0 performs on par with existing legal assistants. Chalkidis et al. <ref type="bibr" target="#b345">[346]</ref> investigated how effective Chat-GPT is for legal text classification by evaluating the model performance on the LexGLUE <ref type="bibr" target="#b359">[360]</ref> benchmark, which consists of seven legal text classification datasets.</p><p>The evaluation is performed in both zero and few-shot settings. Experiment results showed that ChatGPT performs poorly on legal text classification datasets. Choi et al. <ref type="bibr" target="#b346">[347]</ref> demonstrated that the performance of ChatGPT is just above the passing threshold, i.e., equivalent to a C+ grade student. The authors found that advanced prompts like CoT <ref type="bibr" target="#b360">[361]</ref> and Ranking prompts performed worse or the same as simple prompts for multiple-choice questions. For essay writing, the authors used carefully crafted simple prompts by including specific instructions at the end of the prompt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Finance Domain</head><p>The recent works explored GLLMs for a variety of finance NLP tasks like text classification <ref type="bibr" target="#b135">[136]</ref>, <ref type="bibr" target="#b358">[359]</ref>, sentiment analysis <ref type="bibr" target="#b135">[136]</ref>, <ref type="bibr" target="#b351">[352]</ref>, <ref type="bibr" target="#b353">[354]</ref>, <ref type="bibr" target="#b355">[356]</ref>, named entity recognition <ref type="bibr" target="#b135">[136]</ref>, <ref type="bibr" target="#b355">[356]</ref>, question answering <ref type="bibr" target="#b135">[136]</ref>, <ref type="bibr" target="#b356">[357]</ref>, pairwise ranking <ref type="bibr" target="#b354">[355]</ref>, claim detection <ref type="bibr" target="#b355">[356]</ref> and relation extraction <ref type="bibr" target="#b357">[358]</ref>. Table <ref type="table" target="#tab_14">15</ref> presents a summary of research works exploring GLLMs for various NLP tasks in the finance domain.</p><p>Li et al. <ref type="bibr" target="#b135">[136]</ref> compared the performances of general LLMs like ChatGPT and GPT-4 in the finance domain with domain-specific models like BloombergGPT <ref type="bibr" target="#b114">[115]</ref> and small fine-tuned models like FinBERT <ref type="bibr" target="#b81">[82]</ref> and FinQANet <ref type="bibr" target="#b361">[362]</ref>. The evaluation is done on five different datasets related to four financial NLP tasks: news headlines classification, sentiment analysis, entity extraction, and question answering. The ChatGPT and GPT4 models do well in question-answering task but lag behind in tasks requiring domain-specific knowledge like entity extraction and sentiment analysis. Fatouros et al. <ref type="bibr" target="#b352">[353]</ref> evaluated the effectiveness of ChatGPT for financial sentiment analysis by assessing its performance on the forex-related news headlines dataset. Experiment results showed that ChatGPT outperforms the domainspecific FinBERT <ref type="bibr" target="#b82">[83]</ref> model by a large margin of 35% and also exhibits a high correlation with market returns.</p><p>Leippold et al. <ref type="bibr" target="#b353">[354]</ref> explored GPT-3 for financial sentiment analysis and to generate adversarial attacks. Experiment results showed that FinBERT outperforms keyword-based approaches and the few-shot GPT-3 model in financial sentiment analysis. To study the robustness of FinBERT-based and keyword-based approaches, the authors explored GPT-3 to generate adversarial attacks. The main advantage of GPT-3 over existing adversarial attack-generating methods is that the model makes more subtle changes to the instances such that they are not noticeable to humans but still can fool the models. Wiriyathammabhum et al. <ref type="bibr" target="#b354">[355]</ref> explored instruction fine-tuned T5 and GPT-3.5 models to evaluate investments-related social media posts in Chinese. The task involves two subtasks, namely pairwise ranking and unsupervised ranking. Experiment results showed that the few-shot prompted GPT-3.5 model outperforms the instruction fine-tuned T5 model and the few-shot prompted GPT-3.5 model with English-translated social media posts. Shah et al. <ref type="bibr" target="#b355">[356]</ref> compared the performance of Chat-GPT with the performance of fine-tuned pretrained language models for three different financial NLP tasks: claim detection, sentiment analysis and named entity recognition. The authors observed that fine-tuned models outperform ChatGPT, but ChatGPT performs much better than some open-source LLMs. Zhang et al. <ref type="bibr" target="#b356">[357]</ref> introduced FinEval, a new benchmark to evaluate the financial domain of knowledge of LLMs in the Chinese language. FinEval includes 4,661 multiple-choice questions in Chinese language from four different categories spanning 34 academic subjects. Experiment results showed that GPT-4 achieves around 70% accuracy and outperforms all other LLMs, including ChatGPT and Chinese LLMs.</p><p>Rajpoot et al. <ref type="bibr" target="#b357">[358]</ref> assessed the effectiveness of Chat-GPT and GPT-4 for financial relation extraction in fewshot settings. As the choice of examples is crucial in few-shot ICL, the authors explored learning free and learning-based retriever for example selection. The authors observed that GPT-4 outperforms ChatGPT by a decent margin, and the learning-based retriever performs better than the learning-free retriever.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">MULTILINGUAL PERFORMANCE OF GLLMS</head><p>Overview. GLLMs are pretrained over large volumes of text data from multiple languages. For example, the corpus used to pretrain the GPT-3 model includes text from around 90 languages, and the percentage of English text is more than 90% <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b365">[366]</ref>. In the beginning, most of the research focused on assessing the performance of GLLMs on English datasets only. However, it is essential to evaluate these models on datasets from non-English languages, especially low-resource languages, to know how effective GLLMs are for non-English languages, and the insights gained from the comprehensive evaluation help to further improve these models towards non-English languages.</p><p>Research works exploring GLLMs in multilingual settings. Recently, some of the research works focused on evaluating GLLMs across various non-English languages. The evaluation is done on various tasks like parts of speech tagging <ref type="bibr" target="#b362">[363]</ref>, <ref type="bibr" target="#b365">[366]</ref>, named entity recognition <ref type="bibr" target="#b362">[363]</ref>, <ref type="bibr" target="#b369">[370]</ref>, relation extraction <ref type="bibr" target="#b362">[363]</ref>, natural language inference <ref type="bibr" target="#b362">[363]</ref>, <ref type="bibr" target="#b365">[366]</ref>, <ref type="bibr" target="#b369">[370]</ref>, question answering <ref type="bibr" target="#b362">[363]</ref>, <ref type="bibr" target="#b364">[365]</ref>- <ref type="bibr" target="#b366">[367]</ref>, <ref type="bibr" target="#b369">[370]</ref>, text summarization <ref type="bibr" target="#b362">[363]</ref>, <ref type="bibr" target="#b364">[365]</ref>, <ref type="bibr" target="#b365">[366]</ref>, <ref type="bibr" target="#b369">[370]</ref>, commonsense reasoning <ref type="bibr" target="#b362">[363]</ref>, <ref type="bibr" target="#b365">[366]</ref>, grammar error correction <ref type="bibr" target="#b363">[364]</ref>, text generation <ref type="bibr" target="#b364">[365]</ref>, <ref type="bibr" target="#b368">[369]</ref>, paraphrase identification <ref type="bibr" target="#b365">[366]</ref>, sentiment analysis <ref type="bibr" target="#b131">[132]</ref>, <ref type="bibr" target="#b365">[366]</ref>, <ref type="bibr" target="#b369">[370]</ref>, language identification <ref type="bibr" target="#b131">[132]</ref>, machine translation <ref type="bibr" target="#b131">[132]</ref>, <ref type="bibr" target="#b369">[370]</ref>, genre identification <ref type="bibr" target="#b130">[131]</ref>, hate speech detection <ref type="bibr" target="#b367">[368]</ref> and toxicity detection <ref type="bibr" target="#b369">[370]</ref>. Most of the research focused on general domain datasets, except a few focused on other domains like social media <ref type="bibr" target="#b367">[368]</ref>, <ref type="bibr" target="#b369">[370]</ref> and news <ref type="bibr" target="#b369">[370]</ref>. Table <ref type="table" target="#tab_15">16</ref> presents a summary of research works exploring GLLMs for NLP tasks in multilingual settings.</p><p>Bang et al. <ref type="bibr" target="#b131">[132]</ref> presented an extensive multilingual evaluation of ChatGPT across three tasks: sentiment analysis, language identification and machine translation. When compared to English, the performance of ChatGPT degrades in the case of low-resource languages, particularly in the case of languages with non-Latin scripts. Das et al. <ref type="bibr" target="#b367">[368]</ref> assessed the effectiveness of ChatGPT for emoji-based hate speech detection in multilingual settings. The authors reported that ChatGPT exhibits good performance but tends to misclassify abusive content as hate speech for non-English languages in the case of non-protected groups. Moreover, Armengol et al. <ref type="bibr" target="#b364">[365]</ref> reported that the performance of GPT-3 can be improved in the case of low-resource languages with optimized tokenization.</p><p>The focus of existing benchmarks like HELM <ref type="bibr" target="#b370">[371]</ref> and BIG-Bench <ref type="bibr" target="#b371">[372]</ref> is on the English language. So, some of the research works focused on introducing new benchmarks to facilitate a systematic and comprehensive evaluation of the multilingual performance of GLLMs <ref type="bibr" target="#b365">[366]</ref>, <ref type="bibr" target="#b369">[370]</ref>. For example, Ahuja et al. <ref type="bibr" target="#b365">[366]</ref> presented MEGA, a comprehensive evaluation benchmarking having 16 datasets covering 70 languages. Based on the evaluation of GLLMs like GPT-3.5, ChatGPT and GPT-4, the authors reported that GLLMs perform well in the case of languages with Latin scripts, and the performance is worst in the case of low-resource languages with non-Latin scripts across tasks. One of the possible reasons for this is the quality of tokenization. Similarly, Leong et al. <ref type="bibr" target="#b369">[370]</ref> introduced BHASA, a benchmark to evaluate the performance of LLMs in four Southeast Asian languages. The benchmark consists of 20 datasets covering eight NLP tasks. The authors reported that (i) GPT-4 achieves better results compared to ChatGPT, and (ii) overall, the performance on some of the tasks is promising, with a lot of room for improvement in other tasks.</p><p>Some of the existing works demonstrated that using prompts in English improves the performance of GLLMs in the case of non-English languages <ref type="bibr" target="#b130">[131]</ref>, <ref type="bibr" target="#b362">[363]</ref>. For example, Lai et al. <ref type="bibr" target="#b362">[363]</ref> performed a comprehensive evaluation of the multilingual abilities of ChatGPT on seven tasks covering more than 30 languages ranging from high-resource to extremely low-resource languages. The experiment results confirmed the bias of ChatGPT towards the English language, i.e., the performance is better for English compared to other languages and prompts in the English language can enhance the performance for non-English languages. The possible reason for the bias of GLLMs towards the English language is that GLLMs are trained mostly on English text corpus; hence, these models can better understand the prompt if it is in English <ref type="bibr" target="#b130">[131]</ref>.</p><p>Some of the research works investigated how GLLMs exhibit multilingual capabilities <ref type="bibr" target="#b366">[367]</ref> and how effective GLLM-based evaluators are in scaling up evaluation in multilingual settings <ref type="bibr" target="#b368">[369]</ref>. Zhang et al. <ref type="bibr" target="#b366">[367]</ref> proposed a novel back translation prompting approach to systematically study how ChatGPT exhibit multilingual capabilities, although these models are largely pretrained on the English text corpus. The authors demonstrated that ChatGPT does translation in multilingual settings. Moreover, the multilingual performance of GLLMs is good only in the case of tasks which can translated. Hada et al. <ref type="bibr" target="#b368">[369]</ref> assessed the effectiveness of GPT-4 as an evaluator for natural language generation tasks in multilingual settings. The authors reported that GPT-4 tends to favour high scores and should be used carefully.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DATA LABELLING AND DATA AUGMENTA-TION ABILITIES OF GLLMS 7.1 Data Labelling</head><p>Overview. Large language models, specifically GLLMs, have achieved impressive performances in most of the NLP tasks, highlighting the huge potential of these models. However, large model size, high latency, high inference costs, proprietary access (in the case of GLLMs) and confidentiality concerns (in the case of sensitive domains like medical <ref type="bibr" target="#b380">[381]</ref>) have become bottlenecks for the practical use of these models. Because of these bottlenecks, in environments with constrained resources or confidentiality constraints, pretrained language models are preferred over GLLMs as these models are much smaller in size and also more efficient compared to GLLMs <ref type="bibr" target="#b383">[384]</ref>. For example, BERT base and large models contain just 110M and 340M parameters, while the GPT-3 model contains 175B parameters. Moreover, it is reported that GLLMs are trailing the SOTA models, with 4% to 70% lower performance when evaluated across a set of 25 diverse natural language processing tasks <ref type="bibr" target="#b132">[133]</ref>.</p><p>The performance of fine-tuned pretrained language models is largely determined by the quality as well as the quantity of labelled data. Human-annotated data is considered the gold standard <ref type="bibr" target="#b384">[385]</ref>, <ref type="bibr" target="#b385">[386]</ref>, and we have two strategies for this <ref type="bibr" target="#b372">[373]</ref>, <ref type="bibr" target="#b374">[375]</ref>. The first one is using trained expert coders like students and research assistants, and the second one is using crowd workers from online platforms like Amazon Mechanical Turk. Although human-labelled data is considered the gold standard, the human annotation process is expensive, laborious and time-consuming. The second strategy, i.e., using crowd workers, is comparatively less expensive, but there is a growing concern regarding the degrading annotation quality of crowd workers <ref type="bibr" target="#b386">[387]</ref>. Moreover, the annotation quality varies with annotators, and hence it is consistent. To address the challenges associated with the human annotation process, there is a growing interest in the NLP research community to leverage the extraordinary generative abilities of GLLMs to make the data annotation process less expensive, faster and consistent. Similar to the human annotation process, GLLMs are provided with detailed instructions along with some labelled examples to label the data.</p><p>Research exploring GLLMs for data labelling. The research community explored GLLMs for data labelling in a variety of NLP tasks like stance detection <ref type="bibr" target="#b372">[373]</ref>, <ref type="bibr" target="#b375">[376]</ref>, political tweets classification <ref type="bibr" target="#b374">[375]</ref>, sentiment analysis <ref type="bibr" target="#b375">[376]</ref>, <ref type="bibr" target="#b378">[379]</ref>, <ref type="bibr" target="#b379">[380]</ref>, hate speech detection <ref type="bibr" target="#b375">[376]</ref>, <ref type="bibr" target="#b376">[377]</ref>, bot detection <ref type="bibr" target="#b375">[376]</ref>, toxic comments detection <ref type="bibr" target="#b376">[377]</ref>, offensive comments detection <ref type="bibr" target="#b376">[377]</ref>, adverse drug reaction extraction <ref type="bibr" target="#b377">[378]</ref>, text entailment <ref type="bibr" target="#b378">[379]</ref>, topic classification <ref type="bibr" target="#b378">[379]</ref>, text generation <ref type="bibr" target="#b378">[379]</ref>, answer type classification <ref type="bibr" target="#b378">[379]</ref>, question generation <ref type="bibr" target="#b378">[379]</ref>, relation extraction <ref type="bibr" target="#b379">[380]</ref>, named entity recognition <ref type="bibr" target="#b379">[380]</ref>, <ref type="bibr" target="#b380">[381]</ref>, text summarization <ref type="bibr" target="#b381">[382]</ref>, radiology text simplification <ref type="bibr" target="#b323">[324]</ref> etc. Most of the research works focused on English datasets, except a few research works focused on other languages like French <ref type="bibr" target="#b380">[381]</ref>, Spanish <ref type="bibr" target="#b380">[381]</ref>, Italian <ref type="bibr" target="#b380">[381]</ref> and Basque <ref type="bibr" target="#b380">[381]</ref>. Table <ref type="table" target="#tab_16">17</ref> presents a summary of research works exploring GLLMs for data labelling.</p><p>Gu et al. <ref type="bibr" target="#b377">[378]</ref> labelled sentences from PubMed abstracts using the GPT-3.5 model and then fine-tuned the PubMedBERT model for adverse drug reaction extraction. Experiment results showed that (i) PubMedBERT achieves results comparable to the SOTA model and (ii) PubMedBERT outperforms the GPT-3.5 and GPT-4 models by large margins of 6 and 5 points in F1 score, respectively. Based on the evaluation of multiple NLU and NLG tasks, Wang et al. <ref type="bibr" target="#b378">[379]</ref> demonstrated that GPT-3 labelled data can result in a 50 to 96% reduction in labelling expenses. Moreover, pretrained language models fine-tuned on GPT-3 labelled data outperform the few-shot GPT-3 model in both NLU and NLG tasks. Further, the authors proposed an approach based on active learning to make use of both human and GPT-3 labels, which further enhances the performance of the fine-tuned models. Meoni et al. <ref type="bibr" target="#b380">[381]</ref> investigated the effectiveness of GPT-3.5 labelled data and dictionarybased labelled data in fine-tuning pretrained language models to extract clinical entities in multiple languages like English, Spanish, Basque, Italian and French. The authors reported that (i) the performance of GPT-3.5 labelled data is on par with dictionary-based labelled data, and (ii) combining annotations from both approaches further enhances the results. Xu et al. <ref type="bibr" target="#b381">[382]</ref> proposed InhertiSumm, a novel approach for training small text summarization models like ZCode++ <ref type="bibr" target="#b387">[388]</ref> using GPT-3.5 generated summaries. The authors showed that the ZCode++ model with just 390M parameters trained using GPT-3.5 generated summaries performs on par with GPT-3.5 in zero and few-shot settings.</p><p>Zhu et al. <ref type="bibr" target="#b375">[376]</ref> investigated how effective ChatGPT is for labelling data for social computing tasks. Based on the evaluation of five datasets spanning over tasks like stance detection, hate speech detection, bot detection and sentiment analysis, the authors reported that ChatGPT achieves an average accuracy of 60.9. Li et al. <ref type="bibr" target="#b376">[377]</ref> investigated the ability of ChatGPT to label hateful, offensive and toxic comments and compared the performances with MTurk annotations. The authors observed that ChatGPT performance is promising as it is able to label 80% of comments correctly. Moreover, the performance of ChatGPT is more consistent for nonharmful comments than harmful comments.</p><p>Some of the research works <ref type="bibr" target="#b372">[373]</ref>- <ref type="bibr" target="#b374">[375]</ref>, <ref type="bibr" target="#b382">[383]</ref> showed that GLLMs as data annotators can outperform human annotators. Gilardi et al. <ref type="bibr" target="#b372">[373]</ref> investigated the effectiveness of ChatGPT as an annotator in zero-shot settings for four text classification tasks involving tweets and news articles. The authors reported that ChatGPT is more effective than MTurk crowd-workers as (i) Chat-GPT achieves 25 points more than crowd-workers in terms of accuracy, (ii) ChatGPT is approximately 30 times cheaper, and (iii) intercoder agreement of ChatGPT is more than crowd-workers. He et al. <ref type="bibr" target="#b373">[374]</ref> proposed a novel approach called "explain then annotate" to enhance the performance of GLLMs as text data annotators. The proposed approach involves two steps: (i) GLLM generates explanations for the demonstrations and then (ii) annotates the data by leveraging annotation guidelines, demonstrations and explanations through CoT prompting. Evaluation on three binary text classification tasks revealed that GPT-3.5 outperforms crowdworkers on one task and matches the performance of crowd-workers on the other two tasks. Tornberg et al. <ref type="bibr" target="#b374">[375]</ref> demonstrated that zero-shot GPT-4 outperforms human annotators in labelling political English tweets. Further analysis demonstrated that GPT-4 possesses the ability to accurately label tweets that involve logical reasoning from contextual information. Alizadeh et al. <ref type="bibr" target="#b382">[383]</ref> compared the performances of GLLMs like Chat-GPT, open-source LLMs like FLAN <ref type="bibr" target="#b388">[389]</ref> and MTurk annotators in labelling data (tweets and news articles) for five text classification tasks. The authors reported that ChatGPT achieves the best results, outperforming both open-source LLMs and MTurk annotators. One promising observation here is that open-source LLMs outperform MTurk annotators, and the performance is comparable to ChatGPT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Data Augmentation</head><p>Overview. The performance of downstream task-specific models is determined by the quality as well as the quantity of labelled data. Fine-tuning the pretrained language models on a small amount of labelled data will result in overfitting <ref type="bibr" target="#b0">[1]</ref> and, subsequently, poor performances. However, it is not feasible all the time to label a large number of instances as the annotation process is expensive. So, the research community focused on alternative approaches like data augmentation to increase the size of training sets in a relatively inexpensive way <ref type="bibr" target="#b397">[398]</ref>- <ref type="bibr" target="#b401">[402]</ref>. The data augmentation approaches focus on generating additional training instances either by making small changes to the existing instances or creating new instances with a distribution similar to the existing instances.</p><p>Data augmentation is initially explored in the area of computer vision <ref type="bibr" target="#b397">[398]</ref> and then explored in natural language processing <ref type="bibr" target="#b398">[399]</ref>- <ref type="bibr" target="#b401">[402]</ref>. When compared to computer vision, text data augmentation is more challenging because of the discrete nature of text. Data augmentation can be done at character, word and sentence levels. Character-level data augmentation approaches involve random deletion, addition, exchange or insertion of characters <ref type="bibr" target="#b402">[403]</ref>, <ref type="bibr" target="#b403">[404]</ref>. For example, in the case of keyboard augmentation, a random character is replaced with its neighbour based on the QWERTY layout <ref type="bibr" target="#b402">[403]</ref> to character-level data augmentation, word-level data augmentation approaches involve deletion, replacement, exchange or insertion of words at random positions <ref type="bibr" target="#b404">[405]</ref>, <ref type="bibr" target="#b405">[406]</ref>. Sentence-level approaches like back translation and paraphrasing generate augmented instances by rewriting the sentence <ref type="bibr" target="#b406">[407]</ref>, <ref type="bibr" target="#b407">[408]</ref>. Overall, the main drawbacks of existing data augmentation approaches are (i) lack of sufficient diversity in the augmented instances and (ii) often struggle to guarantee the accurate labelling of the augmented data <ref type="bibr" target="#b395">[396]</ref>. To address these drawbacks, the research community focused on leveraging the exceptional generating abilities of GLLMs for data augmentation to ensure sufficient diversity and correct labelling in the augmented data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Paraphrasing</head><p>Research works exploring GLLMs for paraphrasingbased data augmentation. The research community explored GLLMs for paraphrasing in various NLP tasks like intent classification <ref type="bibr" target="#b142">[143]</ref>, <ref type="bibr" target="#b389">[390]</ref>, <ref type="bibr" target="#b396">[397]</ref>, machine translation <ref type="bibr" target="#b390">[391]</ref>, named entity recognition <ref type="bibr" target="#b391">[392]</ref>, question answering <ref type="bibr" target="#b392">[393]</ref>, medical event classification <ref type="bibr" target="#b394">[395]</ref>, medication identification <ref type="bibr" target="#b394">[395]</ref> etc. GLLM-based paraphrasing is explored in multiple domains like general <ref type="bibr" target="#b389">[390]</ref>- <ref type="bibr" target="#b391">[392]</ref>, <ref type="bibr" target="#b393">[394]</ref>, <ref type="bibr" target="#b395">[396]</ref>, <ref type="bibr" target="#b396">[397]</ref>, news <ref type="bibr" target="#b391">[392]</ref>, social media <ref type="bibr" target="#b142">[143]</ref>, <ref type="bibr" target="#b391">[392]</ref> and healthcare <ref type="bibr" target="#b391">[392]</ref>, <ref type="bibr" target="#b392">[393]</ref>, <ref type="bibr" target="#b394">[395]</ref>, <ref type="bibr" target="#b395">[396]</ref>. Table <ref type="table" target="#tab_17">18</ref> presents a summary of research works exploring GLLMs for paraphrasing-based data augmentation. Cegin et al. <ref type="bibr" target="#b389">[390]</ref> compared the quality of paraphrases generated by ChatGPT and crowd workers for intent classification. The authors reported that (i) ChatGPT generates more diversified paraphrases compared to crowd-workers and (ii) the robustness of models finetuned on ChatGPT is comparable to the models finetuned on crowd-workers generated paraphrases. Oh et al. <ref type="bibr" target="#b390">[391]</ref> explored ChatGPT-based data augmentation to generate additional training instances to fine-tune the mBART-50 model <ref type="bibr" target="#b212">[213]</ref> for machine translation involving Korean-German language pairs. Here, the authors explored three different prompting strategies, out of which the storytelling prompting approach achieves the best results and improves the BLUE score by 0.68. Here, the storytelling prompting approach involves generating a three-sentence story based on the source sentence and then translating each of these sentences into the target language. Abaskohi et al. <ref type="bibr" target="#b393">[394]</ref> proposed a novel approach based on prompt-based tuning and contrastive learning to fine-tune pretrained language models for text classification. As contrastive learning requires data augmentation, the authors explored models like GPT-3 and OPT-175B <ref type="bibr" target="#b38">[39]</ref> for paraphrasing. Experiment results showed that GPT-3 based paraphrasing outperforms existing data augmentation approaches like back translation <ref type="bibr" target="#b426">[427]</ref> and easy data augmentation <ref type="bibr" target="#b404">[405]</ref>.</p><p>To overcome the problem of limited training instances for EHR analysis, sarker et al. <ref type="bibr" target="#b394">[395]</ref> explored Chat-GPT to generate additional training instances through paraphrasing. Experiments on medication event classification and medical identification tasks revealed that fine-tuning the pretrained language models on ChatGPT augmented training set enhances the performance. Dai et al. <ref type="bibr" target="#b395">[396]</ref> proposed AugGPT, a ChatGPT-based approach to generate additional training instances by paraphrasing existing training instances for few-shot classification. Experiments on general and medical domain text classification datasets revealed that AugGPT outperforms all the existing data augmentation approaches by a good margin. Further analysis showed that AugGPT generates more diversified instances while preserving the original labels.</p><p>Paraphrasing-based data augmentation for entity extraction is challenging because of the difficulty in preserving span-level labels. Sharma et al. <ref type="bibr" target="#b391">[392]</ref> explored GPT-3 models, back translation and PEGASUS-based paraphraser for synthetic data generation using paraphrasing. The authors observed that the larger GPT-3 variant with inline annotations achieves the best results for entity extraction across datasets from multiple domains. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Paper</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Data Generation</head><p>Research works exploring GLLMs for data generationbased data augmentation. The research community explored GLLMs for data generation-based data augmentation in various NLP tasks like dialogue generation <ref type="bibr" target="#b409">[410]</ref>, training smaller LLMs <ref type="bibr" target="#b410">[411]</ref>, <ref type="bibr" target="#b415">[416]</ref>, common sense reasoning <ref type="bibr" target="#b411">[412]</ref>, hate speech detection <ref type="bibr" target="#b412">[413]</ref>, undesired content detection <ref type="bibr" target="#b413">[414]</ref>, question answering <ref type="bibr" target="#b414">[415]</ref>, <ref type="bibr" target="#b424">[425]</ref>, intent classification <ref type="bibr" target="#b142">[143]</ref>, relation extraction <ref type="bibr" target="#b154">[155]</ref>, <ref type="bibr" target="#b421">[422]</ref>, instruction tuning <ref type="bibr" target="#b416">[417]</ref>, <ref type="bibr" target="#b417">[418]</ref>, paraphrase detection <ref type="bibr" target="#b419">[420]</ref>, tweet intimacy prediction <ref type="bibr" target="#b420">[421]</ref>, named entity recognition <ref type="bibr" target="#b421">[422]</ref>, machine translation <ref type="bibr" target="#b423">[424]</ref> etc. GLLM-based data generation for data augmentation is explored in multiple domains like general <ref type="bibr" target="#b142">[143]</ref>, <ref type="bibr" target="#b154">[155]</ref>, <ref type="bibr" target="#b411">[412]</ref>, <ref type="bibr" target="#b415">[416]</ref>- <ref type="bibr" target="#b417">[418]</ref>, <ref type="bibr" target="#b419">[420]</ref>, <ref type="bibr" target="#b423">[424]</ref>- <ref type="bibr" target="#b425">[426]</ref>, social media <ref type="bibr" target="#b408">[409]</ref>, <ref type="bibr" target="#b412">[413]</ref>, <ref type="bibr" target="#b413">[414]</ref>, <ref type="bibr" target="#b420">[421]</ref>, <ref type="bibr" target="#b422">[423]</ref>, news <ref type="bibr" target="#b422">[423]</ref>, scientific literature <ref type="bibr" target="#b154">[155]</ref>, <ref type="bibr" target="#b419">[420]</ref>, healthcare <ref type="bibr" target="#b409">[410]</ref>, <ref type="bibr" target="#b414">[415]</ref>, <ref type="bibr" target="#b421">[422]</ref>, dialogue <ref type="bibr" target="#b418">[419]</ref>, programming <ref type="bibr" target="#b410">[411]</ref> etc. Table <ref type="table" target="#tab_18">19</ref> presents a summary of research works exploring GLLMs for data generationbased data augmentation. Some of the research works explored GLLMs for data generation-based data augmentation in various text classification tasks <ref type="bibr" target="#b142">[143]</ref>, <ref type="bibr" target="#b408">[409]</ref>, <ref type="bibr" target="#b412">[413]</ref>, <ref type="bibr" target="#b413">[414]</ref>, <ref type="bibr" target="#b420">[421]</ref>, <ref type="bibr" target="#b422">[423]</ref>. For example, Hartvigsen et al. <ref type="bibr" target="#b412">[413]</ref> used GPT-3 with demonstration-based prompting to create a large-scale synthetic dataset for the detection of implicit hate speech. Here, the authors explored a variant of constrained beam search to ensure subtle toxicity in the generated examples. Michail et al. <ref type="bibr" target="#b420">[421]</ref> investigated the effectiveness of ChatGPT-generated synthetic data to fine-tune multilingual models for tweet intimacy prediction in the case of languages with no labelled instances. Here, ChatGPT is prompted with instructions and examples from a high-resource language and asked to generate new examples in the target language. Most of the existing research works use simple prompts for data generation, limiting the diversity of the generated synthetic data. To address this, Yu et al. <ref type="bibr" target="#b422">[423]</ref> proposed a novel approach that leverages attributed prompts for data generation to increase the diversity in the generated data. Based on the evaluation on four topic classification datasets, the authors observed that (i) the proposed approach enhances the model performance and (ii) reduces the querying cost of ChatGPT by a large margin. Some of the research works explored GLLMs for data generation-based data augmentation in various information extraction tasks like relation extraction <ref type="bibr" target="#b154">[155]</ref>, relation classification <ref type="bibr" target="#b421">[422]</ref> and named entity recognition <ref type="bibr" target="#b421">[422]</ref>. Xu et al. <ref type="bibr" target="#b154">[155]</ref> evaluated how effective is the GPT-3.5 model for relation classification. To address the data scarcity problem in few-shot settings, the authors used the GPT-3.5 model to generate additional data. The prompt used for data generation consists of instance descriptions along with some example instances. Tang et al. <ref type="bibr" target="#b421">[422]</ref> used ChatGPT in zero-shot settings to generate synthetic data for tasks like named entity recognition and relation classification in the healthcare domain. The authors showed that the model fine-tuned on this synthetic data outperforms zero-shot ChatGPT by a large margin in both tasks.</p><p>Some of the research works explored GLLMs for data generation in LLM development stages, like LLM pretraining <ref type="bibr" target="#b410">[411]</ref>, <ref type="bibr" target="#b415">[416]</ref> and instruction tuning <ref type="bibr" target="#b416">[417]</ref>, <ref type="bibr" target="#b417">[418]</ref>. Gunasekar et al. <ref type="bibr" target="#b410">[411]</ref> trained Phi-1, a code LLM using GPT-3.5 generated synthetic textbook and code data. Here, the training corpus includes 1B tokens of GPT-3.5 generated Python textbook and code data along with 6B tokens of code data from the web. Eldan et al. <ref type="bibr" target="#b415">[416]</ref> explored GLLMs like GPT-3.5 and GPT-4 models to generate TinyStories, a synthetic dataset of stories with only the words understood by typical 3 to 4-year-old kids. The authors demonstrated that the GLLM generated dataset can be used to train smaller LLMs, which can generate coherent and consistent stories with near-perfect grammar. Instruction tuning requires large human-annotated datasets, which are often difficult to obtain. Stanford Alpaca <ref type="foot" target="#foot_0">4</ref> and Vicuna <ref type="foot" target="#foot_1">5</ref> showed the effectiveness of synthetic instruction tuning datasets generated using GPT-3.5 and ChatGPT, respectively. Inspired by the success of these models, Peng et al. <ref type="bibr" target="#b417">[418]</ref> explored advanced models like GPT-4 to generate instruction-tuning datasets in English and Chinese languages. The experiment results showed that GPT-4 generated instruction tuning datasets further enhance the zero-shot performance of LLaMA models. Liu et al. <ref type="bibr" target="#b416">[417]</ref> used GPT-4 to generate LogiCoT, a synthetic dataset of CoT rationales. This dataset can be used for instruction tuning the LLMs to enhance their logical reasoning abilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">DETECTING GLLM GENERATED TEXT</head><p>Overview. GLLMs demonstrated extraordinary humanlike capabilities to understand user queries, follow the instructions and then answer the user queries with highquality content. Apart from responding to user queries, these models can also generate news articles, research papers, code and essays with human-like fluency. With the ability to generate text with human-like fluency, these models are widely adopted in a variety of real-world applications like writing assistants, coding assistants, chatbots, etc <ref type="bibr" target="#b427">[428]</ref>. Although there is a lot of excitement about GLLMs and their applications in recent times, there are also growing concerns regarding the potential misuse of these models for illegal activities <ref type="bibr" target="#b428">[429]</ref>, such as fake news on social media platforms <ref type="bibr" target="#b429">[430]</ref>, <ref type="bibr" target="#b430">[431]</ref>, fake reviews on e-commerce websites <ref type="bibr" target="#b431">[432]</ref>, fake research papers <ref type="bibr" target="#b432">[433]</ref>, academic fraud <ref type="bibr" target="#b433">[434]</ref>, etc. For example, these models can be easily used by malicious users to create fake news <ref type="bibr" target="#b429">[430]</ref>, <ref type="bibr" target="#b430">[431]</ref> and propagate on social platforms at a large scale to exaggerate or manipulate the facts to get an undue advantage, especially during political campaigns. Similarly, students can use these models to write their assignments or generate code for their projects <ref type="bibr" target="#b433">[434]</ref>, and GLLM generated fake research papers <ref type="bibr" target="#b432">[433]</ref> can have a serious impact on the scientific community as these papers are written without conducting any experiments.</p><p>There is a strong need for the development of approaches to detect GLLM generated text, as there are growing concerns regarding the misuse of GLLMs. Such approaches help to distinguish the GLLM generated text from human-generated text and verify the source as well as the authenticity of the information. However, detecting GLLM generated text is more challenging as models like ChatGPT and GPT-4 can generate content with human-like fluency.</p><p>Research exploring the detection of GLLM generated text. To avoid misuse and ensure the safe use of these models, the research community focused on developing approaches to identify the GLLM generated text accurately. The recent research works explored the detection of GLLM generated text in multiple domains like scientific literature <ref type="bibr" target="#b434">[435]</ref>- <ref type="bibr" target="#b437">[438]</ref>, academic <ref type="bibr" target="#b438">[439]</ref>, <ref type="bibr" target="#b439">[440]</ref>, healthcare <ref type="bibr" target="#b437">[438]</ref>, <ref type="bibr" target="#b440">[441]</ref>, <ref type="bibr" target="#b441">[442]</ref>, news <ref type="bibr" target="#b442">[443]</ref>, legal <ref type="bibr" target="#b428">[429]</ref>, <ref type="bibr" target="#b441">[442]</ref>, social media <ref type="bibr" target="#b431">[432]</ref>, <ref type="bibr" target="#b437">[438]</ref>, Finance <ref type="bibr" target="#b428">[429]</ref> etc. Most of the research works focused on the English language, while a few research works focused on other languages like Japanese <ref type="bibr" target="#b435">[436]</ref>, German <ref type="bibr" target="#b437">[438]</ref> and Spanish <ref type="bibr" target="#b439">[440]</ref>. Table <ref type="table" target="#tab_19">20</ref> presents a summary of research works exploring the detection of GLLM generated text.</p><p>Some of the research works focused on assessing the effectiveness of the existing machine-generated text detection tools to detect GLLM generated text. A number of online tools are available, ranging from simple classifiers based on logistic regression to advanced classifiers based on pretrained language models to detect ChatGPT-generated text. To assess the effectiveness of these tools, Pegoraro et al. <ref type="bibr" target="#b443">[444]</ref> introduced a dataset having ChatGPT-generated responses for questions from various domains like finance, medicine, etc., and usergenerated responses from social media platforms. The comprehensive evaluation showed that the maximum success rate of these tools is less than 50% only, which leaves a lot of room for improvement. Orenstrakh et al. <ref type="bibr" target="#b439">[440]</ref> evaluated the effectiveness of eight popular detectors using three metrics, namely resilience, false positives and accuracy. The authors observed that Copy-Leaks, GPTKit and GLTR achieve the best results for the metrics accuracy, false positives and resilience. However, all these detectors struggle with non-English languages and paraphrased LLM-generated text. There is a lack of comprehensive evaluation benchmark to detect machinegenerated text as the existing approaches use different models, datasets and settings. To address this, He et al. [447] proposed MGTBench, the first machine-generated text detection benchmark. Evaluation on this benchmark showed that, except for the ChatGPT detector <ref type="bibr" target="#b428">[429]</ref> and LM detector <ref type="bibr" target="#b452">[453]</ref>, the performance of other detectors is not satisfactory. Guo et al. <ref type="bibr" target="#b428">[429]</ref> introduced the HC3 dataset, having human-authored and ChatGPT-generated responses to questions from multiple domains like legal, healthcare, finance, psychology, etc. The performance of existing detection approaches on the HC3 dataset is just satisfactory, and linguistic analysis showed that human-authored answers are short in length but use a large vocabulary compared to ChatGPT-generated answers. Some of the research works focused on developing approaches based on trained classifier models to detect GLLM generated text. Theocharopoulos et al. <ref type="bibr" target="#b434">[435]</ref> evaluated the effectiveness of classifiers based on models like logistic regression, support vector machine, LSTM, and BERT to identify GPT-3 generated scientific abstracts. The LSTM-based classifier with word2vec embeddings achieves an accuracy of more than 98% and outperforms other classifiers. Zaitsu et al. <ref type="bibr" target="#b435">[436]</ref> observed that LLM-generated texts differ significantly from human-written texts in terms of stylometric features. The authors demonstrated that random forest trained with different stylometric features can identify the LLMgenerated Japanese text with 100% accuracy. Liu et al. <ref type="bibr" target="#b438">[439]</ref> reported that fine-tuned RoBERTa model achieves an accuracy of more than 90% on the AruGPT dataset of human-written and GLLM generated argumentative essays. Moreover, linguistic analysis revealed that GLLM generated texts tend to be more complex syntactically, while human-generated texts are lexically more complex. To facilitate the development of a ChatGPT-written abstract detector, Yu et al. <ref type="bibr" target="#b436">[437]</ref> introduced CHEAT, a large dataset of ChatGPT and human-written abstracts. Based on the evaluation of multiple existing approaches like ZeroGPT, OpenAI detector, ChatGPTdetector-roberta <ref type="bibr" target="#b428">[429]</ref> and ChatGPT-qa-detector-roberta <ref type="bibr" target="#b428">[429]</ref>, the authors reported that performance is away from satisfactory and the human involvement further increases the detection difficulty. Zhan et al. <ref type="bibr" target="#b441">[442]</ref> treated the detection of LLM generated as a binary classification problem and proposed a novel approach based on finetuned RoBERTa model. The authors reported that the proposed approach exhibits good performance and also has the ability to detect the text generated using a detection evasion technique. Mitrovic et al. <ref type="bibr" target="#b431">[432]</ref> proposed a novel approach based on DistilBERT <ref type="bibr" target="#b91">[92]</ref> and SHAP <ref type="bibr" target="#b453">[454]</ref> to detect the machine-generated text and explain the reasoning. The proposed approach achieves an accuracy of 79%, and based on the explanations, the authors observed that ChatGPT-generated text maintains a polite tone, lacks specific details and generally refrains from expressing emotions.</p><p>Chen et al. <ref type="bibr" target="#b448">[449]</ref> introduced OpenGPTText, which includes ChatGPT-generated paraphrased text. The authors reported that fine-tuned classifiers based on models like RoBERTa and T5 can achieve impressive results in detecting ChatGPT-generated text with an accuracy of more than 97%. Yu et al. <ref type="bibr" target="#b449">[450]</ref> introduced GPT-Pat, a novel approach based on ChatGPT, a Siamese network and binary classifier, to detect machine-generated text effectively. The proposed approach enhances the SOTA accuracy by more than 12% and also exhibits better robustness to attacks like re-translation and text polishing. Yang et al. <ref type="bibr" target="#b450">[451]</ref> focused on detecting GLLM-polished text, which is more challenging and useful in real-world applications. The proposed approach involves training a classification model to identify the machine-generated text and a polish ratio (regression) model to explain the ChatGPT involvement. A Polish ratio of 0.2 indicates ChatGPT involvement and a value of more than 0.6 represents the text is entirely ChatGPT generated.</p><p>Training-based approaches to detect LLM-generated text have limited flexibility, especially when used for new domains <ref type="bibr" target="#b437">[438]</ref>. To overcome this drawback, some of the research works focused on developing trainingfree approaches to detect GLLM generated text. Yang et al. <ref type="bibr" target="#b437">[438]</ref> proposed DNA-GPT, a training-free approach based on divergent n-gram analysis. With the proposed approach, the authors achieved SOTA results on both English and German datasets. Wang et al. <ref type="bibr" target="#b447">[448]</ref> proposed a novel framework called FLAIR to detect LLM-based bots with a single question in an effective way. The results showed that the proposed approach is effective and a good alternative to existing CAPTCHA-based approaches. Mireshghallah et al. <ref type="bibr" target="#b427">[428]</ref> investigated whether models other than the generator can be used to identify machine-generated text. In general, smaller models serve as more effective universal text detectors. These models exhibit better accuracy in identifying text produced by both small and larger models. For example, OPT-125M achieves better results compared to the GPT-J 6B model in detecting ChatGPT-generated text.</p><p>Some of the research works focused on assessing the robustness of machine-generated text detectors towards different attacks. Shi et al. <ref type="bibr" target="#b444">[445]</ref> evaluated the robustness of existing detectors using attacks like synonym word replacement and writing style modification. The authors implemented both attacks using LLMs. The results showed that the existing detectors are not robust to the attacks, which emphasizes the need for more robust and reliable detectors to detect and avoid the misuse of LLMs. Krishna et al. <ref type="bibr" target="#b451">[452]</ref> showed that existing detectors like OpenAI detector, GPTZero and DetectGPT <ref type="bibr" target="#b462">[463]</ref> are not robust to paraphrase attacks. For example, paraphrase attacks result in a drop of more than 65% accuracy in the case of DetectGPT.</p><p>Some of the research works focused on assessing the effectiveness of humans in identifying GLLM generated text. For example, Clark et al. <ref type="bibr" target="#b442">[443]</ref> observed that nonexpert evaluators are unable to differentiate GPT-3 generated text from human-authored text in three different domains, namely news, recipes and stories. The reason for this is the evaluators arrived at their decisions based on surface-level features without considering the advanced text generation capabilities of the GPT-3 model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">ROBUSTNESS OF GLLMS</head><p>Overview. GPT-3 family large language models achieve impressive performances in zero and few-shot settings in many NLP tasks. In some tasks like text classification <ref type="bibr" target="#b143">[144]</ref>, relation extraction <ref type="bibr" target="#b155">[156]</ref>, etc. GLLMs without any explicit fine-tuning outperform state-of-the-art finetuned models. For example, Sun et al. <ref type="bibr" target="#b143">[144]</ref> demonstrated that InstructGPT, with the advanced prompting authors observed that GLLMs are not robust to adversarial prompts. Moreover, word-level attacks are the most effective, which results in a performance drop of more than 30%. Based on the evaluation of ChatGPT on fourteen information extraction sub-tasks, Han et al. <ref type="bibr" target="#b459">[460]</ref> showed that ChatGPT is vulnerable to adversarial prompts, i.e., the performance is greatly affected by including irrelevant context in the prompt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">GLLMS AS EVALUATORS</head><p>Overview. Natural language processing tasks can be broadly classified into natural language understanding (NLU) and natural language generation (NLG). NLU involves the interpretation of text, while NLG involves generating human-like text. The evaluation of NLU outputs is pretty straightforward, while the evaluation of NLG outputs is challenging because of the diversity and inherent complexity of the text <ref type="bibr" target="#b467">[468]</ref>. Moreover, the NLG evaluation involves assessing the generated text outputs in multiple dimensions, such as coherence, fluency, naturalness and semantic consistency. Human evaluation and automatic evaluation are two existing approaches for NLG evaluation. The human evaluation depends on competent annotators for an accurate and reliable assessment <ref type="bibr" target="#b468">[469]</ref>.</p><p>Human Evaluation vs Automatic Evaluation. Human evaluation is treated as the gold standard, but it is timeconsuming, expensive, difficult to scale, inconsistent, and not reproducible <ref type="bibr" target="#b467">[468]</ref>, <ref type="bibr" target="#b480">[481]</ref>. To address the issues with human evaluation, automatic evaluation metrics are developed, which fall broadly into two categories: ngram-based and embedding-based. N-gram-based metrics assess the quality based on the lexical overlap between the generated and reference texts. Some of the commonly used n-gram-based metrics are BLEU <ref type="bibr" target="#b486">[487]</ref>, ROUGE <ref type="bibr" target="#b487">[488]</ref> and METEOR <ref type="bibr" target="#b488">[489]</ref>. However, these metrics have a poor correlation with human scores because of their inability to capture semantic meaning <ref type="bibr" target="#b489">[490]</ref>. Later, with the evolution of transformers and pretrained language models, the researchers developed embeddingbased metrics like BERTScore <ref type="bibr" target="#b490">[491]</ref>, MoverScore <ref type="bibr" target="#b491">[492]</ref>, BARTScore <ref type="bibr" target="#b492">[493]</ref>, CodeBERTScore <ref type="bibr" target="#b493">[494]</ref> etc. These metrics leverage the pretrained language models and assess the quality based on the semantic similarity between the generated and reference text. The main drawback of the existing automatic evaluation metrics is the requirement for references, which are difficult to obtain, especially in low-resource domains. Moreover, with just a few references, it is not possible to get an accurate and reliable assessment as few references cannot account for all the semantic variations <ref type="bibr" target="#b467">[468]</ref>. So, there is a strong need for automatic evaluation metrics which are reference-free.</p><p>GLLM-based Evaluation. Recently, with the huge success of GLLMs in most of the NLP tasks, the research community focused on developing automatic evaluation metrics based on these models. These models possess the ability of in-context learning, while instruction tuning enables these models to align themselves with human evaluation <ref type="bibr" target="#b1">[2]</ref>. These two abilities enable these models to imitate the behaviour of human evaluators, who typically evaluate natural language generation task outputs by understanding instructions and the given examples. The GLLM-based evaluation metrics demonstrate a strong correlation with human scores even in the absence of reference outputs <ref type="bibr" target="#b471">[472]</ref>, <ref type="bibr" target="#b476">[477]</ref>. Table <ref type="table">22</ref> presents a summary of research works exploring GLLM-based evaluation for various natural language generation tasks.</p><p>Research works exploring GLLM-based evaluation. The NLP researchers proposed various GLLM-based evaluation frameworks to evaluate the outputs of various NLG tasks like code generation <ref type="bibr" target="#b469">[470]</ref>, text style transfer <ref type="bibr" target="#b470">[471]</ref>, text summarization <ref type="bibr" target="#b467">[468]</ref>, <ref type="bibr" target="#b471">[472]</ref>, <ref type="bibr" target="#b474">[475]</ref>- <ref type="bibr" target="#b479">[480]</ref>, <ref type="bibr" target="#b481">[482]</ref>, <ref type="bibr" target="#b482">[483]</ref>, dialogue generation <ref type="bibr" target="#b467">[468]</ref>, <ref type="bibr" target="#b471">[472]</ref>, <ref type="bibr" target="#b476">[477]</ref>, machine translation <ref type="bibr" target="#b425">[426]</ref>, <ref type="bibr" target="#b472">[473]</ref>, <ref type="bibr" target="#b473">[474]</ref>, <ref type="bibr" target="#b476">[477]</ref>, <ref type="bibr" target="#b479">[480]</ref>, <ref type="bibr" target="#b484">[485]</ref>, story generation <ref type="bibr" target="#b467">[468]</ref>, <ref type="bibr" target="#b482">[483]</ref>, paraphrase generation <ref type="bibr" target="#b467">[468]</ref>, text-to-image synthesis <ref type="bibr" target="#b284">[285]</ref>, data-to-text generation <ref type="bibr" target="#b476">[477]</ref>, <ref type="bibr" target="#b482">[483]</ref>, image captioning <ref type="bibr" target="#b479">[480]</ref>, text generation <ref type="bibr" target="#b480">[481]</ref>, open-ended question answering <ref type="bibr" target="#b483">[484]</ref>, <ref type="bibr" target="#b485">[486]</ref>. Most of the research works proposed evaluation frameworks using direct prompting, while some of the research works introduced evaluation frameworks based on advanced prompting strategies like chain-of-thoughts <ref type="bibr" target="#b469">[470]</ref>, <ref type="bibr" target="#b471">[472]</ref> and error analysis prompting <ref type="bibr" target="#b473">[474]</ref>. Some of the proposed evaluation frameworks work with and without references <ref type="bibr" target="#b469">[470]</ref>, <ref type="bibr" target="#b472">[473]</ref>, <ref type="bibr" target="#b482">[483]</ref>, while some of them require references <ref type="bibr" target="#b425">[426]</ref>, <ref type="bibr" target="#b470">[471]</ref>, <ref type="bibr" target="#b473">[474]</ref>, <ref type="bibr" target="#b479">[480]</ref>, <ref type="bibr" target="#b484">[485]</ref>, and some don't require any references <ref type="bibr" target="#b467">[468]</ref>, <ref type="bibr" target="#b471">[472]</ref>, <ref type="bibr" target="#b474">[475]</ref>- <ref type="bibr" target="#b478">[479]</ref>, <ref type="bibr" target="#b480">[481]</ref>, <ref type="bibr" target="#b481">[482]</ref>, <ref type="bibr" target="#b483">[484]</ref>, <ref type="bibr" target="#b485">[486]</ref>.</p><p>Lai et al. <ref type="bibr" target="#b470">[471]</ref> investigated how effective ChatGPT is to evaluate text style transfer task along three dimensions: fluency, content and style. The model achieves good correlations with human judgements, and the best results are obtained by using separate prompts for each dimension evaluation. Kocmi et al. <ref type="bibr" target="#b472">[473]</ref> proposed GEMBA, a GPT-based metric to assess translation output quality, with references being optional. The authors reported that GPT-3.5 and higher models are only useful for the assessment, and GPT-4 achieves the best results. Based on the evaluation of four natural language generation tasks, paraphrase generation, text summarization, story generation and dialogue response generation, Chen et al. <ref type="bibr" target="#b467">[468]</ref> showed that explicit score with greedy decoding strategy is the best way to assess NLG outputs using GLLMs like ChatGPT. Luo et al. <ref type="bibr" target="#b474">[475]</ref> evaluated ChatGPT's ability as a factual inconsistency evaluator for text summarization task. Experiment results showed that ChatGPT outperforms existing metrics on most of the datasets.</p><p>Shen et al. <ref type="bibr" target="#b475">[476]</ref> explored how effective ChatGPT can be as a zero-shot evaluator for abstractive summarization systems using different evaluation methods like likert scaling <ref type="bibr" target="#b494">[495]</ref> and head-to-head comparisons <ref type="bibr" target="#b495">[496]</ref>. Extensive analysis showed that likert scaling implemented as a multiple-choice question gives the best and most stable results. Liu et al. <ref type="bibr" target="#b477">[478]</ref> designed a novel approach which code generation evaluation framework based on Chat-GPT and demonstrated that the proposed framework outperforms CodeBERTScore <ref type="bibr" target="#b493">[494]</ref> consistently across multiple programming languages. Moreover, the performance of the evaluation framework can be enhanced using references and zero-shot CoT prompting. Liu et al. <ref type="bibr" target="#b471">[472]</ref> proposed G-EVAL, a novel framework based on GPT-4 for the assessment of natural language generation tasks. The proposed framework uses CoT prompting and a form-filling paradigm. Here, CoT prompting enhances the performance of G-EVAL by offering more guidance and context. The performance of ChatGPTbased evaluation in segment-level machine translation is poor. To overcome this, Lu et al. <ref type="bibr" target="#b473">[474]</ref> proposed a novel prompting called Error Analysis (EA) prompting, which combines error analysis <ref type="bibr" target="#b497">[498]</ref> and CoT prompting. The authors showed that with EA prompting, ChatGPT can assess translations at the segment level much better. Some of the research works explored GLLMs for the evaluation of multi-modal AI tasks <ref type="bibr" target="#b284">[285]</ref>, fine-tuning open-source LLM evaluators <ref type="bibr" target="#b425">[426]</ref>, and paraphrasing references to enhance existing metrics based on pretrained language models <ref type="bibr" target="#b479">[480]</ref>. For example, Lu et al. <ref type="bibr" target="#b284">[285]</ref> introduced LLMScore (based on GPT-4), a new metric which can effectively capture both image and object-level compositionality for text-to-image synthesis evaluation. Some of the research works explored these models to fine-tune open-source LLMs so that they can be used as evaluators, which makes the evaluation less expensive. For example, Xu et al. <ref type="bibr" target="#b425">[426]</ref> introduced InstructScore, a novel and explainable metric based on fine-tuned LLaMA model for text generation evaluation.</p><p>Here the authors use GPT-4 generated synthetic data to fine-tune the LLaMA model. InstructScore can generate an error diagnostic report having error details along with an explanation. Natural language generation evaluation using few references results in poor correlation with human judgements. To overcome this drawback, Tang et al. <ref type="bibr" target="#b479">[480]</ref> introduced Para-Ref, which leverages LLMs to increase the number of references by paraphrasing. The evaluation on three NLG tasks, text summarization, machine translation and image caption, showed that the proposed approach enhances the correlation of sixteen automatic evaluation metrics with human judgements by a good margin. Some of the research works focused on addressing the limitations of using GLLMs as evaluators. For example, Wang et al. <ref type="bibr" target="#b480">[481]</ref> demonstrated positional bias in GLLM-based evaluation, i.e., the order of candidate responses can significantly influence the results. The authors demonstrated that the two proposed strategies, namely multiple evidence calibration and balanced position calibration, can reduce the bias and enhance the correlation with human judgements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">FUTURE RESEARCH DIRECTIONS 11.1 Enhance Robustness of GLLMs</head><p>GLLMs achieved promising results across various NLP tasks in zero and few-shot settings across various NLP tasks. In some of the tasks like data labelling <ref type="bibr" target="#b372">[373]</ref>- <ref type="bibr" target="#b374">[375]</ref>, <ref type="bibr" target="#b382">[383]</ref>, text classification <ref type="bibr" target="#b143">[144]</ref>, relation extraction <ref type="bibr" target="#b155">[156]</ref>, question answering <ref type="bibr" target="#b131">[132]</ref>, <ref type="bibr" target="#b178">[179]</ref>, keyphrase generation <ref type="bibr" target="#b216">[217]</ref>, etc., these models achieved even SOTA results. However, some of the recent research works exposed the brittleness of these models towards out-of-distribution inputs <ref type="bibr" target="#b455">[456]</ref>, <ref type="bibr" target="#b460">[461]</ref>, adversarial prompts <ref type="bibr" target="#b457">[458]</ref>- <ref type="bibr" target="#b459">[460]</ref> and inputs <ref type="bibr" target="#b424">[425]</ref>, <ref type="bibr" target="#b454">[455]</ref>, <ref type="bibr" target="#b456">[457]</ref>, <ref type="bibr" target="#b461">[462]</ref> . For example, Liu et al. <ref type="bibr" target="#b460">[461]</ref> reported that ChatGPT and GPT-4 perform well in multiple choice question answering but struggle to answer out-of-distribution questions. Similarly, Chen et al. <ref type="bibr" target="#b454">[455]</ref> observed more than 35% performance degradation for GPT-3 and GPT-3.5 models in tasks like sentiment analysis and natural language inference for adversarial inputs. The brittleness towards out-of-distribution and adversarial inputs makes these models unreliable and limits their practical utility, especially in sensitive domains. So, it is necessary for the research community to focus more on this research direction to make GLLMs more robust and enhance their reliability and usage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.2">Red Teaming</head><p>Red teaming involves an assessment to expose undesirable model behaviours like generating harmful text <ref type="bibr" target="#b498">[499]</ref>- <ref type="bibr" target="#b501">[502]</ref>. GLLMs trained over large volumes of text data with a simple next-word prediction objective are surprisingly good at generating text with human-like fluency. However, the other side is that these models sometimes generate harmful text. For example, Risabh et al. <ref type="bibr" target="#b498">[499]</ref> observed that GLLMs like ChatGPT and GPT-4 generate answers to more than 60% of harmful queries. One of the possible reasons for this undesirable behaviour of GLLMs is that data used for pretraining these models includes toxic, biased and noisy text to some extent <ref type="bibr" target="#b498">[499]</ref>. This unwanted behaviour of generating harmful text raises concerns and limits the scalable deployment of these models for public use. We can expect more research in future to expose such undesirable behaviour in various scenarios and eventually enhance the safety alignment as well as the safe use of GLLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.3">State-Of-The-Art Results Across NLP Tasks</head><p>In the beginning, GLLMs like GPT-3 achieved impressive performances in zero and few-shot settings across NLP tasks. Advanced GLLMs like ChatGPT and GPT-4 further pushed the results but still lag behind SOTA results achieved by pretrained language models finetuned based on supervised learning. Later, with the evolution of advanced prompting strategies and novel approaches, GLLMs are able to achieve SOTA results in some of the NLP tasks. For example, InstructGPT with CARP prompting strategy using just 16 examples achieves SOTA results on four text classification datasets <ref type="bibr" target="#b143">[144]</ref>. Similarly, Wan et al. <ref type="bibr" target="#b155">[156]</ref> achieved SOTA results in relation extraction with the novel GPT-RE framework. Yang et al. <ref type="bibr" target="#b178">[179]</ref> proposed a novel approach which uses GPT-3 as an implicit knowledge source and achieves SOTA results in knowledge-based visual question answering. In future, we can expect more focus from the research community to achieve SOTA results using GLLMs in as many NLP tasks as possible, which will be treated as a further push towards artificial general intelligence. Moreover, this eliminates the painful process of labelling large amounts of data and then fine-tuning pretrained language models separately for each downstream task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.4">Robust Approaches to Detect GLLM Generated Text</head><p>The ability to generate text with human-like fluency resulted in the wide adoption of GLLMs in various real-world applications like writing assistants, coding assistants, and chatbots <ref type="bibr" target="#b427">[428]</ref>. There is a growing concern regarding the misuse of these models for various illegal activities <ref type="bibr" target="#b428">[429]</ref>, like fake news on social media platforms <ref type="bibr" target="#b429">[430]</ref>, <ref type="bibr" target="#b430">[431]</ref>, fake reviews on e-commerce websites <ref type="bibr" target="#b431">[432]</ref>, fake research papers <ref type="bibr" target="#b432">[433]</ref>, academic fraud <ref type="bibr" target="#b433">[434]</ref>, etc. The performance of existing approaches like DetectGPT, Ze-roGPT, OpenAI detector, ChatGPT-detector-roberta and ChatGPT-qa-detector-roberta is not satisfactory <ref type="bibr" target="#b436">[437]</ref>, <ref type="bibr" target="#b443">[444]</ref>. Moreover, the existing approaches are not robust to various attacks like paraphrasing, synonym word replacement and writing style modification <ref type="bibr" target="#b444">[445]</ref>, <ref type="bibr" target="#b451">[452]</ref>. So, there is a great need for better approaches which can reliably detect GLLM generated text and also robust to various attacks, including paraphrasing. With reliable and robust detection approaches, the misuse of GLLMs for various illegal activities can be reduced to a great extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.5">Reduce Inference Costs</head><p>GLLMs achieve impressive performances across NLP tasks, with SOTA results in some tasks. However, the downside of using GLLMs is the high inference costs <ref type="bibr" target="#b502">[503]</ref>, <ref type="bibr" target="#b503">[504]</ref>. For example, a small business is required to spend more than $21,000 monthly to use GPT-4 for better customer support 6 . Such high inference costs have become a burden to small and medium-sized companies. Recently, Chen et al. <ref type="bibr" target="#b502">[503]</ref> proposed FrugalGPT, a novel framework involving multiple strategies like prompt adaptation and LLM approximation to reduce the inference costs of GLLMs. The inference costs of GLLMs increase with the prompt size as the inference cost is computed based on the number of tokens processed. Prompt adaptation focuses on reducing the size of the prompt by using fewer but effective examples or querying the GLLMs as a batch. LLM approximation 6. <ref type="url" target="https://neoteric.eu/blog/how-much-does-it-cost-to-use-gpt-">https://neoteric.eu/blog/how-much-does-it-cost-to-use-gpt-</ref>models-gpt-3-pricing-explained uses cache to avoid querying GLLM for similar queries, which eventually reduces overall inference costs. Similarly, Cheng et al. <ref type="bibr" target="#b503">[504]</ref> proposed batch prompting, which involves GLLM inference in batches rather than processing one sample individually. The authors demonstrated that the proposed prompting strategy reduces Codex model inference cost across ten datasets with little or no degradation in the performance. Future research in this direction will result in much better approaches which will further reduce the GLLM inference costs and make GLLM usage more affordable for companies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.6">Enhance Performance in Domain-Specific NLP Tasks</head><p>Inspired by the success of GLLMs in general domain NLP tasks, the research community explored GLLMs for NLP tasks in specific domains like healthcare, legal, finance, etc. However, the performances of GLLMs in domain-specific NLP tasks are not as impressive as those achieved in general domain NLP tasks <ref type="bibr" target="#b135">[136]</ref>, <ref type="bibr" target="#b325">[326]</ref>, <ref type="bibr" target="#b334">[335]</ref>, <ref type="bibr" target="#b345">[346]</ref>, <ref type="bibr" target="#b346">[347]</ref>, <ref type="bibr" target="#b355">[356]</ref>. For example, Moradi et al. <ref type="bibr" target="#b325">[326]</ref> reported that the BioBERT model outperforms GPT-3 in few-shot settings even though the BioBERT model is 514 times smaller than GPT-3. Chalkidis et al. <ref type="bibr" target="#b345">[346]</ref> evaluated ChatGPT on the LexGLUE benchmark and reported that ChatGPT performs poorly on legal text classification datasets. Analyzing domain-specific texts is more challenging because of domain-specific terminology and abbreviations, complex language structures, etc. In domains like healthcare, finance and legal, domain experts use many words and abbreviations that are specific to the domain and not commonly found in general domain texts. There is a lot of scope to improve the performance of GLLMs in domain-specific NLP tasks, which reduces the bottleneck for the widespread adoption of these models in specific domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.7">Handle Limited Context Length</head><p>One of the major drawbacks of GLLMs is their limited context length <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b504">[505]</ref>, <ref type="bibr" target="#b505">[506]</ref>. The maximum context length of GLLMs lies in the range of 2049 tokens to 32,768 tokens 7 . This limited context length poses a challenge and becomes a bottleneck for GLLMs to handle long documents or maintain long conservations in which the number of tokens falls beyond the maximum context length. Recently, Li <ref type="bibr" target="#b504">[505]</ref> proposed selective context, a novel approach to effectively utilize the limited context length by filtering out the less useful content in the input text. The authors demonstrated the effectiveness of the proposed approach using the ChatGPT model for question-answering and text summarization tasks across datasets having lengthy input instances. Future research in this direction will help in the evolution of more efficient approaches which will effectively utilize the limited context length and eliminate the bottlenecks for 7. <ref type="url" target="https://platform.openai.com/docs/models/overview">https://platform.openai.com/docs/models/overview</ref> the application of GLLMs in tasks that require processing long inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.8">Ensure Fair Evaluation of GLLMs</head><p>GLLMs achieved impressive performances across NLP tasks and have received much attention recently. However, one concern regarding the evaluation of GLLMs is data contamination, which refers to the presence of test data instances of downstream tasks in the training corpus of GLLMs <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b506">[507]</ref>, <ref type="bibr" target="#b507">[508]</ref>. The problem of data contamination is more relevant in the case of GLLMs because of their proprietary nature and non-disclosure of training corpus details. Recent research works have reported the problem of data contamination in GLLMs like ChatGPT <ref type="bibr" target="#b507">[508]</ref> and GPT-4 <ref type="bibr" target="#b506">[507]</ref>. For example, Golchin et al. <ref type="bibr" target="#b506">[507]</ref> demonstrated that GPT-4 is contaminated with instances from text classification, natural language inference and text summarization datasets like WNLI <ref type="bibr" target="#b508">[509]</ref>, AG News <ref type="bibr" target="#b509">[510]</ref> and XSUM <ref type="bibr" target="#b510">[511]</ref>. Recently, golchin et al. <ref type="bibr" target="#b506">[507]</ref> proposed a novel approach to detect data contamination for LLMs. Future research must focus on developing simple and effective approaches to identify data contamination and ensure fair evaluation, enhancing the reliability of impressive performances of GLLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.9">Reduce Hallucinations</head><p>Despite the remarkable performances of GLLMs, there is a growing concern regarding their tendency to generate factually incorrect information <ref type="bibr" target="#b511">[512]</ref>, <ref type="bibr" target="#b512">[513]</ref>. This tendency to generate text that doesn't align with existing world knowledge, deviates from the user's input or contradicts the context generated earlier is referred to as hallucination <ref type="bibr" target="#b511">[512]</ref>. Hallucination is a serious problem yet to be addressed fully <ref type="bibr" target="#b513">[514]</ref>, and it reduces the reliability of GLLMs, which becomes a bottleneck for the adoption of GLLMs, especially in sensitive domains like healthcare <ref type="bibr" target="#b514">[515]</ref>. Recently, some of the research works focused on evaluating hallucination in GLLMs <ref type="bibr" target="#b514">[515]</ref>, assessing the ability of GLLMs to identify hallucinations <ref type="bibr" target="#b515">[516]</ref> and developing approaches to reduce hallucinations <ref type="bibr" target="#b516">[517]</ref>. For example, Li et al. <ref type="bibr" target="#b515">[516]</ref> proposed HaluEval, a novel benchmark to assess the ability of GLLMs to identify hallucinations. Peng et al. <ref type="bibr" target="#b516">[517]</ref> introduced LLM-AUGMENTER, a novel approach that reduces hallucinations in ChatGPT without impacting the quality of generated responses. Considering the seriousness of the hallucination problem, we can expect more future research to identify and reduce hallucinations in GLLMs, which enhance their reliability and adoption across domains, including sensitive domains like healthcare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.10">Enhance the Performance of GLLMs for Non-English Languages</head><p>The performance of GLLMs is not impressive in the case of non-English languages, especially in the case of languages with non-Latin scripts <ref type="bibr" target="#b130">[131]</ref>, <ref type="bibr" target="#b131">[132]</ref>, <ref type="bibr" target="#b362">[363]</ref>, <ref type="bibr" target="#b365">[366]</ref>. This is because GLLMs are mostly pretrained on English text. For example, more than 90% of text in the pretraining corpus of the GPT-3 model is from the English language <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b365">[366]</ref>. Some of the possible options to enhance the performance of GLLMs for non-English languages are the use of English prompts <ref type="bibr" target="#b130">[131]</ref>, <ref type="bibr" target="#b362">[363]</ref> and optimized tokenization <ref type="bibr" target="#b364">[365]</ref>. There is a great need for better approaches to greatly enhance the performance of GLLMs for non-English languages, which increase their adoption across the globe and benefit users from non-English communities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="12">CONCLUSION</head><p>In this survey paper, we provide a comprehensive review of GPT-3 family large language models in multiple dimensions covering more than 350 recent research papers. Here, we present foundation concepts, GPT-3 family large language models and discuss the performances of these models in various downstream tasks, specific domains and multiple languages. We also discuss data labelling, data augmentation and data generation abilities of GLLMs, the robustness of GLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with multiple insightful future research directions. Overall, this comprehensive survey paper on GPT-3 family large language models will serve as a good resource for both academic and industry people to stay updated with the latest research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>For example, Bloomberg developed BloombergGPT, an exclusive LLM for the finance domain. Similarly, Google developed MedPaLM and MedPaLM2 LLMs exclusively for the healthcare domain based on PaLM and PaLM2 models respectively. Similarly, HuggingFace developed StarCoder, MetaAI developed Code LlaMA, and SalesForce developed CodeGen and CodeGen2 LLMs exclusively for coding tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="3,48.96,56.72,566.94,226.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="6,79.22,56.72,453.55,141.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="7,107.57,56.72,396.85,141.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="8,79.23,56.72,453.54,141.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="9,79.23,56.73,453.54,113.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="11,86.31,56.72,439.37,141.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="11,50.88,236.12,510.24,226.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 4</head><label>4</label><figDesc>The main objective of MT systems is to enhance crosslingual communication by reducing the gap between individuals from different linguistic communities. The</figDesc><table><row><cell>Paper</cell><cell>GLLMs Explored</cell><cell>Prompt Settings</cell><cell cols="2">Domain(s)</cell><cell></cell><cell></cell><cell>Language(s)</cell><cell>Granularity</cell><cell>Outperforms</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Commercial</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Systems</cell></row><row><cell>[196]</cell><cell>ChatGPT</cell><cell>ZS</cell><cell>General</cell><cell></cell><cell></cell><cell></cell><cell>Japanese, Chinese</cell><cell>Sentence</cell><cell>No</cell></row><row><cell>[197]</cell><cell>ChatGPT</cell><cell>ZS</cell><cell cols="3">General, News, Healthcare</cell><cell></cell><cell>English, Chinese, German,</cell><cell>Sentence</cell><cell>No</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Romanian</cell><cell></cell><cell></cell></row><row><cell>[198]</cell><cell>ChatGPT, GPT-4</cell><cell>ZS</cell><cell cols="4">General, Healthcare ,Social Me-</cell><cell>English, Chinese, German,</cell><cell>Sentence</cell><cell>Yes</cell></row><row><cell></cell><cell></cell><cell></cell><cell>dia</cell><cell></cell><cell></cell><cell></cell><cell>Romanian</cell><cell></cell><cell></cell></row><row><cell>[199]</cell><cell>InstructGPT, Chat-</cell><cell>ZS,FS</cell><cell>News,</cell><cell>Social</cell><cell>Media,</cell><cell>E-</cell><cell>English, German, Chinese</cell><cell>Sentence,</cell><cell>Yes</cell></row><row><cell></cell><cell>GPT, GPT-4</cell><cell></cell><cell cols="3">Commerce, Dialogue</cell><cell></cell><cell></cell><cell>Document</cell><cell></cell></row><row><cell>[200]</cell><cell>ChatGPT</cell><cell>ZS, FS</cell><cell cols="4">General, News, Social Media,</cell><cell>English, French, Spanish</cell><cell>Sentence</cell><cell>Yes</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Dialogue, E-Commerce</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[201]</cell><cell>ChatGPT, GPT-4</cell><cell>ZS</cell><cell cols="4">General, Social Media, News,</cell><cell>English, German, Russian</cell><cell>Document</cell><cell>Yes</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Dialogue</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[202]</cell><cell>ChatGPT</cell><cell>ZS, FS</cell><cell>General</cell><cell></cell><cell></cell><cell></cell><cell>102 Languages in 202 direc-</cell><cell>Sentence</cell><cell>No</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>tions</cell><cell></cell><cell></cell></row><row><cell>[203]</cell><cell>ChatGPT</cell><cell>ZS</cell><cell>General</cell><cell></cell><cell></cell><cell></cell><cell>English, Chinese, French</cell><cell>Paragraph</cell><cell>No</cell></row><row><cell>[132]</cell><cell>ChatGPT</cell><cell>ZS</cell><cell>General</cell><cell></cell><cell></cell><cell></cell><cell>Twelve languages, includ-</cell><cell>Sentence</cell><cell>No</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ing four low-resource lan-</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>guages</cell><cell></cell><cell></cell></row><row><cell>[204]</cell><cell>GPT-3.5</cell><cell>ZS</cell><cell>General</cell><cell></cell><cell></cell><cell></cell><cell>18 language Pairs, includ-</cell><cell>Sentence,</cell><cell>Yes</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ing Japanese, English and</cell><cell>Paragraph</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Polish</cell><cell></cell><cell></cell></row><row><cell>[205]</cell><cell>GPT-3.5</cell><cell>ZS, FS</cell><cell>General</cell><cell></cell><cell></cell><cell></cell><cell>English, Arabic, Chinese,</cell><cell>Sentence</cell><cell>Yes</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>German, Spanish</cell><cell></cell><cell></cell></row><row><cell>[206]</cell><cell>GPT-3.5</cell><cell>ZS, FS</cell><cell>General</cell><cell></cell><cell></cell><cell></cell><cell>English, Chinese, Japanese,</cell><cell>Sentence</cell><cell>No</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>German, French</cell><cell></cell><cell></cell></row><row><cell>[207]</cell><cell>GPT-3.5, GPT-4</cell><cell>ZS</cell><cell>General</cell><cell></cell><cell></cell><cell></cell><cell>English, German, Chinese</cell><cell>Sentence</cell><cell>Yes</cell></row><row><cell>[208]</cell><cell>GPT-3.5</cell><cell>ZS</cell><cell>General</cell><cell></cell><cell></cell><cell></cell><cell>English, German, Russian</cell><cell>Sentence</cell><cell>Yes</cell></row></table><note><p>. Summary of research works exploring GLLMs for machine translation. Here ZS represents zero-shot, and FS represents few-shot.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 5 .</head><label>5</label><figDesc>Summary of research works exploring GLLMs for keyphrase generation task. Here ZS represents zero-shot, and FS represents few-shot.</figDesc><table><row><cell></cell><cell>Paper</cell><cell>GLLMs Explored</cell><cell>Prompt</cell><cell>Domain(s)</cell><cell></cell><cell>Language(s)</cell><cell>SOTA</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Settings</cell><cell></cell><cell></cell><cell>Results</cell></row><row><cell></cell><cell>[216]</cell><cell>ChatGPT</cell><cell>ZS</cell><cell cols="2">News, Scientific Literature</cell><cell>English</cell><cell>Yes</cell></row><row><cell></cell><cell>[217]</cell><cell>ChatGPT</cell><cell>ZS</cell><cell>Scientific Literature</cell><cell></cell><cell>English</cell><cell>No</cell></row><row><cell>Paper</cell><cell>Task(s)</cell><cell></cell><cell></cell><cell>GLLMs Explored</cell><cell cols="2">Prompt</cell><cell>Domain(s)</cell><cell>Language(s)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Settings</cell></row><row><cell>[218]</cell><cell cols="3">Spoken Language Understanding and Dialogue</cell><cell>GPT-3.5, ChatGPT</cell><cell>ZS</cell><cell>General</cell><cell>English</cell></row><row><cell></cell><cell cols="2">State Tracking</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[219]</cell><cell cols="3">Emotion Dialogue Understanding and Generation</cell><cell>ChatGPT</cell><cell>ZS, FS</cell><cell>General</cell><cell>English</cell></row><row><cell></cell><cell>Tasks</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[220]</cell><cell cols="2">Dialogue Summarization</cell><cell></cell><cell>GPT-3</cell><cell>ZS</cell><cell>Healthcare</cell><cell>English</cell></row><row><cell>[132]</cell><cell cols="2">Dialogue Generation</cell><cell></cell><cell>ChatGPT</cell><cell>ZS</cell><cell>General</cell><cell>English</cell></row><row><cell>[157]</cell><cell cols="2">Dialogue Summarization</cell><cell></cell><cell>ChatGPT</cell><cell>ZS</cell><cell>General</cell><cell>English</cell></row><row><cell>[221]</cell><cell cols="2">Dialogue Summarization</cell><cell></cell><cell>GPT-3</cell><cell>FS</cell><cell>General</cell><cell>English</cell></row><row><cell>[222]</cell><cell cols="2">Dialog Evaluation</cell><cell></cell><cell>GPT-3</cell><cell>FS</cell><cell>General</cell><cell>English</cell></row><row><cell>[223]</cell><cell cols="2">Dialogue Discourse Analysis</cell><cell></cell><cell>ChatGPT</cell><cell>ZS, FS</cell><cell>General</cell><cell>English,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Chinese</cell></row><row><cell>[224]</cell><cell cols="2">Dialogue Question Answering</cell><cell></cell><cell>ChatGPT</cell><cell>ZS, FS</cell><cell>General</cell><cell>English,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Chinese</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 7 .</head><label>7</label><figDesc>Summary of research works exploring GLLMs for information retrieval tasks. Here ZS represents zero-shot, and FS represents few-shot.</figDesc><table><row><cell>Paper</cell><cell>Task(s)</cell><cell>GLLMs Explored</cell><cell>Prompt</cell><cell>Domain(s)</cell><cell>Language(s)</cell><cell>SOTA</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Settings</cell><cell></cell><cell></cell><cell>Results</cell></row><row><cell>[230]</cell><cell>Passage Re-ranking</cell><cell>GPT-3, GPT-3.5,</cell><cell>ZS, FS</cell><cell>General, News, Healthcare, Scien-</cell><cell>English, Ten Low Resource</cell><cell>Yes</cell></row><row><cell></cell><cell></cell><cell>ChatGPT, GPT-4</cell><cell></cell><cell>tific Literature</cell><cell>Languages</cell><cell></cell></row><row><cell>[231]</cell><cell>Document Retrieval</cell><cell>GPT-3.5</cell><cell>ZS, FS</cell><cell>General</cell><cell>English</cell><cell>Yes</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 8 .</head><label>8</label><figDesc>Summary of research works exploring GLLMs for recommendation systems. Here ZS represents zero-shot, and FS represents few-shot.than GLLMs. Zhang et al.<ref type="bibr" target="#b247">[248]</ref> introduced FaiRLLM, a new benchmark having eight sensitive attributes from domains like movies and music, to investigate the fairness of GLLM recommendations. The authors reported that GLLM-based recommendation systems are not fair to certain sensitive attributes.Liu et al.</figDesc><table><row><cell>Paper</cell><cell>GLLMs Explored</cell><cell>Prompt Settings</cell><cell>Domain(s)</cell><cell cols="2">Language(s) SOTA</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Results</cell></row><row><cell>[243]</cell><cell>GPT-3.5</cell><cell>ZS</cell><cell>Movies</cell><cell>English</cell><cell>No</cell></row><row><cell>[246]</cell><cell>GPT-3.5, ChatGPT</cell><cell>ZS, FS</cell><cell>News, Books, Movies, Music</cell><cell>English</cell><cell>No</cell></row><row><cell>[241]</cell><cell>GPT-3.5, ChatGPT</cell><cell>ZS</cell><cell>Movies</cell><cell>English</cell><cell>No</cell></row><row><cell>[250]</cell><cell>InstructGPT</cell><cell>FS</cell><cell>Social Media</cell><cell>English</cell><cell>No</cell></row><row><cell>[247]</cell><cell>GPT-3.5, ChatGPT</cell><cell>ZS, FS</cell><cell>Movies, Books</cell><cell>English</cell><cell>No</cell></row><row><cell>[248]</cell><cell>ChatGPT</cell><cell>ZS</cell><cell>Music, Movies</cell><cell>English</cell><cell>No</cell></row><row><cell>[245]</cell><cell>ChatGPT</cell><cell>ZS, FS</cell><cell>Beauty</cell><cell>English</cell><cell>Yes</cell></row><row><cell>[249]</cell><cell>ChatGPT</cell><cell>ZS</cell><cell>Movies, Games</cell><cell>English</cell><cell>No</cell></row><row><cell>[244]</cell><cell>ChatGPT</cell><cell>ZS, FS</cell><cell>Books</cell><cell>English</cell><cell>No</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE 10</head><label>10</label><figDesc>et al.<ref type="bibr" target="#b295">[296]</ref> developed</figDesc><table><row><cell>Paper</cell><cell>GLLMs Explored</cell><cell>Task(s)</cell><cell>Prompt</cell><cell>Multimodality</cell><cell>Domain</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Settings</cell><cell></cell><cell></cell></row><row><cell>[291]</cell><cell>GPT-3</cell><cell>Text-based Action Generation</cell><cell>ZS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell>[292]</cell><cell>ChatGPT</cell><cell>Twenty Two Vision Language Tasks</cell><cell>ZS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell>[282]</cell><cell>GPT-3</cell><cell>Knowledge-based Visual Question Answering</cell><cell>FS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell>[300]</cell><cell>ChatGPT</cell><cell>Audio Labelling</cell><cell>ZS</cell><cell>Audio + Language</cell><cell>General</cell></row><row><cell>[293]</cell><cell>ChatGPT</cell><cell>Multi-Image Reasoning, Multi-hop Document Un-</cell><cell>ZS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell></cell><cell></cell><cell>derstanding, Open-World Concept Understand-</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>ing, Video Summarization</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[290]</cell><cell>GPT-3.5,</cell><cell>Chest X-Ray Report Generation</cell><cell>ZS</cell><cell>Image + Language</cell><cell>Healthcare</cell></row><row><cell></cell><cell>ChatGPT, GPT-4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[283]</cell><cell>GPT-3</cell><cell>Knowledge-based Visual Question Answering</cell><cell>FS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell>[299]</cell><cell>GPT-3.5</cell><cell>Five Video Understanding Tasks</cell><cell>ZS</cell><cell>Video + Language</cell><cell>General</cell></row><row><cell>[301]</cell><cell>GPT-4</cell><cell>Generate Instructions</cell><cell>ZS</cell><cell>Audio + Language</cell><cell>General</cell></row><row><cell>[285]</cell><cell>GPT-3.5, GPT-4</cell><cell>Evaluator for Text-to-Image Generation</cell><cell>ZS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell>[286]</cell><cell>GPT-3, GPT-3.5</cell><cell>Editing in Text-to-Image Generation</cell><cell>FS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell>[294]</cell><cell>ChatGPT</cell><cell>Multimodal Named Entity Recognition</cell><cell>FS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell>[295]</cell><cell>GPT-3</cell><cell>Five vision language tasks (four classification</cell><cell>FS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell></cell><cell></cell><cell>tasks and one question answering task)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[288]</cell><cell>GPT-4</cell><cell>Text-to-Video Generation</cell><cell>ZS</cell><cell>Video + Language</cell><cell>General</cell></row><row><cell>[179]</cell><cell>GPT-3</cell><cell>Knowledge-based Visual Question Answering</cell><cell>FS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell>[296]</cell><cell>GPT-3.5,</cell><cell>Layout Generation</cell><cell>FS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell></cell><cell>ChatGPT, GPT-4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[302]</cell><cell>ChatGPT, GPT-4</cell><cell>Multimodal tasks covering text, video, audio and</cell><cell>ZS</cell><cell>Multimodal covering</cell><cell>General</cell></row><row><cell></cell><cell></cell><cell>images</cell><cell></cell><cell>text, video, audio and</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>images</cell><cell></cell></row><row><cell>[287]</cell><cell>GPT-3.5,</cell><cell>Controlled Text-to-Image Generation</cell><cell>ZS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell></cell><cell>ChatGPT, GPT-4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[297]</cell><cell>ChatGPT</cell><cell>Paraphrasing</cell><cell>ZS</cell><cell>Image + Language</cell><cell>General</cell></row><row><cell>[289]</cell><cell>ChatGPT</cell><cell>Audio Understanding and Generation Tasks</cell><cell>ZS</cell><cell>Multimodal covering</cell><cell>General</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>text, audio and images</cell><cell></cell></row><row><cell>[298]</cell><cell>GPT-4</cell><cell>Generate Instruction Tuning Dataset</cell><cell>FS</cell><cell>Image + Language</cell><cell>Healthcare</cell></row><row><cell>[284]</cell><cell>GPT-3</cell><cell>Knowledge-based Visual Question Answering</cell><cell>FS</cell><cell>Image + Language</cell><cell>General</cell></row></table><note><p>. Summary of research works exploring GLLMs for various multimodal AI tasks. Here ZS represents zero-shot, and FS represents few-shot.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE 11 .</head><label>11</label><figDesc>Summary of research works exploring GLLMs to automate machine learning tasks. Here ZS represents zero-shot, and FS represents few-shot.</figDesc><table><row><cell>Paper</cell><cell>Task(s)</cell><cell>GLLMs Explored</cell><cell>Prompt</cell><cell>Language(s)</cell><cell>SOTA Results</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Settings</cell><cell></cell><cell></cell></row><row><cell>[308]</cell><cell>Plan Extraction</cell><cell>GPT-3</cell><cell>FS</cell><cell>English</cell><cell>Yes</cell></row><row><cell>[309]</cell><cell>Planning in Human-Robot Interaction</cell><cell>GPT-3.5</cell><cell>ZS</cell><cell>English</cell><cell>No</cell></row><row><cell>[310]</cell><cell>Plan Extraction</cell><cell>GPT-3.5</cell><cell>FS</cell><cell>English</cell><cell>No</cell></row><row><cell>[311]</cell><cell>Planning</cell><cell>InstructGPT, ChatGPT</cell><cell>FS</cell><cell>English</cell><cell>No</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE 13 .</head><label>13</label><figDesc>. Most of the research Summary of research works exploring GLLMs for various NLP tasks in the healthcare domain. Here ZS represents zero-shot, and FS represents few-shot. Here '-' represents there is no comparison between GLLMs and domain-specific pretrained language models in the paper.</figDesc><table><row><cell>Paper</cell><cell>GLLMs Explored</cell><cell>Task(s)</cell><cell>Prompt</cell><cell>Language(s)</cell><cell>Outperforms</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Settings</cell><cell></cell><cell>Domain-Specific</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Models</cell></row><row><cell>[317]</cell><cell>ChatGPT, GPT-4</cell><cell>Question Answering</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[318]</cell><cell>ChatGPT, GPT-4</cell><cell>Text De-identification</cell><cell>ZS</cell><cell>English</cell><cell>Yes</cell></row><row><cell>[319]</cell><cell>GPT-4</cell><cell>Dialogue Summarization</cell><cell>FS</cell><cell>English</cell><cell>Yes</cell></row><row><cell>[320]</cell><cell>GPT-3.5,</cell><cell>Question Answering</cell><cell>ZS, FS</cell><cell>English</cell><cell>Yes</cell></row><row><cell></cell><cell>ChatGPT, GPT-4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[321]</cell><cell>GPT-3.5, GPT-4</cell><cell>Named Entity Recognition, Relation Extraction, Docu-</cell><cell>ZS, FS</cell><cell>English</cell><cell>Yes</cell></row><row><cell></cell><cell></cell><cell>ment Classification and Semantic Similarity</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[322]</cell><cell>GPT-3.5, ChatGPT</cell><cell>Question Answering</cell><cell>ZS</cell><cell>Japanese</cell><cell>-</cell></row><row><cell>[323]</cell><cell>GPT-3.5, GPT-4</cell><cell>Question Answering, Reasoning</cell><cell>ZS</cell><cell>Chinese</cell><cell>Yes</cell></row><row><cell>[324]</cell><cell>GPT-3</cell><cell>Text Simplification</cell><cell>FS</cell><cell>English</cell><cell>-</cell></row><row><cell>[149]</cell><cell>GPT-3</cell><cell>Entity Extraction, Relation Classification</cell><cell>FS</cell><cell>English</cell><cell>No</cell></row><row><cell>[[137]</cell><cell>ChatGPT, GPT-4</cell><cell>Natural Language Inference</cell><cell>ZS, FS</cell><cell>English</cell><cell>-</cell></row><row><cell>[325]</cell><cell>ChatGPT</cell><cell>Text Summarization</cell><cell>FS</cell><cell>English</cell><cell>Yes</cell></row><row><cell>[138]</cell><cell>GPT3.5, GPT4</cell><cell>Natural Language Inference, Document Classification</cell><cell>ZS, FS</cell><cell>English</cell><cell>-</cell></row><row><cell>[195]</cell><cell>GPT-3, ChatGPT,</cell><cell>Question Answering</cell><cell>FS</cell><cell>Japanese</cell><cell>-</cell></row><row><cell></cell><cell>GPT-4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[326]</cell><cell>GPT-3</cell><cell>Natural Language Inference, Relation Classification,</cell><cell>FS</cell><cell>English</cell><cell>No</cell></row><row><cell></cell><cell></cell><cell>Semantic Similarity, Question Answering, Text Classi-</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>fication</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[327]</cell><cell>ChatGPT</cell><cell>Text Simplification</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[328]</cell><cell>GPT-3, GPT-4</cell><cell>Dialogue Summarization</cell><cell>FS</cell><cell>English</cell><cell>-</cell></row><row><cell>[329]</cell><cell>GPT-3</cell><cell>Clinical Sense Disambiguation, Biomedical Evidence</cell><cell>ZS, FS</cell><cell>English</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>Extraction, Coreference Resolution, Medication Status</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Extraction, Medication Attribute Extraction</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[330]</cell><cell>GPT-3</cell><cell>Dialogue Summarization</cell><cell>ZS, FS</cell><cell>English</cell><cell>-</cell></row><row><cell>[331]</cell><cell>GPT-3</cell><cell>Text Summarization</cell><cell>ZS,FS</cell><cell>English</cell><cell>-</cell></row><row><cell>[332]</cell><cell>ChatGPT</cell><cell>Multi-Turn Medical Dialogue</cell><cell>ZS</cell><cell>Chinese</cell><cell>No</cell></row><row><cell>[117]</cell><cell>GPT-4</cell><cell>Question Answering</cell><cell>FS</cell><cell>English</cell><cell>No</cell></row><row><cell>[333]</cell><cell>ChatGPT</cell><cell>Question Answering</cell><cell>ZS</cell><cell>Chinese</cell><cell>-</cell></row><row><cell>[334]</cell><cell>GPT-3</cell><cell>Synonym Generation</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[335]</cell><cell>GPT-3</cell><cell>Natural Language Inference, Question Answering, Text</cell><cell>ZS</cell><cell>English</cell><cell>No</cell></row><row><cell></cell><cell></cell><cell>Classification</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[336]</cell><cell>ChatGPT</cell><cell>Clinical Decision Support</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[337]</cell><cell>ChatGPT</cell><cell>Question Answering</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[338]</cell><cell>ChatGPT</cell><cell>Question Answering</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[339]</cell><cell>ChatGPT</cell><cell>Diagnosis Lists Generation</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[340]</cell><cell>ChatGPT</cell><cell>Clinical Decision Support</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[341]</cell><cell>GPT-3, GPT-3.5,</cell><cell>Question Answering</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell></cell><cell>ChatGPT</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[342]</cell><cell>ChatGPT</cell><cell>Question Answering</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[343]</cell><cell>ChatGPT, GPT-4</cell><cell>Text Simplification</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE 14 .</head><label>14</label><figDesc>Summary of research works exploring GLLMs for various NLP tasks in the legal domain. Here ZS represents zeroshot, and FS represents few-shot. Here '-' represents there is no comparison between GLLMs and domain-specific pretrained language models in the paper.</figDesc><table><row><cell>Paper</cell><cell>GLLMs Explored</cell><cell>Task(s)</cell><cell>Prompt</cell><cell>Language(s)</cell><cell>Outperforms</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Settings</cell><cell></cell><cell>Domain-Specific</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Models</cell></row><row><cell>[344]</cell><cell>GPT-3</cell><cell>Natural Language Inference</cell><cell>ZS, FS</cell><cell>English</cell><cell>-</cell></row><row><cell>[188]</cell><cell>GPT-3.5</cell><cell>Question Answering</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[345]</cell><cell>GPT-3</cell><cell>Question Answering, Text Generation</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row><row><cell>[346]</cell><cell>ChatGPT</cell><cell>Text Classification</cell><cell>ZS, FS</cell><cell>English</cell><cell>No</cell></row><row><cell>[347]</cell><cell>ChatGPT</cell><cell>Question Answering, Text Generation</cell><cell>ZS</cell><cell>English</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE 15 .</head><label>15</label><figDesc>Summary of research works exploring GLLMs for various NLP tasks in the finance domain. Here ZS represents zero-shot, and FS represents few-shot. Here '-' represents there is no comparison between GLLMs and domain-specific pretrained language models in the paper.</figDesc><table><row><cell>Paper</cell><cell>GLLMs Explored</cell><cell>Task(s)</cell><cell>Prompt</cell><cell>Language(s)</cell><cell>Outperforms</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Settings</cell><cell></cell><cell>Domain-Specific</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Models</cell></row><row><cell>[136]</cell><cell>ChatGPT, GPT-4</cell><cell>News Headlines Classification, Financial Sentiment</cell><cell>ZS</cell><cell>English</cell><cell>Yes</cell></row><row><cell></cell><cell></cell><cell>Analysis, Named Entity Recognition, Question An-</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>swering</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[353]</cell><cell>ChatGPT</cell><cell>Sentiment Analysis</cell><cell>ZS</cell><cell>English</cell><cell>Yes</cell></row><row><cell>[354]</cell><cell>GPT-3</cell><cell>Sentiment Analysis</cell><cell>ZS</cell><cell>English</cell><cell>No</cell></row><row><cell>[355]</cell><cell>GPT-3.5</cell><cell>Pairwise Ranking</cell><cell>FS</cell><cell>Chinese</cell><cell>-</cell></row><row><cell>[356]</cell><cell>ChatGPT</cell><cell>Sentiment Analysis, Claim Detection, Named Entity</cell><cell>ZS</cell><cell>English</cell><cell>No</cell></row><row><cell></cell><cell></cell><cell>Recognition</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[357]</cell><cell>ChatGPT, GPT-4</cell><cell>Question Answering</cell><cell>ZS, FS</cell><cell>Chinese</cell><cell>-</cell></row><row><cell>[358]</cell><cell>ChatGPT, GPT-4</cell><cell>Relation Extraction</cell><cell>FS</cell><cell>English</cell><cell>-</cell></row><row><cell>[352]</cell><cell>ChatGPT</cell><cell>Sentiment Analysis</cell><cell>ZS</cell><cell>Chinese</cell><cell>-</cell></row><row><cell>[359]</cell><cell>GPT-3.5, GPT-4</cell><cell>Text Classification</cell><cell>ZS, FS</cell><cell>English</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>TABLE 16 .</head><label>16</label><figDesc>Summary of research works exploring GLLMs for NLP tasks in multilingual settings. Here, ZS represents zero-shot, and FS represents few-shot.</figDesc><table><row><cell>Paper</cell><cell>GLLMs</cell><cell>Task(s)</cell><cell>Prompt</cell><cell cols="2">Language(s)</cell><cell></cell><cell>Domain(s)</cell></row><row><cell></cell><cell>explored</cell><cell></cell><cell>Settings</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[363]</cell><cell>ChatGPT</cell><cell>PoS Tagging, Entity Extraction, Relation Extraction, Natural</cell><cell>ZS</cell><cell cols="2">37 Languages</cell><cell></cell><cell>General</cell></row><row><cell></cell><cell></cell><cell>Language Inference, Question Answering, Text Summariza-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>tion, Common Sense Reasoning</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[364]</cell><cell>ChatGPT</cell><cell>Grammar Error Correction</cell><cell>ZS, FS</cell><cell cols="3">English, German, Chinese</cell><cell>General</cell></row><row><cell>[365]</cell><cell>GPT-3</cell><cell>Question Answering, Natural Language Generation, Text</cell><cell>ZS</cell><cell cols="3">German, Spanish, Russian,</cell><cell>General</cell></row><row><cell></cell><cell></cell><cell>Summarization</cell><cell></cell><cell cols="2">Turkish, Catalan</cell><cell></cell></row><row><cell>[366]</cell><cell>GPT-3.5,</cell><cell>Natural Language Inference, Paraphrase Identification,</cell><cell>ZS</cell><cell cols="2">70 languages</cell><cell></cell><cell>General</cell></row><row><cell></cell><cell>ChatGPT,</cell><cell>Commonsense Reasoning, Question Answering, Parts of</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>GPT-4</cell><cell>Speech Tagging, Sentiment Analysis, Text Summarization</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[132]</cell><cell>ChatGPT</cell><cell>Sentiment Analysis, Language Identification, Machine</cell><cell>ZS</cell><cell cols="3">Multiple language includ-</cell><cell>General</cell></row><row><cell></cell><cell></cell><cell>Translation</cell><cell></cell><cell cols="3">ing low resource languages</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">like Sudanese, Javanese etc.</cell></row><row><cell>[131]</cell><cell>ChatGPT</cell><cell>Genre Identification</cell><cell>ZS</cell><cell cols="2">English, Slovenian</cell><cell></cell><cell>General</cell></row><row><cell>[367]</cell><cell>ChatGPT</cell><cell>Question Answering, Reasoning</cell><cell>ZS</cell><cell cols="3">Six languages including</cell><cell>General</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Chinese,</cell><cell>German</cell><cell>and</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>French</cell><cell></cell><cell></cell></row><row><cell>[368]</cell><cell>ChatGPT</cell><cell>Hate Speech Detection</cell><cell>ZS</cell><cell cols="3">Eleven languages includ-</cell><cell>Social Media</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">ing Hindi, Arabic and Ital-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>ian</cell><cell></cell><cell></cell></row><row><cell>[369]</cell><cell>GPT-4</cell><cell>Three Text Generation Tasks</cell><cell>ZS</cell><cell cols="3">Ten languages including</cell><cell>General</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Chinese and Japanese.</cell><cell></cell></row><row><cell>[370]</cell><cell>ChatGPT,</cell><cell>Question Answering, Sentiment Analysis, Text Summa-</cell><cell>ZS, FS</cell><cell>Indonesian,</cell><cell cols="2">Vietnamese,</cell><cell>General,</cell></row><row><cell></cell><cell>GPT-4</cell><cell>rization, Named Entity Recognition, Toxicity Detection,</cell><cell></cell><cell>Thai, Tamil</cell><cell></cell><cell></cell><cell>Social Media,</cell></row><row><cell></cell><cell></cell><cell>Machine Translation, Natural Language Inference, Casual</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>News</cell></row><row><cell></cell><cell></cell><cell>Reasoning</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>TABLE 17 .</head><label>17</label><figDesc>Summary of research works exploring GLLMs for data labelling. Here, '-' represents that the paper doesn't include a comparison between GLLMs and human annotators.</figDesc><table><row><cell>Paper</cell><cell>GLLMs Explored</cell><cell>Task(s)</cell><cell>Prompt</cell><cell>Domain(s)</cell><cell>Language(s)</cell><cell>Outperforms</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Settings</cell><cell></cell><cell></cell><cell>Human</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Annotators</cell></row><row><cell>[373]</cell><cell>ChatGPT</cell><cell>Stance, Relevance, Frame and Topics De-</cell><cell>ZS</cell><cell>Social Media,</cell><cell>English</cell><cell>Yes</cell></row><row><cell></cell><cell></cell><cell>tection</cell><cell></cell><cell>News</cell><cell></cell><cell></cell></row><row><cell>[374]</cell><cell>GPT-3.5</cell><cell>Three Binary Text Classification Tasks</cell><cell>ZS, FS</cell><cell>General</cell><cell>English</cell><cell>Yes</cell></row><row><cell>[375]</cell><cell>GPT-4</cell><cell>Political Tweets Classification</cell><cell>ZS</cell><cell>Social Media</cell><cell>English</cell><cell>Yes</cell></row><row><cell>[376]</cell><cell>ChatGPT</cell><cell>Stance Detection, Sentiment Analysis,</cell><cell>ZS</cell><cell>Social Media</cell><cell>English</cell><cell>No</cell></row><row><cell></cell><cell></cell><cell>Hate Speech Detection, Bot Detection</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[377]</cell><cell>ChatGPT</cell><cell>Detection of Hateful, Toxic and Offensive</cell><cell>ZS</cell><cell>Social Media</cell><cell>English</cell><cell>No</cell></row><row><cell></cell><cell></cell><cell>Comments</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[378]</cell><cell>GPT-3.5, GPT-4</cell><cell>Adverse Drug Reaction Extraction</cell><cell>ZS, FS</cell><cell>Healthcare</cell><cell>English</cell><cell>-</cell></row><row><cell>[379]</cell><cell>GPT-3</cell><cell>Text Entailment, Topic Classification,</cell><cell>ZS</cell><cell>General</cell><cell>English</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>Sentiment Analysis, Answer Type Classi-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>fication, Question Generation, Text Gen-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>eration</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[380]</cell><cell>GPT-3</cell><cell>Sentiment Analysis, Relation Extraction,</cell><cell>FS</cell><cell>General</cell><cell>English</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell>Named Entity Recognition</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[381]</cell><cell>GPT-3.5</cell><cell>Named Entity Recognition</cell><cell>ZS</cell><cell>Healthcare</cell><cell>English,</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>French,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Spanish,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Italian,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Basque</cell><cell></cell></row><row><cell>[382]</cell><cell>GPT-3.5</cell><cell>Text Summarization</cell><cell>ZS, FS</cell><cell>General</cell><cell>English</cell><cell>-</cell></row><row><cell>[383]</cell><cell>ChatGPT</cell><cell>Detection of Stance, Topics, Relevance,</cell><cell>ZS,FS</cell><cell>Social Media,</cell><cell>English</cell><cell>Yes</cell></row><row><cell></cell><cell></cell><cell>General Frame and Policy Frame</cell><cell></cell><cell>News</cell><cell></cell><cell></cell></row><row><cell>[324]</cell><cell>GPT-3</cell><cell>Radiology Text Simplification</cell><cell>FS</cell><cell>Healthcare</cell><cell>English</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>TABLE 18 .</head><label>18</label><figDesc>. Similar Summary of research works exploring GLLMs for paraphrasing-based data augmentation.</figDesc><table><row><cell>Paper</cell><cell>GLLMs Explored</cell><cell>Task(s)</cell><cell>Prompt</cell><cell>Domain(s)</cell><cell>Language(s)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Settings</cell><cell></cell><cell></cell></row><row><cell>[390]</cell><cell>ChatGPT</cell><cell>Intent Classification</cell><cell>ZS</cell><cell>General</cell><cell>English</cell></row><row><cell>[391]</cell><cell>ChatGPT</cell><cell>Machine Translation</cell><cell>ZS</cell><cell>General</cell><cell>Korean, Ger-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>man</cell></row><row><cell>[392]</cell><cell>GPT-3</cell><cell>Named Entity Recognition</cell><cell>ZS</cell><cell>News, Social Media,</cell><cell>English</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>General, Healthcare</cell><cell></cell></row><row><cell>[393]</cell><cell>ChatGPT, GPT-4</cell><cell>Question Answering</cell><cell>ZS</cell><cell>Healthcare</cell><cell>English</cell></row><row><cell>[394]</cell><cell>GPT-3</cell><cell>Text Classification</cell><cell>FS</cell><cell>General</cell><cell>English</cell></row><row><cell>[395]</cell><cell>ChatGPT</cell><cell>Medical Event Classification, Medication</cell><cell>ZS</cell><cell>Healthcare</cell><cell>English</cell></row><row><cell></cell><cell></cell><cell>Identification</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[143]</cell><cell>GPT-3</cell><cell>Intent Classification</cell><cell>ZS</cell><cell>Social Media</cell><cell>English</cell></row><row><cell>[396]</cell><cell>ChatGPT</cell><cell>Text Classification</cell><cell>ZS</cell><cell>General, Healthcare</cell><cell>English</cell></row><row><cell>[397]</cell><cell>ChatGPT</cell><cell>Open Intent Detection</cell><cell>ZS</cell><cell>General</cell><cell>English</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>TABLE 19 .</head><label>19</label><figDesc>Summary of research works exploring GLLMs for data generation-based data augmentation. Here ZS represents zero-shot and FS represents few-shot.</figDesc><table><row><cell></cell><cell>GLLMs Explored</cell><cell>Task(s)</cell><cell>Prompt</cell><cell>Domain(s)</cell><cell>Language(s)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Settings</cell><cell></cell><cell></cell></row><row><cell>[409]</cell><cell>ChatGPT</cell><cell>Text Classification</cell><cell>ZS</cell><cell>Social Media</cell><cell>Chinese</cell></row><row><cell>[410]</cell><cell>ChatGPT</cell><cell>Note2Dialogue Generation</cell><cell>ZS</cell><cell>Healthcare</cell><cell>English</cell></row><row><cell>[411]</cell><cell>GPT-3.5</cell><cell>Training Phi-1 LLM</cell><cell>ZS</cell><cell>Programming</cell><cell>English</cell></row><row><cell>[412]</cell><cell>ChatGPT, GPT-4</cell><cell>Cross-lingual Common Sense Rea-</cell><cell>FS</cell><cell>General</cell><cell>Multiple</cell></row><row><cell></cell><cell></cell><cell>soning</cell><cell></cell><cell></cell><cell>Languages</cell></row><row><cell>[413]</cell><cell>GPT-3</cell><cell>Hate Speech Detection</cell><cell>FS</cell><cell>Social Media</cell><cell>English</cell></row><row><cell>[414]</cell><cell>GPT-3</cell><cell>Undesired Context Detection</cell><cell>ZS, FS</cell><cell>Social Media</cell><cell>English</cell></row><row><cell>[415]</cell><cell>ChatGPT, GPT-4</cell><cell>Question Answering</cell><cell>ZS</cell><cell>Healthcare</cell><cell>English</cell></row><row><cell>[143]</cell><cell>GPT-3</cell><cell>Intent Classification</cell><cell>ZS</cell><cell>General</cell><cell>English</cell></row><row><cell>[416]</cell><cell>GPT-3.5, GPT-4</cell><cell>Training Smaller LLMs</cell><cell>ZS</cell><cell>General</cell><cell>English</cell></row><row><cell>[155]</cell><cell>GPT-3.5</cell><cell>Relation Extraction</cell><cell>FS</cell><cell>General, Scientific Literature</cell><cell>English</cell></row><row><cell>[417]</cell><cell>GPT-4</cell><cell>CoT Instruction Tuning</cell><cell>FS</cell><cell>General</cell><cell>English</cell></row><row><cell>[418]</cell><cell>GPT-4</cell><cell>Instruction Tuning</cell><cell>ZS</cell><cell>General</cell><cell>English, Chinese</cell></row><row><cell>[419]</cell><cell>GPT-3</cell><cell>Call segmentation, Topic extraction</cell><cell>ZS</cell><cell>Dialogue</cell><cell>English</cell></row><row><cell>[420]</cell><cell>GPT-3</cell><cell>Paraphrase Detection</cell><cell>ZS</cell><cell>General, Scientific Literature</cell><cell>English</cell></row><row><cell>[421]</cell><cell>ChatGPT</cell><cell>Tweet Intimacy Prediction</cell><cell>FS</cell><cell>Social Media</cell><cell>Multiple</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Languages</cell></row><row><cell>[422]</cell><cell>ChatGPT</cell><cell>Named Entity Recognition, Relation</cell><cell>ZS</cell><cell>Healthcare</cell><cell>English</cell></row><row><cell></cell><cell></cell><cell>Classification</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[423]</cell><cell>ChatGPT</cell><cell>Topic Classification</cell><cell>ZS</cell><cell>News, Social Media</cell><cell>English</cell></row><row><cell>[424]</cell><cell>ChatGPT</cell><cell>Neural Machine Translation</cell><cell>ZS</cell><cell>General</cell><cell>Multiple</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Languages</cell></row><row><cell>[425]</cell><cell>GPT-3, Codex</cell><cell>Table Question Answering</cell><cell>ZS</cell><cell>General</cell><cell>English</cell></row><row><cell>[426]</cell><cell>GPT-4</cell><cell>Text Generation Evaluation</cell><cell>ZS</cell><cell>General</cell><cell>Multiple</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Languages</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>TABLE 20 .</head><label>20</label><figDesc>Summary of research works exploring the detection of GLLM generated text.</figDesc><table><row><cell>Paper</cell><cell>Detect</cell><cell></cell><cell>Approach</cell><cell>Satisfactory</cell><cell>Training Free</cell><cell>Domain(s)</cell><cell></cell><cell>Language(s)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Performance</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[444]</cell><cell>ChatGPT</cell><cell></cell><cell>Evaluate multiple online tools</cell><cell>No</cell><cell>-</cell><cell cols="2">Multiple do-</cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>mains</cell><cell></cell></row><row><cell>[435]</cell><cell cols="2">GPT-3 generated</cell><cell>Classifiers based on machine learning</cell><cell>Yes</cell><cell>No</cell><cell cols="2">Scientific Lit-</cell><cell>English</cell></row><row><cell></cell><cell>text</cell><cell></cell><cell>models like LR, SVM and deep learning</cell><cell></cell><cell></cell><cell>erature</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>models like LSTM and BERT</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[436]</cell><cell>ChatGPT</cell><cell>and</cell><cell>Classifier based on random forest and</cell><cell>Yes</cell><cell>No</cell><cell cols="2">Scientific Lit-</cell><cell>Japanese</cell></row><row><cell></cell><cell cols="2">GPT-4 generated</cell><cell>stylometric features</cell><cell></cell><cell></cell><cell>erature</cell><cell></cell></row><row><cell></cell><cell>text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[439]</cell><cell>GPT-3</cell><cell>and</cell><cell>Classifier based on models like SVM and</cell><cell>Yes</cell><cell>No</cell><cell>Academic</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>ChatGPT</cell><cell></cell><cell>RoBERTa</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[437]</cell><cell>ChatGPT</cell><cell></cell><cell>Classifier based on models like RoBERTa</cell><cell>No</cell><cell>No</cell><cell cols="2">Scientific Lit-</cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>erature</cell><cell></cell></row><row><cell>[441]</cell><cell>ChatGPT</cell><cell></cell><cell>Classifier based on models like BERT</cell><cell>Yes</cell><cell>No</cell><cell>Healthcare</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[440]</cell><cell>ChatGPT</cell><cell></cell><cell>Evaluate multiple online tools</cell><cell>Yes</cell><cell>-</cell><cell>Academic</cell><cell></cell><cell>English,</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Spanish</cell></row><row><cell>[443]</cell><cell cols="2">GPT-3 generated</cell><cell>Evaluate human evaluators</cell><cell>No</cell><cell>-</cell><cell>Stories,</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>News,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Recipies</cell><cell></cell></row><row><cell>[442]</cell><cell>ChatGPT</cell><cell>and</cell><cell>Classifier based on models like BERT and</cell><cell>Yes</cell><cell>No</cell><cell>Law,</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell cols="2">GPT-4 generated</cell><cell>RoBERTa</cell><cell></cell><cell></cell><cell>Medical,</cell><cell></cell></row><row><cell></cell><cell>text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dialogue,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>General</cell><cell></cell></row><row><cell>[438]</cell><cell cols="2">GPT-3.5, ChatGPT</cell><cell>Training free divergent N-gram Analysis</cell><cell>Yes</cell><cell>Yes</cell><cell>Healthcare,</cell><cell></cell><cell>English, Ger-</cell></row><row><cell></cell><cell cols="2">and GPT-4 gener-</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Social Media,</cell><cell>man</cell></row><row><cell></cell><cell>ated text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Scientific</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Literature</cell><cell></cell></row><row><cell>[445]</cell><cell>ChatGPT</cell><cell></cell><cell>Evaluate the robustness of existing detec-</cell><cell>No</cell><cell>-</cell><cell>General</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell>tors</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[446]</cell><cell>ChatGPT</cell><cell></cell><cell>Evaluate existing plagiarism tools</cell><cell>No</cell><cell>-</cell><cell>General</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[447]</cell><cell>ChatGPT</cell><cell></cell><cell>Propose benchmark and evaluate exist-</cell><cell>Yes</cell><cell>-</cell><cell>General</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell>ing detectors</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[432]</cell><cell>ChatGPT</cell><cell></cell><cell>Propose novel approach based on Distil-</cell><cell>Yes</cell><cell>No</cell><cell>Social Media</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell>BERT and SHAP to detect and explain</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[429]</cell><cell>ChatGPT</cell><cell></cell><cell>Introduce new dataset and evaluate mul-</cell><cell>Yes</cell><cell>-</cell><cell>General,</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell>tiple existing detection models</cell><cell></cell><cell></cell><cell>Finance,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Healthcare,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Legal</cell><cell>,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Psychology</cell><cell></cell></row><row><cell>[448]</cell><cell>GPT-3</cell><cell>and</cell><cell>Propose FLAIR to detect online GPT-3</cell><cell>Yes</cell><cell>Yes</cell><cell>General</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell cols="2">ChatGPT-based</cell><cell>and ChatGPT-based bots</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>bots</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[449]</cell><cell>ChatGPT</cell><cell></cell><cell>Classifiers based on models like</cell><cell>Yes</cell><cell>No</cell><cell>General</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell>RoBERTa and T5</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[428]</cell><cell>ChatGPT</cell><cell></cell><cell>Propose a zero-shot approach based on</cell><cell>Yes</cell><cell>Yes</cell><cell>General</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell>local optimality</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[450]</cell><cell>ChatGPT</cell><cell></cell><cell>Propose an approach based on Siamese</cell><cell>Yes</cell><cell>No</cell><cell>General</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell>Network and binary classifier</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[451]</cell><cell>ChatGPT</cell><cell></cell><cell>Trains classifier and polish ratio models</cell><cell>Yes</cell><cell>No</cell><cell>General</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>polished text</cell><cell></cell><cell>to detect and explain</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[452]</cell><cell>GPT-3.5</cell><cell></cell><cell>Evaluate robustness using paraphrase at-</cell><cell>No</cell><cell>-</cell><cell>General</cell><cell></cell><cell>English</cell></row><row><cell></cell><cell>generated text</cell><cell></cell><cell>tacks</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>https://crfm.stanford.edu/2023/03/13/alpaca.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>https://lmsys.org/blog/2023-03-30-vicuna/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The author would like to thank <rs type="person">Ajit Rajasekharan</rs> for his encouragement and support.</p></div>
			</div>
			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Code Repair ZS, FS Java Yes [252] GPT-3, ChatGPT Code Vulnerability Detection ZS Java No [253] ChatGPT Code Generation ZS Python No [254] ChatGPT Finding Failure-Inducing Test Cases ZS Python Yes [255] ChatGPT Code Generation ZS Java, C# No [256] GPT-4 Code Generation, Code Refactoring, Test Case Generation ZS Python No [257] ChatGPT, GPT-4 Code Generation ZS Python No [258] ChatGPT Code Explanation Generation ZS Python No [259] ChatGPT Code Generation ZS C++ No [260] Codex Code Documentation Generation ZS, FS Java, Python, PHP, GO, Ruby, JS Yes [261] GPT-3 Code Explanation Generation ZS C No [262] ChatGPT Code Generation ZS</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Paper</head><p>GLLMs Explored Task(s) Prompt Settings Robustness Domain(s) Language(s) <ref type="bibr" target="#b454">[455]</ref> GPT-3, GPT-3.5 Nine NLU Tasks ZS, FS Adversarial Input General English <ref type="bibr" target="#b455">[456]</ref> GPT-3.   <ref type="bibr" target="#b155">[156]</ref> achieved SOTA results in relation extraction with the GPT-RE framework. However, to increase the reliability of these models in real-world applications, especially in critical domains like medicine, it is essential to systematically study the robustness of these models in various scenarios. Adversarial robustness refers to the model's ability to maintain good performance even in the case of deliberately crafted instances <ref type="bibr" target="#b463">[464]</ref>, <ref type="bibr" target="#b464">[465]</ref>. These instances are called adversarial instances and are carefully designed by making subtle changes in the original inputs to deceive the model. Out-ofdistribution (OOD) instances refer to examples that differ significantly from the data distribution used to train the model <ref type="bibr" target="#b465">[466]</ref>. These instances fall outside the range of the model's training data and present challenges to the model's performance and generalization ability. Some of the recent research works focused on evaluating the robustness of GLLMs to out-of-distribution instances <ref type="bibr" target="#b455">[456]</ref>, <ref type="bibr" target="#b460">[461]</ref>, adversarial prompts <ref type="bibr" target="#b457">[458]</ref>- <ref type="bibr" target="#b459">[460]</ref> and adversarial inputs <ref type="bibr" target="#b424">[425]</ref>, <ref type="bibr" target="#b454">[455]</ref>, <ref type="bibr" target="#b456">[457]</ref>, <ref type="bibr" target="#b461">[462]</ref> in one or more natural language processing tasks. Table <ref type="table">21</ref> presents a summary of research works assessing GLLMs robustness to out-of-distribution instances, adversarial prompts and adversarial inputs.</p><p>Research works exploring GLLMs robustness. Some of the research works evaluated the robustness of GLLMs in specific tasks like semantic parsing <ref type="bibr" target="#b456">[457]</ref>, code generation <ref type="bibr" target="#b458">[459]</ref>, table question answering <ref type="bibr" target="#b424">[425]</ref>, multi-choice question answering <ref type="bibr" target="#b460">[461]</ref> and text-to-SQL generation <ref type="bibr" target="#b461">[462]</ref>. Zhuo et al. <ref type="bibr" target="#b456">[457]</ref> reported that Codexbased semantic parsers are not robust to adversarial examples, and the robustness can be enhanced using few-shot in-context learning. Shirafuji et al. <ref type="bibr" target="#b458">[459]</ref> studied the robustness of GPT-3 family models like Codex, In-structGPT, and ChatGPT to adversarial prompts in code generation task. The authors observed that InstructGPT and ChatGPT exhibit better robustness compared to Codex. However, there is much room for improvement, indicating that quality code generation requires welldesigned prompts. Zhao et al. <ref type="bibr" target="#b424">[425]</ref> proposed RobuT, a benchmark to systematically study the robustness of large language models to adversarial inputs in table question answering. The authors reported that GLLMs like GPT-3 and Codex exhibit better robustness than fine-tuned models. Moreover, the authors demonstrated that GLLM generated adversarial inputs can enhance the adversarial robustness of fine-tuned models. Liu et al. <ref type="bibr" target="#b460">[461]</ref> reported that ChatGPT and GPT-4 perform well in multiple choice question answering but struggle to answer out-of-distribution questions. Liu et al. <ref type="bibr" target="#b461">[462]</ref> showed that ChatGPT exhibits impressive zeroshot performance in Text-to-SQL generation. Moreover, ChatGPT demonstrates better robustness to adversarial inputs than SOTA models in text-to-SQL generation. Some of the research works evaluated the GLLM robustness in multiple natural language understanding and generation tasks <ref type="bibr" target="#b454">[455]</ref>, <ref type="bibr" target="#b455">[456]</ref>, <ref type="bibr" target="#b457">[458]</ref>, <ref type="bibr" target="#b459">[460]</ref>. Chen et al. <ref type="bibr" target="#b454">[455]</ref> assessed the robustness of GPT-3 and GPT-3.5 models on 21 datasets covering nine natural language understanding tasks. Here the authors used adversarial text transformations from TextFlint <ref type="bibr" target="#b466">[467]</ref>. The authors observed that the models are robust in tasks like machine reading comprehension and exhibit performance degradation of more than 35% in tasks like sentiment analysis and natural language inference. Wang et al. <ref type="bibr" target="#b455">[456]</ref> evaluated the robustness of GPT-3.5 and ChatGPT models on adversarial and out-of-distribution (OOD) samples on nine datasets covering four NLU tasks and machine translation. The authors observed that ChatGPT exhibits good performances on adversarial and OOD samples, but still, there is much room for improvement.</p><p>Zhu et al. <ref type="bibr" target="#b457">[458]</ref> developed PromptBench, a benchmark with more than 4k adversarial prompts to evaluate the robustness of large language models to adversarial prompts. The benchmark covers <ref type="bibr" target="#b12">13</ref>  uses BRIO <ref type="bibr" target="#b496">[497]</ref>, a contrastive learning-based method, to train smaller models like BART for text summarization and metrics like GPTScore <ref type="bibr" target="#b476">[477]</ref> or GPTRank for evaluation. The contrastive learning training method helps the model to effectively utilize the supervision signal offered by the reference LLMs. The evaluation showed that the proposed approach helps the smaller model to outperform LLMs like GPT-3 and ChatGPT. Gao et al. <ref type="bibr" target="#b478">[479]</ref> evaluated ChatGPT for text summarization using various human evaluation methods and reported that (i) ChatGPT-based evaluation is both costeffective and reproducible, unlike human evaluation, (ii) the performance of ChatGPT-based evaluation is highly dependent on the prompt design, and (iii) ChatGPT generated explanations correlates with its scores. Jain et al. <ref type="bibr" target="#b481">[482]</ref> explored the effectiveness of the GPT-3.5 model as a multi-dimensional evaluator of text summarization. The authors reported that using in-context learning, GPT-3.5-based evaluation achieves SOTA performances on factual consistency and relevance dimensions. Based on the evaluation of five datasets covering text summarization, story generation and data-to-text generation, Wang et al. <ref type="bibr" target="#b482">[483]</ref> reported that ChatGPT as an evaluator (i) exhibits good correlations with human scores, especially in the case of story generation task and (ii) is prompt sensitive. Bai et al. <ref type="bibr" target="#b483">[484]</ref> introduced a novel evaluation framework called Language-Model-asan-Examiner to evaluate open-ended questions. In this framework, GLLM acts as a knowledgeable examiner, generates questions using its own knowledge and then does the reference-free evaluation. Yang et al. <ref type="bibr" target="#b484">[485]</ref> developed the BigTrans model (based on LLaMA -13B model) with a multilingual translation capacity of more than 100 languages. GPT-4 based assessment showed that BigTrans performance is on par with ChatGPT and Google translate. Zheng et al. <ref type="bibr" target="#b485">[486]</ref> explored GPT-4 as a judge to evaluate open-ended question answering using two newly introduced benchmarks MT-Bench and Chatbot Arena. The experiment results showed that GPT-4 achieves more than 80</p><p>Unlike the above-discussed research works, which used direct prompting, some of the works explored advanced prompting to offer better guidance and context for the GLLM evaluator. Zhuo et al. <ref type="bibr" target="#b469">[470]</ref> developed a</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Ammus: A survey of transformer-based pretrained models in natural language processing</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Kalyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajasekharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sangeetha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.05542</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27" to="730" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ammu: a survey of transformer-based biomedical pretrained language models</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Kalyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajasekharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sangeetha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page">103982</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing</title>
		<meeting>the 2014 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the association for computational linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="655" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Recent advances in recurrent neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Salehinejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barfett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Colak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Valaee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.01078</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2014 Workshop on Deep Learning</title>
		<imprint>
			<date type="published" when="2014-12">December 2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Computational and Biological Learning Society</publisher>
		</imprint>
	</monogr>
	<note>in 3rd International Conference on Learning Representations (ICLR 2015</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Bert: Pretraining of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Self-supervised learning: Generative or contrastive</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="857" to="876" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A survey of self-supervised learning from multiple perspectives: Algorithms, theory, applications and future trends</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.05712</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Electra: Pretraining text encoders as discriminators rather than generators</title>
		<author>
			<persName><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Albert: A lite bert for self-supervised learning of language representations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Soricut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing</title>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deberta: Decoding-enhanced bert with disentangled attention</title>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5485" to="5551" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Palm: Scaling language modeling with pathways</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Training compute-optimal large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D L</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15556</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Glam: Efficient scaling of language models with mixture-of-experts</title>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5547" to="5569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Lamda: Language models for dialog applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08239</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.11446</idno>
		<title level="m">Scaling language models: Methods, analysis &amp; insights from training gopher</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Norick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Legresley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajbhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prabhumoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zerveas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Korthikanti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11990</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Bloom: A 176b-parameter open-access multilingual language model</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ilić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Castagné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gallé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05100</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scialom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hartshorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Saravia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Poulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kerkez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stojnic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09085</idno>
		<title level="m">Galactica: A large language model for science</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Opt: Open pre-trained transformer language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">V</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01068</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Llama: Open and efficient foundation language models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-A</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Azhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Llama 2: Open foundation and fine-tuned chat models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhosale</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Gpt-4 technical report</title>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lundberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.12712</idno>
		<title level="m">Sparks of artificial general intelligence: Early experiments with gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">A survey of large language models</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.18223</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">A survey for in-context learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.00234</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">A survey on evaluation of large language models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.03109</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Through the lens of core competency: Survey on evaluation of large language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.07902</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Aligning large language models with human: A survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.12966</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Trustworthy llms: a survey and guideline for evaluating large language models&apos; alignment</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Ton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Klochkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Taufiq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.05374</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A survey of safety and trustworthiness of large language models through the lens of verification and validation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bensalem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11391</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-C</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10403</idno>
		<title level="m">Towards reasoning in large language models: A survey</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Challenges and applications of large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kaddour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mozes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raileanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mchardy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.10169</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">A survey on model compression for large language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.07633</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">A survey on multimodal large language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.13549</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Recent trends in deep learning based natural language processing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ieee Computational intelligenCe magazine</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="55" to="75" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">1724</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A comprehensive survey on transfer learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="76" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A survey of the usages of deep learning for natural language processing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Otter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="604" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Pre-trained models: Past, present and future</title>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="225" to="250" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th annual meeting of the association of computational linguistics</title>
		<meeting>the 45th annual meeting of the association of computational linguistics</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="440" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A survey on semi-supervised learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Van Engelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="373" to="440" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A survey on multi-task learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5586" to="5609" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Ieee</publisher>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Unsupervised learning of sentence embeddings using compositional n-gram features</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pagliardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter</title>
		<title level="s">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="528" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/N18-1202" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06">Jun. 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shakeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Taropa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10403</idno>
		<title level="m">Palm 2 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A survey of transformers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Pre-trained models for natural language processing: A survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Technological Sciences</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1872" to="1897" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Roberta: A robustly optimized bert pretraining approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Pegasus: Pre-training with extracted gap-sentences for abstractive summarization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="11" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">A primer on pretrained multilingual language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Doddapaneni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kunchukuttan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.00676</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">mt5: A massively multilingual pre-trained text-to-text transformer</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Multilingual denoising pretraining for neural machine translation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="726" to="742" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Indicnlpsuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for indian languages</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kakwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kunchukuttan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Golla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gokul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="4948" to="4961" />
		</imprint>
	</monogr>
	<note>in Findings of the Association for Computational Linguistics: EMNLP 2020, 2020</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Cross-lingual language model pretraining</title>
		<author>
			<persName><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Bertweet: A pre-trained language model for english tweets</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Tweeteval: Unified benchmark and comparative evaluation for tweet classification</title>
		<author>
			<persName><forename type="first">F</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Anke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1644" to="1650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Finbert: A pretrained language model for financial communications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C S</forename><surname>Uy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.08097</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Finbert: Financial sentiment analysis with pre-trained language models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Araci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10063</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Finbert: A pretrained financial language representation model for financial text mining</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-ninth international conference on international joint conferences on artificial intelligence</title>
		<meeting>the twenty-ninth international conference on international joint conferences on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4513" to="4519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Legal-bert: The muppets straight out of law school</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fergadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Aletras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2898" to="2904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">A benchmark for lease contract review</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leivaditi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.10386</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Codebert: A pre-trained model for programming and natural languages</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1536" to="1547" />
		</imprint>
	</monogr>
	<note>in Findings of the Association for Computational Linguistics: EMNLP 2020, 2020</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Codet5: Identifieraware unified pre-trained encoder-decoder models for code understanding and generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8696" to="8708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Codet5+: Open code large language models for code understanding and generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Gotmare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.07922</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Domain-specific language model pretraining for biomedical natural language processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.15779</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Bioelectra: pretrained biomedical text encoder using discriminators</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kanakarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kundumani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sankarasubbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Workshop on Biomedical Language Processing</title>
		<meeting>the 20th Workshop on Biomedical Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="143" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Tinybert: Distilling bert for natural language understanding</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="4163" to="4174" />
		</imprint>
	</monogr>
	<note>in Findings of the Association for Computational Linguistics: EMNLP 2020, 2020</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Mobilebert: a compact task-agnostic bert for resource-limited devices</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2158" to="2170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.10957</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Longformer: The longdocument transformer</title>
		<author>
			<persName><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Big bird: Transformers for longer sequences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Guruganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ontanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ravula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Selfalignment pretraining for biomedical entity representations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shareghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Basaldella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4228" to="4238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Umlsbert: Clinical domain knowledge augmentation of contextual embeddings using the unified medical language system metathesaurus</title>
		<author>
			<persName><forename type="first">G</forename><surname>Michalopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.10391</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Artificial general intelligence: concept, state of the art, and future prospects</title>
		<author>
			<persName><forename type="first">B</forename><surname>Goertzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial General Intelligence</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Emergent abilities of large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Are emergent abilities of large language models a mirage?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schaeffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koyejo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.15004</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P D O</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Competition-level code generation with alphacode</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Eccles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lago</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="issue">6624</biblScope>
			<biblScope unit="page" from="1092" to="1097" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Improving alignment of dialogue agents via targeted human judgements</title>
		<author>
			<persName><forename type="first">A</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trebacz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Firoiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ewalds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Weidinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chadwick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Thacker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.14375</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">Ernie 3.0 titan: Exploring larger-scale knowledge enhanced pre-training for language understanding and generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.12731</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Jurassic-1: Technical details and evaluation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Lieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sharir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">White Paper. AI21 Labs</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Alexatm 20b: Few-shot learning using a large-scale multilingual seq2seq model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Soltan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ananthakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rawls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rumshisky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.01448</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">Opt-iml: Scaling language model instruction meta learning through the lens of generalization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">V</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Simig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Koura</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.12017</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Crosslingual generalization through multitask finetuning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-X</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schoelkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.01786</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Jais and jais-chat: Arabic-centric foundation and instruction-tuned open generative large language models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katipomu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Koto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kamboj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pandit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2308.16149</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Glm-130b: An open bilingual pre-trained model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Flm-101b: An open llm and how to train it with 100 k budget</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.03852</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Fingpt: Open-source financial large language models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.06031</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dabravolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kambadur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17564</idno>
		<title level="m">Bloomberggpt: A large language model for finance</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Large language models encode clinical knowledge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tanwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cole-Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pfohl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">Towards expertlevel medical question answering with large language models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gottweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sayres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wulczyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pfohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cole-Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Neal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.09617</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Allal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kocetkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.06161</idno>
		<title level="m">Starcoder: may the source be with you!</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title level="m" type="main">Code llama: Open foundation models for code</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gloeckle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sootla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">E</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Adi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Remez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rapin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.12950</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Codegen: An open large language model for code with multi-turn program synthesis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title level="m" type="main">Codegen2: Lessons for training llms on programming and natural languages</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.02309</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<title level="m" type="main">Learning to generate reviews and discovering sentiment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01444</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title level="m" type="main">Investigating chain-of-thought with chatgpt for stance detection on social media</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03087</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Evaluation of chatgpt for nlp-based mental health applications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lamichhane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.15727</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">On the evaluations of chatgpt and emotion-enhanced prompting for mental health analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03347</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<title level="m" type="main">Is chatgpt a good sentiment analyzer? a preliminary study</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.04339</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<title level="m" type="main">Can chatgpt forecast stock price movements? return predictability and large language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lopez-Lira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.07619</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<title level="m" type="main">Can large language models transform computational social science?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ziems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shaikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.03514</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<title level="m" type="main">Chatgpt: Beginning of an end of manual annotation? use case of automatic genre identification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kuzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ljubešić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mozetič</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.03953</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title level="m" type="main">A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wilie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lovenia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.04023</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title level="m" type="main">Chatgpt: Jack of all trades, master of none</title>
		<author>
			<persName><forename type="first">J</forename><surname>Koco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cichecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kaszyca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kochanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Szydło</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Baran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bielaniewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gruza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Janz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kanclerz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.10724</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<title level="m" type="main">Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.10198</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">A comprehensive capability analysis of gpt-3 and gpt-3.5 series models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.10420</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Are chatgpt and gpt-4 general-purpose solvers for financial text analytics? an examination on several typical tasks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.05862</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<title level="m" type="main">Exploring the trade-offs: Unified large language models vs local fine-tuned models for highly-specific radiology nli task</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.09138</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Are large language models ready for healthcare? a comparative study on clinical language understanding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Petzold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05368</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title level="m" type="main">Detecting hate speech with gpt-3</title>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alexander</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12407</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<title level="m" type="main">Is chatgpt better than human annotators? potential and limitations of chatgpt in explaining implicit hate speech</title>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>An</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.07736</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">Evaluation of chatgpt family of models for biomedical reasoning and classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Aerts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Bitterman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.02496</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Will affective computing emerge from foundation models and general ai? a first evaluation on chatgpt</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Schuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<title level="m" type="main">Exploring zero and few-shot techniques for intent classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Vohra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tumbade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tiwari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.07157</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b143">
	<monogr>
		<title level="m" type="main">Text classification via large language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08377</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">A survey on text classification: From traditional to deep learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<author>
			<persName><forename type="first">C.-E</forename><surname>González-Gallardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Girdhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17322</idno>
		<title level="m">Yes but.. can chatgpt identify entities in historical documents?</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">Zero-shot clinical entity recognition using chatgpt</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ameer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.16416</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<title level="m" type="main">Zero-shot information extraction via chatting with chatgpt</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.10205</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Thinking about gpt-3 in-context learning for biomedical ie? think again</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Gutiérrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mcneal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Washington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4497" to="4512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<title level="m" type="main">Exploring the feasibility of chatgpt for event extraction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.03836</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<title level="m" type="main">Evaluation of gpt and bert-based models on identifying protein-protein interactions in biomedical text</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rehana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Basmaci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Özg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17728</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<title level="m" type="main">Zero-shot temporal relation extraction with chatgpt</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05454</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">Evaluating chatgpt&apos;s information extraction capabilities: An assessment of performance, explainability, calibration, and faithfulness</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.11633</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b153">
	<monogr>
		<title level="m" type="main">Chatgpt evaluation on sentence level relations: A focus on temporal, causal, and discourse relations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.14827</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<title level="m" type="main">How to unleash the power of large language models for few-shot relation extraction?</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.01555</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b155">
	<monogr>
		<title level="m" type="main">Gpt-re: In-context learning for relation extraction using large language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kurohashi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.02105</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b156">
	<monogr>
		<title level="m" type="main">Is chatgpt a general-purpose natural language processing task solver?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.06476</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<title level="m" type="main">Large language model is not a good few-shot information extractor, but a good reranker for hard samples</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08559</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b158">
	<monogr>
		<title level="m" type="main">Gpt-ner: Named entity recognition via large language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.10428</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Heroes, villains, and victims, and gpt-3: Automated extraction of character roles without training data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Stammbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Antoniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop of Narrative Understanding</title>
		<meeting>the 4th Workshop of Narrative Understanding</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="47" to="56" />
		</imprint>
		<respStmt>
			<orgName>WNU2022</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<monogr>
		<title level="m" type="main">Revisiting relation extraction in the era of large language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wadhwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.05003</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b161">
	<monogr>
		<title level="m" type="main">Codeie: Large code generation models are better few-shot information extractors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.05711</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b162">
	<monogr>
		<title level="m" type="main">Aligning instruction tasks unlocks large language models as zero-shot relation extractors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Gutiérrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11159</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Unified structure generation for universal information extraction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5755" to="5772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Learning from sibling mentions with scalable graph inference in fine-grained entity typing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2076" to="2087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Container: Few-shot named entity recognition via contrastive learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6338" to="6353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Enriching pre-trained language model with entity information for relation classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM international conference on information and knowledge management</title>
		<meeting>the 28th ACM international conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2361" to="2364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Packed levitated marker for entity and relation extraction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4904" to="4917" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Knowledgeenhanced self-supervised prototypical network for few-shot event detection</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6266" to="6275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Prompt for extraction? paie: Prompting argument interaction for event argument extraction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6759" to="6774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Event extraction by answering (almost) natural questions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="671" to="683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Calibrate before use: Improving few-shot performance of language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12" to="697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alipoormolabashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mirzaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ashok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Dhanasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arunkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5085" to="5109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Conversational question answering: A survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">Z</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3151" to="3195" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Improving graph-based random walks for complex question answering using syntactic, shallow semantic and extended string subsequence kernels</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Joty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="843" to="855" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<monogr>
		<title level="m" type="main">Natural language processing advancements by deep learning: A survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Torfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Shirvani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Keneshloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tavaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.01200</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b176">
	<monogr>
		<title level="m" type="main">Evaluating gpt-3.5 and gpt-4 models on brazilian university admission exams</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nunes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Primi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lotufo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17003</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<title level="m" type="main">Evaluation of chatgpt as a question answering system for answering complex questions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.07992</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">An empirical study of gpt-3 for few-shot knowledge-based vqa</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="3081" to="3089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<monogr>
		<title level="m" type="main">Towards zero-shot and few-shot table question answering using gpt-3</title>
		<author>
			<persName><forename type="first">P</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ganu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.17284</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b180">
	<monogr>
		<title level="m" type="main">Why does chatgpt fall short in answering questions faithfully?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-C</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.10513</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Assessing the accuracy of responses by the language model chatgpt to questions regarding bariatric surgery</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Samaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rajeev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hawley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Obesity surgery</title>
		<imprint>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Evaluating large language models on a highly-specialized topic, radiation oncology physics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Sio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Mcgee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Ashman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Oncology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">1219326</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<monogr>
		<title level="m" type="main">Chatgpt-a blessing or a curse for undergraduate computer science students and instructors?</title>
		<author>
			<persName><forename type="first">I</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Budhiraja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Ataullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Akolekar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.14993</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b184">
	<monogr>
		<title level="m" type="main">Capabilities of gpt-4 on medical challenge problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mckinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carignan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13375</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b185">
	<monogr>
		<title level="m" type="main">Evaluation of ai chatbots for patientspecific ehr questions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hamidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.02549</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b186">
	<monogr>
		<title level="m" type="main">Large language models (gpt) struggle to answer multiple-choice questions about code</title>
		<author>
			<persName><forename type="first">J</forename><surname>Savelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bogart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sakr</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08033</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b187">
	<monogr>
		<title level="m" type="main">Gpt takes the bar exam</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bommarito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Katz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.14402</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Visconde: Multi-document qa with gpt-3 and neural reranking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fidalgo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lotufo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="534" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Performance of chatgpt on the plastic surgery inservice training examination</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weisberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Firouzbakht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ocon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Mailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aesthetic surgery journal</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Performance of generative pretrained transformer on the national medical licensing examination in japan</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nakata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Etani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muramatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kawai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Higashino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Enomoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Noda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">medRxiv</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2024" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Leveraging large language models for multiple choice question answering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wingate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<monogr>
		<title level="m" type="main">Large language models need holistically thought in medical conversational qa</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.05410</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Truthfulqa: Measuring how models mimic human falsehoods</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3214" to="3252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<monogr>
		<title level="m" type="main">Evaluating gpt-4 and chatgpt on japanese medical licensing examinations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.18027</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b195">
	<monogr>
		<title level="m" type="main">Linguistically informed chatgpt prompts to enhance japanese-chinese machine translation: A case study on attributive clauses</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.15587</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b196">
	<monogr>
		<title level="m" type="main">Towards making the most of chatgpt for machine translation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13780</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b197">
	<monogr>
		<title level="m" type="main">Is chatgpt a good translator? yes with gpt-4 as the engine</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.08745</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b198">
	<monogr>
		<title level="m" type="main">How good are gpt models at machine translation? a comprehensive evaluation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hendy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abdelrehim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Raunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Afify</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Awadalla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.09210</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b199">
	<monogr>
		<title level="m" type="main">How to design translation prompts for chatgpt: An empirical study</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">2304</biblScope>
		</imprint>
	</monogr>
	<note>arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b200">
	<monogr>
		<title level="m" type="main">Document-level machine translation with large language models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.02210</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b201">
	<monogr>
		<title level="m" type="main">Multilingual machine translation with large language models: Empirical results and analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.04675</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b202">
	<monogr>
		<title level="m" type="main">New trends in machine translation using large language models: Case examples with chatgpt</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.01181</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b203">
	<monogr>
		<title level="m" type="main">Large language models effectively leverage document-level context for literary translation, but critical errors persist</title>
		<author>
			<persName><forename type="first">M</forename><surname>Karpinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03245</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b204">
	<monogr>
		<title level="m" type="main">Adaptive machine translation with large language models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Moslem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Way</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.13294</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b205">
	<monogr>
		<title level="m" type="main">Exploring human-like translation strategy with large language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.04118</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b206">
	<monogr>
		<title level="m" type="main">Leveraging gpt-4 for automatic translation post-editing</title>
		<author>
			<persName><forename type="first">V</forename><surname>Raunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Menezes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14878</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b207">
	<monogr>
		<title level="m" type="main">Do gpts produce less literal translations?</title>
		<author>
			<persName><forename type="first">V</forename><surname>Raunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Awadallah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.16806</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">Neural machine translation: A review</title>
		<author>
			<persName><forename type="first">F</forename><surname>Stahlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="343" to="418" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">A survey of deep learning techniques for neural machine translation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<idno>abs/2002.07526</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Neural machine translation: A review of methods, resources, and tools</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5" to="21" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<monogr>
		<title level="m" type="main">Multilingual translation with extensible multilingual pretraining and finetuning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.00401</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Beyond english-centric multilingual machine translation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>El-Kishky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>¸elebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Liptchinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<idno>abs/2010.11125</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<monogr>
		<title level="m" type="main">No language left behind: Scaling human-centered machine translation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>¸elebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elbayad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Heffernan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kalbassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Licht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Maillard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.04672</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b215">
	<monogr>
		<title level="m" type="main">Chatgpt vs state-of-the-art models: A benchmarking study in keyphrase generation task</title>
		<author>
			<persName><forename type="first">R</forename><surname>Martínez-Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Ópez-L Ópez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Portela</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.14177</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b216">
	<monogr>
		<title level="m" type="main">Is chatgpt a good keyphrase generator? a preliminary study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13001</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b217">
	<monogr>
		<title level="m" type="main">A preliminary evaluation of chatgpt for zero-shot dialogue understanding</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.04256</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b218">
	<monogr>
		<title level="m" type="main">Is chatgpt equipped with emotional dialogue capabilities?</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.09582</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">Medically aware gpt-3 as a data generator for medical dialogue summarization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chintagunta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Katariya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Amatriain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kannan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Healthcare Conference</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="354" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<analytic>
		<title level="a" type="main">Prompt scoring system for dialogue summarization using gpt-3</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Prodan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pelican</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transaction on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<monogr>
		<title level="m" type="main">Understanding the effectiveness of very large language models on dialog evaluation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.12004</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b222">
	<monogr>
		<title level="m" type="main">Uncovering the potential of chatgpt for discourse analysis in dialogue: An empirical study</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08391</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b223">
	<monogr>
		<title level="m" type="main">Chain-of-thought prompting for responding to in-depth dialogue questions with llm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Wong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11792</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b224">
	<analytic>
		<title level="a" type="main">An empirical study on neural keyphrase generation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4985" to="5007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<analytic>
		<title level="a" type="main">One size does not fit all: Generating and evaluating variable number of keyphrases</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Thaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brusilovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7961" to="7975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<analytic>
		<title level="a" type="main">Learning rich representation of keyphrases from text</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mahata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhowmik</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.findings-naacl.67" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: NAACL 2022</title>
		<meeting><address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-07">Jul. 2022</date>
			<biblScope unit="page" from="891" to="906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title level="a" type="main">A survey of available corpora for building data-driven dialogue systems: The journal version</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue &amp; Discourse</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="49" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<monogr>
		<title level="m" type="main">A survey of intent classification and slot-filling datasets for task-oriented dialog</title>
		<author>
			<persName><forename type="first">S</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.13211</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b229">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.09542</idno>
		<title level="m">Is chatgpt good at search? investigating large language models as reranking agent</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b230">
	<monogr>
		<title level="m" type="main">Large language models are built-in autoregressive search engines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ziems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.09612</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b231">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Idahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.02405</idno>
		<title level="m">Explainable information retrieval: A survey</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b232">
	<monogr>
		<title level="m" type="main">Document ranking with a pretrained sequence-to-sequence model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="708" to="718" />
		</imprint>
	</monogr>
	<note>in Findings of the Association for Computational Linguistics: EMNLP 2020, 2020</note>
</biblStruct>

<biblStruct xml:id="b233">
	<analytic>
		<title level="a" type="main">Beir: A heterogeneous benchmark for zero-shot evaluation of information retrieval models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ücklé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<monogr>
		<title level="m" type="main">Dense text retrieval based on pretrained language models: A survey</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.14876</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b235">
	<analytic>
		<title level="a" type="main">Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="734" to="749" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<monogr>
		<title level="m" type="main">A survey on modern recommendation system based on big data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.02631</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b237">
	<analytic>
		<title level="a" type="main">A survey of attack detection approaches in collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rezaimehr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dadkhah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="2011" to="2066" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b238">
	<monogr>
		<title level="m" type="main">Rethinking multi-interest learning for candidate matching in recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.14532</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b239">
	<analytic>
		<title level="a" type="main">An interactive knowledge-based recommender system for fashion product design in the big data environment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Koehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">540</biblScope>
			<biblScope unit="page" from="469" to="488" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<monogr>
		<title level="m" type="main">Chat-rec: Towards interactive and explainable llms-augmented recommender system</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.14524</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b241">
	<monogr>
		<title level="m" type="main">Crossdomain recommendation: challenges, progress, and prospects</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.01696</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b242">
	<monogr>
		<title level="m" type="main">Zero-shot next-item recommendation using large pretrained language models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-P</forename><surname>Lim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03153</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b243">
	<monogr>
		<title level="m" type="main">Bookgpt: A general framework for book recommendation empowered by large language model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhiyuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.15673</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b244">
	<monogr>
		<title level="m" type="main">Is chatgpt a good recommender? a preliminary study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.10149</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b245">
	<monogr>
		<title level="m" type="main">Uncovering chatgpt&apos;s capabilities in recommender systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.02182</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b246">
	<monogr>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sathiamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.06474</idno>
		<title level="m">Do llms understand user preferences? evaluating llms on user rating prediction</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b247">
	<monogr>
		<title level="m" type="main">Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.07609</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b248">
	<monogr>
		<title level="m" type="main">Large language models are zero-shot rankers for recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08845</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b249">
	<monogr>
		<title level="m" type="main">Large language model augmented narrative driven recommendations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mysore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zamani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.02250</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b250">
	<monogr>
		<title level="m" type="main">Keep the conversation going: Fixing 162 out of 337 bugs for 0.42 each using chatgpt</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.00385</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b251">
	<monogr>
		<title level="m" type="main">Evaluation of chatgpt model for vulnerability detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cheshkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zadorozhny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Levichev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.07232</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b252">
	<monogr>
		<title level="m" type="main">Evaluating the code quality of ai-assisted code generation tools: An empirical study on github copilot, amazon codewhisperer, and chatgpt</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yetis ¸tiren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Özsoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ayerdem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Üz Ün</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.10778</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b253">
	<monogr>
		<title level="m" type="main">Finding failure-inducing test cases with chatgpt</title>
		<author>
			<persName><forename type="first">T.-O</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Cheung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.11686</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b254">
	<monogr>
		<title level="m" type="main">Improving chatgpt prompt for code generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08360</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b255">
	<monogr>
		<title level="m" type="main">Ai-assisted coding: Experiments with gpt-4</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Poldrack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Beguš</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.13187</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b256">
	<monogr>
		<title level="m" type="main">Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.01210</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b257">
	<monogr>
		<title level="m" type="main">Gptutor: a chatgpt-powered programming tool for code explanation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-Y</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.01863</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b258">
	<monogr>
		<title level="m" type="main">Comparing software developers with chatgpt: An empirical investigation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nascimento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alencar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cowan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11837</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b259">
	<analytic>
		<title level="a" type="main">Automatic code documentation generation using gpt-3</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Uddin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering</title>
		<meeting>the 37th IEEE/ACM International Conference on Automated Software Engineering</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b260">
	<monogr>
		<title level="m" type="main">Comparing code explanations created by students and large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leinonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Denny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Macneil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sarsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hellas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03938</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b261">
	<monogr>
		<author>
			<persName><forename type="first">X.-Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-T</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10679</idno>
		<title level="m">Think outside the code: Brainstorming boosts large language models in code generation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b262">
	<monogr>
		<title level="m" type="main">Automatic program repair with openai&apos;s codex: Evaluating quixbugs</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Prenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Robbes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.03922</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b263">
	<analytic>
		<title level="a" type="main">Exploring the effectiveness of large language models in generating unit tests</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Siddiq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C S</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Tanvir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ulfat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Rifat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Lopes</surname></persName>
		</author>
		<idno>abs/2305.00418</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b264">
	<monogr>
		<title level="m" type="main">Is chatgpt the ultimate programming assistant-how far is it?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Bissyandé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.11938</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b265">
	<analytic>
		<title level="a" type="main">An empirical study on using large language models for multi-intent comment generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<idno>abs/2304.11384</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b266">
	<monogr>
		<title level="m" type="main">Explainable automated debugging via large language model-driven scientific debugging</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Lou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.02195</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b267">
	<analytic>
		<title level="a" type="main">Chatgpt for programming numerical methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kashefi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mukerji</surname></persName>
		</author>
		<idno>abs/2303.12093</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b268">
	<monogr>
		<title level="m" type="main">A preliminary analysis on the code generation capabilities of gpt-3.5 and bard ai models for java functions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Destefanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bartolucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ortu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.09402</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b269">
	<analytic>
		<title level="a" type="main">No more manual tests? evaluating and improving chatgpt for unit test generation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<idno>abs/2305.04207</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b270">
	<analytic>
		<title level="a" type="main">Generative ai for programming education: Benchmarking chatgpt, gpt-4, and human tutors</title>
		<author>
			<persName><forename type="first">T</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V.-A</forename><surname>Padurean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Cambronero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soares</surname></persName>
		</author>
		<idno>abs/2306.17156</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b271">
	<monogr>
		<title level="m" type="main">Large language models for software engineering: A systematic literature review</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grundy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.10620</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b272">
	<analytic>
		<title level="a" type="main">Codexglue: A machine learning benchmark dataset for code understanding and generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Svyatkovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
	<note>Round 1</note>
</biblStruct>

<biblStruct xml:id="b273">
	<analytic>
		<title level="a" type="main">Cotext: Multi-task learning with code-text transformer</title>
		<author>
			<persName><forename type="first">L</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Annibal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Peltekian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Natural Language Processing for Programming</title>
		<meeting>the 1st Workshop on Natural Language Processing for Programming</meeting>
		<imprint>
			<date type="published" when="2021">4Prog 2021. 2021</date>
			<biblScope unit="page" from="40" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b274">
	<analytic>
		<title level="a" type="main">Graphcodebert: Pretraining code representations with data flow</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shujie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Svyatkovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b275">
	<analytic>
		<title level="a" type="main">Unified pre-training for program understanding and generation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
		<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2655" to="2668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b276">
	<monogr>
		<title level="m" type="main">Cert: Continual pre-training on sketches for library-oriented code generation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Lou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.06888</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b277">
	<analytic>
		<title level="a" type="main">Defects4j: A database of existing faults to enable controlled testing studies for java programs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Just</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 international symposium on software testing and analysis</title>
		<meeting>the 2014 international symposium on software testing and analysis</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="437" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b278">
	<analytic>
		<title level="a" type="main">Quixbugs: A multi-lingual program repair benchmark set based on the quixey challenge</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Solar-Lezama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Companion of the 2017 ACM SIGPLAN international conference on systems, programming, languages, and applications: software for humanity</title>
		<meeting>Companion of the 2017 ACM SIGPLAN international conference on systems, programming, languages, and applications: software for humanity</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="55" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b279">
	<analytic>
		<title level="a" type="main">Multimodal conversational ai: A survey of datasets and approaches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on NLP for Conversational AI</title>
		<meeting>the 4th Workshop on NLP for Conversational AI</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="131" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b280">
	<analytic>
		<title level="a" type="main">Multimodal learning with transformers: A survey</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Clifton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b281">
	<analytic>
		<title level="a" type="main">Prompting large language models with answer heuristics for knowledge-based visual question answering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">983</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b282">
	<monogr>
		<title level="m" type="main">Revive: Regional visual representation matters in knowledge-based visual question answering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.01201</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b283">
	<analytic>
		<title level="a" type="main">Kat: A knowledge augmented transformer for visionand-language</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter</title>
		<meeting>the 2022 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="956" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b284">
	<monogr>
		<title level="m" type="main">Llmscore: Unveiling the power of large language models in text-to-image synthesis evaluation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11116</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b285">
	<monogr>
		<title level="m" type="main">Collaborative generative ai: Integrating gpt-k for efficient editing in text-to-image generation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11317</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b286">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.18583</idno>
		<title level="m">Controllable text-to-image generation with gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b287">
	<monogr>
		<title level="m" type="main">Large language models are frame-level directors for zero-shot text-to-video generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14330</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b288">
	<monogr>
		<title level="m" type="main">Audiogpt: Understanding and generating speech, music, sound, and talking head</title>
		<author>
			<persName><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.12995</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b289">
	<monogr>
		<title level="m" type="main">Retrieval augmented chest x-ray report generation using openai gpt models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranjit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ganapathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ganu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.03660</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b290">
	<monogr>
		<title level="m" type="main">Action-gpt: Leveraging large-scale language models for improved and generalized zero shot action generation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Kalakonda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maheshwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Sarvadevabhatla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.15603</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b291">
	<monogr>
		<title level="m" type="main">Visual chatgpt: Talking, drawing and editing with visual foundation models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.04671</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b292">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Azarnasab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.11381</idno>
		<title level="m">Mm-react: Prompting chatgpt for multimodal reasoning and action</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b293">
	<monogr>
		<title level="m" type="main">Prompt chatgpt in mner: Improved multimodal named entity recognition method based on auxiliary refining knowledge from chatgpt</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.12212</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b294">
	<monogr>
		<title level="m" type="main">Images in language space: Exploring the suitability of large language models for vision &amp; language tasks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hakimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schlangen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13782</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b295">
	<monogr>
		<title level="m" type="main">Layoutgpt: Compositional visual planning and generation with large language models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>-J. Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Akula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.15393</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b296">
	<monogr>
		<title level="m" type="main">Improving clip training with language rewrites</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.20088</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b297">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.00890</idno>
		<title level="m">Llava-med: Training a large language-and-vision assistant for biomedicine in one day</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b298">
	<monogr>
		<title level="m" type="main">A video is worth 4096 tokens: Verbalize story videos to understand them in zero shot</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.09758</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b299">
	<monogr>
		<title level="m" type="main">Wavcaps: A chatgpt-assisted weakly-labelled audio captioning dataset for audio-language multimodal research</title>
		<author>
			<persName><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Plumbley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17395</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b300">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11000</idno>
		<title level="m">Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b301">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.16103</idno>
		<title level="m">Chatbridge: Bridging modalities with large language model as a language catalyst</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b302">
	<monogr>
		<title level="m" type="main">Can gpt-4 perform neural architecture search?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Albanie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.10970</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b303">
	<monogr>
		<title level="m" type="main">Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17580</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b304">
	<monogr>
		<title level="m" type="main">Mlcopilot: Unleashing the power of large language models in solving machine learning tasks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.14979</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b305">
	<monogr>
		<title level="m" type="main">Automlgpt: Automatic machine learning with gpt</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.02499</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b306">
	<monogr>
		<title level="m" type="main">Automated machine learning: methods, systems, challenges</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kotthoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanschoren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Springer Nature</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b307">
	<monogr>
		<title level="m" type="main">Gpt3-toplan: Extracting plans from text using gpt-3</title>
		<author>
			<persName><forename type="first">A</forename><surname>Olmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sreedharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kambhampati</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.07131</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b308">
	<monogr>
		<title level="m" type="main">Large language models as zero-shot human models for human-robot interaction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Soh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.03548</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b309">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Soh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.05128</idno>
		<title level="m">Translating natural language to planning goals with large-language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b310">
	<monogr>
		<title level="m" type="main">Chain-ofsymbol prompting elicits planning in large langauge models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10276</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b311">
	<analytic>
		<title level="a" type="main">Large language models still can&apos;t plan (a benchmark for llms on planning and reasoning about change)</title>
		<author>
			<persName><forename type="first">K</forename><surname>Valmeekam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Olmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sreedharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kambhampati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2022 Foundation Models for Decision Making Workshop</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b312">
	<monogr>
		<title level="m" type="main">Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.05718</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b313">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Mahowald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Blank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fedorenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.06627</idno>
		<title level="m">Dissociating language and thought in large language models: a cognitive perspective</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b314">
	<analytic>
		<title level="a" type="main">Medical concept normalization in user-generated texts by learning target concept embeddings</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Kalyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sangeetha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Health Text Mining and Information Analysis</title>
		<meeting>the 11th International Workshop on Health Text Mining and Information Analysis</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="18" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b315">
	<analytic>
		<title level="a" type="main">The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Deep Learning Inside Out</title>
		<meeting>Deep Learning Inside Out</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="64" to="73" />
		</imprint>
	</monogr>
	<note>Target concept guided medical concept normalization in noisy user-generated texts</note>
</biblStruct>

<biblStruct xml:id="b316">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Sio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Mcgee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Ashman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.01938</idno>
		<title level="m">Evaluating large language models on a highly-specialized topic, radiation oncology physics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b317">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.11032</idno>
		<title level="m">Deid-gpt: Zero-shot medical text deidentification by gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b318">
	<analytic>
		<title level="a" type="main">Wanglab at mediqa-chat 2023: Clinical note generation from doctor-patient conversations using large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Toma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Clinical Natural Language Processing Workshop</title>
		<meeting>the 5th Clinical Natural Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="323" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b319">
	<analytic>
		<title level="a" type="main">Capabilities of gpt-4 on medical challenge problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mckinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carignan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<idno>abs/2303.13375</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b320">
	<monogr>
		<title level="m" type="main">Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Keloth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.16326</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b321">
	<monogr>
		<title level="m" type="main">Performance of generative pretrained transformer on the national medical licensing examination in japan</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nakata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Etani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muramatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kawai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Higashino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Enomoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Noda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kometani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yoneda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kakizaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nomura</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>in medRxiv</note>
</biblStruct>

<biblStruct xml:id="b322">
	<monogr>
		<title level="m" type="main">Benchmarking large language models on cmexam-a comprehensive chinese medical exam dataset</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.03030</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b323">
	<analytic>
		<title level="a" type="main">Data augmentation for radiology report simplification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vucetic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EACL 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1877" to="1887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b324">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.08448</idno>
		<title level="m">Impressiongpt: an iterative optimizing framework for radiology report summarization with chatgpt</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b325">
	<monogr>
		<title level="m" type="main">Gpt-3 models are poor few-shot learners in the biomedical domain</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moradi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Blagec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Haberl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Samwald</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.02555</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b326">
	<monogr>
		<title level="m" type="main">Chatgpt makes medicine easy to swallow: An exploratory case study on simplified radiology reports</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jeblick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schachtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dexl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mittermeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>St Über</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Topalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wesp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ricke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.14882</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b327">
	<monogr>
		<title level="m" type="main">Gersteinlab at mediqachat 2023: Clinical note summarization from doctor-patient conversations through fine-tuning and in-context learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gerstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.05001</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b328">
	<analytic>
		<title level="a" type="main">Large language models are few-shot clinical information extractors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hegselmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1998" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b329">
	<monogr>
		<title level="m" type="main">Generating medicallyaccurate summaries of patient-provider dialogue: A multistage approach using large language models</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schumacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kannan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.05982</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b330">
	<monogr>
		<title level="m" type="main">Summarizing, simplifying, and synthesizing medical evidence using gpt-3 (with varying success)</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shaib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.06299</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b331">
	<monogr>
		<title level="m" type="main">Medgpteval: A dataset and benchmark to evaluate responses of large language models in medicine</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.07340</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b332">
	<monogr>
		<title level="m" type="main">Chatgpt performs on the chinese national medical licensing examination</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b333">
	<analytic>
		<title level="a" type="main">Using gpt-3 to build a lexicon of drugs of abuse synonyms for social media pharmacovigilance</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomolecules</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">387</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b334">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alsentzer</surname></persName>
		</author>
		<idno>PMLR</idno>
		<title level="m">Do we still need clinical language models?&quot; in Conference on Health, Inference, and Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="578" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b335">
	<analytic>
		<title level="a" type="main">Assessing the utility of chatgpt throughout the entire clinical workflow</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Landman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dryer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Succi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">medRxiv</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2025" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b336">
	<analytic>
		<title level="a" type="main">Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cheatham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Medenilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sillos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>De Leon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Elepa Ño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Madriaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Aggabao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Diaz-Candido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Maningo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS digital health</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">e0000198</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b337">
	<analytic>
		<title level="a" type="main">Chatgpt-versus humangenerated answers to frequently asked questions about diabetes: a turing test-inspired survey among employees of a danish diabetes center</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L</forename><surname>Dollerup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mortensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fenech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stoevring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">medRxiv</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2025" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b338">
	<analytic>
		<title level="a" type="main">Diagnostic accuracy of differential-diagnosis lists generated by generative pretrained transformer 3 chatbot for clinical vignettes with common chief complaints: A pilot study</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hirosawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yokose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sakamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kawamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shimizu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of environmental research and public health</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">3378</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b339">
	<analytic>
		<title level="a" type="main">Assessing the value of chatgpt for clinical decision support optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Wanderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Turer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Sittig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MedRxiv</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2025" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b340">
	<analytic>
		<title level="a" type="main">How does chatgpt perform on the united states medical licensing examination? the implications of large language models for medical education and knowledge assessment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Safranek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Socrates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chartash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMIR Medical Education</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">e45312</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b341">
	<analytic>
		<title level="a" type="main">Evaluating the performance of chatgpt in ophthalmology: An analysis of its successes and shortcomings</title>
		<author>
			<persName><forename type="first">F</forename><surname>Antaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Touma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Milad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>El-Khoury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Duval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmology Science</title>
		<imprint>
			<biblScope unit="page">100324</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b342">
	<analytic>
		<title level="a" type="main">Translating radiology reports into plain language using chatgpt and gpt-4 with prompt learning: results, limitations, and potential</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Zapadka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponnatapura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Whitlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomedicine, and Art</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Visual Computing for Industry</note>
</biblStruct>

<biblStruct xml:id="b343">
	<monogr>
		<title level="m" type="main">Legal prompting: Teaching a language model to think like a lawyer</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Quartey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schilder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.01326</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b344">
	<monogr>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.05729</idno>
		<title level="m">A brief report on lawgpt 1.0: A virtual legal assistant based on gpt-3</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b345">
	<monogr>
		<title level="m" type="main">Chatgpt may pass the bar exam soon, but has a long way to go for the lexglue benchmark</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.12202</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b346">
	<monogr>
		<title level="m" type="main">Chatgpt goes to law school</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Monahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schwarcz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b347">
	<analytic>
		<title level="a" type="main">Chestxraybert: A pretrained language model for chest radiology report summarization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b348">
	<monogr>
		<title level="m" type="main">Doctorglm: Fine-tuning your chinese doctor is not a herculean task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.01097</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b349">
	<analytic>
		<title level="a" type="main">Overview of the mediqa-chat 2023 shared tasks on the summarization &amp; generation of doctor-patient conversations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>-W. Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Snider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yetisgen-Yildiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Clinical Natural Language Processing Workshop</title>
		<meeting>the 5th Clinical Natural Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="503" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b350">
	<monogr>
		<title level="m" type="main">One embedder, any task: Instruction-finetuned text embeddings</title>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>-T. Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09741</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b351">
	<monogr>
		<title level="m" type="main">Chinese finegrained financial sentiment analysis with large language models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.14096</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b352">
	<monogr>
		<title level="m" type="main">Transforming sentiment analysis in the financial domain with chatgpt</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fatouros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Soldatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kouroumali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Makridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kyriazis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.07935</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b353">
	<analytic>
		<title level="a" type="main">Sentiment spin: Attacking financial sentiment with gpt-3</title>
		<author>
			<persName><forename type="first">M</forename><surname>Leippold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Finance Research Letters</title>
		<imprint>
			<biblScope unit="page">103957</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b354">
	<analytic>
		<title level="a" type="main">Promptshots at the finnlp-2022 erai task: Pairwise comparison and unsupervised ranking</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wiriyathammabhum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Financial Technology and Natural Language Processing</title>
		<meeting>the Fourth Workshop on Financial Technology and Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="104" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b355">
	<monogr>
		<title level="m" type="main">Zero is not hero yet: Benchmarking zero-shot performance of llms for financial tasks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chava</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.16633</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b356">
	<monogr>
		<title level="m" type="main">Fineval: A chinese financial domain knowledge evaluation benchmark for large language models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.09975</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b357">
	<monogr>
		<title level="m" type="main">Gpt-finre: In-context learning for financial relation extraction using large language models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Rajpoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parikh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.17519</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b358">
	<monogr>
		<title level="m" type="main">Breaking the bank with chatgpt: Few-shot text classification for finance</title>
		<author>
			<persName><forename type="first">L</forename><surname>Loukas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stogiannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vassos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.14634</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b359">
	<analytic>
		<title level="a" type="main">Lexglue: A benchmark dataset for legal language understanding in english</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hartung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bommarito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Aletras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4310" to="4330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b360">
	<analytic>
		<title level="a" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24" to="824" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b361">
	<analytic>
		<title level="a" type="main">Finqa: A dataset of numerical reasoning over financial data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Smiley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Borova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Langdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moussa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Routledge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3697" to="3711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b362">
	<monogr>
		<title level="m" type="main">Chatgpt beyond english: Towards a comprehensive evaluation of large language models in multilingual learning</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P B</forename><surname>Veyseh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05613</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b363">
	<monogr>
		<title level="m" type="main">Is chatgpt a highly fluent grammatical error correction system? a comprehensive evaluation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.01746</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b364">
	<analytic>
		<title level="a" type="main">On the multilingual capabilities of very large-scale english language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Armengol-Estapé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>De Gibert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName><surname>Melero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Language Resources and Evaluation Conference</title>
		<meeting>the Thirteenth Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3056" to="3068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b365">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ochieng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Diddee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ganu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Axmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bali</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.12528</idno>
		<title level="m">Mega: Multilingual evaluation of generative ai</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b366">
	<monogr>
		<title level="m" type="main">Don&apos;t trust gpt when your question is not in english</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kondrak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.16339</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b367">
	<monogr>
		<title level="m" type="main">Evaluating chatgpt&apos;s performance for multilingual and emoji-based hate speech detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13276</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b368">
	<monogr>
		<title level="m" type="main">Are large language model-based evaluators the solution to scaling up multilingual evaluation?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gumma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De Wynter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Diddee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sitaram</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.07462</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b369">
	<monogr>
		<title level="m" type="main">Bhasa: A holistic southeast asian linguistic and cultural evaluation suite for large language models</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Q</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Ngui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Susanto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rengarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sarveswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Tjhi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.06085</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b370">
	<analytic>
		<title level="a" type="main">Holistic evaluation of language models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b371">
	<analytic>
		<title level="a" type="main">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A M</forename><surname>Shoeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garriga-Alonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b372">
	<monogr>
		<title level="m" type="main">Chatgpt outperforms crowd-workers for text-annotation tasks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gilardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kubli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.15056</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b373">
	<monogr>
		<title level="m" type="main">Annollm: Making large language models to be better crowdsourced annotators</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Yiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.16854</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b374">
	<monogr>
		<title level="m" type="main">Chatgpt-4 outperforms experts and crowd workers in annotating political twitter messages with zero-shot learning</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Örnberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.06588</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b375">
	<monogr>
		<title level="m" type="main">Can chatgpt reproduce human-generated labels? a study of social computing tasks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-U</forename><surname>Haq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tyson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.10145</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b376">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Atreja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hemphill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.10619</idno>
		<title level="m">hot&quot; chatgpt: The promise of chatgpt in detecting and discriminating hateful, offensive, and toxic comments on social media</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b377">
	<monogr>
		<title level="m" type="main">Distilling large language models for biomedical knowledge extraction: A case study on adverse drug events</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Woldesenbet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sanapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Valluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Strandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.06439</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b378">
	<analytic>
		<title level="a" type="main">Want to reduce labeling cost? gpt-3 can help</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4195" to="4205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b379">
	<monogr>
		<title level="m" type="main">Is gpt-3 a good data annotator?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10450</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b380">
	<analytic>
		<title level="a" type="main">Large language models as instructors: A study on multilingual clinical entity extraction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Meoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>De La Clergerie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ryffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="178" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b381">
	<monogr>
		<title level="m" type="main">Inheritsumm: A general, versatile and compact summarizer by distilling from gpt</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13083</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b382">
	<monogr>
		<title level="m" type="main">Open-source large language models outperform crowd workers and approach chatgpt in textannotation tasks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kubli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Samei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Bermeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Korobeynikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gilardi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.02179</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b383">
	<analytic>
		<title level="a" type="main">From humans to machines: can chatgpt-like llms effectively replace human annotators in nlp tasks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thapa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nasim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop Proceedings of the 17th International AAAI Conference on Web and Social Media</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b384">
	<analytic>
		<title level="a" type="main">Twitsenti: a realtime twitter sentiment analysis and visualization framework</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Siddesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Srinivasa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information &amp; Knowledge Management</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page">1950013</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b385">
	<analytic>
		<title level="a" type="main">The validity of sentiment analysis: Comparing manual annotation, crowd-coding, dictionary approaches, and machine learning algorithms</title>
		<author>
			<persName><forename type="first">W</forename><surname>Van Atteveldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Van Der Velden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boukes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communication Methods and Measures</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="140" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b386">
	<analytic>
		<title level="a" type="main">An mturk crisis? shifts in data quality and the impact on study results</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chmielewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Kucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Psychological and Personality Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="464" to="473" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b387">
	<monogr>
		<title level="m" type="main">Z-code++: A pre-trained language model optimized for abstractive summarization</title>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Awadalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.09770</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b388">
	<monogr>
		<title level="m" type="main">Scal-ing instruction-finetuned language models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brahma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11416</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b389">
	<monogr>
		<title level="m" type="main">Chatgpt to replace crowdsourcing of paraphrases for intent classification: Higher diversity and comparable model robustness</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cegin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Simko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brusilovsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.12947</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b390">
	<monogr>
		<title level="m" type="main">Data augmentation for neural machine translation using generative language model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.16833</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b391">
	<analytic>
		<title level="a" type="main">Systematic review of effect of data augmentation using paraphrasing on named entity recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mukhija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bhathena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Biswas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b392">
	<monogr>
		<title level="m" type="main">Dr. llama: Improving small language models in domain-specific qa via generative data augmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.07804</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b393">
	<monogr>
		<title level="m" type="main">Lm-cppf: Paraphrasing-guided data augmentation for contrastive promptbased few-shot fine-tuning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abaskohi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.18169</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b394">
	<monogr>
		<title level="m" type="main">Medical data augmentation via chatgpt: A case study on medication identification and medication event classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sarker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.07297</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b395">
	<monogr>
		<title level="m" type="main">Auggpt: Leveraging chatgpt for text data augmentation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13007</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b396">
	<monogr>
		<title level="m" type="main">Chatgpt as data augmentation for compositional generalization: A case study in open intent detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.13517</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b397">
	<analytic>
		<title level="a" type="main">A survey on image data augmentation for deep learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shorten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of big data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b398">
	<analytic>
		<title level="a" type="main">Data augmentation approaches in natural language processing: A survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ai Open</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="71" to="90" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b399">
	<analytic>
		<title level="a" type="main">A survey of text data augmentation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 International Conference on Computer Communication and Network Security (CCNS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="191" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b400">
	<analytic>
		<title level="a" type="main">A survey of data augmentation approaches for nlp</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gangal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="968" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b401">
	<analytic>
		<title level="a" type="main">A survey on data augmentation for text classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-A</forename><surname>Kaufhold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Reuter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b402">
	<analytic>
		<title level="a" type="main">Synthetic and natural noise both break neural machine translation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b403">
	<monogr>
		<title level="m" type="main">Text data augmentation made simple by leveraging nlp cloud apis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Coulombe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.04718</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b404">
	<analytic>
		<title level="a" type="main">Eda: Easy data augmentation techniques for boosting performance on text classification tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6382" to="6388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b405">
	<analytic>
		<title level="a" type="main">That&apos;s so annoying!!!: A lexical and frame-semantic embedding based data augmentation approach to automatic categorization of annoying behaviors using# petpeeve tweets</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 conference on empirical methods in natural language processing</title>
		<meeting>the 2015 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2557" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b406">
	<analytic>
		<title level="a" type="main">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="86" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b407">
	<analytic>
		<title level="a" type="main">Question classification using limited labelled data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mallikarjuna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sivanesan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">103094</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b408">
	<monogr>
		<title level="m" type="main">Socialdial: A benchmark for socially-aware dialogue systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-K</forename><surname>Soon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.12026</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b409">
	<monogr>
		<title level="m" type="main">Umass bionlp at mediqa-chat 2023: Can llms generate high-quality synthetic note-oriented doctor-patient conversations?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.16931</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b410">
	<analytic>
		<title level="a" type="main">Textbooks are all you need</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aneja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C T</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Giorno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Javaheripi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Kauffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Saarikivi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Behl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Kalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/2306.11644</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b411">
	<analytic>
		<title level="a" type="main">Llm-powered data augmentation for enhanced crosslingual performance</title>
		<author>
			<persName><forename type="first">C</forename><surname>Whitehouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Aji</surname></persName>
		</author>
		<idno>abs/2305.14288</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b412">
	<analytic>
		<title level="a" type="main">Toxigen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hartvigsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kamar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3309" to="3326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b413">
	<analytic>
		<title level="a" type="main">A holistic approach to undesired content detection in the real world</title>
		<author>
			<persName><forename type="first">T</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Nekoul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b414">
	<analytic>
		<title level="a" type="main">Dr. llama: Improving small language models on pubmedqa via generative data augmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/2305.07804</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b415">
	<monogr>
		<title level="m" type="main">Tinystories: How small can language models be and still speak coherent english?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.07759</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b416">
	<monogr>
		<title level="m" type="main">Logicot: Logical chain-of-thought instruction-tuning data collection with gpt-4</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.12147</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b417">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03277</idno>
		<title level="m">Instruction tuning with gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b418">
	<monogr>
		<title level="m" type="main">Gpt-calls: Enhancing call segmentation and tagging by generating synthetic conversations via large language models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Malkiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yehuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Keren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Barkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ronen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Koenigstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.07941</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b419">
	<analytic>
		<title level="a" type="main">How large language models are transforming machine-paraphrase plagiarism</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Wahle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ruas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kirstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="952" to="963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b420">
	<monogr>
		<title level="m" type="main">Uzh clyp at semeval-2023 task 9: Head-first fine-tuning and chatgpt data generation for cross-lingual learning in tweet intimacy prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Michail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Konstantinou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.01194</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b421">
	<monogr>
		<title level="m" type="main">Does synthetic data generation of llms help clinical text mining?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.04360</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b422">
	<monogr>
		<title level="m" type="main">Large language model as attributed training data generator: A tale of diversity and bias</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.15895</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b423">
	<monogr>
		<title level="m" type="main">Neural machine translation data generation and augmentation using chatgpt</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nicolai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.05779</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b424">
	<monogr>
		<title level="m" type="main">Robut: A systematic study of table qa robustness against human-annotated adversarial perturbations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.14321</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b425">
	<monogr>
		<title level="m" type="main">Instructscore: Towards explainable text generation evaluation with automatic feedback</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14282</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b426">
	<analytic>
		<title level="a" type="main">Data augmentation using backtranslation for context-aware neural machine translation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yoshinaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth workshop on discourse in machine translation</title>
		<meeting>the fourth workshop on discourse in machine translation</meeting>
		<imprint>
			<date type="published" when="2019">DiscoMT 2019. 2019</date>
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b427">
	<analytic>
		<title level="a" type="main">Smaller language models are better black-box machine-generated text detectors</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mireshghallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mattern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<idno>abs/2305.09859</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b428">
	<analytic>
		<title level="a" type="main">How close is chatgpt to human experts? comparison corpus, evaluation, and detection</title>
		<author>
			<persName><forename type="first">B</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno>abs/2301.07597</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b429">
	<analytic>
		<title level="a" type="main">Regulating chatgpt and other large generative ai models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2023 ACM Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1112" to="1123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b430">
	<analytic>
		<title level="a" type="main">Chatgpt and the rise of large language models: the new ai-driven infodemic threat in public health</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Angelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Baglivo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Arzilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Privitera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Tozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rizzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Public Health</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">1166120</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b431">
	<analytic>
		<title level="a" type="main">Chatgpt or human? detect and explain. explaining decisions of machine learning model for detecting short chatgpt-generated text</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mitrovi'c</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Andreoletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ayoub</surname></persName>
		</author>
		<idno>abs/2301.13852</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b432">
	<analytic>
		<title level="a" type="main">Comparing scientific abstracts generated by chatgpt to real abstracts with detectors and blinded human reviewers</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ Digital Medicine</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">75</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b433">
	<analytic>
		<title level="a" type="main">Chatting and cheating: Ensuring academic integrity in the era of chatgpt</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Cotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Cotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Shipway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Innovations in Education and Teaching International</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b434">
	<monogr>
		<title level="m" type="main">Detection of fake generated scientific abstracts</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Theocharopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Anagnostou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tsoukala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Georgakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Tasoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Plagianakos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.06148</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b435">
	<monogr>
		<title level="m" type="main">Distinguishing chatgpt (-3.5,-4)-generated and human-written papers through japanese stylometric analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zaitsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05534</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b436">
	<monogr>
		<title level="m" type="main">Cheat: A large-scale dataset for detecting chatgpt-written abstracts</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.12008</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b437">
	<monogr>
		<title level="m" type="main">Dnagpt: Divergent n-gram analysis for training-free detection of gptgenerated text</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Petzold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.17359</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b438">
	<monogr>
		<title level="m" type="main">Argugpt: evaluating, understanding and identifying argumentative essays generated by gpt models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.07666</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b439">
	<monogr>
		<title level="m" type="main">Detecting llm-generated text in computing education: A comparative study for chatgpt cases</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Orenstrakh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Karnalim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Suarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.07411</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b440">
	<monogr>
		<title level="m" type="main">Differentiate chatgpt-generated and humanwritten medical texts</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.11567</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b441">
	<monogr>
		<title level="m" type="main">G3detector: General gpt-generated text detector</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.12680</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b442">
	<analytic>
		<title level="a" type="main">All that&apos;s &apos;human&apos;is not gold: Evaluating human evaluation of generated text</title>
		<author>
			<persName><forename type="first">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Haduong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7282" to="7296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b443">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Pegoraro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fereidooni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-R</forename><surname>Sadeghi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.01487</idno>
		<title level="m">To chatgpt, or not to chatgpt: That is the question!</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b444">
	<monogr>
		<title level="m" type="main">Red teaming language model detectors with language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.19713</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b445">
	<monogr>
		<title level="m" type="main">Will chatgpt get you caught? rethinking of plagiarism detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Er</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.04335</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b446">
	<monogr>
		<title level="m" type="main">Mgtbench: Benchmarking machine-generated text detection</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.14822</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b447">
	<analytic>
		<title level="a" type="main">Bot or human? detecting chatgpt imposters with a single question</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<idno>abs/2305.06424</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b448">
	<analytic>
		<title level="a" type="main">Gpt-sentinel: Distinguishing human and chatgpt generated content</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<idno>abs/2305.07969</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b449">
	<analytic>
		<title level="a" type="main">Gpt paternity test: Gpt generated text detection with gpt genetic inheritance</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/2305.12519</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b450">
	<analytic>
		<title level="a" type="main">Is chatgpt involved in texts? measure the polish ratio to detect chatgpt-generated text</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/2307.11380</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b451">
	<monogr>
		<title level="m" type="main">Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense</title>
		<author>
			<persName><forename type="first">K</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karpinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13408</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b452">
	<analytic>
		<title level="a" type="main">Automatic detection of generated text is easiest when humans are fooled</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duckworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1808" to="1822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b453">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-I</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b454">
	<monogr>
		<title level="m" type="main">How robust is gpt-3.5 to predecessors? a comprehensive study on language understanding tasks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.00293</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b455">
	<monogr>
		<title level="m" type="main">On the robustness of chatgpt: An adversarial and out-of-distribution perspective</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.12095</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b456">
	<monogr>
		<title level="m" type="main">On robustness of prompt-based semantic parsing with large pre-trained language model: An empirical study on codex</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shiri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.12868</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b457">
	<monogr>
		<title level="m" type="main">Promptbench: Towards evaluating the robustness of large language models on adversarial prompts</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Z</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.04528</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b458">
	<monogr>
		<title level="m" type="main">Exploring the robustness of large language models for solving programming problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shirafuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Watanobe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Suzuki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.14583</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b459">
	<monogr>
		<title level="m" type="main">Is information extraction solved by chatgpt? an analysis of performance, evaluation criteria, robustness and errors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14450</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b460">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.03439</idno>
		<title level="m">Evaluating the logical reasoning ability of chatgpt and gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b461">
	<monogr>
		<title level="m" type="main">A comprehensive evaluation of chatgpt&apos;s zero-shot text-to-sql capability</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13547</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b462">
	<monogr>
		<title level="m" type="main">Detectgpt: Zero-shot machine-generated text detection using probability curvature</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khazatsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.11305</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b463">
	<analytic>
		<title level="a" type="main">A survey of adversarial defences and robustness in nlp</title>
		<author>
			<persName><forename type="first">S</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Doddapaneni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ravindran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b464">
	<analytic>
		<title level="a" type="main">Adversarial attack and defense technologies in natural language processing: A survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">492</biblScope>
			<biblScope unit="page" from="278" to="307" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b465">
	<monogr>
		<title level="m" type="main">Towards out-of-distribution generalization: A survey</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.13624</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b466">
	<analytic>
		<title level="a" type="main">Textflint: Unified multilingual robustness evaluation toolkit for natural language processing</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="347" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b467">
	<monogr>
		<title level="m" type="main">Exploring the use of large language models for reference-free text quality evaluation: A preliminary empirical study</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.00723</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b468">
	<analytic>
		<title level="a" type="main">A survey of evaluation metrics used for nlg systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Sai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mohankumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b469">
	<monogr>
		<title level="m" type="main">Large language models are state-of-the-art evaluators of code generation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Zhuo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.14317</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b470">
	<monogr>
		<title level="m" type="main">Multidimensional evaluation for text style transfer using chatgpt</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Toral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nissim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.13462</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b471">
	<monogr>
		<title level="m" type="main">Gpteval: Nlg evaluation using gpt-4 with better human alignment</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.16634</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b472">
	<monogr>
		<title level="m" type="main">Large language models are state-of-the-art evaluators of translation quality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kocmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.14520</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b473">
	<monogr>
		<title level="m" type="main">Error analysis prompting enables human-like translation evaluation in large language models: A case study on chatgpt</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13809</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b474">
	<monogr>
		<title level="m" type="main">Chatgpt as a factual inconsistency evaluator for text summarization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b475">
	<monogr>
		<title level="m" type="main">Are large language models good evaluators for abstractive summarization?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13091</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b476">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.04166</idno>
		<title level="m">Gptscore: Evaluate as you desire</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b477">
	<monogr>
		<title level="m" type="main">On learning to summarize with large language models as references</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14239</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b478">
	<monogr>
		<title level="m" type="main">Humanlike summarization evaluation with chatgpt</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.02554</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b479">
	<monogr>
		<title level="m" type="main">Not all metrics are guilty: Improving nlg evaluation with llm paraphrasing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">E</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.15067</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b480">
	<monogr>
		<title level="m" type="main">Large language models are not fair evaluators</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.17926</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b481">
	<monogr>
		<title level="m" type="main">Multi-dimensional evaluation of text summarization with in-context learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Keshava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Sathyendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.01200</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b482">
	<monogr>
		<title level="m" type="main">Is chatgpt a good nlg evaluator? a preliminary study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.04048</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b483">
	<monogr>
		<title level="m" type="main">Benchmarking foundation models with language-model-as-an-examiner</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lyu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.04181</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b484">
	<monogr>
		<title level="m" type="main">Bigtrans: Augmenting large language models with multilingual translation capability over 100 languages</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.18098</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b485">
	<monogr>
		<title level="m" type="main">Judging llm-as-a-judge with mt-bench and chatbot arena</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-L</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.05685</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b486">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b487">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text summarization branches out</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b488">
	<analytic>
		<title level="a" type="main">Meteor: An automatic metric for mt evaluation with improved correlation with human judgments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization</title>
		<meeting>the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b489">
	<analytic>
		<title level="a" type="main">To ship or not to ship: An extensive evaluation of automatic metrics for machine translation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kocmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Menezes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Machine Translation</title>
		<meeting>the Sixth Conference on Machine Translation</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="478" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b490">
	<analytic>
		<title level="a" type="main">Bertscore: Evaluating text generation with bert</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b491">
	<analytic>
		<title level="a" type="main">Moverscore: Text generation evaluating with contextualized embeddings and earth mover distance</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Peyrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="563" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b492">
	<analytic>
		<title level="a" type="main">Bartscore: Evaluating generated text as text generation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="27" to="263" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b493">
	<monogr>
		<title level="m" type="main">Codebertscore: Evaluating code generation with pretrained models of code</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.05527</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b494">
	<analytic>
		<title level="a" type="main">Ctrlsum: Towards generic controllable text summarization</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kryści Ński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5879" to="5915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b495">
	<analytic>
		<title level="a" type="main">Sentbs: Sentencelevel beam search for controllable summarization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b496">
	<analytic>
		<title level="a" type="main">Brio: Bringing order to abstractive summarization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2890" to="2903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b497">
	<monogr>
		<title level="m" type="main">Toward human-like evaluation for natural language generation with error analysis</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10179</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b498">
	<monogr>
		<title level="m" type="main">Red-teaming large language models using chain of utterances for safety-alignment</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bhardwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.09662</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b499">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lovitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schiefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ndousse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.07858</idno>
		<title level="m">Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b500">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dupuy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.04265</idno>
		<title level="m">Flirt: Feedback loop in-context red teaming</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b501">
	<analytic>
		<title level="a" type="main">Red teaming language models with language models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3419" to="3448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b502">
	<monogr>
		<title level="m" type="main">Frugalgpt: How to use large language models while reducing cost and improving performance</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.05176</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b503">
	<monogr>
		<title level="m" type="main">Batch prompting: Efficient inference with large language model apis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.08721</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b504">
	<monogr>
		<title level="m" type="main">Unlocking context constraints of llms: Enhancing context efficiency of llms with self-information-based content filtering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.12102</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b505">
	<monogr>
		<title level="m" type="main">Leancontext: Cost-efficient domain-specific question answering using llms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Arefeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chakradhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.00841</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b506">
	<monogr>
		<title level="m" type="main">Time travel in llms: Tracing data contamination in large language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Golchin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.08493</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b507">
	<monogr>
		<title level="m" type="main">Can we trust the evaluation on chatgpt</title>
		<author>
			<persName><forename type="first">R</forename><surname>Aiyappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Y</forename><surname>Ahn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.12767</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b508">
	<analytic>
		<title level="a" type="main">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b509">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b510">
	<analytic>
		<title level="a" type="main">Don&apos;t give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1797" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b511">
	<monogr>
		<title level="m" type="main">Siren&apos;s song in the ai ocean: A survey on hallucination in large language models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.01219</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b512">
	<monogr>
		<title level="m" type="main">A survey of hallucination in large foundation models</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rawte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.05922</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b513">
	<monogr>
		<title level="m" type="main">Chain-of-verification reduces hallucination in large language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Komeili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raileanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b514">
	<monogr>
		<title level="m" type="main">Med-halt: Medical domain hallucination test for large language models</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Umapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sankarasubbu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.15343</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b515">
	<monogr>
		<title level="m" type="main">Halueval: A large-scale hallucination evaluation benchmark for large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">2305</biblScope>
		</imprint>
	</monogr>
	<note>arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b516">
	<monogr>
		<title level="m" type="main">Check your facts and try again: Improving large language models with external knowledge and automated feedback</title>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.12813</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Turning large language models into cognitive models</title>
				<funder>
					<orgName type="full">Deutsche Forschungsgemeinschaft (DFG, German Research Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Max Planck Society</orgName>
				</funder>
				<funder>
					<orgName type="full">Volkswagen Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Marcel</forename><surname>Binz</surname></persName>
							<email>marcel.binz@tue.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">MPRG Computational Principles of Intelligence Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Schulz</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">MPRG Computational Principles of Intelligence Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Turning large language models into cognitive models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">50CC744DCF08E306E5D1272CD78464AF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-04-29T15:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">92ea31e</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=1, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models are powerful systems that excel at many tasks, ranging from translation to mathematical reasoning. Yet, at the same time, these models often show unhuman-like characteristics. In the present paper, we address this gap and ask whether large language models can be turned into cognitive models. We find that -after finetuning them on data from psychological experiments -these models offer accurate representations of human behavior, even outperforming traditional cognitive models in two decision-making domains. In addition, we show that their representations contain the information necessary to model behavior on the level of individual subjects. Finally, we demonstrate that finetuning on multiple tasks enables large language models to predict human behavior in a previously unseen task. Taken together, these results suggest that large, pre-trained models can be adapted to become generalist cognitive models, thereby opening up new research directions that could transform cognitive psychology and the behavioral sciences as a whole.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large language models are neural networks trained on vast amounts of data to predict the next token for a given text sequence <ref type="bibr" target="#b5">[Brown et al., 2020]</ref>. These models display many emergent abilities that were not anticipated by extrapolating the performance of smaller models <ref type="bibr" target="#b35">[Wei et al., 2022]</ref>. Their abilities are so impressive and far-reaching that some have argued that they show sparks of general intelligence <ref type="bibr" target="#b6">[Bubeck et al., 2023]</ref>. We may currently witness one of the biggest revolutions in artificial intelligence, but the impact of modern language models is felt far beyond, permeating into education <ref type="bibr" target="#b18">[Kasneci et al., 2023]</ref>, medicine <ref type="bibr" target="#b20">[Li et al., 2023]</ref>, and the labor market <ref type="bibr" target="#b10">[Eloundou et al., 2023]</ref>.</p><p>In-context learning -the ability to extract information from a context and to use that information to improve the production of subsequent outputs -is one of the defining features of such models. It is through this mechanism that large language models are able to solve a variety of tasks, ranging from translation <ref type="bibr" target="#b5">[Brown et al., 2020]</ref> to analogical reasoning <ref type="bibr" target="#b34">[Webb et al., 2022]</ref>. Previous work has shown that these models can even successfully navigate when they are placed into classic psychological experiments <ref type="bibr">[Binz and Schulz, 2023</ref><ref type="bibr" target="#b8">, Coda-Forno et al., 2023</ref><ref type="bibr" target="#b9">, Dasgupta et al., 2022</ref><ref type="bibr" target="#b15">, Hagendorff et al., 2022]</ref>. To provide just one example, GPT-3 -an autoregressive language model designed by <ref type="bibr">OpenAI [Brown et al., 2020]</ref> -outperformed human subjects in a sequential decision-making task that required to balance between exploitative and exploratory actions <ref type="bibr">[Binz and Schulz, 2023]</ref>.</p><p>Even though these models show human-like behavioral characteristics in some situations, this is not always the case. In the sequential decision-making task mentioned above, for instance, GPT-3 relied heavily on exploitative strategies, while people applied a combination of elaborate exploration strategies <ref type="bibr" target="#b36">[Wilson et al., 2014]</ref>. Moreover, GPT-3 stopped improving after only a few trials, while people continued learning as the task progressed.</p><p>In the present paper, we investigate whether it is possible to fix the behavioral discrepancy between large language models and humans. To do so, we rely on the idea of finetuning on domain-specific data. This approach has been fruitful across a number of areas <ref type="bibr" target="#b29">[Sanh et al., 2019</ref><ref type="bibr" target="#b23">, Ouyang et al., 2022]</ref> and eventually led to the creation of the term foundation models <ref type="bibr" target="#b4">[Bommasani et al., 2021]</ref> -models trained on broad data at scale and adapted to a wide range of downstream tasks. In the context of human cognition, such domain-specific data can be readily accessed by tapping the vast amount of behavioral studies that psychologists have conducted over the last century. We made use of this and extracted data sets for several behavioral paradigms which we then used to finetune a large language model. We show that this approach can be used to create models that describe human behavior better than traditional cognitive models. We verify this result through extensive model simulations, which confirm that finetuned language models indeed show human-like behavioral characteristics. Furthermore, we find that the embeddings obtained from such models contain the information necessary to capture individual differences. Finally, we highlight that a model finetuned on two tasks is capable of predicting human behavior on a third, hold-out task. Taken together, our work demonstrates that it is possible to turn large language models into cognitive models, thereby opening up completely new opportunities to harvest the power of large language models for building domain-general models of human learning and decision-making.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Finetuned language models beat domain-specific models</head><p>We started our investigations by testing whether it is possible to capture how people make decisions through finetuning a large language model. For our analyses, we relied on the Large Language Model Meta AI, or in short: LLaMA <ref type="bibr" target="#b32">[Touvron et al., 2023]</ref>. LLaMA is a family of state-of-the-art foundational large language models (with either 7B, 13B, 33B, or 65B parameters) that were trained on trillions of tokens coming from exclusively publicly available data sets. We focused on the largest of these models -the 65B parameter version -for the analyses in the main text. LLaMA is publicly available, meaning that researchers are provided with complete access to the network architecture including its pre-trained weights. We utilized this feature to extract embeddings for several cognitive tasks and then finetuned a linear layer on top of these embeddings to predict human choices (see Figure <ref type="figure" target="#fig_0">1a</ref> for a visualization). We call the resulting class of models CENTaUR, in analogy to the mythical creature that is half human and half ungulate.</p><p>We considered two paradigms that have been extensively studied in the human decision-making literature for our initial analyses: decisions from descriptions <ref type="bibr" target="#b17">[Kahneman and Tversky, 1972]</ref> and decisions from experience <ref type="bibr" target="#b16">[Hertwig et al., 2004</ref>]. In the former, a decision-maker is asked to choose between one of two hypothetical gambles like the ones shown in Figure <ref type="figure" target="#fig_0">1b</ref>. Thus, for both options, there is complete information about outcome probabilities and their respective values. In contrast, the decisions from experience paradigm does not provide such explicit information. Instead, the decision-maker has to learn about outcome probabilities and their respective values from repeated interactions with the task as shown in Figure <ref type="figure" target="#fig_0">1d</ref>. Importantly, this modification calls for a change in how an ideal decision-maker should approach such problems: it is not enough to merely exploit currently available knowledge anymore but also crucial to explore options that are unfamiliar <ref type="bibr" target="#b31">[Schulz and Gershman, 2019]</ref>.</p><p>For both these paradigms, we created a data set consisting of embeddings and the corresponding human choices. We obtained embeddings by passing prompts that included all the information that people had access to on a given trial through LLaMA and then extracting the hidden activations of the final layer (see Figure <ref type="figure" target="#fig_0">1b</ref> and d for example prompts, and the Supplementary Materials for a more detailed description about the prompt generation procedure). We relied on publicly available data from earlier studies in this process. In the decisions from descriptions setting, we used the choices13k data set <ref type="bibr" target="#b25">[Peterson et al., 2021]</ref>, which is a large-scale data set consisting of over 13,000 choice problems (all in all, 14,711 participants made over one million choices on these problems). In the decisions from experience setting, we used data from the horizon task <ref type="bibr" target="#b36">[Wilson et al., 2014]</ref> and a replication study <ref type="bibr" target="#b12">[Feng et al., 2021]</ref>, which combined include 60 participants making a total of 67,200 choices. With these two data sets at hand, we fitted a regularized logistic regression model from the extracted embeddings to human choices. In this section, we restricted ourselves to a joint model for all participants, thereby neglecting potential individual differences (but see one of the following sections for an analysis that allows for individual differences). Model performance was measured through the predictive log-likelihood on hold-out data obtained using a 100-fold cross-validation procedure. We standardized all input features and furthermore applied a nested cross-validation for tuning the hyperparameter that controls the regularization strength. Further details are provided in the Materials and Methods section.</p><p>We compared the goodness-of-fit of the resulting models against three baselines: a random guessing model, LLaMA without finetuning (obtained by reading out log-probabilities of the pre-trained model), and a domain-specific model (Best Estimate and Sampling Tools, or BEAST, for the choices13k data set <ref type="bibr" target="#b11">[Erev et al., 2017</ref>] and a hybrid model <ref type="bibr" target="#b14">[Gershman, 2018]</ref> that involves a combination of different exploitation and exploration strategies for the horizon task). We found that LLaMA did not capture human behavior well, obtaining a negative log-likelihood (NLL) close to chance-level for the choices13k data set (NLL = 96248.5) and the horizon task (NLL = 46211.4). However, finetuning led to models that captured human behavior better than the domain-specific models under consideration. In the choices13k data set, CENTaUR achieved a negative log-likelihood of 48002.3 while BEAST only achieved a negative log-likelihood of 49448.1 (see Figure <ref type="figure" target="#fig_0">1c</ref>). In the horizon task, CENTaUR achieved a negative log-likelihood of 25968.6 while the hybrid model only achieved a negative log-likelihood of 29042.5 (see Figure <ref type="figure" target="#fig_0">1e</ref>). Together, these results suggest that the representations extracted from large language models are rich enough to attain state-of-the-art results for modeling human decision-making. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model simulations reveal human-like behavior</head><p>We next verified that CENTaUR shows human-like behavioral characteristics. To do so, we simulated the model on the experimental data. Looking at performance, we found that finetuning led to models that closely resemble human performance as shown in Figure <ref type="figure" target="#fig_1">2a</ref> and <ref type="figure">b</ref>. For the choices-13k data set, CENTaUR obtained a regret (defined as the difference between the highest possible reward and the reward for the action selected by the model) of 1.35 (SE = 0.01), which was much closer to the human regret (M = 1.24, SE = 0.01) than the regret of LLaMA (M = 1.85, SE = 0.01). The results for the horizon task showed an identical pattern, with CENTaUR (M = 2.38, SE = 0.01) matching human regret (M = 2.33, SE = 0.05) more closely than LLaMA (M = 7.21, SE = 0.02).</p><p>In addition to looking at performance, we also inspected choice curves. For this analysis, we took the data from the first free-choice trial in the horizon task and divided it into two conditions: (1) an equal information condition that includes trials where the decision-maker had access to an equal number of observations for both options and (2) an unequal information condition that includes trials where the decision-maker previously observed one option fewer times than the other. We then fitted a separate logistic regression model for each condition with reward difference, horizon, and their interaction as independent variables onto the simulated choices. Earlier studies with human subjects <ref type="bibr" target="#b36">[Wilson et al., 2014]</ref> identified the following two main results regarding their exploratory behavior: (1) people's choices become more random with a longer horizon in the equal information condition (as shown in Figure <ref type="figure" target="#fig_1">2c</ref>) and ( <ref type="formula">2</ref>) people in the unequal information condition select the more informative option more frequently when the task horizon is longer (as shown in Figure <ref type="figure" target="#fig_1">2d</ref>). While LLaMA did not show any of the two effects (see Figure <ref type="figure" target="#fig_1">2e</ref> and <ref type="figure">f</ref>), CENTaUR exhibited both of them (see Figure <ref type="figure" target="#fig_1">2g</ref> and h), thereby further corroborating that it accurately captures human behavior. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Language model embeddings capture individual differences</head><p>We also investigated how well CENTaUR describes the behavior of each individual participant. Note that this form of analysis is only possible for the horizon task as choice information on the participant level is not available for the choices13k data set. In total, the majority of participants (N = 52 out of 60) was best modeled by CENTaUR (see Figure <ref type="figure" target="#fig_2">3a</ref> for a detailed visualization). We furthermore entered the negative log-likelihoods into a random-effects model selection procedure which estimates the probability that a particular model is the most frequent explanation within a set of candidate models <ref type="bibr" target="#b27">[Rigoux et al., 2014]</ref>. This procedure favored CENTaUR decisively, assigning a probability that it is the most frequent explanation of close to one.</p><p>Thus far, we have finetuned LLaMA jointly for all participants. However, people may exhibit individual differences that are not captured by this analysis. To close this gap and test whether LLaMA embeddings can account for individual differences, we incorporated random effects in the finetuned layer. We added a random effect for each participant and embedding dimension while keeping the remaining evaluation procedure the same. Figure <ref type="figure" target="#fig_2">3b</ref> illustrates the resulting negative log-likelihoods. Including the random-effect structure improved goodness-of-fit considerably (NLL = 23929.5) compared to the fixed-effect-only model (NLL = 25968.6). Furthermore, CENTaUR remained superior to the hybrid model with an identical random-effect structure (NLL = 24166.0). Taken together, the findings reported in this section highlight that embeddings of large language models contain the information necessary to model behavior on the participant level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluating goodness-of-fit on hold-out tasks</head><p>Finally, we examined whether CENTaUR -after being finetuned on multiple tasks -is able to predict human behavior in an entirely different task. This evaluation protocol provides a much stronger test for the generalization abilities of our approach. Following our initial analyses, we finetuned a linear layer on top of LLaMA embeddings. However, this time, we fitted a joint model using both the data from the choices13k data set and the horizon task, and then evaluated how well the finetuned model captures human choices on a third task. Further details about the fitting procedure are provided in the Materials and Methods section. For the hold-out task, we considered data from a recent study that provided participants with a choice between one option whose information is provided via a description and another option for which information is provided via a list of experienced outcomes <ref type="bibr" target="#b13">[Garcia et al., 2023]</ref>. Figure <ref type="figure" target="#fig_3">4a</ref> shows an example prompt for this experimental paradigm.</p><p>Finetuning was generally beneficial for modeling human behavior on the hold-out task: negative log-likelihoods for CENTaUR (NLL = 4521.1) decreased both in comparison to a random guessing model (NLL = 5977.7) and LLaMA (NLL = 6307.9). We were thus curious whether CENTaUR also captures human behavior on a qualitative level. To test this, we took a look at the key insight from the original study: people tend to overvalue options that are provided through a description (symbolic or S-options) over the options that come with a list of experienced outcomes (experiential or E-options) as illustrated in Figure <ref type="figure" target="#fig_3">4b</ref> and <ref type="figure">c</ref>. LLaMA does not show this characteristic and instead weighs both option types equally (Figure <ref type="figure" target="#fig_3">4d</ref> and <ref type="figure">e</ref>). In contrast to this, CENTaUR shows human-like behavior, taking mostly the S-option into account (Figure <ref type="figure" target="#fig_3">4f</ref> and <ref type="figure">g</ref>). This is remarkable because we never presented data from the experiment under consideration during finetuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We have demonstrated that large language models can be turned into cognitive models by finetuning their final layer. This process led to models that achieved state-of-the-art performance in two domains. Furthermore, these models were able to capture behavioral differences at the individual participant level. Finally, we have shown that our approach generalizes to previously unseen tasks. In particular, a model that was finetuned on two tasks also exhibited human-like behavior on a third, hold-out task.</p><p>These results complement earlier work showing that large language model embeddings allow us to predict behavior and neural activations in linguistic settings <ref type="bibr" target="#b30">[Schrimpf et al., 2021</ref><ref type="bibr" target="#b19">, Kumar et al., 2022</ref><ref type="bibr" target="#b33">, Tuckute et al., 2023</ref><ref type="bibr" target="#b0">, Antonello et al., 2023]</ref>. For example, <ref type="bibr" target="#b30">Schrimpf et al. [2021]</ref> showed that large language models can predict neural and behavioral responses in tasks that involved reading short passages with an accuracy that was close to noise ceiling. While it may be expected that large language models explain human behavior in linguistic domains (after all these models are trained to predict future word occurrences), the observation that these results also transfer to more cognition domains like the ones studied here is highly non-trivial.</p><p>We are particularly excited about one feature of CENTaUR: embeddings extracted for different tasks all lie in a common space. This property allows finetuned large language models to solve multiple tasks in a unified architecture. We have presented preliminary results in this direction, showing that a model finetuned on two tasks can predict human behavior on a third. However, we believe that our current results only hint at the potential of this approach. Ideally, we would like to scale up our approach to finetuning on a larger number of tasks from the psychology literature. If one would include enough tasks in the training set, the resulting system should -in principle -generalize to any hold-out task. Therefore, our approach provides a path towards a domain-general model of human cognition, which has been the goal of theoreticians for decades <ref type="bibr" target="#b22">[Newell, 1992</ref><ref type="bibr" target="#b37">, Yang et al., 2019</ref><ref type="bibr" target="#b28">, Riveland and Pouget, 2022</ref><ref type="bibr">, Binz et al., 2023]</ref>. We believe that having access to such a model would transform psychology and the behavioral sciences more generally. It could, among other applications, be used to rapidly prototype the outcomes of projected experiments, thereby easing the trial-and-error process of experimental design, or to provide behavioral policy recommendations while avoiding expensive data collection procedures.</p><p>Finally, we have to ask ourselves what we can learn about human cognition when finetuning large language models. For now, our insights are limited to the observation that large language model embeddings are rich enough to explain human decision-making. While this is interesting in its own right, it is certainly not the end of the story. Looking beyond the current work, having access to an accurate neural network model of human behavior provides the opportunity to apply a wide range of explainability techniques from the machine learning literature. For instance, we could pick a particular neuron in the embedding and trace back what parts of a particular input sequence excite that neuron using methods such as layer-wise relevance propagation <ref type="bibr" target="#b1">[Bach et al., 2015</ref><ref type="bibr" target="#b7">, Chefer et al., 2021]</ref>. Thus, our work also opens up a new spectrum of analyses that are not possible when working with human subjects.</p><p>To summarize, large language models are an immensely powerful tool for studying human behavior. We believe that our work has only scratched the surface of this potential and there is certainly much more to come.</p><p>-Machine 2 delivered 57 dollars.</p><p>-Machine 1 delivered 37 dollars.</p><p>Your goal is to maximize the sum of received dollars within six additional choices. Q: Which machine do you choose? A: Machine <ref type="bibr">[insert]</ref> For the experiential-symbolic task, we prompted each decision independently and only considered the post-learning phase. We furthermore simplified the observation history by only including the option that is relevant to the current decision. We used the following template:</p><p>You made the following observations in the past: -Machine 1 delivered 1 dollars.</p><p>-Machine 1 delivered 1 dollars.</p><p>-Machine 1 delivered -1 dollars.</p><p>-Machine 1 delivered 1 dollars.</p><p>-Machine 1 delivered 1 dollars.</p><p>-Machine 1 delivered -1 dollars.</p><p>[. . .] -Machine 1 delivered 1 dollars.</p><p>Machine 2 delivers -1 dollars with 30.0% chance and 1 dollars with 70.0% chance.</p><p>Your goal is to maximize the amount of received dollars. Q: Which machine do you choose? A: Machine <ref type="bibr">[insert]</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of our approach and main results. (a) We provided text-based descriptions of psychological experiments to a large language model and extracted the resulting embeddings. We then finetuned a linear layer on top of these embeddings to predict human choices. We refer to the resulting model as CENTaUR. (b) Example prompt for the choices13k data set. (c) Negative log-likelihoods for the choices13k data set. (d) Example prompt for the horizon task. (e) Negative log-likelihoods for the horizon task. Prompts shown in this figure are stylized for readability. Exact prompts can be found in the Supplementary Materials.</figDesc><graphic coords="2,108.00,72.00,404.46,302.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model simulations. (a) Performance for different models and human participants on the choices13k data set. (b) Performance for different models and human participants on the horizon task. (c) Human choice curves in the equal information condition of the horizon task. (d) Human choice curves in the unequal information condition of the horizon task. (e) LLaMA choice curves in the equal information condition of the horizon task. (f) LLaMA choice curves in the unequal information condition of the horizon task. (g) CENTaUR choice curves in the equal information condition of the horizon task. (h) CENTaUR choice curves in the unequal information condition of the horizon task.</figDesc><graphic coords="4,108.63,72.00,394.74,253.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Individual differences. (a) Negative log-likelihood difference to the best-fitting model for each participant. Black highlights the best-fitting model, while white corresponds to a difference larger than ten. (b) Negative log-likelihoods for models that were finetuned using the random-effects structure described in the main text.</figDesc><graphic coords="5,108.09,72.00,395.82,139.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Hold-out task evaluations. (a) Example prompt for the experiential-symbolic task of Garcia et al. [2023]. (b) Human choice curves as a function of win probabilities for both options. (c) Human indifference points as a function of win probability for the E-option. Indifferent points express the win probabilities at which a decision-maker is equally likely to select both options. (d) LLaMA choice curves as a function of win probabilities for both options. (e) LLaMA indifference points as a function of win probability for the E-option. (f) CENTaUR choice curves as a function of win probabilities for both options. (g) CENTaUR indifference points as a function of win probability for the E-option.</figDesc><graphic coords="6,108.00,72.00,405.54,205.74" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Preprint. Under review.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements: We like to thank <rs type="person">Robert Wilson</rs> and <rs type="person">Basile Garcia</rs> for their help on the horizon task and the experiential-symbolic task respectively, <rs type="person">Ido Erev</rs> and <rs type="person">Eyal Ert</rs> for their help with the BEAST model, and <rs type="person">Meta AI</rs> for making LLaMA accessible to the research community.</p><p>Funding: This work was funded by the <rs type="funder">Max Planck Society</rs>, the <rs type="funder">Volkswagen Foundation</rs>, as well as the <rs type="funder">Deutsche Forschungsgemeinschaft (DFG, German Research Foundation</rs>) under Germany's Excellence Strategy-EXC2064/1-390727645.</p><p>Data and materials availability: Data and code for the current study are available through the GitHub repository <ref type="url" target="https://github.com/marcelbinz/CENTaUR">https://github.com/marcelbinz/CENTaUR</ref>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Materials</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Methods</head><p>Fitting procedure: For the main analyses, we fitted a separate regularized logistic regression model for each data set via a maximum likelihood estimation. Final model performance was measured through the predictive log-likelihood on hold-out data obtained using a 100-fold cross-validation procedure. In each fold, we split the data into a training set (90%), a validation set (9%), and a test set (1%). The validation set was used to identify the parameter α that controls the strength of the ℓ 2 -regularization term. We considered discrete α-values of [0, 0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0]. The optimization procedure was implemented in PYTORCH <ref type="bibr" target="#b24">[Paszke et al., 2019]</ref> and used the default LBFGS optimizer <ref type="bibr" target="#b21">[Liu and Nocedal, 1989]</ref>. For the individual difference analyses, the procedure was identical except that we added a random effect for each participant and embedding dimension.</p><p>For the hold-out task analyses, the training set consisted of the concatenated choices13k and horizon task data. To obtain a validation and test set, we split the data of the experiential-symbolic task into eight folds and repeated the previously described fitting procedure for each fold. The validation set was used to identify the parameter α that controls the strength of the ℓ 2 -regularization term and an inverse temperature parameter τ -1 . We considered discrete inverse temperature values of [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1] and α-values as described above.</p><p>Model simulations: For the main analyses, we simulated model behavior by sampling from the predictions on the test set. For the hold-out task analyses, we simulated data deterministically based on a median threshold (again using the predictions on the test set). The resulting choice curves were generated by fitting a separate logistic regression model for each possible win probability of the E-option. Each model used the win probability of the S-option and an intercept term as independent variables and the probability of choosing the E-option as the dependent variable.</p><p>Baseline models: For the LLaMA baseline, we fitted an inverse temperature parameter to human choices using the procedure described above. For the BEAST baseline, we relied on the version provided for the choice prediction competition 2018 <ref type="bibr" target="#b26">[Plonsky et al., 2018]</ref>. We additionally included an error model that selects a random choice with a particular probability. We treated this probability as a free parameter and fitted it using the procedure described above. The hybrid model closely followed the implementation of Gershman <ref type="bibr">[2018]</ref>. We replaced the probit link function with a logit link function to ensure comparability to CENTaUR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Text</head><p>For the choices13k data set, we prompted each decision independently, thereby ignoring the potential effect of feedback. We used the following template:</p><p>Machine 1 delivers 90 dollars with 10.0% chance and -12 dollars with 90.0% chance. Machine 2 delivers -13 dollars with 40.0% chance and 22 dollars with 60.0% chance.</p><p>Your goal is to maximize the amount of received dollars.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q: Which machine do you choose? A: Machine [insert]</head><p>For the horizon task, we prompted each task independently, thereby ignoring potential learning effects across the experiment. We used the following template: You made the following observations in the past: -Machine 1 delivered 34 dollars.</p><p>-Machine 1 delivered 41 dollars.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Scaling laws for language encoding models in fmri</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Antonello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Vaidya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Huth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11863</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grégoire</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Klauschen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">130140</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using cognitive psychology to understand gpt-3</title>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">2218523120</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishita</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshay</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.06729</idno>
		<title level="m">Meta-learned models of cognition</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">On the opportunities and risks of foundation models</title>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drew</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simran</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><surname>Sydney Von Arx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeannette</forename><surname>Michael S Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><surname>Brunskill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07258</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronen</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Tat Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Lundberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.12712</idno>
		<title level="m">Sparks of artificial general intelligence: Early experiments with gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transformer interpretability beyond attention visualization</title>
		<author>
			<persName><forename type="first">Hila</forename><surname>Chefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shir</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="782" to="791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Inducing anxiety in large language models increases exploration and bias</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Coda-Forno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><surname>Witte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Akshay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeynep</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName><surname>Schulz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.11111</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Language models show human-like content effects on reasoning</title>
		<author>
			<persName><forename type="first">Ishita</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><surname>Andrew K Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Stephanie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonia</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dharshan</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">L</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><surname>Hill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.07051</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Gpts are gpts: An early look at the labor market impact potential of large language models</title>
		<author>
			<persName><forename type="first">Tyna</forename><surname>Eloundou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Rock</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.10130</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">From anomalies to forecasts: Toward a descriptive model of decisions under risk, under ambiguity, and from experience</title>
		<author>
			<persName><forename type="first">Ido</forename><surname>Erev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eyal</forename><surname>Ert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ori</forename><surname>Plonsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doron</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oded</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">369</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The dynamics of explore-exploit decisions reveal a signal-to-noise mechanism for random exploration</title>
		<author>
			<persName><forename type="first">Siyu</forename><surname>Samuel F Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Zarnescu</surname></persName>
		</author>
		<author>
			<persName><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Experiential values are underweighted in decisions involving symbolic options</title>
		<author>
			<persName><forename type="first">Basile</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maël</forename><surname>Lebreton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sacha</forename><surname>Bourgeois-Gironde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Palminteri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature human behaviour</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deconstructing the human algorithms for exploration</title>
		<author>
			<persName><surname>Samuel J Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="34" to="42" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Thilo</forename><surname>Hagendorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Fabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michal</forename><surname>Kosinski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.05206</idno>
		<title level="m">Machine intuition: Uncovering human-like intuitive decision-making in gpt-3.5</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Decisions from experience and the effect of rare events in risky choice</title>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Hertwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elke</forename><forename type="middle">U</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Erev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="534" to="539" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Subjective probability: A judgment of representativeness</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="430" to="454" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Chatgpt for good? on opportunities and challenges of large language models for education</title>
		<author>
			<persName><forename type="first">Enkelejda</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathrin</forename><surname>Seßler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Küchemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Bannert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daryna</forename><surname>Dementieva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urs</forename><surname>Gasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Groh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eyke</forename><surname>Hüllermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page">102274</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reconstructing the cascade of language processing in the brain using the internal computations of a transformer-based language model</title>
		<author>
			<persName><forename type="first">Sreejan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodore</forename><forename type="middle">R</forename><surname>Sumers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takateru</forename><surname>Yamakoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">A</forename><surname>Nastase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioRxiv</title>
		<imprint>
			<biblScope unit="page" from="2022" to="2026" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ethics of large language models in medicine and medical research</title>
		<author>
			<persName><forename type="first">Hanzhou</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">T</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saptarshi</forename><surname>Purkayastha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Anthony Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hari</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judy</forename><forename type="middle">W</forename><surname>Gichoya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Lancet Digital Health</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="333" to="e335" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the limited memory bfgs method for large scale optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical programming</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="503" to="528" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Unified theories of cognition and the role of soar. Soar: A cognitive architecture in perspective: A tribute to Allen Newell</title>
		<author>
			<persName><forename type="first">Allen</forename><surname>Newell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="25" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Using large-scale experiments and machine learning to discover theories of human decision-making</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">D</forename><surname>Joshua C Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Bourgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Reichman</surname></persName>
		</author>
		<author>
			<persName><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<biblScope unit="issue">6547</biblScope>
			<biblScope unit="page" from="1209" to="1214" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Eyal Ert, and Moshe Tennenholtz. When and how can social scientists add value to data scientists? a choice prediction competition for human decision making</title>
		<author>
			<persName><forename type="first">Ori</forename><surname>Plonsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reut</forename><surname>Apel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Erev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Unpublished Manuscript</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bayesian model selection for group studies-revisited</title>
		<author>
			<persName><forename type="first">Lionel</forename><surname>Rigoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaas</forename><surname>Enno Stephan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Daunizeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="971" to="985" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A neural model of task compositionality with natural language instructions</title>
		<author>
			<persName><forename type="first">Reidar</forename><surname>Riveland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Pouget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The neural architecture of language: Integrative modeling converges on predictive processing</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Schrimpf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idan</forename><forename type="middle">Asher</forename><surname>Blank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greta</forename><surname>Tuckute</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carina</forename><surname>Kauf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eghbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Kanwisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evelina</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><surname>Fedorenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">45</biblScope>
			<date type="published" when="2021">2105646118. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The algorithmic architecture of exploration in the human brain</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel J Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current opinion in neurobiology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="7" to="14" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971</idno>
		<title level="m">Open and efficient foundation language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Driving and suppressing the human language network using large language models</title>
		<author>
			<persName><forename type="first">Greta</forename><surname>Tuckute</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aalok</forename><surname>Sathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashank</forename><surname>Srikant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maya</forename><surname>Taliaferro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingye</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Schrimpf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kendrick</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evelina</forename><surname>Fedorenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Emergent analogical reasoning in large language models</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">J</forename><surname>Holyoak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongjing</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09196</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Emergent abilities of large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMLR</title>
		<idno type="ISSN">2835-8856</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Humans use directed and random exploration to solve the explore-exploit dilemma</title>
		<author>
			<persName><forename type="first">Andra</forename><surname>Robert C Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">M</forename><surname>Geana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><forename type="middle">A</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">D</forename><surname>Ludvig</surname></persName>
		</author>
		<author>
			<persName><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">2074</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Task representations in neural networks trained to perform many cognitive tasks</title>
		<author>
			<persName><forename type="first">Guangyu</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Madhura R Joglekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">T</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao-Jing</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="297" to="306" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>

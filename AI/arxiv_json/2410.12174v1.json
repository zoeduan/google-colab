{
  "title": "Exploring Large Language Models for Hate Speech Detection in Rioplatense Spanish",
  "authors": [
    "Juan Manuel Pérez",
    "Paula Miguel",
    "Viviana Cotik"
  ],
  "abstract": "\n Hate speech detection deals with many language variants, slang, slurs, expression modalities, and cultural nuances. This outlines the importance of working with specific corpora, when addressing hate speech within the scope of Natural Language Processing, recently revolutionized by the irruption of Large Language Models. This work presents a brief analysis of the performance of large language models in the detection of Hate Speech for Rioplatense Spanish. We performed classification experiments leveraging chain-of-thought reasoning with ChatGPT 3.5, Mixtral, and Aya, comparing their results with those of a state-of-theart BERT classifier. These experiments outline that, even if large language models show a lower precision compared to the fine-tuned BERT classifier and, in some cases, they find hard-to-get slurs or colloquialisms, they still are sensitive to highly nuanced cases (particularly, homophobic/transphobic hate speech). We make our code and models publicly available for future research. \n",
  "references": [
    {
      "id": null,
      "title": "Exploring Large Language Models for Hate Speech Detection in Rioplatense Spanish",
      "authors": [
        "Juan Manuel Pérez",
        "Paula Miguel",
        "Viviana Cotik"
      ],
      "year": "2024",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Overview of mex-a3t at ibereval 2018: Authorship and aggressiveness analysis in mexican spanish tweets",
      "authors": [
        "Miguel Ángel Álvarez-Carmona",
        "Estefanía Guzmán-Falcón",
        "Manuel Montes-Y Gómez",
        "Hugo Jair Escalante",
        "Luis Villasenor Pineda",
        "Verónica Reyes-Meza",
        "Antonio Rico Sulayes"
      ],
      "year": "2018",
      "venue": "IberEval@ SEPLN",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Online hate speech in the European Union: a discourse-analytic perspective",
      "authors": [
        "Stavros Assimakopoulos",
        "H Fabienne",
        "Sharon Baider",
        "Millar"
      ],
      "year": "2017",
      "venue": "Online hate speech in the European Union: a discourse-analytic perspective",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "Semeval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter",
      "authors": [
        "Cristina Valerio Basile",
        "Elisabetta Bosco",
        "Debora Fersini",
        "Viviana Nozza",
        "Francisco Patti",
        "Manuel Rangel",
        "Paolo Pardo",
        "Manuela Rosso",
        "Sanguinetti"
      ],
      "year": "2019",
      "venue": "Proceedings of the 13th international workshop on semantic evaluation",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Massimo Poesio, and Alexandra Uma. 2021. We need to consider disagreement in evaluation",
      "authors": [
        "Michael Valerio Basile",
        "Tommaso Fell",
        "Dirk Fornaciari",
        "Silviu Hovy",
        "Paun"
      ],
      "year": "",
      "venue": "Proceedings of the 1st Workshop on Benchmarking: Past, Present and Future",
      "doi": "10.18653/v1/2021.bppf-1.3"
    },
    {
      "id": "b4",
      "title": "Relevance of cyber hate in europe and current topics that shape online hate speech",
      "authors": [
        "Tamás Berecz",
        "Charlotte Devinat"
      ],
      "year": "2017",
      "venue": "INACH",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "Experiment tracking with weights and biases",
      "authors": [],
      "year": "",
      "venue": "Experiment tracking with weights and biases",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "Language models are few-shot learners",
      "authors": [
        "Tom Brown",
        "Benjamin Mann",
        "Nick Ryder",
        "Melanie Subbiah",
        "Jared D Kaplan",
        "Prafulla Dhariwal",
        "Arvind Neelakantan",
        "Pranav Shyam",
        "Girish Sastry",
        "Amanda Askell"
      ],
      "year": "2020",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "Evaluation of chatgpt and bert-based models for turkish hate speech detection",
      "authors": [
        "Nur Bengisu",
        "Çam",
        "Arzucan Özgür"
      ],
      "year": "2023",
      "venue": "2023 8th International Conference on Computer Science and Engineering (UBMK)",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Spanish Pre-Trained BERT Model and Evaluation Data",
      "authors": [
        "José Cañete",
        "Gabriel Chaperon",
        "Rodrigo Fuentes",
        "Jou-Hui Ho",
        "Hojin Kang",
        "Jorge Pérez"
      ],
      "year": "2020",
      "venue": "Spanish Pre-Trained BERT Model and Evaluation Data",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models",
      "authors": [
        "Chung Hyung Won",
        "Le Hou",
        "Shayne Longpre",
        "Barret Zoph",
        "Yi Tay",
        "William Fedus",
        "Yunxuan Li",
        "Xuezhi Wang",
        "Mostafa Dehghani"
      ],
      "year": "",
      "venue": "Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "Argentine spanish",
      "authors": [],
      "year": "2018",
      "venue": "Journal of the International Phonetic Association",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Lunfardo rioplatense: delimitación, descripción y evolución. De parces y troncos. Nuevos enfoques sobre los argots hispánicos",
      "authors": [
        "Oscar Conde"
      ],
      "year": "2013",
      "venue": "Lunfardo rioplatense: delimitación, descripción y evolución. De parces y troncos. Nuevos enfoques sobre los argots hispánicos",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "A study of hate speech in social media during the COVID-19 outbreak",
      "authors": [
        "Viviana Cotik",
        "Natalia Debandi",
        "M Franco",
        "Paula Luque",
        "Agustín Miguel",
        "Juan Moro",
        "Pablo Manuel Pérez",
        "Joaquin Serrati",
        "Demián Zajac",
        "Zayat"
      ],
      "year": "2020",
      "venue": "A study of hate speech in social media during the COVID-19 outbreak",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "Diccionario del habla de los argentinos",
      "authors": [],
      "year": "2003",
      "venue": "Diccionario del habla de los argentinos",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "The benefits and challenges of chatgpt: An overview",
      "authors": [
        "Jianyang Deng",
        "Yijia Lin"
      ],
      "year": "2022",
      "venue": "Frontiers in Computing and Intelligent Systems",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "What is a slur?",
      "authors": [
        "Justina Diaz-Legaspe"
      ],
      "year": "2020",
      "venue": "Philosophical Studies",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "Ethnologue: Languages of the World",
      "authors": [
        "David M Eberhard",
        "Gary F Simons",
        "Charles D Fennig"
      ],
      "year": "2024",
      "venue": "Ethnologue: Languages of the World",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "you don't understand, this is a new war!\" analysis of hate speech in news web sites' comments",
      "authors": [
        "Karmen Erjavec",
        "Melita Poler",
        "Kovačič"
      ],
      "year": "2012",
      "venue": "you don't understand, this is a new war!\" analysis of hate speech in news web sites' comments",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Confidence Intervals for evaluation in machine learning",
      "authors": [
        "Luciana Ferrer",
        "Pablo Riera"
      ],
      "year": "2023",
      "venue": "Confidence Intervals for evaluation in machine learning",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "Overview of the task on automatic misogyny identification at ibereval 2018",
      "authors": [
        "Elisabetta Fersini",
        "Paolo Rosso",
        "Maria Anzovino"
      ],
      "year": "2018",
      "venue": "Ibereval@ sepln",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "A survey on automatic detection of hate speech in text",
      "authors": [
        "Paula Fortuna",
        "Sérgio Nunes"
      ],
      "year": "2018",
      "venue": "ACM Computing Surveys (CSUR)",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Deep learning tuning playbook",
      "authors": [
        "Varun Godbole",
        "George E Dahl",
        "Justin Gilmer",
        "Christopher J Shallue",
        "Zachary Nado"
      ],
      "year": "2023",
      "venue": "Deep learning tuning playbook",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "Don't Stop Pretraining: Adapt Language Models to Domains and Tasks",
      "authors": [
        "Suchin Gururangan",
        "Ana Marasović",
        "Swabha Swayamdipta",
        "Kyle Lo",
        "Iz Beltagy",
        "Doug Downey",
        "Noah A Smith"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2020.acl-main.740"
    },
    {
      "id": "b23",
      "title": "Networks of hate: the alt-right,\"troll culture\", and the cultural geography of social movement spaces online",
      "authors": [
        "Edwin Hodge",
        "Helga Kristín Hallgrímsdóttir"
      ],
      "year": "2021",
      "venue": "British Columbia's Borders in Globalization",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "Is chatgpt better than human annotators? potential and limitations of chatgpt in explaining implicit hate speech",
      "authors": [
        "Fan Huang",
        "Haewoon Kwak",
        "Jisun An"
      ],
      "year": "2023",
      "venue": "Companion Proceedings of the ACM Web Conference 2023",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "",
      "authors": [
        "Albert Q Jiang",
        "Alexandre Sablayrolles",
        "Antoine Roux",
        "Arthur Mensch",
        "Blanche Savary",
        "Chris Bamford",
        "Devendra Singh Chaplot",
        "Diego De Las Casas",
        "Emma Bou Hanna",
        "Florian Bressand",
        "Gianna Lengyel",
        "Guillaume Bour",
        "Guillaume Lample",
        "Renard Lélio",
        "Lucile Lavaud",
        "Marie-Anne Saulnier",
        "Pierre Lachaux",
        "Sandeep Stock",
        "Sophia Subramanian",
        "Szymon Yang",
        "Teven Antoniak",
        "Théophile Le Scao",
        "Thibaut Gervet",
        "Thomas Lavril",
        "Timothée Wang",
        "Lacroix"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Adam: A method for stochastic optimization",
      "authors": [
        "P Diederik",
        "Jimmy Kingma",
        "Ba"
      ],
      "year": "2014",
      "venue": "Adam: A method for stochastic optimization",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Geographical and social varieties of spanish: An overview. The handbook of Hispanic linguistics",
      "authors": [
        "M John",
        "Lipski"
      ],
      "year": "2012",
      "venue": "Geographical and social varieties of spanish: An overview. The handbook of Hispanic linguistics",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Crosslingual generalization through multitask finetuning",
      "authors": [
        "Niklas Muennighoff",
        "Thomas Wang",
        "Lintang Sutawika",
        "Adam Roberts",
        "Stella Biderman",
        "Teven Le Scao",
        "M Saiful Bari",
        "Sheng Shen",
        "Zheng Xin Yong",
        "Hailey Schoelkopf",
        "Xiangru Tang"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2023.acl-long.891"
    },
    {
      "id": "b29",
      "title": "The social life of slurs. New work on speech acts",
      "authors": [
        "Geoffrey Nunberg"
      ],
      "year": "2018",
      "venue": "The social life of slurs. New work on speech acts",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "How good is chatgpt for detecting hate speech in portuguese?",
      "authors": [
        "Amanda S Oliveira",
        "Pedro Hl Thiago C Cecote",
        "Jadson C Silva",
        "Gertrudes",
        "L S Vander",
        "Eduardo Js Freitas",
        "Luz"
      ],
      "year": "2023",
      "venue": "Anais do XIV Simpósio Brasileiro de Tecnologia da Informação e da Linguagem Humana",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "Training language models to follow instructions with human feedback",
      "authors": [
        "Long Ouyang",
        "Jeffrey Wu",
        "Xu Jiang",
        "Diogo Almeida",
        "Carroll Wainwright",
        "Pamela Mishkin",
        "Chong Zhang",
        "Sandhini Agarwal",
        "Katarina Slama",
        "Alex Ray"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "Hate speech: A systematized review",
      "authors": [
        "Antonia María",
        "Julio Paz",
        "Alicia Montero-Díaz",
        "Moreno-Delgado"
      ],
      "year": "2020",
      "venue": "Sage Open",
      "doi": ""
    },
    {
      "id": "b33",
      "title": "Robertuito: a pre-trained language model for social media text in spanish",
      "authors": [
        "Juan Manuel Pérez",
        "Damián Ariel Furman",
        "Laura Alonso Alemany",
        "Franco M Luque"
      ],
      "year": "2022",
      "venue": "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
      "doi": ""
    },
    {
      "id": "b34",
      "title": "Assessing the impact of contextual information in hate speech detection",
      "authors": [
        "Juan Manuel Pérez",
        "Demian Franco M Luque",
        "Martín Zayat",
        "Agustín Kondratzky",
        "Pablo Santiago Moro",
        "Joaquín Serrati",
        "Paula Zajac",
        "Natalia Miguel",
        "Agustín Debandi",
        "Gravano"
      ],
      "year": "2023",
      "venue": "IEEE Access",
      "doi": ""
    },
    {
      "id": "b35",
      "title": "Respectful or toxic? using zero-shot learning with language models to detect hate speech",
      "authors": [
        "Flor Miriam",
        "Plaza-Del Arco",
        "Debora Nozza",
        "Dirk Hovy"
      ],
      "year": "2023",
      "venue": "The 7th Workshop on Online Abuse and Harms (WOAH)",
      "doi": "10.18653/v1/2023.woah-1.6"
    },
    {
      "id": "b36",
      "title": "Resources and benchmark corpora for hate speech detection: a systematic review",
      "authors": [
        "Fabio Poletto",
        "Valerio Basile",
        "Manuela Sanguinetti",
        "Cristina Bosco",
        "Viviana Patti"
      ],
      "year": "2021",
      "venue": "Language Resources and Evaluation",
      "doi": ""
    },
    {
      "id": "b37",
      "title": "Hacia un plan nacional contra la discriminación",
      "authors": [],
      "year": "2006",
      "venue": "Boletín Oficial",
      "doi": ""
    },
    {
      "id": "b38",
      "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "authors": [
        "Colin Raffel",
        "Noam Shazeer",
        "Adam Roberts",
        "Katherine Lee",
        "Sharan Narang",
        "Michael Matena",
        "Yanqi Zhou",
        "Wei Li",
        "Peter J Liu"
      ],
      "year": "2020",
      "venue": "Journal of Machine Learning Research",
      "doi": ""
    },
    {
      "id": "b39",
      "title": "Alexander Sahn, Claudia von Vacano, and Chris Kennedy. 2022. The measuring hate speech corpus: Leveraging rasch measurement theory for data perspectivism",
      "authors": [
        "Pratik Sachdeva",
        "Renata Barreto",
        "Geoff Bacon"
      ],
      "year": "",
      "venue": "Proceedings of the 1st Workshop on Perspectivist Approaches to NLP @LREC2022",
      "doi": ""
    },
    {
      "id": "b40",
      "title": "Social bias frames: Reasoning about social and power implications of language",
      "authors": [
        "Maarten Sap",
        "Saadia Gabriel",
        "Lianhui Qin",
        "Dan Jurafsky",
        "Noah A Smith",
        "Yejin Choi"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b41",
      "title": "A survey on hate speech detection using natural language processing",
      "authors": [
        "Anna Schmidt",
        "Michael Wiegand"
      ],
      "year": "2017",
      "venue": "Proceedings of the fifth international workshop on natural language processing for social media",
      "doi": ""
    },
    {
      "id": "b42",
      "title": "Defining and detecting toxicity on social media: context and knowledge are key",
      "authors": [
        "Amit Sheth",
        "Valerie L Shalin",
        "Ugur Kursuncu"
      ],
      "year": "2022",
      "venue": "Neurocomputing",
      "doi": ""
    },
    {
      "id": "b43",
      "title": "Thirty years of research into hate speech: topics of interest and their evolution",
      "authors": [
        "Alice Tontodimamma",
        "Eugenia Nissi",
        "Annalina Sarra",
        "Lara Fontanella"
      ],
      "year": "2021",
      "venue": "Scientometrics",
      "doi": ""
    },
    {
      "id": "b44",
      "title": "Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model",
      "authors": [
        "Ahmet Üstün",
        "Viraat Aryabumi",
        "Zheng-Xin Yong",
        "Wei-Yin Ko",
        "D' Daniel",
        "Gbemileke Souza",
        "Neel Onilude",
        "Shivalika Bhandari",
        "Hui-Lee Singh",
        "Amr Ooi",
        "Freddie Kayid",
        "Phil Vargus",
        "Shayne Blunsom",
        "Niklas Longpre",
        "Marzieh Muennighoff",
        "Julia Fadaee",
        "Sara Kreutzer",
        "Hooker"
      ],
      "year": "2024",
      "venue": "Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model",
      "doi": "10.48550/arXiv.2402.07827"
    },
    {
      "id": "b45",
      "title": "Evaluating gpt-3 generated explanations for hateful content moderation",
      "authors": [
        "Han Wang",
        "Ming Shan Hee",
        "Md Rabiul Awal",
        "Kenny Tsu",
        "Wei Choo",
        "Roy Ka-Wei Lee"
      ],
      "year": "2023",
      "venue": "Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI-23",
      "doi": "10.24963/ijcai.2023/694"
    },
    {
      "id": "b46",
      "title": "Finetuned language models are zero-shot learners",
      "authors": [
        "Jason Wei",
        "Maarten Bosma",
        "Vincent Zhao",
        "Kelvin Guu",
        "Adams Wei Yu",
        "Brian Lester",
        "Nan Du",
        "Andrew M Dai",
        "Quoc V Le"
      ],
      "year": "2021",
      "venue": "International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b47",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Fei Xia",
        "Ed Chi",
        "V Quoc",
        "Denny Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b48",
      "title": "Make America meme again: The rhetoric of the Alt-Right",
      "authors": [
        "Suzanne Heather",
        "Leslie A Woods",
        "Hahner"
      ],
      "year": "2019",
      "venue": "Make America meme again: The rhetoric of the Alt-Right",
      "doi": ""
    },
    {
      "id": "b49",
      "title": "A brief overview of chatgpt: The history, status quo and potential future development",
      "authors": [
        "Tianyu Wu",
        "Shizhu He",
        "Jingping Liu",
        "Siqi Sun",
        "Kang Liu",
        "Qing-Long Han",
        "Yang Tang"
      ],
      "year": "2023",
      "venue": "IEEE/CAA Journal of Automatica Sinica",
      "doi": ""
    },
    {
      "id": "b50",
      "title": "Context sensitivity estimation in toxicity detection",
      "authors": [
        "Alexandros Xenos",
        "John Pavlopoulos",
        "Ion"
      ],
      "year": "2021",
      "venue": "Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)",
      "doi": "10.18653/v1/2021.woah-1.15"
    },
    {
      "id": "b51",
      "title": "Transformer-based hate speech detection for multiclass and multi-label classification",
      "authors": [
        "Gemeda Mesay",
        "Olga Yigezu",
        "Grigori Kolesnikova",
        "Alexander F Sidorov",
        "Gelbukh"
      ],
      "year": "2023",
      "venue": "Transformer-based hate speech detection for multiclass and multi-label classification",
      "doi": ""
    },
    {
      "id": "b52",
      "title": "Measuring and characterizing hate speech on news websites",
      "authors": [
        "Savvas Zannettou",
        "Mai Elsherief",
        "Elizabeth Belding",
        "Shirin Nilizadeh",
        "Gianluca Stringhini"
      ],
      "year": "2020",
      "venue": "Proceedings of the 12th ACM conference on web science",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Exploring Large Language Models For Hate Speech Detection In",
      "text": "_Rioplatense_ Spanish Juan Manuel Perez Instituto de Cs. de la Computacion CONICET, UBA jmperez at dc.uba.ar Paula Miguel Instituto Gino Germani FSOC, UBA CONICET paula at sociales.uba.ar Viviana Cotik Instituto de Cs. de la Computacion Departamento de Computacion, FCEN UBA CONICET, UBA vcotik at dc.uba.ar"
    },
    {
      "title": "Abstract",
      "text": "Hate speech detection deals with many language variants, slang, slurs, expression modalities, and cultural nuances. This outlines the importance of working with specific corpora, when addressing hate speech within the scope of Natural Language Processing, recently revolutionized by the irruption of Large Language Models. This work presents a brief analysis of the performance of large language models in the detection of Hate Speech for _Rioplatense_ Spanish. We performed classification experiments leveraging chain-of-thought reasoning with _ChatGPT 3.5_, _Mixral_, and _Aya_, comparing their results with those of a state-of-the-art BERT classifier. These experiments outline that, even if large language models show a lower precision compared to the fine-tuned BERT classifier and, in some cases, they find hard-to-get slurs or colloquialisms, they still are sensitive to highly nuanced cases (particularly, homophobic/transphobic hate speech). We make our code and models publicly available for future research."
    },
    {
      "title": "1 Introduction",
      "text": "In recent years, an increasingly unfolding of violent, discriminatory and hateful speeches can be found on digital platforms, media and networks (Berecz and Devinat, 2017; Woods and Hahner, 2019; Hodge and Hallgrimsdottir, 2021). While discriminatory discourses emerge in different enunciation areas and modalities, we are particularly interested in the way this kind of problematic speech is spread along with certain themes in the public arena and the circulation of news (Assimakopoulos et al., 2017). The news published on social networks encourages the debate or discussion of public issues and problems among users. And many times the tweets displaying hate speech are reactions to that news tweets, meaning the context of those messages is extremely important (Cotik et al., 2020). Social media, such as Twitter, offers valuable data access to a relatively natural environment for the study of hate speech, being particularly interesting the activation of hate speech regarding public topics, for example topics triggered by news that are subject of discussion (Zannettou et al., 2020; Erjavec and Kovacic, 2012). Hate speech detection, from the Natural Language Processing (NLP) perspective, has to deal with languages crossed by variants, slang, slurs, and other specific modalities found (Nunberg, 2018; Diaz-Legaspe, 2020). Being aware of cultural nuances and specific contexts of use is crucial to address this task and shows the relevance of developing dialectal corpora and analysis that allows to automatically detect specific hateful expressions in different lexical contexts. Regarding this issue, a particular interest arises in the performance of large language models (LLMs) by analyzing hate speech in relation to local expression nuances. LLMs have shown to be effective in a wide range of NLP tasks (Brown et al., 2020; Wei et al., 2021; Ouyang et al., 2022). Given that GPT-3.5 (also known as ChatGPT) is one of the most popular and emerging large language models (Wu et al., 2023; Deng and Lin, 2022), we have the question of how well it can detect hateful messages in a specific dialectal variant of Spanish, focusing on the _Rioplatense_ variety. With over 450 million native speakers, primarilyin Latin America, Spain, and also parts of the US (Eberhard, David M. and Simons, Gary F., and Fennig, Charles D., 2024), Spanish includes many varieties and dialects. Each one represents a common cultural background and semantic field, expressing different uses for some words or, contrary wise, the use of specific words or phrases addressing the same purpose. Among them, _Rioplatense_ Spanish, mainly spoken both in Argentina and Uruguay, is thought to be spoken by more than one-tenth of Spanish native speakers (Lipski, 2012; Coloma, 2018). One of the most interesting features of _Rioplatense_ Spanish is that includes ruralisms, indigenous, argot and slang, especially _lunfardo_, among other vocabularies. While almost all languages have repertoires of expression outside of general use, the case of _lunfardo_ constitutes a linguistic phenomenon in which words and expressions of very diverse origin converge (Italian, popular Spanish, French, Portuguese, Guarani, Quechua, among others), as result of the migratory processes in Argentina, with its epicenter in Buenos Aires, especially during the 19th century and the first half of the 20th century (de Letras, 2003; Conde, 2013). _Lunfardo_ shows as an integrated lexical repertoire, which has around 6,000 voices, of which only about 300 are recognized by the Dictionary of the Royal Spanish Academy,1 such as the term \"_laburar_\", from Italian \"_lavorare_\", standing as the verb \"to work\" or \"_trabajar_\" in Spanish. Many words have other meanings, for example \"_trola_\" means a lie o deceit in Iberian Spanish, but in _Rioplatense_ Spanish it refers to \"_whore_\", and it also has a masculine form \"_trolo_\" that means \"_faggot_\". These terms are commonly used to derogatorily address both women and gaps. These examples point out that the understanding of many expressions constitutes a challenge even to Spanish native speakers unfamiliar with the _Rioplatense_ variant. Would that be the case of LLMs? Footnote 1: The Royal Spanish Academy (RAE) is a cultural institution dedicated to linguistic regularization in the Spanish-speaking world. Following that question, this paper develops an exploratory approach to the effectiveness of LLMs addressing the task of detecting specific texts and tagging corpora linked to hate speech. We take as a benchmark a fine-tuned BERT classifier trained with a corpus of news articles and Twitter's comments in _Rioplatense_ Spanish, annotated to detect hate speech (Perez et al., 2023). We performed classification experiments leveraging the chain-of-thought (CoT) reasoning within the LLMs _ChatGPT_, _Mixtal_ and _Aya_, and compare their results against a fine-tuned BERT classifier. Our experiments point out that LLMs show a lower precision compared to the fine-tuned BERT classifier, but a higher recall for highly nuanced cases (particularly, homophobic/transphobic hate speech). However, explanations given by ChatGPT are --while not equal to human annotators-- convincing in most cases. The results of this work, focused in _Rioplatense_ Spanish, contribute to understanding possible forms of bias and to evaluate the specificity of _Rioplatense_ variant that is not part of the typical corpus used for training LLMs. This highlights its unique characteristics and the importance of developing and working with dialect-specific corpora for the automated detection of hate speech. Focusing exclusively on _Rioplatense_ Spanish is a first step in addressing cultural nuances and specific local expressions inherent in this dialect, particularly in relation to the performance of LLMs. Future work could be pursued on this basis, aiming to compare Rioplatense Spanish with other variants, such as Mexican or Iberian Spanish."
    },
    {
      "title": "2 Related Work",
      "text": "There is a plethora of resources for automatic detection of hate speech in English. Nevertheless, when it comes to Spanish, despite being one of the main languages in terms of the number of native speakers worldwide (Eberhard, David M. and Simons, Gary F., and Fennig, Charles D., 2024), corpora are scarce, with only a few datasets publicly available. Some of the main references of published and available resources in Spanish are found in datasets like _IberEval_, which presents a ~4k Twitter dataset for the Automatic Misogyny Identification (AMI) (Fersini et al., 2018); those released by the MEX-A3T task, that included a dataset of 11k Mexican Spanish tweets annotated for aggressiveness (Alvarez-Carmona et al., 2018); and the dataset launched in the context of the HateEval challenge, a ~6.6k tweets dataset annotated for misogyny and xenophobia (Basile et al., 2019). To the best of our knowledge, only one dataset annotated for hate speech detection is available in _Rioplatense_(Perez et al., 2023). This highlights the positive impact of contributions tending to build resources in Spanish and its variants. Regarding the automatic detection and treatment of hate speech, a broad amount of literature has been published. We refer the readers to Poletto et al. (2021); Schmidt and Wiegand (2017); Fortuna and Nunes (2018) for extensive reviews of work in the field of NLP. In this section, we focus on the most recent work on hate speech detection, explanation, and treatment using LLMs. Upon the blazing development of LLMs (Brown et al., 2020; Wei et al., 2021; Ouyang et al., 2022), some studies have been conducted to evaluate their performance in hate speech detection, explanation and treatment. Sap et al. (2020) used GPT-2 to detect and generate hate speech explanations. Plaza-del arco et al. (2023) assessed the performance of several language models (such as the instruction-finetuned _mT0_Muennighoff et al., 2023) and _FLAN-T5_Chung et al. (2022) in zero-shot setting over several hate speech and toxicity datasets. Wang et al. (2023); Huang et al. (2023) evaluated the performance of GPT-3/GPT-3.5 to detect and explain hate speech messages, finding that LLM-generated explanations are equally good (and even preferred to) human-written explanations. Some of these explanations are inducted by chain-of-thought reasoning (Wei et al., 2022), also known as the \"let's think step by step\" technique. Oliveira et al. (2023) tested ChatGPT for hate speech detection in Portuguese, particularly in its Brazilian dialect, achieving almost state-of-the-art results in a zero-shot setting. Cam and Ozgur (2023) performed experiments for Turkish, with similar results."
    },
    {
      "title": "3 Data",
      "text": "Our experiments are based on an anonymized dataset available in _Rioplatense_Spanish, consisting of Twitter replies to posts from Argentinean news outlets; with models, partitions and class distributions arealso available (Perez et al., 2023). In this dataset, comments to news posted by regional users were annotated for the presence of hate speech and categorized into one or more of eight possible types: politics, misogyny, homophobia/transphobia, racism/xenophobia, class hatred, appearance, hate against criminals and disabled people. All annotated instances have a context (the tweet posted by the news outlet, plus the news title and whole text content of the news) and the text being analyzed and annotated for hate speech (each Twitter user's comment). This is important as contextual information situates the comment and that it has been shown to be relevant to detect hate speech (Sheth et al., 2022; Xenos et al., 2021). Along with the annotated dataset, another unannotated dataset suitable for unsupervised training is provided. The unsupervised corpus used to continue pre-training includes around 5,000,000 _Rioplatense_ tweets comments, with a contextual information of 288,000 news tweets and full articles. In this work, we address the presence of hate speech linked to four possible types: misogyny, homophobia/transphobia, racism/xenophobia, and class hatred/classism, according to the attacked characteristics, from now on dubbed WOMEN, LGBT, RACISM, and CLASS (see Appendix A.1 for a broader definition). The selection of those categories was made based on the prevalence of each category among hateful speech and their societal impact. Also, these topics are widely covered and considered in the available literature, meaning the results could be a useful contribution to standard ground and state of the art (Paz et al., 2020; Tontodimamma et al., 2021). We used the same train and development samples as Perez et al. (2023) (\\(36,420\\) and \\(9120\\) examples respectively), but, for budget reasons, we subsampled the test set to \\(5670\\) examples (\\(50\\%\\) of the original test set). Among these, \\(479\\) comments contain hate speech, distributed as shown in Table 1. Some comments express attacks to more than one category. In those cases, we find two relevant combinations: RACISM associated with CLASS (21 cases), followed by the association of WOMEN and LGBT (10 cases). Only one comment targeted 3 categories at the same time. Table 2 shows some examples of the dataset. In order to assess whether the large language models were able to capture the meaning of regional terms and expressions or not, we marked the test dataset for the presence of regionalisms. We referred to regionalisms as idiomatic phrases, words \\begin{table} \\begin{tabular}{l c c} Category & Number & Percentage \\\\ \\hline RACISM & 230 & 4.06 \\% \\\\ WOMEN & 131 & 2.31 \\% \\\\ LGBT & 88 & 1.55 \\% \\\\ CLASS & 76 & 1.34 \\% \\\\ \\hline TOTAL & 479 & 8.45 \\% \\\\ \\end{tabular} \\end{table} Table 1: Number and percentage of messages containing hate speech in each category. exclusively used in _Rioplatense_ Spanish, or with a meaning that is differentially used in Argentina or only in _Rioplatense_-speaking countries (eg. \"pelotudo\" for \"asshole\"). As aforementioned, there is a vacancy area regarding _Rioplatense_: resources are scarce and, when available, they are not the best to work with. Therefore, we generated a very basic and not exhaustive list of regional terms, scraped from an crowd-sourced dictionary of regionalisms in _Rioplatense_ Spanish.2 Footnote 2: [https://www.dicionarioergentino.com/](https://www.dicionarioergentino.com/)"
    },
    {
      "title": "4 Classification Experiments",
      "text": "We compared two kinds of classification algorithms: * Pre-trained language models based on _BERT_: fine-tuned on supervised data from the corpus. * Large Language Models (LLMs) using few-shot learning and chain-of-thought reasoning (CoT) (Wei et al., 2022). For the first group of classifiers, we tested two pre-trained models in Spanish: _BETO_(Canete et al., 2020), and RoBERTuito (Perez et al., 2022). For each model, we performed a small hyperparameter search following the guidelines of Godbole et al. (2023), searching for the best-performing values for the number of epochs, the learning rate and warm-up ratio. To track our experiments, we used the _wandb_ library (Biewald, 2020). For each of the pre-trained models, we previously fine-tuned them on the unsupervised corpus provided along with the used dataset (Perez et al., 2023), as it has been shown to improve the performance in domain-specific tasks (Gururangan et al., 2020). The fine-tuning process of the supervised models followed standard practices in fine-tuning BERT-like models. The classifiers were trained with Adam (Kingma and Ba, 2014) as the optimizer with weight decay, and a triangular learning rate schedule. Table 3 outlines the spectrum of values applied to each hyperparameter. For every model, task, and language, we conducted between 30 and 60 runs, choosing the optimal model based on the Macro F1 score from the validation set. We adopted a batch size of 32, tailored to accommodate our GPU memory limitations (either a GTX 1080Ti or Tesla T4, with memory ranging from 11 to 14GB). The best hyperparameters found in the tuning process were roughly the same for all the models: \\(0.1\\) for warm-up ratio, \\(3\\) and \\(4\\) (only RoBERTuito on its non-finetuned version) the number of training epochs, and finally \\(6e^{-5}\\) for the learning rate."
    },
    {
      "title": "Prompting Strategies",
      "text": "Regarding the large language models, we selected three models that show good performance in Spanish to run the experiments and prompts: * _GPT-3.5_ turbo-0125 (Ouyang et al., 2022): a closed-source large language model provided by OpenAI, that has an outstanding performance in several tasks. * _Mixtral_(Jiang et al., 2024): a mixture-of-experts open-source language model pre-trained in English, French, Italian, German and Spanish. \\begin{table} \\begin{tabular}{l l l} Category & Context & Comment \\\\ \\hline WOMEN & Mia Khalifa: acted in porn videos for a few months, became world famous and now fights to erase her & HAHAHA KEEP SUCKING.... \\\\ LGBT & The story of the Colombian trans model kissing the & A male kissing another male \\\\ & belly of her eight-month pregnant husband & Urgent bombs to that damned race \\\\ RACISM & Yanzhong Huang: “It is quite likely that a Covid-21 & get to work, mfs \\\\ & is already brewing” & \\\\ CLASS & Social movements cut off 9 de Julio Av.: they demand a minimum wage of $45,000 & \\\\ \\hline \\end{tabular} \\end{table} Table 2: Hateful examples from the analyzed dataset. \\begin{table} \\begin{tabular}{c c} **Hyperparameter** & **Values** \\\\ \\hline Epochs & 3, 4, 5 \\\\ Batch Size & 32 \\\\ Learning Rate & 2e-5, 3e-5, 5e-5, 6e-5, 7e-5, 8e-5, 1e-4 \\\\ Weight Decay & 0.1 \\\\ Warmup Ratio & 0.06, 0.08, 0.10 \\\\ \\hline \\end{tabular} \\end{table} Table 3: Hyperparameter search space considered for each model. * _Aya_(Ustun et al., 2024): a massively-multilingual sequence-to-sequence language model, that follows the architecture of \\(T\\)5 (Raffel et al., 2020), pre-trained in 101 languages. Mixtral and Aya were run in two NVIDIA A30, using the Transformers library. The same prompt was used for the three LLMs. To build the prompt, we resorted to few-shot or in-context learning. Early experiments using zero-shot, one-shot settings and few-shot learning were conducted. Then, different prompts were evaluated in the development split until no improvement in performance was observed. That prompt engineering process led to the following prompt:3 Footnote 3: Originally in _Rioplatense_ Spanish (see in Appendix), translated to English for the purpose of this paper. Determine if the following text, corresponding to a tweet, presented with a context, contains hate speech. We understand that there is hate speech if it has statements of an intense and irrational nature of rejection, enmity, and abhorrence against an individual or against a group, being the targets of these expressions for possessing a protected characteristic. The protected characteristics we consider are: * WOMEN: refers to women or the feminist movement * LGBT: refers to gays, lesbians, transgender individuals, and other gender identities * RACISM: refers to immigrants, xenophobia, or against indigenous peoples * CLASS: refers to low-income people or class-related issues The tweets are written in Rioplatense Spanish, and within the cultural context of Argentina. Respond with one or more of the characteristics separated by commas, or \"nothing\" if there is no hate speech. Think and justify the response step by step before answering. We leveraged chain-of-thought reasoning Wei et al. (2022) to both enhance the model's performance and to provide an explanation for the prediction. The model was prompted with a total of 12 examples of hate speech considering the different characteristics. The examples were selected from the training set, and consisted of three lines, such as this: **context:**: Wuhan celebrates the end of the coronavirus quarantine with a message for the rest of the world: \"Learn from our mistakes\" **text:**: Motherfuckers! I wish you all chinese people die **output:**: The text wishes that Chinese people would die, blaming them for the COVID-19 pandemic. answer is \"racism\". The output consisted of a natural language explanation. The 12 examples considered the different characteristics and target labels and were balanced by their labels. They also included \"nothing\" examples, that pointed out cases where there was no hate speech towards the targeted categories (women, LGBT, racism or class). The selection of examples provided in the prompt had the following distribution of categories: 2 examples for racism, 2 for LGBT, 2 for women and 2 for \"nothing\"; 1 example for classism; and 1 multi-class example for racism and class. The full list of examples and the original prompt in Spanish can be found in Appendix A.2."
    },
    {
      "title": "Evaluation",
      "text": "To evaluate the performance of the classifiers, we assessed the precision, recall, and F1-score for each class, in a multi-label classification schema. We get bootstrap 95%-CI intervals using the _confidence-intervals_ library Ferrer and Riera (2023). We also evaluated a subset of the dataset, that specifically contains regional terms."
    },
    {
      "title": "5 Results",
      "text": "Table 4 shows the F1 scores for all the considered BERT classifiers. As mentioned in Section 4, we \\begin{table} \\begin{tabular}{c c c c c c} & WOMEN & RACISM & LGBT & CLASS & Macro \\\\ \\hline BETO & 0.366 & 0.698 & 0.414 & 0.437 & 0.570 \\\\ RoBERTBuis & 0.414 & 0.675 & 0.435 & 0.451 & 0.582 \\\\ BRTO (P) & 0.422 & 0.736 & 0.468 & 0.511 & 0.614 \\\\ RoBERTBuis (P) & 0.405 & 0.694 & 0.474 & 0.471 & 0.598 \\\\ \\hline \\end{tabular} \\end{table} Table 4: F1 scores for the considered BERT classifiers. FT stands for fine-tuned, marking those pre-trained models that were further fine-tuned in the unsupervised corpus. considered BETO (Canete et al., 2020) and RoBERTuito (Perez et al., 2022), and also their fine-tuned versions in the unsupervised corpus provided by the considered dataset (Perez et al., 2023). We can observe that, although RoBERTuito performs better in the non-finetuned version, BETO achieves the best results after the pre-training process. Table 5 shows the results for the multi-label classification task, represented as the macro averages of F1, Precision and Recall. We report only the results of the best BERT classifier, the fine-tuned version of BETO. While the BETO classifier outperforms their counterparts in terms of precision and F1, the LLMs have higher recall. As Aya model performed poorly, qualitative analysis is focused on the LLMs GPT-3.5 and Mixtral. A closer inspection of each of the considered characteristics is presented in the multi-label classification results, shown in Figure 1. It is shown that _Mixtral_ obtains a better recall for all of the characteristics but at the cost of low precision, while _GPT-3.5_ has a better trade-off between them. The case of the LGBT characteristic, is particularly interesting given that is the case where _GPT-3.5_ outperforms the fine-tuned classifier (\\(F1=49.9\\pm 4.4\\) for _GPT-3.5_ and \\(F1=45.7\\pm 5.1\\) for _BETO_, Mann-Whitney U=\\(16386.5,p\\leq 1*10^{-6}\\)). This is particularly relevant as this characteristic is difficult to detect, as it often involves culturally complex language, irony and metaphors and where _BERT_-based classifiers show a significant gap compared to humans (Yigezu et al., 2023; Perez et al., 2023). Focusing in those messages that contain regionalisms, no conclusive differences are detected. As seen in 6, in general, the performance of all the classifiers follows similar patterns: they stay equal or get better when regionalisms are present in the text. This might be due to the fact that regionalisms are likely to be matched with slang slurs which both the _BETO_ and the LLMs (particularly, _GPT-3.5_) leverage for this detection task. Indeed, hate speech messages represented 9% of the original dataset, and this rises to a 16% of hateful messages within those that have regionalisms. Following up, for example, in CLASS category, words such as _planero, vilero_, constituted part of the repertoire of classist denigrational speech; and regionalisms in form of slurs against WOMEN (_trola, yegua, abortera_) are also very common. These two classes are, in fact, those with more hateful comments containing regionalisms: 71% of CLASS hateful messages contains regionalisms and the same account for 62% of those against women. These slur, regional expressions may make the task of flagging hateful speech easier compared to comments lacking it. In the case of LGBT hateful instances, when hate speech detection task faces subtle, non-slur, slang related language attacking transgender peo \\begin{table} \\begin{tabular}{c c c c c c} Model & \\multicolumn{2}{c}{BETO} & \\multicolumn{2}{c}{GPT-3.5} & \\multicolumn{2}{c}{Mixtral} \\\\ \\hline Regional & reg. & wo. reg. & reg. & wo. reg. & reg. & wo. reg. \\\\ \\hline CLASS & 0.67 & 0.30 & 0.46 & 0.11 & 0.28 & 0.09 \\\\ LGBT & 0.47 & 0.44 & 0.50 & 0.48 & 0.44 & 0.47 \\\\ RACSI & 0.70 & 0.76 & 0.60 & 0.54 & 0.56 & 0.50 \\\\ WOMEN & 0.51 & 0.27 & 0.42 & 0.25 & 0.39 & 0.20 \\\\ \\hline Macro & 0.60 & 0.48 & 0.50 & 0.37 & 0.42 & 0.32 \\\\ \\hline \\end{tabular} \\end{table} Table 6: F1 by category for messages containing regionalism (reg.) and those not containing it (wo. reg.). Figure 1: Precision, recall and F1 of the classifiers: ChatGPT 3.5, Aya, Mixtral and the fine-tuned _BETO_ classifier. \\begin{table} \\begin{tabular}{l l l l} Model & F1 & Precision & Recall \\\\ \\hline _Aya_ & \\(21.2\\pm 0.8\\) & \\(11.9\\pm 0.5\\) & \\(93.0\\pm 1.2\\) \\\\ _GPT-3.5_ & \\(47.8\\pm 1.8\\) & \\(39.2\\pm 1.8\\) & \\(61.2\\pm 2.2\\) \\\\ _Mixtral_ & \\(38.6\\pm 1.3\\) & \\(25.1\\pm 1.0\\) & \\(83.8\\pm 1.7\\) \\\\ _BETO_ & \\(63.5\\pm 1.8\\) & \\(72.9\\pm 2.4\\) & \\(56.3\\pm 2.1\\) \\\\ \\hline \\end{tabular} \\end{table} Table 5: Classification results for LLMs and fine-tuned BETO, expressed as macro averages of F1, Precision and Recall for all the considered labels. [MISSING_PAGE_FAIL:7] models."
    },
    {
      "title": "6 Conclusions",
      "text": "The culture and communication of Latin America is diverse and full of different expressions, idioms, slang, specific uses, and adaptations of, among others, the Spanish language, which embodies subtle differences that are often context-dependent and cannot be captured outside of their context of use. We believe this work is a first step toward filling a gap in resources regarding _Rioplatense_, a particular variety of Spanish, and aims to contribute to the understanding of how large language models perform in these specific, \"under-resourced\" language varieties and their cultural contexts, which is particularly important when addressing the phenomenon of hate speech. This study shows the effectiveness of _ChatGPT_ and _Mixtral_ classifiers in the task of hate speech detection, specifically in the context of cultural and linguistic complexities present in _Rioplatense_ Spanish tweets. The findings highlight that while _Mixtral_ excels in recall across various characteristics, it does so at the expense of precision. Conversely, _ChatGPT_ offers a more balanced performance, particularly in detecting the LGBT characteristic, where it outperforms traditional fine-tuned classifiers, such as BETO. Comparing LLMs with a state-of-the-art fine-tuned BETO classifier, _ChatGPT_ and _Mixtral_ showed a lower precision but a higher recall in some categories, particularly in difficult cases that the supervised classifier was not able to detect. These results underline the potential for LLMs to capture cultural nuances and regional expressions effectively and to interpret culturally sensitive language rich with ironies and metaphors. The results of _ChatGPT_ to identify hate speech laden with regionalisms show ability in processing colloquial language. Notably, the prevalence of regional slurs in classist and misogynistic discourse appears to indicate the importance of incorporating regional context to improve hate speech detection. However, the observed higher rate of false positives in LLM classifications relative to BETO emphasizes the need for careful evaluation metrics when assessing the efficacy of these models. While LLMs have proven to be a powerful tool for hate speech detection, supervised classifiers still outperform them in the general case and are more suitable for detecting hate speech at large scale. Regarding cultural and linguistic nuances, we found that LLMs were able to detect some of them, but not all, missing some slurs, expressions and insults typical of the _Rioplatense_ dialect. The insights from this study emphasize the importance of building models that are sensitive to cultural and linguistic diversity, while also highlighting the value of producing corpora on specific topics and linguistic variants that serve as benchmarks. In that sense, this paper contributes to variant-focused research in NLP, being in this case _Rioplatense_ Spanish, underlining the importance of a comprehensive understanding of variants, its cultural nuances and language uses as a vital step in addressing hate speech in a linguistically diverse context."
    },
    {
      "title": "7 Limitations",
      "text": "One of the main challenges faced in this work is related to the task itself: hate speech detection, which tries to capture a complex social phenomenon. Additionally, it is important to note that the original dataset lacked natural language explanations for the annotations. Also, the task of regionalism detection could be enhanced, whether by human annotation or by dictionary enrichment, based on human annotations. Finally, the analysis of LLMs explanations was performed in a very limited way, being their soundness assessed solely by the authors. A deeper analysis of those explanations could be of interest, by including larger samples, more annotators, and the use of other metrics (such as informativeness)."
    },
    {
      "title": "8 Future Work",
      "text": "As a future work, it would be interesting to develop a multi-variant of Spanish evaluation, as this kind of analytic effort and experiments were out of the scope of this work at this stage. In particular, it could be of interest to conduct similar experiments with other Spanish variants, such as Iberian, where there are more available corpora and/or Mexican Spanish, which represents the major variant of spoken Spanish. It also could be worthwhile to consider regional specificity and/or contextual information, to distinguish text containing challenging elements, such as wordplays, metaphors related to regional knowledge, idiomatic expressions, and instances of irony. Taking that into account, would lead to better identification of regional terms, and future work could be enhanced by exploring in depth different categoriesof hate speech and the specific use of slang and colloquialisms tied to them. Along with this, future work could focus on improving the prompting engineering to have a better handling of dialectal variants."
    },
    {
      "title": "Acknowledgements",
      "text": "This research has been supported by funds for interdisciplinary projects evaluated and accredited by the Universidad de Buenos Aires, Argentina (PIUBA-2020-3; PIUBA-2022-04-02; PIUBA-2023). The authors would like to thank to the research team members for their collaboration in previous work. They also thank the National Council for Scientific and Technical Research (CONICET) for their support. The authors are specially grateful to the CCAD, Universidad Nacional de Cordoba,7 part of SNCAD-MinCyT, Argentina, for providing access to the computational resources used in this work. Footnote 7: [https://ccad.unc.edu.ar/](https://ccad.unc.edu.ar/)"
    },
    {
      "title": "References",
      "text": "* A. Alvarez-Carmona, E. Guzman-Falcon, M. Montes-y Gomez, H. J. Escalante, L. Villasenor Pineda, V. Reyes-Meza, and A. R. Sulayes (2018)Overview of mex-a3t at ibereval 2018: authorship and aggressiveness analysis in mexican spanish tweets. In IberEval@ SEPLN, pp. 74-96. Cited by: SS1. * S. Assimakopoulos, F. H. Baider, and S. Millar (2017)Online hate speech in the european union: a discourse-analytic perspective. Springer Nature. Cited by: SS1. * V. Basile, C. Bosco, E. Fersini, D. Nozza, V. Patti, F. Manuel Rangel Pardo, P. Rosso, and M. Sanguinetti (2019)Semeval-2019 task 5: multilingual detection of hate speech against immigrants and women in twitter. In Proceedings of the 13th international workshop on semantic evaluation, pp. 54-63. Cited by: SS1. * V. Basile, M. Fell, T. Fornaciari, D. Hovy, S. Paun, B. Plank, M. Poesio, and A. Uma (2021)We need to consider disagreement in evaluation. In Proceedings of the 1st Workshop on Benchmarking: Past, Present and Future, Online, pp. 15-21. Cited by: SS1. * T. Berecz and C. Devinat (2017)Relevance of cyber hate in europe and current topics that shape online hate speech. INACH EU7, pp. 2020. Cited by: SS1. * L. Biewald (2020)Experiment tracking with weights and biases. Software available from wandb.com. Cited by: SS1. * T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. (2020)Language models are few-shot learners. Advances in neural information processing systems33, pp. 1877-1901. Cited by: SS1. * N. B. Cam and A. Ozgur (2023)Evaluation of chatgpt and bert-based models for turkish hate speech detection. In 2023 8th International Conference on Computer Science and Engineering (UBMK), pp. 229-233. Cited by: SS1. * J. Cafete, G. Chaperon, R. Fuentes, J. Ho, H. Kang, and J. Perez (2020)Spanish pre-trained BERT model and evaluation data. PMLDC at ICLR. Cited by: SS1. * H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, Y. Li, X. Wang, M. Dehghani, S. Brahma, et al. (2022)Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416. Cited by: SS1. * G. Coloma (2018)Argentine spanish. Journal of the International Phonetic Association48 (2), pp. 243-250. Cited by: SS1. * O. Conde (2013)Lunfardo rioplatense: delimitacion, descripcion y evolucion. De parces y troncos. Nuevos enfoques sobre los argots hispanicos, pp. 77-106. Cited by: SS1. * V. Cotik, N. Debandi, F. M. Luque, P. Miguel, A. Moro, J. M. Perez, P. Serrati, J. Zajac, and D. Zayat (2020)A study of hate speech in social media during the COVID-19 outbreak. Cited by: SS1. * A. Argentina de Letras (2003)Diccionario del habla de los argentinos. Cited by: SS1. * J. Deng and Y. Lin (2022)The benefits and challenges of chatgpt: an overview. Frontiers in Computing and Intelligent Systems2 (2), pp. 81-83. Cited by: SS1. * J. Diaz-Legaspe (2020)What is a slur?. Philosophical Studies177 (5), pp. 1399-1422. Cited by: SS1. * E. E. E. and M. P. Kovacic (2012)\"you don't understand, this is a new war!\" analysis of hate speech in news web sites' comments. Mass Communication and Society15 (6), pp. 899-920. Cited by: SS1. * L. Ferrer and P. Riera (2023)Confidence intervals for evaluation in machine learning. Originaldate: 2023-12-06T12:26:21Z. Elisabetta Fersini, Paolo Rosso, Maria Anzovino, et al. 2018. Overview of the task on automatic misog-syny identification at ibereval 2018. _Ibereval@ sepln_, 2150:214-228. * Fortuna and Nunes (2018) Paula Fortuna and Sergio Nunes. 2018. A survey on automatic detection of hate speech in text. _ACM Computing Surveys (CSUR)_, 51(4):1-30. * Godbole et al. (2023) Varun Godbole, George E. Dahl, Justin Gilmer, Christopher J. Shallue, and Zachary Nado. 2023. Deep learning tuning playbook. Version 1. * Gururangan et al. (2020) Suchin Gururangan, Ana Marasovic, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and Noah A. Smith. 2020. Don't Stop Pretraining: Adapt Language Models to Domains and Tasks. In _Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics_, pages 8342-8360, Online. Association for Computational Linguistics. * Hodge and Hallgrimsdottir (2021) Edwin Hodge and Helga Kristin Hallgrimsdottir. 2021. Networks of hate: the alt-right,\"troll culture\", and the cultural geography of social movement spaces online. In _British Columbia's Borders in Globalization_, pages 102-119. Routledge. * Huang et al. (2023) Fan Huang, Haewoon Kwak, and Jisun An. 2023. Is chatgpt better than human annotators? potential and limitations of chatgpt in explaining implicit hate speech. In _Companion Proceedings of the ACM Web Conference 2023_, pages 294-297. * Jiang et al. (2024) Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lelio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Theophile Gervet, Thibaut Lavril, Thomas Wang, Timothee Lacroix, and William El Sayed. 2024. Mistral of Experts. * Kingma and Ba (2014) Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_. * Lipski (2012) John M Lipski. 2012. Geographical and social varieties of spanish: An overview. _The handbook of Hispanic linguistics_, pages 1-26. * Muennighoff et al. (2023) Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, and Colin Raffel. 2023. Crosslingual generalization through multitask finetuning. In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 15991-16111, Toronto, Canada. Association for Computational Linguistics. * Nunberg (2018) Geoffrey Nunberg. 2018. The social life of slurs. _New work on speech acts_, pages 237-295. * Oliveira et al. (2023) Amanda S Oliveira, Thiago C Cecote, Pedro HL Silva, Jadson C Gertrudes, Vander LS Freitas, and Eduardo JS Luz. 2023. How good is chatgpt for detecting hate speech in portuguese? In _Anais do XIV Simposio Brasileiro de Tecnologia da Informacao e da Linguagem Humana_, pages 94-103. SBC. * Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. _Advances in Neural Information Processing Systems_, 35:27730-27744. * Paz et al. (2020) Maria Antonia Paz, Julio Montero-Diaz, and Alicia Moreno-Delgado. 2020. Hate speech: A systematized review. _Sage Open_, 10(4):2158244020973022. * Perez et al. (2022) Juan Manuel Perez, Damian Ariel Furman, Laura Alonso Alemany, and Franco M Luque. 2022. Robertuito: a pre-trained language model for social media text in spanish. In _Proceedings of the Thirteenth Language Resources and Evaluation Conference_, pages 7235-7243. * Perez et al. (2023) Juan Manuel Perez, Franco M Luque, Demian Zayat, Martin Kondratzky, Agustin Moro, Pablo Santiago Serrati, Joaquin Zajac, Paula Miguel, Natalia Debandi, Agustin Gravano, et al. 2023. Assessing the impact of contextual information in hate speech detection. _IEEE Access_, 11:30575-30590. * Plaza-del arco et al. (2023) Flor Miriam Plaza-del arco, Debora Nozza, and Dirk Hovy. 2023. Respectful or toxic? using zero-shot learning with language models to detect hate speech. In _The 7th Workshop on Online Abuse and Harms (WOAH)_, pages 60-68, Toronto, Canada. Association for Computational Linguistics. * Poletto et al. (2021) Fabio Poletto, Valerio Basile, Manuela Sanguinetti, Cristina Bosco, and Viviana Patti. 2021. Resources and benchmark corpora for hate speech detection: a systematic review. _Language Resources and Evaluation_, 55(2):477-523. * de la Nacion (2006) Presidencia de la Nacion. 2006. Hacia un plan nacional contra la discriminacion\". _Boletin Oficial_, 30. * Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. _Journal of Machine Learning Research_, 21(140):1-67. * Sachdeva et al. (2022) Pratik Sachdeva, Renata Barreto, Geoff Bacon, Alexander Sahn, Claudia von Vacano, and Chris Kennedy. 2022. The measuring hate speech corpus: Leveraging rasch measurement theory for data perspectivism. In _Proceedings of the 1st Workshop on Perspectivist Approaches to NLP @LREC2022_, pages 83-94, Marseille, France. European Language Resources Association. * Sanker et al. (2020)Maarten Sap, Saadia Gabriel, Lianhui Qin, Dan Jurafsky, Noah A Smith, and Yejin Choi. 2020. Social bias frames: Reasoning about social and power implications of language. In _Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics_, pages 5477-5490. Schmidt and Wiegand (2017) Anna Schmidt and Michael Wiegand. 2017. A survey on hate speech detection using natural language processing. In _Proceedings of the fifth international workshop on natural language processing for social media_, pages 1-10. Sheth et al. (2022) Amit Sheth, Valerie L Shalin, and Ugur Kursuncu. 2022. Defining and detecting toxicity on social media: context and knowledge are key. _Neurocomputing_, 490:312-318. Tontodimamma et al. (2021) Alice Tontodimamma, Eugenia Nissi, Annalina Sarra, and Lara Fontanella. 2021. Thirty years of research into hate speech: topics of interest and their evolution. _Scientometrics_, 126:157-179. Ustun et al. (2024) Ahmet Ustun, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel D'souza, Ghemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, and Sara Hooker. 2024. Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model. Han Wang, Ming Shan Hee, Md Rabiul Awal, Kenny Tsu Wei Choo, and Roy Ka-Wei Lee. 2023. Evaluating gpt-3 generated explanations for hateful content moderation. In _Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI-23_, pages 6255-6263. International Joint Conferences on Artificial Intelligence Organization. AI for Good. Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021. Finetuned language models are zero-shot learners. In _International Conference on Learning Representations_. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. _Advances in Neural Information Processing Systems_, 35:24824-24837. Heather Suzanne Woods and Leslie A Hahner. 2019. _Make America meme again: The rhetoric of the Alth-Right_. Peter Lang New York. Tianyu Wu, Shizhu He, Jingping Liu, Siqi Sun, Kang Liu, Qing-Long Han, and Yang Tang. 2023. A brief overview of chatgpt: The history, status quo and potential future development. _IEEE/CAA Journal of Automatica Sinica_, 10(5):1122-1136. Alexandros Xenos, John Pavlopoulos, and Ion Androutsopoulos. 2021. Context sensitivity estimation in toxicity detection. In _Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)_, pages 140-145, Online. Association for Computational Linguistics. Mesay Gemeda Yigezu, Olga Kolesnikova, Grigori Sidorov, and Alexander F Gelbukh. 2023. Transformer-based hate speech detection for multi-class and multi-label classification. In _IberLEF@ SEPLN_. Savvas Zannettou, Mai ElSherief, Elizabeth Belding, Shirin Nilizadeh, and Gianluca Stringhini. 2020. Measuring and characterizing hate speech on news websites. In _Proceedings of the 12th ACM conference on web science_, pages 125-134."
    },
    {
      "title": "Appendix A Appendix",
      "text": "In this appendix, we present the definition of each targeted class of hate speech and we describe details of the original prompt and instruction provided to the LLMs"
    },
    {
      "title": "Classes Definition",
      "text": "Definition of each class addressed in hate speech detection according to the _Plan Nacional contra la Discriminacion_ (Argentinean National Plan Against Discrimination) guidelines (Presidencia de la Nacion, 2006)."
    },
    {
      "title": "A.1.1 Racism",
      "text": "Racism can be defined as a set of beliefs, attitudes and practices that discriminate against individuals or groups based on their race, ethnicity, or physical characteristics, denying them equal rights and dignity. This discrimination can be both individual and institutional and can occur in various ways: Individual racism; Institutional racism; Structural racism; Cultural racism; Xenophobia (rejection or fear of people from other countries or cultures); and also includes Antisemitism, Arabophobia, Islamophobia and Afrophobia."
    },
    {
      "title": "A.1.2 Women",
      "text": "Discrimination against women is a social phenomenon that manifests itself as a set of actions and beliefs that devalue women compared to men, through attitudes, practices and structures that perpetuate gender inequality and limit women's access to resources, rights and opportunities in various areas of life. Discrimination against women can be expressed in different areas, such as Economic Inequality; Gender Violence; Access to Education; Political Representation; Cultural Norms and Stereotypes; among others. Added to this is intersectional discrimination (women who belong to minority groups may experience additional forms of discrimination, which further complicates their situation)."
    },
    {
      "title": "A.1.3 Lgbti",
      "text": "Gender-based discrimination refers to attitudes, behaviors, and policies that marginalize and devalue people based on their sexual orientation or gender identity. This form of discrimination manifests itself in various dimensions and contexts, affecting the daily lives and fundamental rights of LGBTQ+ people. Gender-based discrimination can be expressed as violence and harassment; legal inequality; social stigmatization; unequal access to services; non-positive media representation; among others. Likewise, gender-based discrimination can intersect with other forms of discrimination, such as racism or poverty, exacerbating the difficulties faced by individuals belonging to multiple marginalized groups."
    },
    {
      "title": "A.1.4 Class",
      "text": "Class-based discrimination refers to attitudes, practices, and social structures that marginalize people based on their socioeconomic status/poverty. This form of discrimination manifests itself in various dimensions, affecting access to resources, rights, and opportunities, and perpetuating social exclusion. Expressing itself, for example, as Limited Access to Resources; Social Stigmatization; Labor Inequality; Violence and Crime; Lack of Political Representation, among others. Furthermore, class-based discrimination can intersect with other forms of discrimination, such as racism or sexism, exacerbating the difficulties faced by individuals belonging to multiple marginalized groups."
    },
    {
      "title": "Original Prompt And Examples",
      "text": "In this subsection, we present the original prompt and the provided examples for the few-shot scenario, both in Spanish. _Instruccion_ stands for Instruction, _Ejemplos_ for Example, _Contexto_, _Texto_ and _Salida_ for Context, Text, and Output. **Instruccion:** \"Determinar si el siguiente texto, correspondiente a un tweet y presentado con un contexto, contiene discusco de odio. Entendemos que hay discusco de odio si tiene declaraciones de caracter intenso y/o irracional de rechazo, enemistad o aborrecimiento contra un individu o contra un grupo, siendo el individu o el grupo objetivo de las expresiones por poseer una caracteristica protegida. Las caracteristicas protegidas que conemplamos son: * mujer: hace referencia a mujeres o al movimiento feminista. * lgbti: hace referencia a gays, lesbianas, transexuales y otras identidades de genero. * racismo: hace referencia a inmigrantes, xenofobia, o a pueblos aborigenes. * clase: hace referencia a personas de bajos recursos o motivos de clase. Los tweets estan escritos en espanol rioplatense, y dentro del contexto cultural de Argentina. Responder una o varias de las caracteristicas separadas por coma, o bien \"nada\" si no hay discusco de odio. Pensar y justificar paso a paso la respuesta antes de responder.\" **Ejemplos:** **contexto:** 'Wuhan celebra el fin de la cuarentena por el coronavirus con un mensaje para el resto del mundo: \"Apron-dan de nuestros errores\" **texto:** \"Chinos culiados de mierda ojala se mueran todos\" **salida:** 'El texto insulta a los chinos (\"culiarados\") y desea que se mueran, implicando que son los culpables del COVID-19. La respuesta final es \"racismo.\" **contexto:**\"Al borde del llanto, Nati Jota pidio disculpas por sus repudiables tu-its pero los justifico: 'Queria sumar seguidores\" **texto:** \"Show o nada mi amorr!! Sos una imbesil!\" **salida:** 'El texto contiene un insulto pero no menciona nada relacionado a las caracteristicas protegidas, pese a mencionar a una mujer. La respuesta final es \"nada\". **contexto:**'Funcionario publico y drag queen: la \"doble vida\" del politico que representa a Salta en tacos, peluca y barba con brillos', **texto:** \"Que asco..!\", **salida:**'El texto expresa desagrado hacia la identidad de genero de la persona. La respuesta final es \"lgbti\" **contexto:**\"Violento motin en la carcel de Devoto: tomaron e incendiaron pabellones\", **texto:**\"Hermanito lo que son esos grones. Ahi adentro le robaron la billetera al coronavirus\" **salida:**'El texto utiliza la palabra \"grones\", que significa negros (se obtiene \"grones\" a partir de \"negros\" cambiando el orden de las sflabas). Negro o grone es una manera despectiva de refererirse a alguien por su color de piel. Ademas, da a entender que los presos son ladrones. La respuesta final es \"racismo\". **context:**'Mayra Mendoza critico el banderazo contra el Gobierno: \"No tiene sentiido y es antidemocratico\" **text:**\"Que negrita villera....ni con la plata q roba puede arreglarse\" **output:**'El texto alude al color de piel de Mayra Mendoza (\"negrita\") y a su condicion social (\"villera\") de manera discriminatoria. La respuesta final es \"racismo, clase\". **context:**\"No da tregua: sin ropa y desafiante Flor Pena volvio a mostrar su lado mas hot\" **text:**\"K lado hot tiene mas varices k mi abuela. Tiene mas puesta de espalda k karagian trola\" **output:**'El texto alude al aspecto de Flor Pena (sus varices) y la desprecia por \"trola\", un insulto que significa \"prostituta\". La respuesta final es \"mujer\".' **context:**\"Otro ataque de furia contra un colectivero: una mujer trans le pateo la unidad y le tiro un ladrillazo\" **text:**\"Un tipo operado. Con la fuerza de un hombre y no la de una mujer\" **output:**\"salida\": 'El texto asegura que la mujer trans es \"un tipo operado\", implicando que en los hechos es un hombre y negando su identifidad de genero. La respuesta final es \"lgbti\" **context:**'Elisa Carrio denuncio que el Gobierno usa la pandemia para \"establecer un estado de sitio\" **text:**\"Gorda psiquiatrica\" **output:**'El texto habla de su aspecto (gorda) y la acusa de tener problemas psiquiatricos. Sin embargo, no hace ninguna alusion a una caracteristica protegida. La respuesta final es \"nada\". **context:**'Loly Antoniale mastro su impressionante cas en Miami: \"Soy la reina de mi castillo\" **text:**\"No pudo enganchar al viejo famoso..se busco otro..y este le puso su castillo en Miami...\" **output:**'El texto alude a la vida amorosa de Loly Antoniale, sugiriendo que busca hombres por interes economico. Esta apreciacion es sexista y despectiva. La respuesta final es \"mujer\".' **context:**\"Les daran DNI provisorio a personas en situacion vulnerable, para que puedan empezar a cobrar planes sociales\" **text:**\"Seguimos alimentando vagos\" **output:**'El texto se refiere a quienes cobran planes sociales como vagos a quienes hay que alimentar. Esto muestra un desprecio hacia las clases bajas que requieren de la asistencia estatal. La respuesta final es \"clase\".' **context:**\"Los dos presos heridos de bala en el motin de Devoto tienen Covid-19 y uno quedo hemiplejico\" **text:**\"justicia divina!\" **output:**\"salida\": \"El comentario contiene una celebracion frente a un ataque a presos. A pesar de ser sumamente ofensivo, no hace ninguna alusion a unacaracteristica proteegida. La respuesta final as 'nada'.\""
    }
  ]
}
{
  "title": "Improving Arithmetic Reasoning Ability of Large Language Models through Relation Tuples, Verification and Dynamic Feedback",
  "authors": [
    "Zhongtao Miao",
    "Kaiyan Zhao",
    "Yoshimasa Tsuruoka"
  ],
  "abstract": "\n Current representations used in reasoning steps of large language models can mostly be categorized into two main types: (1) natural language, which is difficult to verify; and (2) nonnatural language, usually programming code, which is difficult for people who are unfamiliar with coding to read. In this paper, we propose to use a semi-structured form to represent reasoning steps of large language models. Specifically, we use relation tuples, which are not only human-readable but also machinefriendly and easier to verify than natural language. We implement a framework that includes three main components: (1) introducing relation tuples into the reasoning steps of large language models; (2) implementing an automatic verification process of reasoning steps with a local code interpreter based on relation tuples; and (3) integrating a simple and effective dynamic feedback mechanism, which we found helpful for self-improvement of large language models. The experimental results on various arithmetic datasets demonstrate the effectiveness of our method in improving the arithmetic reasoning ability of large language models. The source code is available at  https://github.com/gpgg/art . \n",
  "references": [
    {
      "id": null,
      "title": "Improving Arithmetic Reasoning Ability of Large Language Models through Relation Tuples, Verification and Dynamic Feedback",
      "authors": [
        "Zhongtao Miao",
        "Kaiyan Zhao",
        "Yoshimasa Tsuruoka"
      ],
      "year": "2024",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Shyamal Anadkat, et al. 2023. Gpt-4 technical report",
      "authors": [
        "Josh Achiam",
        "Steven Adler",
        "Sandhini Agarwal",
        "Lama Ahmad",
        "Ilge Akkaya",
        "Florencia Leoni Aleman",
        "Diogo Almeida",
        "Janko Altenschmidt",
        "Sam Altman"
      ],
      "year": "",
      "venue": "Shyamal Anadkat, et al. 2023. Gpt-4 technical report",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Towards a mathematics formalisation assistant using large language models",
      "authors": [
        "Ayush Agrawal",
        "Siddhartha Gadgil",
        "Navin Goyal",
        "Ashvni Narayanan",
        "Anand Tadipatri"
      ],
      "year": "2022",
      "venue": "Towards a mathematics formalisation assistant using large language models",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "Llama 3 model card",
      "authors": [
        "Ai@meta"
      ],
      "year": "2024",
      "venue": "Llama 3 model card",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Palm 2 technical report",
      "authors": [
        "Rohan Anil",
        "Andrew M Dai",
        "Orhan Firat",
        "Melvin Johnson",
        "Dmitry Lepikhin",
        "Alexandre Passos",
        "Siamak Shakeri",
        "Emanuel Taropa",
        "Paige Bailey",
        "Zhifeng Chen"
      ],
      "year": "2023",
      "venue": "Palm 2 technical report",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models",
      "authors": [
        "Maciej Besta",
        "Nils Blach",
        "Ales Kubicek",
        "Robert Gerstenberger",
        "Lukas Gianinazzi",
        "Joanna Gajda",
        "Tomasz Lehmann",
        "Michał Podstawski",
        "Hubert Niewiadomski",
        "Piotr Nyczyk",
        "Torsten Hoefler"
      ],
      "year": "2024",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v38i16.29720"
    },
    {
      "id": "b5",
      "title": "Alec Radford, Ilya Sutskever, and Dario Amodei",
      "authors": [
        "Tom Brown",
        "Benjamin Mann",
        "Nick Ryder",
        "Melanie Subbiah",
        "Jared D Kaplan",
        "Prafulla Dhariwal",
        "Arvind Neelakantan",
        "Pranav Shyam",
        "Girish Sastry",
        "Amanda Askell",
        "Sandhini Agarwal",
        "Ariel Herbert-Voss",
        "Gretchen Krueger",
        "Tom Henighan",
        "Rewon Child",
        "Aditya Ramesh",
        "Daniel Ziegler",
        "Jeffrey Wu",
        "Clemens Winter",
        "Chris Hesse",
        "Mark Chen",
        "Eric Sigler",
        "Mateusz Litwin",
        "Scott Gray",
        "Benjamin Chess",
        "Jack Clark",
        "Christopher Berner",
        "Sam Mccandlish"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "Training verifiers to solve math word problems",
      "authors": [
        "Karl Cobbe",
        "Vineet Kosaraju",
        "Mohammad Bavarian",
        "Mark Chen",
        "Heewoo Jun",
        "Lukasz Kaiser",
        "Matthias Plappert",
        "Jerry Tworek",
        "Jacob Hilton",
        "Reiichiro Nakano",
        "Christopher Hesse",
        "John Schulman"
      ],
      "year": "2021",
      "venue": "Training verifiers to solve math word problems",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "PAL: Program-aided language models",
      "authors": [
        "Luyu Gao",
        "Aman Madaan",
        "Shuyan Zhou",
        "Uri Alon",
        "Pengfei Liu",
        "Yiming Yang",
        "Jamie Callan",
        "Graham Neubig"
      ],
      "year": "2023",
      "venue": "Proceedings of the 40th International Conference on Machine Learning",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Think before you speak: Training language models with pause tokens",
      "authors": [
        "Sachin Goyal",
        "Ziwei Ji",
        "Ankit Singh Rawat",
        "Aditya Krishna Menon",
        "Sanjiv Kumar",
        "Vaishnavh"
      ],
      "year": "2024",
      "venue": "The Twelfth International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "Language models can teach themselves to program better",
      "authors": [
        "Patrick Haluptzok",
        "Matthew Bowers",
        "Adam Tauman",
        "Kalai"
      ],
      "year": "2023",
      "venue": "The Eleventh International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "Large language models can self-improve",
      "authors": [
        "Jiaxin Huang",
        "Shixiang Gu",
        "Le Hou",
        "Yuexin Wu",
        "Xuezhi Wang",
        "Hongkun Yu",
        "Jiawei Han"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2023.emnlp-main.67"
    },
    {
      "id": "b11",
      "title": "Mistral 7b",
      "authors": [
        "Alexandre Albert Q Jiang",
        "Arthur Sablayrolles",
        "Chris Mensch",
        "Devendra Bamford",
        "Diego Singh Chaplot",
        "Florian De Las Casas",
        "Gianna Bressand",
        "Guillaume Lengyel",
        "Lucile Lample",
        "Saulnier"
      ],
      "year": "2023",
      "venue": "Mistral 7b",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Calc-X and calcformers: Empowering arithmetical chain-of-thought through interaction with symbolic systems",
      "authors": [
        "Marek Kadlčík",
        "Michal Štefánik",
        "Ondrej Sotolar",
        "Vlastimil Martinek"
      ],
      "year": "2023",
      "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2023.emnlp-main.742"
    },
    {
      "id": "b13",
      "title": "Large language models are zero-shot reasoners",
      "authors": [
        "Takeshi Kojima",
        "( Shixiang",
        ") Shane",
        "Machel Gu",
        "Yutaka Reid",
        "Yusuke Matsuo",
        "Iwasawa"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "MAWPS: A math word problem repository",
      "authors": [
        "Rik Koncel-Kedziorski",
        "Subhro Roy",
        "Aida Amini",
        "Nate Kushman",
        "Hannaneh Hajishirzi"
      ],
      "year": "2016",
      "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/N16-1136"
    },
    {
      "id": "b15",
      "title": "Efficient memory management for large language model serving with pagedattention",
      "authors": [
        "Woosuk Kwon",
        "Zhuohan Li",
        "Siyuan Zhuang",
        "Ying Sheng",
        "Lianmin Zheng",
        "Cody Hao Yu",
        "Joseph Gonzalez",
        "Hao Zhang",
        "Ion Stoica"
      ],
      "year": "2023",
      "venue": "Proceedings of the 29th Symposium on Operating Systems Principles, SOSP '23",
      "doi": "10.1145/3600006.3613165"
    },
    {
      "id": "b16",
      "title": "Era-cot: Improving chain-of-thought through entity relationship analysis",
      "authors": [
        "Yanming Liu",
        "Xinyue Peng",
        "Tianyu Du",
        "Jianwei Yin",
        "Weihao Liu",
        "Xuhong Zhang"
      ],
      "year": "2024",
      "venue": "Era-cot: Improving chain-of-thought through entity relationship analysis",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Self-refine: Iterative refinement with self-feedback",
      "authors": [
        "Aman Madaan",
        "Niket Tandon",
        "Prakhar Gupta",
        "Skyler Hallinan",
        "Luyu Gao",
        "Sarah Wiegreffe",
        "Uri Alon",
        "Nouha Dziri",
        "Shrimai Prabhumoye",
        "Yiming Yang",
        "Shashank Gupta",
        "Bodhisattwa Prasad Majumder",
        "Katherine Hermann",
        "Sean Welleck",
        "Amir Yazdanbakhsh",
        "Peter Clark"
      ],
      "year": "2023",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "A diverse corpus for evaluating and developing English math word problem solvers",
      "authors": [
        "Chao-Chun Shen-Yun Miao",
        "Keh-Yih Liang",
        "Su"
      ],
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2020.acl-main.92"
    },
    {
      "id": "b19",
      "title": "Isabelle/HOL: a proof assistant for higher-order logic",
      "authors": [
        "Tobias Nipkow",
        "Markus Wenzel",
        "Lawrence C Paulson"
      ],
      "year": "2002",
      "venue": "Isabelle/HOL: a proof assistant for higher-order logic",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "Show your work: Scratchpads for intermediate computation with language models",
      "authors": [
        "Maxwell Nye",
        "Anders Johan Andreassen",
        "Guy Gur-Ari",
        "Henryk Michalewski",
        "Jacob Austin",
        "David Bieber",
        "David Dohan",
        "Aitor Lewkowycz",
        "Maarten Bosma",
        "David Luan"
      ],
      "year": "2021",
      "venue": "Show your work: Scratchpads for intermediate computation with language models",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Are NLP models really able to solve simple math word problems?",
      "authors": [
        "Arkil Patel",
        "Satwik Bhattamishra",
        "Navin Goyal"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/2021.naacl-main.168"
    },
    {
      "id": "b22",
      "title": "Reasoning with language model prompting: A survey",
      "authors": [
        "Shuofei Qiao",
        "Yixin Ou",
        "Ningyu Zhang",
        "Xiang Chen",
        "Yunzhi Yao",
        "Shumin Deng",
        "Chuanqi Tan",
        "Fei Huang",
        "Huajun Chen"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2023.acl-long.294"
    },
    {
      "id": "b23",
      "title": "FaiRR: Faithful and robust deductive reasoning over natural language",
      "authors": [
        "Soumya Sanyal",
        "Harman Singh",
        "Xiang Ren"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2022.acl-long.77"
    },
    {
      "id": "b24",
      "title": "Edouard Grave, and Guillaume Lample. 2023a. Llama: Open and efficient foundation language models",
      "authors": [
        "Hugo Touvron",
        "Thibaut Lavril",
        "Gautier Izacard",
        "Xavier Martinet",
        "Marie-Anne Lachaux",
        "Timothée Lacroix",
        "Baptiste Rozière",
        "Naman Goyal",
        "Eric Hambro",
        "Faisal Azhar",
        "Aurelien Rodriguez",
        "Armand Joulin"
      ],
      "year": "",
      "venue": "Edouard Grave, and Guillaume Lample. 2023a. Llama: Open and efficient foundation language models",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava",
        "Shruti Bhosale",
        "Dan Bikel",
        "Lukas Blecher",
        "Cristian Canton Ferrer",
        "Moya Chen",
        "Guillem Cucurull",
        "David Esiobu",
        "Jude Fernandes",
        "Jeremy Fu",
        "Wenyin Fu",
        "Brian Fuller",
        "Cynthia Gao",
        "Vedanuj Goswami",
        "Naman Goyal",
        "Anthony Hartshorn",
        "Saghar Hosseini",
        "Rui Hou",
        "Hakan Inan",
        "Marcin Kardas",
        "Viktor Kerkez",
        "Madian Khabsa",
        "Isabel Kloumann",
        "Artem Korenev",
        "Punit Singh Koura",
        "Marie-Anne Lachaux",
        "Thibaut Lavril",
        "Jenya Lee",
        "Diana Liskovich",
        "Yinghai Lu",
        "Yuning Mao",
        "Xavier Martinet",
        "Todor Mihaylov",
        "Pushkar Mishra",
        "Igor Molybog",
        "Yixin Nie",
        "Andrew Poulton",
        "Jeremy Reizenstein",
        "Rashi Rungta",
        "Kalyan Saladi",
        "Alan Schelten",
        "Ruan Silva"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Iteratively prompt pre-trained language models for chain of thought",
      "authors": [
        "Boshi Wang",
        "Xiang Deng",
        "Huan Sun"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/2022.emnlp-main.174"
    },
    {
      "id": "b27",
      "title": "Mathcoder: Seamless code integration in LLMs for enhanced mathematical reasoning",
      "authors": [
        "Ke Wang",
        "Houxing Ren",
        "Aojun Zhou",
        "Zimu Lu",
        "Sichun Luo",
        "Weikang Shi",
        "Renrui Zhang",
        "Linqi Song",
        "Mingjie Zhan",
        "Hongsheng Li"
      ],
      "year": "2024",
      "venue": "The Twelfth International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Self-consistency improves chain of thought reasoning in language models",
      "authors": [
        "Xuezhi Wang",
        "Jason Wei",
        "Dale Schuurmans",
        "V Quoc",
        "Ed H Le",
        "Sharan Chi",
        "Aakanksha Narang",
        "Denny Chowdhery",
        "Zhou"
      ],
      "year": "2023",
      "venue": "The Eleventh International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b29",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Fei Xia",
        "Ed Chi",
        "Denny Quoc V Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "2024a. WizardLM: Empowering large pre-trained language models to follow complex instructions",
      "authors": [
        "Can Xu",
        "Qingfeng Sun",
        "Kai Zheng",
        "Xiubo Geng",
        "Pu Zhao",
        "Jiazhan Feng",
        "Chongyang Tao",
        "Qingwei Lin",
        "Daxin Jiang"
      ],
      "year": "",
      "venue": "The Twelfth International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "2024b. Faithful logical reasoning via symbolic chain-of-thought",
      "authors": [
        "Jundong Xu",
        "Hao Fei",
        "Liangming Pan",
        "Qian Liu",
        "Mong-Li Lee",
        "Wynne Hsu"
      ],
      "year": "",
      "venue": "2024b. Faithful logical reasoning via symbolic chain-of-thought",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "Buffer of thoughts: Thoughtaugmented reasoning with large language models",
      "authors": [
        "Ling Yang",
        "Zhaochen Yu",
        "Tianjun Zhang",
        "Shiyi Cao",
        "Minkai Xu",
        "Wentao Zhang",
        "Joseph E Gonzalez",
        "Bin Cui"
      ],
      "year": "2024",
      "venue": "Buffer of thoughts: Thoughtaugmented reasoning with large language models",
      "doi": ""
    },
    {
      "id": "b33",
      "title": "Tree of thoughts: Deliberate problem solving with large language models",
      "authors": [
        "Shunyu Yao",
        "Dian Yu",
        "Jeffrey Zhao",
        "Izhak Shafran",
        "Tom Griffiths",
        "Yuan Cao",
        "Karthik Narasimhan"
      ],
      "year": "2023",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b34",
      "title": "Teaching language models to selfimprove through interactive demonstrations",
      "authors": [
        "Xiao Yu",
        "Baolin Peng",
        "Michel Galley",
        "Jianfeng Gao",
        "Zhou Yu"
      ],
      "year": "2023",
      "venue": "Teaching language models to selfimprove through interactive demonstrations",
      "doi": ""
    },
    {
      "id": "b35",
      "title": "Star: Bootstrapping reasoning with reasoning",
      "authors": [
        "Eric Zelikman",
        "Yuhuai Wu",
        "Jesse Mu",
        "Noah Goodman"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b36",
      "title": "Automatic model selection with large language models for reasoning",
      "authors": [
        "James Zhao",
        "Yuxi Xie",
        "Kenji Kawaguchi",
        "Junxian He",
        "Michael Xie"
      ],
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2023",
      "doi": "10.18653/v1/2023.findings-emnlp.55"
    },
    {
      "id": "b37",
      "title": "2024a. Solving challenging math word problems using GPT-4 code interpreter with code-based self-verification",
      "authors": [
        "Aojun Zhou",
        "Ke Wang",
        "Zimu Lu",
        "Weikang Shi",
        "Sichun Luo",
        "Zipeng Qin",
        "Shaoqing Lu",
        "Anya Jia",
        "Linqi Song",
        "Mingjie Zhan",
        "Hongsheng Li"
      ],
      "year": "",
      "venue": "The Twelfth International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b38",
      "title": "Least-to-most prompting enables complex reasoning in large language models",
      "authors": [
        "Denny Zhou",
        "Nathanael Schärli",
        "Le Hou",
        "Jason Wei",
        "Nathan Scales",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Claire Cui",
        "Olivier Bousquet",
        "Ed H Quoc V Le",
        "Chi"
      ],
      "year": "2023",
      "venue": "The Eleventh International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b39",
      "title": "2024b. Don't trust: Verify -grounding LLM quantitative reasoning with autoformalization",
      "authors": [
        "Jin Peng Zhou",
        "Charles E Staats",
        "Wenda Li",
        "Christian Szegedy",
        "Kilian Q Weinberger",
        "Yuhuai Wu"
      ],
      "year": "",
      "venue": "The Twelfth International Conference on Learning Representations",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Improving Arithmetic Reasoning Ability Of Large Language Models",
      "text": "through Relation Tuples, Verification and Dynamic Feedback Zhongtao Miao, Kaiyan Zhao, Yoshimasa Tsuruoka The University of Tokyo, Tokyo, Japan {mzt, zhaokaiyan1006, yoshimasa-tsuruoka}@g.ecc.u-tokyo.ac.jp"
    },
    {
      "title": "Abstract",
      "text": "Current representations used in reasoning steps of large language models can mostly be categorized into two main types: (1) natural language, which is difficult to verify; and (2) non-natural language, usually programming code, which is difficult for people who are unfamiliar with coding to read. In this paper, we propose to use a semi-structured form to represent reasoning steps of large language models. Specifically, we use relation tuples, which are not only human-readable but also machine-friendly and easier to verify than natural language. We implement a framework that includes three main components: (1) introducing relation tuples into the reasoning steps of large language models; (2) implementing an automatic verification process of reasoning steps with a local code interpreter based on relation tuples; and (3) integrating a simple and effective dynamic feedback mechanism, which we found helpful for self-improvement of large language models. The experimental results on various arithmetic datasets demonstrate the effectiveness of our method in improving the arithmetic reasoning ability of large language models. The source code is available at [https://github.com/gpgg/art](https://github.com/gpgg/art)."
    },
    {
      "title": "1 Introduction",
      "text": "Large language models, such as GPT series Brown et al. (2020); Achiam et al. (2023), PaLM Anil et al. (2023), Mistral Jiang et al. (2023), and LLaMA Touvron et al. (2023, 2023); AI@Meta (2024), have shown great success in numerous tasks that require reasoning. Besides the approach to scaling up the size of large language models and training data to enhance their reasoning ability, many prompting methods have been proposed to improve their reasoning performance. Previous works Wei et al. (2022); Kojima et al. (2022); Zelikman et al. (2022); Gao et al. (2023), which aim to enhance the reasoning ability of large language models, can be categorized into two main types: natural language-based approaches and non-natural language-based approaches. The natural language-based approaches include Chain-of-Thought (CoT) Wei et al. (2022) and Zero-shot CoT Kojima et al. (2022), which utilize intermediate reasoning steps in natural language to elicit the reasoning ability of large language models. The non-natural language-based approaches include PAL Gao et al. (2023), which proposes to use Python code to solve math word problems. However, the reasoning steps represented in nat Figure 1: Schematic overview of our framework, ART. “Q” denotes a question. “NL” means “Natural Language”. “RT” means “Relation Tuple”. The left subfigure shows our proposed framework ART without Self-Consistency Wang et al. (2023). The right subfigure shows that our framework can be integrated with Self-Consistency seamlessly. ural language are usually long, which can significantly increase inference cost and may contain computational errors and unjustified logical leaps Zhou et al. (2024). Besides, unlike graphs or formal languages, they are difficult to verify because of the nature of natural language Zhou et al. (2024). Recently, there have been some studies that focus on translating natural language statements into formal languages such as Isabelle Nipkow et al. (2002) using large language models Agrawal et al. (2022); Zhou et al. (2024); Xu et al. (2024). However, those formal languages are hard for humans to read. In this study, we propose a framework named ART1 to enhance the arithmetic reasoning ability of large language models. A schematic overview of our ART framework is shown in Figure 1. First, we utilize in-context learning to make a large language model generate reasoning steps mixed with a simple semi-structured form, relation tuples. We can obtain an answer after reasoning. These relation tuples are very similar to pseudo-code, which can easily be translated into real programming code. Next, the large language model generates a Python code solution to verify the reasoning steps based on the question and relation tuples. We run the Python code in a local code interpreter to obtain the verification answer. Finally, we check whether the two answers are consistent or not and provide a dynamic feedback when necessary. If the two answers are inconsistent, we will use the large language model to regenerate a new reasoning process based on a simple dynamic feedback mechanism. The answer is determined if the two answers are consistent or reach the maximum number of tries in the feedback loop. Footnote 1: ART: Improving **A**rithmetic Reasoning Ability through **R**elation **T**uples, Verification and Dynamic Feedback The main contributions of this paper can be summarized as follows: * We introduce a semi-structured representation, relation tuples, into the reasoning steps of large language models. Relation tuples are usually shorter and easier to read, compared with long reasoning steps in natural language. They are more machine friendly because they are very similar to pseudo-code, which can be translated to real Python or other programming language code easily. Our findings also reveal that incorporating relation tuples into few-shot examples can improve the accuracy on four out of seven arithmetic datasets. * This study provides a local code interpreter and employs it to develop a reasoning step verifier based on relation tuples. This local code interpreter can be integrated with any large language model seamlessly, regardless of whether they are open source or not. * We implement a simple and effective dynamic feedback mechanism. Unlike Self-Refine Madaan et al. (2023), our dynamic feedback mechanism is considerably simpler but effective. Here, \"Dynamic\" means that feedback is provided when necessary."
    },
    {
      "title": "2 Method",
      "text": ""
    },
    {
      "title": "Problem Formulation",
      "text": "We denote a large language model as LM. Suppose that we have a dataset \\(D\\). The dataset can be denoted as \\(D=\\{Q_{i},A_{i}\\}_{i=0}^{N-1}\\), where \\(Q_{i}\\) is the \\(i\\)-th question, \\(A_{i}\\) is the answer of \\(Q_{i}\\) and \\(N\\) is the number of examples in the dataset. The CoT method aims to generate a series of reasoning steps and an answer, which can be denoted as: \\[[\\hat{R_{i}},\\hat{A_{i}}]=\\text{LM}(Q_{i}), \\tag{1}\\] where \\(\\hat{R_{i}}\\) denotes the generated intermediate reasoning steps of the large language model LM and \\(\\hat{A_{i}}\\) denotes the predicted answer after the reasoning steps. The local code interpreter is denoted as LCI."
    },
    {
      "title": "Art Framework",
      "text": "The ART framework can be described in the following steps: Step 1: Reasoning with relation tuples.Given a question \\(Q_{i}\\) from the dataset \\(D\\), LM generates reasoning process \\(\\hat{R_{i}}=\\text{LM}(Q_{i})\\) and its answer, \\(\\hat{A_{i}}\\). The reasoning process consists of a series of reasoning steps and each reasoning step contains a natural language statement and its relation tuple equivalent. The reasoning process can be denoted as a list: \\[\\hat{R_{i}}=[(r_{0},t_{0}),\\ldots,(r_{i},t_{i}),\\ldots,(r_{n-1},t_{n-1})], \\tag{2}\\] where \\(r_{i}\\) is the reasoning step in natural language and \\(t_{i}\\) is its equivalent in the relation tuple form. \\(n\\) is the number of reasoning steps. The prompt used in this step is shown in Figure 3. Step 2: Automatic verification with relation triples and a local code interpreter.We can extract the relation tuples from the reasoning steps \\(\\hat{R}_{i}\\) in Step 1. The relation tuples extracted are denoted as a list: \\[T_{i}=[t_{0},\\ldots,t_{i},\\ldots,t_{n-1}]. \\tag{3}\\] To verify whether the reasoning steps in Step 1 are correct or not, we decide to use Python code and implement a local code interpreter. Based on the question \\(Q_{i}\\) and reasoning steps in relation tuples \\(T_{i}\\), LM generates a Python code solution \\(C_{i}\\) step by step. The code generation process can be denoted as: \\[C_{i}=\\text{LM}(Q_{i},T_{i}). \\tag{4}\\] After obtaining the Python solution \\(C_{i}\\). We execute it using our local code interpreter LCI and get the verification answer \\(\\hat{A}_{i}^{v}\\) from the execution result: \\[\\hat{A}_{i}^{v}=\\text{LCI}(C_{i}). \\tag{5}\\] The prompt used in this step is shown in Figure 4. Step 3: Checking consistency and providing dynamic feedback when necessary.From Step 1, we can get one answer \\(\\hat{A}_{i}\\) based on reasoning steps with relation tuples. From Step 2, we can obtain the verification answer \\(\\hat{A}_{i}^{v}\\). If these two answers are Figure 2: A detailed example illustrating how our method works. This example shows the solution to the first question of the test split of the GSM8K dataset, generated by our framework using ChatGPT. equal, it indicates that the reasoning steps in Step 1 are consistent with Step 2, confirming that there is no computational error. Therefore, the answer is determined. However, if the two answers are inconsistent, the previous reasoning steps \\(\\hat{R}_{i}\\) will be resent to the large language model LM as a feedback. LM regenerates reasoning process \\(\\hat{R}_{i}\\) and its answer \\(\\hat{A}_{i}\\) based on the feedback. The feedback prompt used here is shown in Figure 5. We record all the answers from Step 1 and Step 2 and choose the most common one as the final answer, ensuring seamless integration with the Self-Consistency approach Wang et al. (2023). We also provide an example to show the effectiveness of this dynamic feedback mechanism in Figure 6."
    },
    {
      "title": "3 Experiments",
      "text": ""
    },
    {
      "title": "Setup",
      "text": "Datasets.In this study, we focus on the arithmetic reasoning ability of large language models. We conduct experiments on seven arithmetic datasets, including GSM8K Cobbe et al. (2021), SVAMP Patel et al. (2021), ASDIV Miao et al. (2020), SingleOP, SingleEQ, AddSub and MultiArith Koncel-Kedziorski et al. (2016), following Zhao et al. (2023). GSM8K is a high-quality dataset which contains 8.5K problems and solutions in total. These problems usually involve 2-8 basic arithmetic operation (addition, subtraction, multiplication and division) steps to reach the final answers. SVAMP, ASDIV, SingleOP, SingleEQ, AddSub and MultiArith are different arithmetic datasets which cover various patterns. The statistics of the datasets are shown in Table 1. The primary metric used for evaluation is accuracy. Models.To evaluate our approach, we employ two proprietary large language models, ChatGPT (gpt-3.5-turbo-0301)2 and GPT4o (gpt-4o-2024-05-13)3 and one open source large language model, Llama3-8B-Instruct (meta-llama/Meta-llama-3-8B-Instruct)4. Footnote 2: [https://platform.openai.com/docs/deperations/2023-06-13-updated-chat-models](https://platform.openai.com/docs/deperations/2023-06-13-updated-chat-models) Footnote 3: [https://platform.openai.com/docs/models/gpt-4o](https://platform.openai.com/docs/models/gpt-4o) Footnote 4: [https://huggingface.co/meta-llama/Meta-llama-3-8B](https://huggingface.co/meta-llama/Meta-llama-3-8B) Specifically, we utilize ChatGPT for our main ex \\begin{table} \\begin{tabular}{c c} \\hline \\hline Dataset Name & \\# Test Set \\\\ \\hline GSM8K & 1319 \\\\ ASDIV & 2096 \\\\ SVAMP & 1000 \\\\ SingleOP & 562 \\\\ SingleEQ & 508 \\\\ AddSub & 395 \\\\ MultiArith & 600 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 1: Number of examples in the test splits of the seven arithmetic datasets we use in this study. Figure 4: Prompt of program verification in Step 2. Figure 5: Feedback prompt when ART needs feedback. Figure 3: Prompt of relation tuple reasoning in Step 1. periments and use GPT-4o and Llama3-8B-Instruct in our ablation study. In our framework, the temperatures of Llama3-8B-Instruct are set to 0.5 in both Step 1 and Step 2. For the results in Table 2, both temperatures in Step 1 and Step 2 are set to 0, and the top_p parameter is set to 1 to ensure a fair comparison with ModelSelection (Zhao et al., 2023). We use the same prompt for all seven arithmetic datasets for each large language model. In-context Learning.For ChatGPT and Llama3-8B-Instruct, we employ in-context learning using an eight-shot setting. In this setting, we select the first eight questions from the train split of the GSM8K dataset. The process of obtaining our eight-shot examples is as follows: First, we use GPT-4 to generate CoT solutions based on the questions. Then, we incorporate relation tuples into the reasoning steps based on the CoT solutions generated by GPT-4. The complete eight-shot examples are provided in Appendix B. The reason for using the first eight examples of the train split of GSM8K is to avoid cherry-picking examples for in-context learning. For GPT-4o, following previous works (Zhao et al., 2023), we utilize a five-shot setting. The five examples are sampled from the eight-shot examples used in the eight-shot setting. Further details can be found in Appendix B. Implementation.We implement our framework and conduct evaluations based on the ModelSelection codebase5 provided by Zhao et al. (2023). For our local code interpreter implementation, we developed a customized version by adapting the code from Local-Code-Interpreter6. For the OpenAI Python library, we use version 1.23.2. For the open source Llama3-8B-Instruct, we employ the large language model inference library vLM (version 0.4.3)7(Kwon et al., 2023) and a single NVIDIA A100 80GB GPU to run our experiments. Footnote 5: [https://github.com/XuZhao0/Model-Selection-Reasoning](https://github.com/XuZhao0/Model-Selection-Reasoning) Footnote 6: [https://github.com/MrGreyfun/Local-Code-Interpreter](https://github.com/MrGreyfun/Local-Code-Interpreter) Footnote 7: [https://github.com/vllm-project/vllm](https://github.com/vllm-project/vllm) When the answers from Step 1 and Step 2 are inconsistent, the maximum number of attempts allowed in Step 3 of our framework is set to 3. Figure 6: Comparison of “Reasoning with RT” solutions without feedback and with feedback, generated by our framework. This example shows the predicted solution for the \\(55\\)-th question in the test split of the GSM8K dataset, using our method with ChatGPT (gpt-3.5-turbo-0301)."
    },
    {
      "title": "Main Results",
      "text": "As shown in Table 2, we report the accuracy results on the seven arithmetic datasets. Table 2 shows that our approach outperforms CoT, PAL and ModelSelection baselines on ChatGPT (gpt-3.5-turbo-0301). Notably, our method is particularly effective on the GSM8K, SVAMP and AddSub datasets. Specifically, it improves accuracy on the SVAMP dataset by 2.8%, compared with ModelSelection and achieves a 1.9% improvement over ModelSelection's 82.6% accuracy on the GSM8K dataset."
    },
    {
      "title": "4 Analysis And Discussion",
      "text": "In this section, we analyze various factors affecting the performance of our framework. The dataset we use here is GSM8K. First, we investigate the effects of prior prompts used in ModelSelection (Zhao et al., 2023) and GPT-4 generated prompts using the same CoT method because our eight-shot examples are created based on the GPT-4 generated solutions. Then, we assess the contributions of relation tuples, verification by programming code and feedback individually using three different large language models. Finally, we show that our method can be integrated into Self-Consistency."
    },
    {
      "title": "Original Prompt Vs. Gpt-4 Generated Prompt",
      "text": "We utilize in-context learning to build our framework. Existing works use the eight-shot examples from CoT while the eight-shot examples in our method are manually created with the help of GPT-4. Therefore, in this section, we aim to test the impact of difficulty of different prompts on the model's performance with CoT. As shown in Table 3, we find that the performance difference between using the two versions of prompts is not significant on ChatGPT and Llama3-8B-Instruct. The GPT-4 generated eight-shot prompt and the eight-shot prompt used in our framework are shown in Appendix B."
    },
    {
      "title": "Role Of Relation Tuples In Step 1",
      "text": "In this section, we analyze the role of relation tuples. From Table 4, we can observe that the reasoning process incorporating relation tuples outperforms the CoT reasoning process on four out of the seven arithmetic datasets. Relation tuples in the reasoning process can be viewed as notes that record key points in the reasoning steps in natural language. These relation tuples may function as \"pause\" tokens (Goyal et al., 2024), prompting large language models to \"think\" before generating the next reasoning step."
    },
    {
      "title": "Role Of Verification By Programming Code In Step 2",
      "text": "Table 5 shows the accuracy on the GSM8K dataset when using the answers from different steps of our framework as the final answers. In the table, \"Reasoning with RT\" represents the accuracy obtained by using the answer from Step 1 of our framework as the final answer. \"Verification by Programming Code\" indicates the accuracy achieved by using the answer from Step 2 of our framework as the final answer. The third row \"Reasoning with RT \\(+\\) Verification \\(\\mathrm{w/o}\\) Feedback\" shows the accuracy when the two answers from Step 1 and Step 2 of our framework are consistent and correct on the first attempt. \\begin{table} \\begin{tabular}{c c c c c c c c} \\hline \\hline Backbone & Method & SVAMP & ASDIV & SingleOP & SingleEQ & AddSub & MultiArith & GSM8K \\\\ \\hline \\multirow{4}{*}{ChatGPT} & CoT & 83.0 & 89.3 & 94.8 & 97.4 & 90.4 & 98.7 & 80.8 \\\\ & PAL & 80.3 & 83 & 90.7 & 97.6 & 89.4 & 96.3 & 79.2 \\\\ \\cline{1-1} & ModelSelection & 84.3 & 89.4 & 94.8 & 97.8 & 90.6 & 98.7 & 82.6 \\\\ \\cline{1-1} & ART (ours) & **87.1** & **89.6** & **96.3** & **97.8** & **93.2** & **98.7** & **84.5** \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 2: Accuracy results on seven arithmetic datasets. The ChatGPT backbone that we use is gpt-3.5-turbo-0301 to ensure a fair comparison with other baselines. The results of CoT, PAL and ModelSelection are quoted from Zhao et al. (2023). Bold fonts highlight the best performance for each dataset. \\begin{table} \\begin{tabular}{c c c} \\hline \\hline Backbone & Method & GSM8K \\\\ \\hline \\multirow{2}{*}{ChatGPT} & CoT (original prompt) & 80.8 \\\\ & CoT (GPT-4-generated prompt) & 80.1 \\\\ \\hline \\multirow{2}{*}{Llama3-8B-Instruct} & CoT (original prompt) & 80.1 \\\\ & CoT (GPT-4-generated prompt) & 80.1 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 3: Accuracy results on GSM8K with different eight-shot examples. The “CoT (original prompt)” result with ChatGPT is quoted from ModelSelection (Zhao et al., 2023)From Table 5, it is evident that the accuracy scores on the GSM8K dataset using the verification answers from Step 2 of our framework are are lower than those using relation tuples. We can observe that the most obvious one is Llama3-8B-Instruct, which cannot generate programming code very well based on the semi-structured form of reasoning (relation tuples), whereas ChatGPT and GPT-4o excel in this task. A possible reason for this discrepancy could be that in Step 2 of our framework, we use relation tuples and questions as inputs for large language models, which are infrequently encountered during their training phases. Consequently, these models struggle with generating Python solutions from this semi-structured form. This is particularly evident in the Llama3-8B-Instruct model, where there is an accuracy gap between using answers from Step 1 and Step 2 as final answers. This indicates that Llama3-8B-Instruct may have difficulty generating Python verification solutions based on relation tuples. We also observe several common execution errors when Llama3-8B-instruct generates and executes Python solution code to verify the reasoning process in Step 2. Empirically, the most frequent error is \"UnboundLocalError: local variable referenced before assignment\", typically caused by using symbols that cannot serve as variable names in Python. Additionally, \"SyntaxError\" is another commonly encountered error."
    },
    {
      "title": "Role Of Feedback In Step 3",
      "text": "We explore the effect of the dynamic feedback mechanism in our framework in this section. Figure 7 and 8 show the percentage of questions utilizing feedback on the GSM8K dataset and the other 6 arithmetic datasets, respectively. In Figure 7, we observe an interesting phenomenon: as the coding capabilities of the large language models increase (Llama3-8B-Instruct < ChatGPT < GPT-4o) as shown in Table 5, the percentage of questions requiring feedback continuously decreases. From Figure 8, we observe that the dataset on which ChatGPT requires feedback most frequently is ASDIV. The percentage of feedback utilization might be related to the quality of datasets and the \\begin{table} \\begin{tabular}{l c c c c c c c c} \\hline \\hline Backbone & Method & SVAMP & ASDIV & SingleOP & SingleEQ & AddSub & MultiArith & GSM8K \\\\ \\hline \\multirow{2}{*}{ChatGPT} & CoT & 83.0 & **89.3** & 94.8 & **97.4** & 90.4 & **98.7** & 80.8 \\\\ & Reasoning with RT & **85.4** & 89.1 & **96.3** & 97.0 & **93.0** & 98.2 & **81.9** \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 4: Comparison of accuracy on the seven arithmetic datasets between using prior eight-shot prompt (CoT eight-shot prompt) and using our eight-shot prompt (reasoning with RT eight-shot prompt). Figure 8: Percentage of questions requiring feedback on the test splits of the other six datasets (SVAMP, ASDIV, SingleEQ, SingleOP, AddSub, MultiArith) using ChatGPT (gpt-3.5-turbo-0301). The details can be found in Table 8, Appendix C. \\begin{table} \\begin{tabular}{c c c} \\hline \\hline Model & Method & GSM8K \\\\ \\hline \\multirow{4}{*}{ChatGPT} & Reasoning with RT & 81.9 \\\\ & Verification by Programming Code & 79.9 \\\\ & Reasoning with RT + Verification w/o Feedback & 75.2 \\\\ & ART (ours) & 84.5 \\\\ \\hline \\multirow{4}{*}{Llama3-8B-Instruct} & Reasoning with RT & 79.6 \\\\ & Verification by Programming Code & 71.6 \\\\ & Reasoning with RT + Verification w/o Feedback & 69.1 \\\\ & ART (ours) & 80.4 \\\\ \\hline \\multirow{4}{*}{GPT-4o} & Reasoning with RT & 96.4 \\\\ & Verification by Programming Code & 95.5 \\\\ & Reasoning with RT + Verification w/o Feedback & 95.2 \\\\ & ART (ours) & 96.6 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 5: Accuracy results of the ablation study of our framework on the GSM8K dataset. “RT” means Relation Tuples. Figure 7: Percentage of questions requiring feedback on the test split of the GSM8K dataset. Note that “Llama3” denotes Llama3-8B-Instruct model. The details can be found in Table 7, Appendix C. programming code understanding and generation capabilities of large language models."
    },
    {
      "title": "Integration With Self-Consistency",
      "text": "Our framework is designed for seamless integration with the Self-Consistency approach Wang et al. (2023). The core idea of Self-Consistency is to select the most common answer derived from multiple reasoning paths. In our framework, we also determine the final answer by choosing the most frequent answer from different steps. From Table 6, we can observe that with the aid of Self-Consistency, our framework significantly enhances the arithmetic reasoning performance of Llama3-8B-Instruct on the GSM8K dataset."
    },
    {
      "title": "5 Related Work",
      "text": "Natural language reasoning.There are large amounts of studies (Qiao et al., 2023; Sanyal et al., 2022; Nye et al., 2021; Wang et al., 2022) focusing on enhancing the reasoning ability of large language models in natural language. Chain-of-Thought (CoT) (Wei et al., 2022) shows that intermediate reasoning steps can improve the performance of large language models. Zero-shot CoT, as proposed by Kojima et al. (2022), involves simply adding \"Let's think step by step\" before generating answers to elicit the reasoning ability of large language models. Least-to-most prompting Zhou et al. (2023) breaks down complex problems to simpler problems and solve them in sequence to enable complex reasoning in large language models. Self-Consistency Wang et al. (2023) extends CoT by sampling various reasoning paths, generating multiple answers and choosing the most common one. Tree-of-Thought Yao et al. (2023) generalizes over Chain-of-Thought by framing any problem as a search over a tree. Besta et al. (2024) propose Graph-of-Thoughts to improve large language model's reasoning ability by modeling large language model thoughts as vertices and dependencies between these vertices as edges. Buffer-of-Thoughts Yang et al. (2024) is a novel prompting approach which employs a meta-buffer to store a series of thought templates (high-level thoughts) and retrieves a relevant thought template and instantiate it when conducting reasoning. Non-natural language reasoning and verification.There are many works Kadlick et al. (2023); Gao et al. (2023); Xu et al. (2024) aiming to enhance the reasoning ability of large language models by using non-natural language forms during the reasoning process. PAL Gao et al. (2023) employs large language models to generate Python code as intermediate reasoning steps. ERA-CoT Liu et al. (2024) aids large language models in reasoning by analyzing entities and relationships in natural language statements. Zhou et al. (2024) find that GPT-4's powerful skills in generating and executing code could be utilized to enhance mathematical reasoning ability by analyzing the Code Usage Frequency of the GPT-4 Code Interpreter. MathCoder Wang et al. (2024) integrates natural language reasoning, code generation and execution results to enhance the mathematical reasoning ability of large language models by fine-tuning them. SymbolCoT Xu et al. (2024) integrates symbolic expressions and logic rules into the reasoning process of large language models to enhance their logical reasoning ability. Zhou et al. (2024) translate informal natural language reasoning statements into formal Isabelle code which can be verified automatically to enhance internal consistency of reasoning in large language models. Different from these works, our method utilizes the semi-structure understanding and code generation ability of large language models to verify the reasoning process. Self-improvement and verification.There are many works focusing on the self-improvement of large language models Huang et al. (2023); Madaan et al. (2023); Haluptzok et al. (2023); Xu et al. (2024); Yu et al. (2023). Zelikman et al. (2022) propose Self-Taught Reasoner (STaR), which employs a reasoning process generation loop to produce reasoning steps and use these generated reasoning paths whose final answers are correct to further fine-tune large language models. Madaan et al. (2023) propose Self-Refine, which has three components (generator, feedback provider and refiner). Compared with Self-Refine, the dynamic feedback in our framework is provided only when necessary. Moreover, our framework does not need the feedback provider. \\begin{table} \\begin{tabular}{c c c} \\hline \\hline Backbone & Method & GSM8K \\\\ \\hline Llama3-8B-Instruct & ART (SC@1) & 80.4 \\\\ & ART (SC@5) & 84.2 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 6: Accuracy on the GSM8K dataset after integrating Self-Consistency (SC@5) into our framework ART. “SC@5” means that the number of sampled paths is 5. Conclusion In this paper, we propose to use a semi-structured representation for the arithmetic reasoning steps of large language models. Specifically, we utilize relation tuples to connect reasoning in natural language with formal languages, such as programming code, to more effectively verify the reasoning process of large language models. These relation tuples are human-readable and can easily be translated into formal languages. Based on this new representation of reasoning steps, we have implemented a novel framework that integrates the semi-structured representation, relation tuples, into the reasoning process of large language models. Additionally, we developed a local code interpreter to verify the reasoning process of large language models. Our framework also includes a simple and effective dynamic feedback mechanism to elicit the self-improvement ability of large language models. Experimental results demonstrate that our framework can improve the arithmetic reasoning ability of large language models."
    },
    {
      "title": "Limitations",
      "text": "We utilize programming code based on relation tuples to verify reasoning process. Therefore, our method highly depends on the programming code understanding and generation ability of large language models that we use. Besides, the reasoning process in our method is a mixture of informal natural language statements and semi-structured relation tuples. Therefore, the inference cost is high. It will be great if large language models can reason with relation tuples only, which can reduce the inference cost while maintaining readability and are easy for machine to further process these relation tuples (e.g., automatic verification). Finally, there might be other semi-structured forms of reasoning steps which are easy to verify."
    },
    {
      "title": "Ethics Statement",
      "text": "This research aims to improve arithmetic reasoning ability of large language models by introducing a semi-structured form into reasoning process of large language models, a verification process and a dynamic feedback mechanism. We utilized publicly available datasets compiled from other research papers. No personal data was used in this study. We agree to the License Terms and Privacy Policy of corresponding large language models and datasets used in our study. Our research adheres to ethical AI principles, promoting the beneficial use of AI. In addition, large language models may generate harmful contents which we are trying to avoid. We employ GitHub Copilot to help with coding our experiments."
    },
    {
      "title": "References",
      "text": "* Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. _arXiv preprint arXiv:2303.08774_. * Agrawal et al. (2022) Ayush Agrawal, Siddhartha Gadgil, Navin Goyal, Ashvni Narayanan, and Anand Tadipatri. 2022. Towards a mathematics formalisation assistant using large language models. _arXiv preprint arXiv:2211.07524_. * Al@Meta (2024) AI@Meta. 2024. Llama 3 model card. * Anil et al. (2023) Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. 2023. Palm 2 technical report. _arXiv preprint arXiv:2305.10403_. * Besta et al. (2024) Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler. 2024. Graph of Thoughts: Solving Elaborate Problems with Large Language Models. _Proceedings of the AAAI Conference on Artificial Intelligence_, 38(16):17682-17690. * Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In _Advances in Neural Information Processing Systems_, volume 33, pages 1877-1901. Curran Associates, Inc. * Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021. Training verifiers to solve math word problems. _arXiv preprint arXiv:2110.14168_. * Gao et al. (2023) Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023. PAL: Program-aided language models. In _Proceedings of the 40th International Conference on Machine Learning_, volume 202 of _Proceedings of Machine Learning Research_, pages 10764-10799. PMLR. * Goyal et al. (2024) Sachin Goyal, Ziwei Ji, Ankit Singh Rawat, Aditya Krishna Menon, Sanjiv Kumar, and Vaishnavh Nagarajan. 2024. Think before you speak: Training language models with pause tokens. In _The Twelfth International Conference on Learning Representations_. * Haluptzok et al. (2023) Patrick Haluptzok, Matthew Bowers, and Adam Tauman Kalai. 2023. Language models can teach themselves to program better. In _The Eleventh International Conference on Learning Representations_. * Huang et al. (2023) Jiaxin Huang, Shixiang Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2023. Large language models can self-improve. In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, pages 1051-1068, Singapore. Association for Computational Linguistics. * Jiang et al. (2023) Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023. Mistral 7b. _arXiv preprint arXiv:2310.06825_. * Kadlick et al. (2023) Marek Kadlick, Michal Stefanik, Ondrej Sotolar, and Vlastimil Martinek. 2023. Calc-X and calcformers: Empowering arithmetical chain-of-thought through interaction with symbolic systems. In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, pages 12101-12108, Singapore. Association for Computational Linguistics. * Kojima et al. (2022) Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. In _Advances in Neural Information Processing Systems_, volume 35, pages 22199-22213. Curran Associates, Inc. * Koncel-Kedziorski et al. (2016) Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016. MAWPS: A math word problem repository. In _Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_, pages 1152-1157, San Diego, California. Association for Computational Linguistics. * Kwon et al. (2023) Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serving with megadetation. In _Proceedings of the 29th Symposium on Operating Systems Principles_, SOSP '23, page 611-626, New York, NY, USA. Association for Computing Machinery. * Liu et al. (2024) Yanming Liu, Xinyue Peng, Tianyu Du, Jianwei Yin, Weihao Liu, and Xuhong Zhang. 2024. Era-cot: Improving chain-of-thought through entity relationship analysis. _arXiv preprint arXiv:2403.06932_. * Madaan et al. (2023) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimiai Prabhumoye, Yiming Yang, Shashank Gupta, Bodishatru Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark. 2023. Self-refine: Iterative refinement with self-feedback. In _Advances in Neural Information Processing Systems_, volume 36, pages 46534-46594. Curran Associates, Inc. * Miao et al. (2020) Shen-yun Miao, Chao-Chun Liang, and Keh-Yih Su. 2020. A diverse corpus for evaluating and developing English math word problem solvers. In _Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics_, pages 975-984, Online. Association for Computational Linguistics. * Nipkow et al. (2002) Tobias Nipkow, Markus Wenzel, and Lawrence C. Paulson. 2002. _Isabelle/HOL: a proof assistant for higher-order logic_. Springer-Verlag, Berlin, Heidelberg. * Nye et al. (2021) Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work: Scratchpads for intermediate computation with language models. _arXiv preprint arXiv:2112.00114_. * Patel et al. (2021) Arkil Patel, Satwik Bhattacharya, and Navin Goyal. 2021. Are NLP models really able to solve simple math word problems? In _Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_, pages 2080-2094, Online. Association for Computational Linguistics. * Qiao et al. (2023) Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, and Huajun Chen. 2023. Reasoning with language model prompting: A survey. In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 5368-5393, Toronto, Canada. Association for Computational Linguistics. * Sanyal et al. (2022) Soumya Sanyal, Harman Singh, and Xiang Ren. 2022. FaiRR: Faithful and robust deductive reasoning over natural language. In _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 1075-1093, Dublin, Ireland. Association for Computational Linguistics. * Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Bapiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a. Llama: Open and efficient foundation language models. _Preprint_, arXiv:2302.13971. * Touvron et al. (2021) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esibou, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswarin, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jens Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023b. Llama 2: Open foundation and fine-tuned chat models. _Preprint_, arXiv:2307.09288. * Wang et al. (2022) Boshi Wang, Xiang Deng, and Huan Sun. 2022. Iteratively prompt pre-trained language models for chain of thought. In _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 2714-2730, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. * Wang et al. (2024) Ke Wang, Houxing Ren, Aojun Zhou, Zimu Lu, Sichun Luo, Weikang Shi, Renrui Zhang, Linqi Song, Mingjie Zhan, and Hongsheng Li. 2024. Mathcoder: Seamless code integration in LLMs for enhanced mathematical reasoning. In _The Twelfth International Conference on Learning Representations_. * Wang et al. (2023) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023. Self-consistency improves chain of thought reasoning in language models. In _The Eleventh International Conference on Learning Representations_. * Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. Chain-of-thought prompting elicits reasoning in large language models. In _Advances in Neural Information Processing Systems_, volume 35, pages 24824-24837. Curran Associates, Inc. * Xu et al. (2024a) Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Qingwei Lin, and Daxin Jiang. 2024a. WizardLM: Empowering large pre-trained language models to follow complex instructions. In _The Twelfth International Conference on Learning Representations_. * Xu et al. (2024b) Jundong Xu, Hao Fei, Liangming Pan, Qian Liu, Mong-Li Lee, and Wynne Hsu. 2024b. Faithful logical reasoning via symbolic chain-of-thought. _Preprint_, arXiv:2405.18357. * Yang et al. (2024) Ling Yang, Zhaochen Yu, Tianjun Zhang, Shiyi Cao, Minkai Xu, Wentao Zhang, Joseph E Gonzalez, and Bin Cui. 2024b. Buffer of thoughts: Thought-augmented reasoning with large language models. _arXiv preprint arXiv:2406.04271_. * Yao et al. (2023) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts: Deliberate problem solving with large language models. In _Advances in Neural Information Processing Systems_, volume 36, pages 11809-11822. Curran Associates, Inc. * Yu et al. (2023) Xiao Yu, Baolin Peng, Michel Galley, Jianfeng Gao, and Zhou Yu. 2023. Teaching language models to self-improve through interactive demonstrations. _arXiv preprint arXiv:2310.13522_. * Zelikman et al. (2022) Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman. 2022. Star: Bootstraping reasoning with reasoning. In _Advances in Neural Information Processing Systems_, volume 35, pages 15476-15488. Curran Associates, Inc. * Zhao et al. (2023) James Zhao, Yuxi Xie, Kenji Kawaguchi, Junxian He, and Michael Xie. 2023. Automatic model selection with large language models for reasoning. In _Findings of the Association for Computational Linguistics: EMNLP 2023_, pages 758-783, Singapore. Association for Computational Linguistics. * Zhou et al. (2024a) Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, and Hongsheng Li. 2024a. Solving challenging math word problems using GPT-4 code interpreter with code-based self-verification. In _The Twelfth International Conference on Learning Representations_. * Zhou et al. (2023) Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, and Ed H. Chi. 2023. Least-to-most prompting enables complex reasoning in large language models. In _The Eleventh International Conference on Learning Representations_. * grounding LLM quantitative reasoning with autoformalization. In _The Twelfth International Conference on Learning Representations_. Comparison of different methods A comparison of different methods is shown in Figure 9."
    },
    {
      "title": "Appendix B Full Prompts",
      "text": ""
    },
    {
      "title": "Eight-Shot Examples",
      "text": "Figure 10, Figure 11 and Figure 12 show the full prompts of CoT (GPT-4-generated Prompt). Figure 13, Figure 14 and Figure 15 show the full prompts used in step 1 of our framework in the eight-shot setting. Figure 16, Figure 17, Figure 18, Figure 19 and Figure 20 show the full prompts used in step 2 of our framework in the eight-shot setting."
    },
    {
      "title": "Five-Shot Examples",
      "text": "Figure 21 and Figure 22 show the full prompts used in step 1 of our framework in the five-shot setting. Figure 23, Figure 24 and Figure 25 show the full prompts used in step 2 of our framework in the five-shot setting."
    },
    {
      "title": "Appendix C Number Of Questions Using Feedback On Arithmetic Datasets",
      "text": "The statistics of the number of the questions which need feedback and the questions which do not need feedback during inference using our framework on GSM8K dataset are shown in Table 7. The statistics of the number of the questions that need feedback and the questions that do not need feedback in our framework on the other six arithmetic datasets are shown in Table 8. \\begin{table} \\begin{tabular}{c c c c c c} \\hline \\hline Backbone & \\# No Feedback & \\# Feedback (one-time) & \\# Feedback (two-times) & \\# Feedback (three-times) & \\# Feedback \\\\ \\hline Llama3-8B-Instruct & 1051 (79.7\\%) & 41 (3.1\\%) & 20 (1.5\\%) & 207 (15.7\\%) & 268 (20.3\\%) \\\\ ChatGPT & 1077 (81.7\\%) & 34 (2.6\\%) & 43 (3.3\\%) & 165 (12.5\\%) & 242 (18.3\\%) \\\\ GPT-4o & 1296 (98.3\\%) & 8 (0.6\\%) & 4 (0.3\\%) & 11 (0.8\\%) & 23 (1.7\\%) \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 7: Number of questions which require feedback during inference using our framework on the GSM8K dataset. \\begin{table} \\begin{tabular}{l c c c c c} \\hline \\hline Dataset & \\# No Feedback & \\# Feedback (one-time) & \\# Feedback (two-times) & \\# Feedback (three-times) & \\# Feedback \\\\ \\hline SVAMP & 874 (87.4\\%) & 27 (2.7\\%) & 22 (2.2\\%) & 77 (7.7\\%) & 126 (12.6\\%) \\\\ ASDIV & 1746 (83.5\\%) & 13 (0.6\\%) & 31 (1.5\\%) & 302 (14.4\\%) & 346 (16.5\\%) \\\\ SingleEQ & 477 (93.9\\%) & 2 (0.4\\%) & 7 (1.3\\%) & 22 (4.3\\%) & 31 (6.1\\%) \\\\ SingleOP & 548 (97.5\\%) & 5 (0.9\\%) & 3 (0.5\\%) & 6 (1.1\\%) & 14 (2.5\\%) \\\\ AddSub & 360 (91.1\\%) & 2 (0.5\\%) & 3 (0.8\\%) & 30 (7.6\\%) & 35 (8.9\\%) \\\\ MultiArith & 590 (98.3\\%) & 4 (0.7\\%) & 4 (0.7\\%) & 4 (0.7\\%) & 2 (0.3\\%) & 10 (1.7\\%) \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 8: Number of questions which need feedback during inference using our framework on SVAMP, ASDIV, SingleEQ, SingleOP, AddSub and MultiArith. Note that there are four questions which do not have solutions on ASDIV because program error occurs. Figure 9: Comparison of different methods. **System Prompt** You are a helpful assistant that can solve math problems step by step. **User Prompt** Answer the following question. The final answer must be in numeric format, not in words. The final answer should be in this format with only a number shown: The final answer: \\(<\\)your answer\\(>\\).* Here is one example: Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? Answer: To solve this problem, we first need to determine the number of clips Natalia sold in May. It is given that she sold half as many clips in May as she did in April. From the problem, we know clips sold in April is 48. Therefore, the number of clips sold in May is half of 48. 48/2 = 24. Now, we find the total number of clips sold over both April and May by adding the clips sold in each month. 48+24= 72. Thus, Natalia sold a total of 72 clips in April and May combined. The final answer: 72. Now it's your turn. Here is another math problem: Question: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn? Question: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet? Question: Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read? Question: James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year? Question: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden? Question: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day? Question: Ken created a care package to send to his brother, who was away at boarding school. Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough brownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough gummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds? Figure 10: The system prompt and user prompt of the eight-shot example of CoT (GPT-4-Generated Prompt). Answer: To calculate Weng's earnings for 50 minutes of babysitting at S12 per hour, you need to convert the time to hours. Since there are 60 minutes in an hour, 50 minutes is \\(\\langle\\) (frac\\(\\{\\)50\\(\\}\\)\\(\\{60\\}\\) = \\(\\langle\\)frac\\(\\{\\)5\\(\\}\\)\\(\\{6\\}\\) \\(\\rangle\\) of an hour. Now, multiply the fraction of an hour by Weng's hourly rate to find her earnings: \\(\\langle\\) (frac\\(\\{\\)5\\(\\}\\)\\(\\{6\\}\\) \\(\\rangle\\) times \\(\\langle\\)S12 = \\(\\langle\\)S10 \\(\\rangle\\)\\(\\rangle\\) So, Weng earned $10 for 50 minutes of babysitting. The final answer: 10. Answer: First, let's calculate how much money Betty has saved so far: 1. Betty has half of the money she needs for the wallet, which is \\(\\langle\\) (frac\\(\\{\\)1\\(\\}\\)\\(\\{\\)2\\(\\}\\) \\(\\rangle\\) times \\(\\langle\\)S100 = \\(\\langle\\)S50 \\(\\rangle\\)). 2. Her parents gave her an additional $15. 3. Her grandparents gave her twice as much as her parents, so that's \\(\\langle\\) 2 times \\(\\langle\\)S15 = \\(\\langle\\)S30 \\(\\rangle\\). Now, let's add up all the money Betty has: \\(\\langle\\)\\(\\{\\)$50 (Betty's savings) + \\(\\langle\\)S15 (from parents) + \\(\\langle\\)S30 (from grandparents) = \\(\\langle\\)S50 + \\(\\langle\\)S15 + \\(\\langle\\)S30 = \\(\\langle\\)S95 \\(\\rangle\\)\\(\\}\\) Betty now has $95. To find out how much more she needs, subtract the total amount she has from the cost of the wallet: \\(\\langle\\)\\(\\{\\)$100 (cost of wallet) - $95 (total money saved) = \\(\\langle\\)S5 \\(\\rangle\\)\\(\\}\\) So, Betty still needs $5 more to buy the wallet. The final answer: 5. Answer: Let's break down the information given: 1. Julie is reading a 120-page book. 2. Yesterday, she read 12 pages. 3. Today, she read twice as many pages as yesterday, which is \\(\\langle\\)2 times 12 = 24\\(\\rangle\\) pages. 4. So far, she has read \\(\\langle\\)\\(12\\) + 24 = 36\\(\\rangle\\) pages. To find out how many pages she has left to read: \\(\\langle\\) (text {Total pages} \\(\\rangle\\) - text\\(\\{\\)Pages read\\(\\}\\) = 120 - 36 = 84 \\(\\langle\\)text { pages left} \\(\\rangle\\)\\(\\}\\) If Julie wants to read half of the remaining pages tomorrow, she should read \\(\\langle\\) (frac\\(\\{\\)1\\(\\}\\)\\(\\{\\)2\\(\\}\\) \\(\\rangle\\) times 84 = 42 \\(\\rangle\\)) pages. So, Julie should read 42 pages tomorrow. The final answer: 42. Answer: Let's break down the information provided: 1. James writes a 3-page letter to 2 different friends. 2. He does this twice a week. So, the total number of pages James writes in a week is: \\(\\langle\\) 3 text\\(\\{\\)pages/letter\\(\\}\\) \\(\\langle\\) times 2 \\(\\langle\\)text { letters\\(\\}\\rangle\\) \\(\\langle\\)times 2 \\(\\langle\\)text { times 2 \\(\\langle\\)text { times a week\\(\\}\\) = 12 \\(\\langle\\)text { pages/week\\(\\}\\) \\(\\rangle\\)\\(\\}\\) To find out how many pages he writes in a year, we need to multiply the number of pages he writes per week by the number of weeks in a year. There are typically 52 weeks in a year. \\(\\langle\\) 12 text\\(\\{\\)pages/week\\(\\}\\) \\(\\langle\\)times 52 \\(\\langle\\)text { weeks/year\\(\\}\\) = 624 \\(\\langle\\)text { pages/year\\(\\}\\) \\(\\rangle\\)\\(\\}\\) So, James writes 624 pages in a year. The final answer: 624. Figure 11: The assistant prompt of the eight-shot example of CoT (GPT-4-Generated Prompt). Answer: Let's break down the information provided: 1. Mark has flowers of three different colors: yellow, purple, and green. 2. There are ten yellow flowers. 3. There are 80% more purple flowers than yellow flowers. 4. There are 25% as many green flowers as there are yellow and purple flowers combined. First, let's find out how many purple flowers there are: 80% more purple flowers than yellow flowers means there are \\(\\langle\\) 10 + 80% \\(\\rangle\\) of 10 purple flowers. \\(\\langle\\) 80% text{ of } 10 = 0.80 \\(\\rangle\\)times 10 = 8 \\(\\rangle\\) So, there are \\(\\langle\\) 10 + 8 = 18 \\(\\rangle\\) purple flowers. Now, let's find out how many yellow and purple flowers there are combined: \\(\\langle\\) 10 text{ yellow flowers} + 18 text{ purple flowers} = 28 text{ flowers (yellow and purple)} \\(\\rangle\\) Now, let's find out how many green flowers there are: There are 25% as many green flowers as there are yellow and purple flowers combined. So, it's \\(\\langle\\) 25% \\(\\rangle\\) of 28: \\(\\langle\\) 25% text{ of } 28 = 0.25 times 28 = 7 \\(\\rangle\\) So, there are 7 green flowers. To find the total number of flowers, we add up the number of flowers of each color: \\(\\langle\\) 10 text{ yellow flowers} + 18 text{ purple flowers} + 7 \\(\\rangle\\)text{ { green flowers} = 35 text{ flowers} } \\(\\rangle\\) So, Mark has 35 flowers in his garden. The final answer: 35. Answer: To find out how many pieces of pizza Albert eats in one day, we first need to calculate the total number of slices. For the large pizzas: \\(\\langle\\) 2 text{ large pizzas} \\(\\rangle\\)times 16 text{ slices per pizza} = 32 text{ slices} \\(\\rangle\\) For the small pizzas: \\(\\langle\\) 2 text{ small pizzas} \\(\\rangle\\)times 8 text{ slices per pizza} = 16 text{ slices} \\(\\rangle\\) Now, let's add up the slices from both the large and small pizzas to find the total number of pieces of pizza Albert eats in one day: \\(\\langle\\) 32 text{ slices from large pizzas} + 16 text{ slices from small pizzas} = 48 text{ slices} \\(\\rangle\\) So, Albert eats 48 pieces of pizza in one day. The final answer: 48. Answer: Let's break down the steps Ken took: 1. Ken placed a box on a scale, making its weight 0 pounds. 2. He poured enough jelly beans to bring the weight to 2 pounds. 3. He added enough brownies to cause the weight to triple, so the weight became \\(\\langle\\) 2 times 3 = 6\\(\\rangle\\) pounds. 4. Next, he added another 2 pounds of jelly beans, bringing the weight to \\(\\langle\\) 6 + 2 = 8\\(\\rangle\\) pounds. 5. Finally, he added enough gummy worms to double the weight again, making the final weight \\(\\langle\\) 8 times 2 = 16\\(\\rangle\\) pounds. So, the final weight of the box of goodies is 16 pounds. The final answer: 16. Figure 12: The assistant prompt of the eight-shot example of CoT (GPT-4-Generated Prompt) (continued). [MISSING_PAGE_EMPTY:17] Assistant Prompt Answer: First, we know that Weng earns $12 an hour for babysitting, (earning-per-hour, is, $12). Yesterday, she did 50 minutes of babysitting, (minutes-weng-worked, is, 50). The question we want to solve is How much did she earn!, (earnings-during-this-babysitting, is,?). To find out her earnings, we need to calculate how much Weng earns per minute, (earning-per-minute, is,?). Since there are 60 minutes in an hour, (minutes-in-an-hour, is, 60), we can determine her per-minute earnings, (earning-per-minute, is, earning-per-hour / minutes-in-an-hour). Therefore, $12 divided by 60 minutes equals $0.2 per minute. So Weng earns $0.2 per minute of babysitting. To find out her earnings for this duration, we multiply her per-minute earnings by the number of minutes she worked, (earnings-during-this-babysitting, is, earning-per-minute * minutes-weng-worked). Therefore, $0.2 multiplied by 50 minutes equals $10. Thus, Weng earned $10 for 50 minutes of babysitting. The final answer: 10. Answer: First, we know that the new wallet costs $100, (cost-of-wallet, is, $100). Betty has half of the money she needs for the wallet, (money-betty-has, is, cost-of-wallet / 2). 100 / 2 = 50. Betty has $50. Her parents gave her $15, (money-parents-gave, is, $15). Her grandparents gave her twice as much as her parents, (money-grandparents-gave, is, money-parents-gave * 2). 15 * 2 = 30. So her grandparents gave her $30. The question is How much more money does Betty need to buy the wallet!, (money-betty-needs, is,?). Adding these amounts together will tell us how much money Betty currently has, (money-betty-has, is, money-betty-has + money-parents-gave + money-grandparents-gave). $50 + $15 + $30 = $95. Betty has $95, (money-betty-has, is, $95). To find out how much more she needs to buy the wallet, we subtract the total amount she has from the cost of the wallet, (money-betty-needs, is, cost-of-wallet - money-betty-has). 100 - 95 = 5. Betty still needs $5 to buy the wallet. The final answer: 5. Answer: We know that the book has 120 pages, (total-number-of-pages-in-book, is, 120). Yesterday, Julie read 12 pages, (number-of-pages-read-yesterday, is, 12). Today, she read twice as many pages as yesterday, (number-of-pages-read-today, is, number-of-pages-read-yesterday * 2). 12 * 2 = 24. The question is 'If she wants to read half of the remaning pages tomorrow, how many pages should she read'. So first we need to calculate the remaining pages she has to read. The number of pages left in the book is equal to the total number of pages minus the number of pages she read in the previous two days, (number-of-pages-julie-has-left-to-read, is, total-number-of-pages-in-book - number-of-pages-read-today - number-of-pages-read-today). 120 - 12 - 24 = 84. Julie has 84 pages left to read. To find out how many pages she should read tomorrow, we calculate half of the remaining pages, (number-of-pages-julie-should-read-tomorrow, is, number-of-pages-julie-has-left-to-read / 2). 84 / 2 = 42. Therefore, Julie should read 42 pages tomorrow. The final answer: 42. Figure 14: The assistant prompt of the eight-shot example in step 1 of our framework. Figure 15: The assistant prompt of the eight-shot example in step 1 of our framework (continued). **System Prompt** You are a helpful assistant capable of solving math problems by using Python functions, based on the question provided and its reasoning steps which are formatted as relation triples. Given a question and its answer's thinking process in format of relation triples. Write a python function to solve the question based on those relation triples with the markdown format, that is, \"'python'='your code>n'. The output of the function should be in this format with only a number shown: The final answer: <your answer>'. **User Prompt** Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? Thinking process in relation triple format: (number-of-clips-sold-in-April, is, 48) (number-of-clips-sold-in-May, is, number-of-clips-sold-in-April/2) (number-clips-sold-in-April-and-May, is, number-of-clips-sold-in-April+number-of-clips-sold-in-May) Here is a Python function based on the given relation triples: \"python def total_clips_sold(): number_of_clips_sold in April = 48 number_clips_sold_in_May = number_of_clips_sold in April /2 return \"The final answer: {int(number_clips_sold_in_April_and_May)}\""
    },
    {
      "title": "Call The Function To Display The Result",
      "text": "print(total_clips_sold()) ... Now it's your turn. Question: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn? Thinking process in relation triple format: (earning-per-hour, is, $12) (minutes-weng-worked, is, 50) (earnings-during-this-babysitting, is,?) (earning-per-minute, is,?) (minutes-in-an-hour, is, 60) (earning-per-minute, is, earning-per-hour/minutes-in-an-hour) (earnings-during-this-babysitting, is, earning-per-minute* minutes-weng-worked) Question: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet? Thinking process in relation triple format: (cost-of-wallet, is, $100) (money-betty-has, is, cost-of-wallet/2) (money-parents-gave, is, $15) (money-grandparents-gave, is, money-parents-gave*2) (money-betty-needs, is,?) (money-betty-has, is, money-betty-has+money-parents-gave+money-grandparents-gave) (money-betty-has, is, $95) (money-betty-needs, is, cost-of-wallet-money-betty-has) Figure 16: The system prompt and user prompt of the eight-shot example in step 2 of our framework. Question: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day? Thinking process in relation triple format: (number-of-large-pizzas, is, 2) (number-of-small-pizzas, is, 2) (slices-per-large-pizza, is, 16) (total-slices-from-large-pizzas, is, number-of-large-pizzas * slices-per-large-pizza) (slices-per-small-pizza, is, 8) (total-slices-from-small-pizzas, is, number-of-small-pizzas * slices-per-small-pizza) (total-slices-for-the-day, is, total-slices-from-large-pizzas + total-slices-from-small-pizzas) Question: Ken created a care package to send to his brother, who was away at boarding school. Ken placed a box on a scale, and then be poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough brownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough gummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds? Thinking process in relation triple format: (current-weight, is, 2 pounds) (current-weight, is, current-weight * 3) (current-weight, is, current-weight + 2) (final-weight, is, current-weight * 2) Question: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden? Thinking process in relation triple format: (number-of-yellow-flowers, is, 10) (number-of-purple-flowers, is, 80%-more-than-number-of-yellow-flowers) (total-number-of-yellow-and-purple-flowers, is, number-of-yellow-flowers + number-of-purple-flowers) (number-of-green-flowers, is, 25%-of-total-number-of-yellow-and-purple-flowers) (total-number-of-flowers, is, number-of-yellow-flowers + number-of-purple-flowers + number-of-green-flowers) Figure 17: The user prompt of the eight-shot example in step 2 of our framework (continued). Figure 18: The assistant prompt of the eight-shot example in step 2 of our framework."
    },
    {
      "title": "6 Conclusion",
      "text": "Figure 19: The assistant prompt of the eight-shot example in step 2 of our framework (continued)."
    },
    {
      "title": "6 Conclusion",
      "text": "Figure 20: The assistant prompt of the eight-shot example in step 2 of our framework (continued). **System Prompt** You are a helpful assistant that can solve math problems step by step with relation triples. Answer the following question. Write your thoughts first. Please make sure when you make a statement that includes reasoning, you must always write down those reasoning steps as relation triples. The final answer must be in numeric format, not in words. The final answer should be in the format with only a number shown: 'The final answer: \\(<\\)your answer\\(>\\). **User Prompt** Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? Answer: First we know that Natalia sold clips to 48 of her friends in April, (number-of-clips-sold-in-April, is, 48). She sold half as many clips in May, (number-of-clips-sold-in-May, is, number-of-clips-sold-in-April/2). 48 / 2 = 24. She sold 24 clips in May. The problem we want to solve is 'How many clips did Natalia sell altogether in April and May'. To find the total number of clips sold in April and May, we add the clips sold in each month, (number-clips-sold-in-April-and-May, is, number-of-clips-sold-in-April+number-of-clips-sold-in-May). 48 + 24 = 72. Thus, Natalia sold a total of 72 clips in April and May combined. The final answer: 72. Now it's your turn. Here is another math problem: Question: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn? Question: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day? Question: Ken created a care package to send to his brother, who was away at boarding school. Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough brownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough gummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds? Question: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden? Figure 21: The system and user prompt of the five-shot example in step 1 of our framework. [MISSING_PAGE_EMPTY:26] **System Prompt** You are a helpful assistant capable of solving math problems by using Python functions, based on the question provided and its reasoning steps which are formatted as relation triples. Given a question and its answer's thinking process in format of relation triples. Write a python function to solve the question based on those relation triples with the markdown format, that is, \"'python'n\\(>\\)your code\\(>\\)n\". The output of the function should be in this format with only a number shown: The final answer: \\(<\\)your answer\\(>\\). **User Prompt** Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? Thinking process in relation triple format: (number-of-clips-sold-in-Apirl, is, 48) (number-of-clips-sold-in-May, is, number-of-clips-sold-in-Apirl / 2) (number-clips-sold-in-April-and-May, is, number-of-clips-sold-in-Apirl + number-of-clips-sold-in-May) Here is a Python function based on the given relation triples: \"'python def total clips sold(): number_of_clips_sold_in_April = 48 number_of_clips_sold_in_May = number_of_clips_sold_in_April / 2 number_clips_sold_in_April_and_May = number_of_clips_sold_in_April + number_of_clips_sold_in_May return f\"The final answer: {int(number_clips_sold_in_April_and_May)}\" \\(\\#\\) Call the function to display the result print(total_clips_sold()) ... Now it's your turn. Question: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn? Thinking process in relation triple format: (earning-per-hour, is, $12) (minutes-weng-word, is, 50) (earnings-during-this-babysitting, is,?) (earning-per-minute, is,?) (minutes-in-an-hour, is, 60) (earning-per-minute, is, earning-per-hour / minutes-in-an-hour) (earnings-during-this-babysitting, is, earning-per-minute * minutes-weng-worked) Question: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day? Thinking process in relation triple format: (number-of-large-pizzas, is, 2) (number-of-small-pizzas, is, 2) (slices-per-large-pizza, is, 16) (total-slices-from-large-pizzas, is, number-of-large-pizzas * slices-per-large-pizza) (slices-per-small-pizza, is, 8) (total-slices-from-small-pizzas, is, number-of-small-pizzas * slices-per-small-pizza) (total-slices-for-the-day, is, total-slices-from-large-pizzas + total-slices-from-small-pizzas) Figure 23: The system and user prompt of the five-shot example in step 2 of our framework. Question: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden? Thinking process in relation triple format: (number-of-yellow-flowers, is, 10) (number-of-purple-flowers, is, 80%-more-than-number-of-yellow-flowers) (total-number-of-yellow-and-purple-flowers, is, number-of-yellow-flowers + number-of-purple-flowers) (number-of-green-flowers, is, 25%-of-total-number-of-yellow-and-purple-flowers) (total-number-of-flowers, is, number-of-yellow-flowers + number-of-purple-flowers + number-of-green-flowers) Figure 24: The user prompt of the five-shot example in step 2 of our framework (continued)."
    },
    {
      "title": "6 Conclusion",
      "text": "Figure 25: The assistant prompt of the five-shot example in step 2 of our framework."
    }
  ]
}
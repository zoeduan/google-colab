{
  "title": "EXPLORING THE IN-CONTEXT LEARNING ABILITY OF LARGE LANGUAGE MODEL FOR BIOMEDICAL CONCEPT LINKING A PREPRINT",
  "authors": [
    "Qinyong Wang",
    "Zhenxiang Gao",
    "Rong Xu"
  ],
  "abstract": "\n The biomedical field relies heavily on concept linking in various areas such as literature mining, graph alignment, information retrieval, question-answering, data, and knowledge integration. Although large language models (LLMs) have made significant strides in many natural language processing tasks, their effectiveness in biomedical concept mapping is yet to be fully explored. This research investigates a method that exploits the in-context learning (ICL) capabilities of large models for biomedical concept linking. The proposed approach adopts a two-stage retrieve-and-rank framework. Initially, biomedical concepts are embedded using language models, and then embedding similarity is utilized to retrieve the top candidates. These candidates' contextual information is subsequently incorporated into the prompt and processed by a large language model to re-rank the concepts. This approach achieved an accuracy of 90.1% in BC5CDR disease entity normalization and 94.7% in chemical entity normalization, exhibiting a competitive performance relative to supervised learning methods. Further, it showed a significant improvement, with an over 20-point absolute increase in F1 score on an oncology matching dataset. Extensive qualitative assessments were conducted, and the benefits and potential shortcomings of using large language models within the biomedical domain were discussed. \n",
  "references": [
    {
      "id": null,
      "title": "EXPLORING THE IN-CONTEXT LEARNING ABILITY OF LARGE LANGUAGE MODEL FOR BIOMEDICAL CONCEPT LINKING A PREPRINT",
      "authors": [
        "Qinyong Wang",
        "Zhenxiang Gao",
        "Rong Xu"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Systematic integration of biomedical knowledge prioritizes drugs for repurposing",
      "authors": [
        "Daniel Scott Himmelstein",
        "Antoine Lizee",
        "Christine Hessler",
        "Leo Brueggeman",
        "Sabrina L Chen",
        "Dexter Hadley",
        "Ari Green",
        "Pouya Khankhanian",
        "Sergio E Baranzini"
      ],
      "year": "2017",
      "venue": "Systematic integration of biomedical knowledge prioritizes drugs for repurposing",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "A survey on literature based discovery approaches in biomedical domain",
      "authors": [
        "Kishlay Vishrawas Gopalakrishnan",
        "Wei Jha",
        "Aidong Jin",
        "Zhang"
      ],
      "year": "2019",
      "venue": "Journal of biomedical informatics",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "A comprehensive survey of entity alignment for knowledge graphs",
      "authors": [
        "Kaisheng Zeng",
        "Chengjiang Li",
        "Lei Hou",
        "Juanzi Li",
        "Ling Feng"
      ],
      "year": "2021",
      "venue": "AI Open",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Biomedical named entity recognition and linking datasets: survey and our recent development",
      "authors": [
        "Ming-Siang Huang",
        "Po-Ting Lai",
        "Pei-Yen Lin",
        "Yu-Ting You",
        "Richard Tzong-Han",
        "Wen-Lian Tsai",
        "Hsu"
      ],
      "year": "2020",
      "venue": "Briefings in Bioinformatics",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Bert-based ranking for biomedical entity normalization",
      "authors": [
        "Zongcheng Ji",
        "Qiang Wei",
        "Hua Xu"
      ],
      "year": "2020",
      "venue": "AMIA Summits on Translational Science Proceedings",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "Fine-tuning bidirectional encoder representations from transformers (bert)-based models on large-scale electronic health record notes: an empirical study",
      "authors": [
        "Fei Li",
        "Yonghao Jin",
        "Weisong Liu",
        "Bhanu Pratap Singh",
        "Pengshan Rawat",
        "Hong Cai",
        "Yu"
      ],
      "year": "2019",
      "venue": "JMIR medical informatics",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "Medical subject headings (mesh)",
      "authors": [
        "Carolyn E Lipscomb"
      ],
      "year": "2000",
      "venue": "Bulletin of the Medical Library Association",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "Ammu: a survey of transformer-based biomedical pretrained language models",
      "authors": [
        "Katikapalli Subramanyam Kalyan",
        "Ajit Rajasekharan",
        "Sivanesan Sangeetha"
      ],
      "year": "2022",
      "venue": "Journal of biomedical informatics",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Ontology mapping for semantically enabled applications",
      "authors": [
        "Ian Harrow",
        "Rama Balakrishnan",
        "Ernesto Jimenez-Ruiz",
        "Simon Jupp",
        "Jane Lomax",
        "Jane Reed",
        "Martin Romacker",
        "Christian Senger",
        "Andrea Splendiani",
        "Jabe Wilson"
      ],
      "year": "2019",
      "venue": "Drug discovery today",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "Deep learning methods for biomedical named entity recognition: a survey and qualitative comparison",
      "authors": [
        "Bosheng Song",
        "Fen Li",
        "Yuansheng Liu",
        "Xiangxiang Zeng"
      ],
      "year": "2021",
      "venue": "Briefings in Bioinformatics",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "A comprehensive survey on pretrained foundation models: A history from bert to chatgpt",
      "authors": [
        "Ce Zhou",
        "Qian Li",
        "Chen Li",
        "Jun Yu",
        "Yixin Liu",
        "Guangjing Wang",
        "Kai Zhang",
        "Cheng Ji",
        "Qiben Yan",
        "Lifang He"
      ],
      "year": "2023",
      "venue": "A comprehensive survey on pretrained foundation models: A history from bert to chatgpt",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Chatgpt and the rise of large language models: the new ai-driven infodemic threat in public health",
      "authors": [
        "Luigi De Angelis",
        "Francesco Baglivo",
        "Guglielmo Arzilli",
        "Pierpaolo Gaetano",
        "Paolo Privitera",
        "Alberto Eugenio Ferragina",
        "Caterina Tozzi",
        "Rizzo"
      ],
      "year": "2023",
      "venue": "Frontiers in Public Health",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Accelerating the integration of chatgpt and other large-scale ai models into biomedical research and healthcare",
      "authors": [
        "Ding-Qiao Wang",
        "Long-Yu Feng",
        "Jin-Guo Ye",
        "Jin-Gen Zou",
        "Ying-Feng Zheng"
      ],
      "year": "2023",
      "venue": "MedComm-Future Medicine",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "A survey on in-context learning. arXiv",
      "authors": [
        "Qingxiu Dong",
        "Lei Li",
        "Damai Dai",
        "Ce Zheng",
        "Zhiyong Wu",
        "Baobao Chang",
        "Xu Sun",
        "Jingjing Xu",
        "Lei Li",
        "Zhifang Sui"
      ],
      "year": "2023",
      "venue": "A survey on in-context learning. arXiv",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "Scispacy: fast and robust models for biomedical natural language processing",
      "authors": [
        "Mark Neumann",
        "Daniel King",
        "Iz Beltagy",
        "Waleed Ammar"
      ],
      "year": "2019",
      "venue": "Scispacy: fast and robust models for biomedical natural language processing",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "Bertmap: a bert-based ontology alignment system",
      "authors": [
        "Yuan He",
        "Jiaoyan Chen",
        "Denvar Antonyrajah",
        "Ian Horrocks"
      ],
      "year": "2022",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "The unified medical language system (umls): integrating biomedical terminology",
      "authors": [
        "Olivier Bodenreider"
      ],
      "year": "2004",
      "venue": "Nucleic acids research",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Metamap lite: an evaluation of a new java implementation of metamap",
      "authors": [
        "Dina Demner-Fushman",
        "Willie J Rogers",
        "Alan R Aronson"
      ],
      "year": "2017",
      "venue": "Journal of the American Medical Informatics Association",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Quickumls: a fast, unsupervised approach for medical concept extraction",
      "authors": [
        "Luca Soldaini",
        "Nazli Goharian"
      ],
      "year": "2016",
      "venue": "MedIR workshop, sigir",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "Knowledge-rich self-supervision for biomedical entity linking",
      "authors": [
        "Sheng Zhang",
        "Hao Cheng",
        "Shikhar Vashishth",
        "Cliff Wong",
        "Jinfeng Xiao",
        "Xiaodong Liu",
        "Tristan Naumann",
        "Jianfeng Gao",
        "Hoifung Poon"
      ],
      "year": "2022",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "Self-alignment pretraining for biomedical entity representations",
      "authors": [
        "Fangyu Liu",
        "Ehsan Shareghi",
        "Zaiqiao Meng",
        "Marco Basaldella",
        "Nigel Collier"
      ],
      "year": "2020",
      "venue": "Self-alignment pretraining for biomedical entity representations",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Graph representation learning in bioinformatics: trends, methods and applications",
      "authors": [
        "Hai-Cheng Yi",
        "Zhu-Hong You",
        "De-Shuang Huang",
        "Chee Keong",
        "Kwoh"
      ],
      "year": "2022",
      "venue": "Briefings in Bioinformatics",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "Review of ontology matching approaches and challenges",
      "authors": [
        "Sarawat Anam",
        "Yang Sok Kim",
        "Byeong Ho Kang",
        "Qing Liu"
      ],
      "year": "2015",
      "venue": "International journal of Computer Science and Network Solutions",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "Machine learning-friendly biomedical datasets for equivalence and subsumption ontology matching",
      "authors": [
        "Yuan He",
        "Jiaoyan Chen",
        "Hang Dong",
        "Ernesto Jiménez-Ruiz",
        "Ali Hadian",
        "Ian Horrocks"
      ],
      "year": "2022",
      "venue": "The Semantic Web-ISWC 2022: 21st International Semantic Web Conference, Virtual Event",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
      "authors": [
        "Jinhyuk Lee",
        "Wonjin Yoon",
        "Sungdong Kim",
        "Donghyeon Kim",
        "Sunkyu Kim",
        "Chan Ho",
        "So",
        "Jaewoo Kang"
      ],
      "year": "2020",
      "venue": "Bioinformatics",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "Contrastive representation learning: A framework and review",
      "authors": [
        "Graham Phuc H Le-Khac",
        "Alan F Healy",
        "Smeaton"
      ],
      "year": "2020",
      "venue": "Ieee Access",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Attention is all you need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan N Gomez",
        "Łukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Language models are few-shot learners",
      "authors": [
        "Tom Brown",
        "Benjamin Mann",
        "Nick Ryder",
        "Melanie Subbiah",
        "Jared D Kaplan",
        "Prafulla Dhariwal",
        "Arvind Neelakantan",
        "Pranav Shyam",
        "Girish Sastry",
        "Amanda Askell"
      ],
      "year": "2020",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Sparks of artificial general intelligence: Early experiments with gpt-4",
      "authors": [
        "Sébastien Bubeck",
        "Varun Chandrasekaran",
        "Ronen Eldan",
        "Johannes Gehrke",
        "Eric Horvitz",
        "Ece Kamar",
        "Peter Lee",
        "Yin Tat Lee",
        "Yuanzhi Li",
        "Scott Lundberg"
      ],
      "year": "2023",
      "venue": "Sparks of artificial general intelligence: Early experiments with gpt-4",
      "doi": ""
    },
    {
      "id": "b29",
      "title": "Open and efficient foundation language models",
      "authors": [
        "Hugo Touvron",
        "Thibaut Lavril",
        "Gautier Izacard",
        "Xavier Martinet",
        "Marie-Anne Lachaux",
        "Timothée Lacroix",
        "Baptiste Rozière",
        "Naman Goyal",
        "Eric Hambro",
        "Faisal Azhar"
      ],
      "year": "2023",
      "venue": "Open and efficient foundation language models",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "Pmc-llama: Further finetuning llama on medical papers",
      "authors": [
        "Chaoyi Wu",
        "Xiaoman Zhang",
        "Ya Zhang",
        "Yanfeng Wang",
        "Weidi Xie"
      ],
      "year": "2023",
      "venue": "Pmc-llama: Further finetuning llama on medical papers",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "Llama-adapter: Efficient fine-tuning of language models with zero-init attention",
      "authors": [
        "Renrui Zhang",
        "Jiaming Han",
        "Aojun Zhou",
        "Xiangfei Hu",
        "Shilin Yan",
        "Pan Lu",
        "Hongsheng Li",
        "Peng Gao",
        "Yu Qiao"
      ],
      "year": "2023",
      "venue": "Llama-adapter: Efficient fine-tuning of language models with zero-init attention",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "How language model hallucinations can snowball",
      "authors": [
        "Muru Zhang",
        "Ofir Press",
        "William Merrill",
        "Alisa Liu",
        "Noah A Smith"
      ],
      "year": "2023",
      "venue": "How language model hallucinations can snowball",
      "doi": ""
    },
    {
      "id": "b33",
      "title": "Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova",
        "Bert"
      ],
      "year": "2018",
      "venue": "Pre-training of deep bidirectional transformers for language understanding",
      "doi": ""
    },
    {
      "id": "b34",
      "title": "Generative agents: Interactive simulacra of human behavior",
      "authors": [
        "Sung Joon",
        "Park",
        "C O' Joseph",
        "Carrie J Brien",
        "Meredith Ringel Cai",
        "Percy Morris",
        "Michael S Liang",
        "Bernstein"
      ],
      "year": "2023",
      "venue": "Generative agents: Interactive simulacra of human behavior",
      "doi": ""
    },
    {
      "id": "b35",
      "title": "Biocreative v cdr task corpus: a resource for chemical disease relation extraction",
      "authors": [
        "Jiao Li",
        "Yueping Sun",
        "Robin J Johnson",
        "Daniela Sciaky",
        "Chih-Hsuan Wei",
        "Robert Leaman",
        "Allan Peter Davis",
        "Carolyn J Mattingly",
        "Thomas C Wiegers",
        "Zhiyong Lu"
      ],
      "year": "2016",
      "venue": "Biocreative v cdr task corpus: a resource for chemical disease relation extraction",
      "doi": ""
    },
    {
      "id": "b36",
      "title": "Pubmed central: The genbank of the published literature",
      "authors": [
        "J Richard",
        "Roberts"
      ],
      "year": "2001",
      "venue": "Victor McKusick. Omim (online mendelian inheritance in man)",
      "doi": ""
    },
    {
      "id": "b37",
      "title": "Ordo: an ontology connecting rare disease, epidemiology and genetic data",
      "authors": [
        "Drashtti Vasant",
        "Laetitia Chanas",
        "James Malone",
        "Marc Hanauer",
        "Annie Olry",
        "Simon Jupp",
        "Helen Peter N Robinson",
        "Ana Parkinson",
        "Rath"
      ],
      "year": "2014",
      "venue": "Proceedings of ISMB",
      "doi": ""
    },
    {
      "id": "b38",
      "title": "Snomed clinical terms: overview of the development process and project status",
      "authors": [
        "Colin Michael Q Stearns",
        "Kent A Price",
        "Amy Y Spackman",
        "Wang"
      ],
      "year": "2001",
      "venue": "Proceedings of the AMIA Symposium",
      "doi": ""
    },
    {
      "id": "b39",
      "title": "Chain of thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Ed Chi",
        "Quoc Le",
        "Denny Zhou"
      ],
      "year": "2022",
      "venue": "Chain of thought prompting elicits reasoning in large language models",
      "doi": ""
    },
    {
      "id": "b40",
      "title": "Self-consistency improves chain of thought reasoning in language models",
      "authors": [
        "Xuezhi Wang",
        "Jason Wei",
        "Dale Schuurmans",
        "Quoc Le",
        "Ed Chi",
        "Sharan Narang",
        "Aakanksha Chowdhery",
        "Denny Zhou"
      ],
      "year": "2022",
      "venue": "Self-consistency improves chain of thought reasoning in language models",
      "doi": ""
    },
    {
      "id": "b41",
      "title": "Bern2: an advanced neural biomedical named entity recognition and normalization tool",
      "authors": [
        "Mujeen Sung",
        "Minbyul Jeong",
        "Yonghwa Choi",
        "Donghyeon Kim",
        "Jinhyuk Lee",
        "Jaewoo Kang"
      ],
      "year": "2022",
      "venue": "Bioinformatics",
      "doi": ""
    },
    {
      "id": "b42",
      "title": "Lsmatch results for oaei 2021",
      "authors": [
        "Abhisek Sharma",
        "Archana Patel",
        "Sarika Jain"
      ],
      "year": "2021",
      "venue": "OM@ ISWC",
      "doi": ""
    },
    {
      "id": "b43",
      "title": "Logmap: Logic-based and scalable ontology matching",
      "authors": [
        "Ernesto Jiménez",
        "- Ruiz",
        "Bernardo Cuenca Grau"
      ],
      "year": "2011",
      "venue": "The Semantic Web-ISWC 2011: 10th International Semantic Web Conference",
      "doi": ""
    },
    {
      "id": "b44",
      "title": "Low-rank adaptation of large language models",
      "authors": [
        "J Edward",
        "Yelong Hu",
        "Phillip Shen",
        "Zeyuan Wallis",
        "Yuanzhi Allen-Zhu",
        "Shean Li",
        "Lu Wang",
        "Weizhu Wang",
        "Chen",
        "Lora"
      ],
      "year": "2021",
      "venue": "Low-rank adaptation of large language models",
      "doi": ""
    },
    {
      "id": "b45",
      "title": "Efficient finetuning of quantized llms",
      "authors": [
        "Tim Dettmers",
        "Artidoro Pagnoni",
        "Ari Holtzman",
        "Luke Zettlemoyer",
        "Qlora"
      ],
      "year": "2023",
      "venue": "Efficient finetuning of quantized llms",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Exploring The In-Context Learning Ability Of Large Language Model For Biomedical Concept Linking",
      "text": "Qinyong Wang Center for Artificial Intelligence in Drug Discovery Case Western Reserve University Cleveland, OH, 44106 qxw225@case.edu &Zhenxiang Gao Center for Artificial Intelligence in Drug Discovery Case Western Reserve University Cleveland, OH, 44106 zxg306@case.edu &Rong Xu Center for Artificial Intelligence in Drug Discovery Case Western Reserve University Cleveland, OH, 44106 rxx@case.edu"
    },
    {
      "title": "Abstract",
      "text": "The biomedical field relies heavily on concept linking in various areas such as literature mining, graph alignment, information retrieval, question-answering, data, and knowledge integration. Although large language models (LLMs) have made significant strides in many natural language processing tasks, their effectiveness in biomedical concept mapping is yet to be fully explored. This research investigates a method that exploits the in-context learning (ICL) capabilities of large models for biomedical concept linking. The proposed approach adopts a two-stage retrieve-and-rank framework. Initially, biomedical concepts are embedded using language models, and then embedding similarity is utilized to retrieve the top candidates. These candidates' contextual information is subsequently incorporated into the prompt and processed by a large language model to re-rank the concepts. This approach achieved an accuracy of 90.1% in BC5CDR disease entity normalization and 94.7% in chemical entity normalization, exhibiting a competitive performance relative to supervised learning methods. Further, it showed a significant improvement, with an over 20-point absolute increase in F1 score on an oncology matching dataset. Extensive qualitative assessments were conducted, and the benefits and potential shortcomings of using large language models within the biomedical domain were discussed."
    },
    {
      "title": "1 Introduction",
      "text": "Biomedical concept linking is a critical procedure in knowledge integrationHimmelstein et al. (2017) and information retrievalGopalakrishnan et al. (2019). This process identifies biomedical concepts within the text and associates these concepts with matching entities in a biomedical knowledge base. It essentially forms a bridge between text and structured knowledge databases, facilitating the efficient extraction and utilization of intricate biomedical information. Concept linking is integral to diverse applications, such as literature mining, graph alignmentZeng et al. (2021), and information retrieval within the biomedical domain. Moreover, the efficacy of concept linking directly influences the performance of graph-based algorithms, search algorithms, and question-answering systems. While significant progress has been made in the field of biomedical concept linking, major issues still pertain to their limited capacity to handle the ambiguity and complexity characteristic of biomedical conceptsHuang et al. (2020). Supervised Training or fine-tuning methods typically require extensive labeled data, which is labor-intensive and expensive to compile Ji et al. (2020), Li et al. (2019). The reliance on labeled data also introduces the data expiration problem, given the evolving nature of biomedical knowledge. For instance, biomedical entities linkingdatasets often utilize an ontology system for labeling text mentions; however, these systems change over time. The Medical Subject Headings (MeSH) system housed 28,000 concepts in 2016, but by 2023, the count has increased to 32,000 conceptsLipscomb (2000). Consequently, if we were to employ label-dependent supervised methods, models may need recurrent retraining to stay updated. Additionally, these techniques are often task-specific, lacking the requisite adaptability to handle different datasets or tasks without comprehensive retraining. There is a need for a more generalized framework for biomedical concept linking that can navigate the complex landscape of biomedical text data effectively. The ideal system should be adaptable, capable of processing various datasets and tasks without the need for task-specific training data. It should also possess the robustness to handle the ambiguity and complexity of biomedical concepts. Biomedical concept linking can be described as the process of identifying concepts within a given text and associating them with corresponding concepts in a biomedical knowledge base. This task encompasses a range of specific tasks, including biomedical entity linkingKalyan et al. (2022), disease name normalizationHuang et al. (2020), and ontology matching Harrow et al. (2019). Biomedical entity linking or disease name normalization typically involves mapping unstructured text to an ontology system. On the other hand, ontology matching refers to identifying identical concepts across two distinct ontology systems and establishing a link between them. Notably, there are differences between tasks like entity normalization and ontology matching. While entity normalization operates on free text, ontology matching deals with more structured text and the related contextual information of the concepts. Furthermore, entity normalization typically encompasses a smaller percentage of an ontology's concepts, while ontology matching often covers a larger and more diverse array of concepts. Biomedical concept linking extends beyond tasks such as entity normalizationHuang et al. (2020) and ontology matchingHarrow et al. (2019). For instance, a concept linking method should be capable of matching two heterogeneous biomedical graphs at the concept level. This task presents a significant challenge for supervised training methods, as it's nearly impossible to generate labels for arbitrary heterogeneous graphs. It's important to note that concept linking does not include entity recognitionSong et al. (2021), a common procedure in text-mining tasks. Entity recognition often precedes concept linking and may not even feature in some tasks. Thus, concept linking is a distinct, wider task, facilitating effective navigation of intricate biomedical information. Traditional BERT-based methods may struggle to adapt to the diverse array of datasets and tasks associated with this fieldKalyan et al. (2022), Li et al. (2019). LLMs Zhou et al. (2023), however, have recently demonstrated remarkable Figure 1: Overview of the proposed methodology and comparison with previous methods. profficiency in the biomedical domain De Angelis et al. (2023); Wang et al. (2023). This paper aims to investigate a generalized and effective framework for biomedical concept linking, leveraging the ICL capabilities of LLMs. In-context learning forms the backbone of our proposed methodology. It operates on the principle of learning by analogy, offering a unique method for LLMs to make informed predictionsDong et al. (2023). This novel paradigm offers several compelling benefits. As the demonstration is rendered in natural language, it provides an interpretive interface for interaction with LLMs, making it significantly simpler to incorporate biomedical knowledge into LLMs by altering the demonstration and templates. Compared to supervised training, in-context learning is a training-free learning framework. This drastically cuts down the developing time required to adapt the model to new tasks. As such, it can be readily applied to real-world tasks, broadening its applicability and utility. In this research, we propose a classic yet effective, generalized methodology for biomedical concept linking that leverages the ICL capabilities of LLMs. Our method involves a two-stage retrieve-and-rank system: The first stage embeds biomedical concepts using language models and uses these embedding to retrieve top candidate concepts. In the second stage, the contextual information of these candidates is incorporated into the prompt, and an LLM ranks these concepts. Our proposed method presents several advantages. Firstly, it is adaptable, requiring no task-specific training, and can be applied to different datasets and tasks. Secondly, it demonstrates competitive performance with state-of-the-art supervised learning methodsNeumann et al. (2019); He et al. (2022), as evidenced by our results on entity normalization datasets and ontology matching datasets. Lastly, by leveraging the ICL abilities of large models, it effectively navigates the inherent ambiguity and complexity of biomedical concepts, significantly improving the efficacy of concept linking in the biomedical domain. The objective of this paper is to delve into a more comprehensive framework utilizing LLMs for broader and more challenging tasks in the biomedical field. Our contributions are manifold; We identify a straightforward yet effective approach for tackling the complexity inherent in biomedical linking problems, and we also carry out an extensive application test to scrutinize various embedding methods and different language models. We further analyze the functioning of the large model and identify circumstances leading to its failure. A qualitative test is conducted to provide nuanced insights into the model's operation. All these explorations collectively guide the development of the next generation of accurate and trustworthy artificial intelligence solutions in the biomedical domain."
    },
    {
      "title": "2 Backgrounds",
      "text": "Entity Linking and Entity NormalizationEntity linking refers to the task of mapping mentions in free text to unique concepts in ontologies Huang et al. (2020). This can take the form of linking a certain drug to its specific drug ID or associating the disease with its corresponding disease/symptom ID. The Unified Medical Language System (UMLS) Bodenreider (2004) is a compendium of biomedical vocabularies, The Unified Medical Language System (UMLS), a representative ontology for biomedicine, contains over 4 million entities. UMLS has been extensively used as a knowledge base to link biomedical entities in the text to their corresponding concepts. These tasks often involve mapping free text terms in the biomedical literature to UMLS Concept Unique Identifiers(CUIs). A notable tool in this field is the MetaMap system Demner-Fushman et al. (2017). MetaMap utilizes natural language processing techniques to map biomedical text to concepts in the UMLS. Although robust, its rule-based method can struggle with semantic ambiguity, demanding supplementary solutions like advanced deep learning models to improve its accuracy and adaptability. Traditional methods often rely on rule-based approaches or string matchingSoldaini and Goharian (2016), which unfortunately proved to be ill-suited for dealing with concepts carrying contextual meanings and disease subtypes. A popular approach in recent years has been to utilize BERT-based methodsNeumann et al. (2019); Huang et al. (2020), which are primarily supervised. However, these techniques encounter significant challenges due to the scarcity of annotated examples, particularly given the vast number of entities involved. Recently, the development of self-supervised methods has introduced a fresh perspectiveZhang et al. (2022); Liu et al. (2020). These methods, requiring no supervised samples, have demonstrated comparable results to supervised training methods. Despite these advances, such techniques cannot be applied universally across an array of tasks. Additionally, the process of constructing a dataset and training model is time-consuming. By leveraging the ICL capabilities of LLMs, the difficulties associated with constructing training corpora and executing training are significantly alleviated. By adjusting the prompts in natural language, this framework can be easily adapted to various tasks, demonstrating its potential for efficiency and versatility. Ontology MatchingOntology matching, a key area of research, is the process of identifying corresponding entities or concepts across diverse ontology systemsHarrow et al. (2019). This procedure is fundamental for integrating heterogeneous databasesYi et al. (2022) and enhancing interoperability in the biomedical sector. Historically, ontology matching approaches primarily relied on exploiting lexical, structural, and semantic similaritiesAnam et al. (2015). The advent of deep learning has ushered in an era where many current studies are investigating the use of Transformer, or specifically BERThe et al. (2022), for ontology matching. However, these BERT-based methods often grapple with the challenges previously outlined. Moreover, their performance is less than ideal when it comes to biomedical ontologyHe et al. (2022). Biomedical ontology often encompasses a multitude of concepts that demand expert-level understanding, such as the ability to distinguish between two rare diseases that may appear similar but are caused by distinct genes. BERT-based methods frequently struggle to address these scenarios. Yet, the identification of the relationship between genes and diseases is paramount to advancements in biomedical discoveries. By capitalizing on the in-context learning capabilities of large language models, we're able to more accurately differentiate between complex biomedical concepts and enhance the efficacy of ontology matching in the biomedical sector. Text EmbeddingThe quality of text embedding plays a critical role in enhancing the recall rate of concept linking. Many text embedding methods Lately, transformer-based models have been gaining traction due to their ability to generate context-aware embeddings. Moreover, recent studies have made significant strides in training BERT models on the biomedical textLiu et al. (2020), Lee et al. (2020) and using innovative training techniques such as contrastive learningLe-Khac et al. (2020). Domain-specific language models, those specifically trained on biomedical texts, have demonstrated superior performance compared to standard BERT modelsLee et al. (2020). This performance boost highlights the importance of domain-specific knowledge in enhancing the accuracy of embedding. Large Language ModelsLLMs have demonstrated remarkable capabilities in natural language understanding and generation. These models are trained on massive amounts of text data and can generate coherent and contextually appropriate responses Zhou et al. (2023). However, they often lack domain-specific knowledge and struggle with understanding specialized terminologies, which is a crucial aspect of biomedical concept linking. LLMs are built using deep learning architectures like TransformersVaswani et al. (2017) and have demonstrated remarkable proficiency in understanding and generating human-like text. Two of the most well-known LLMs are GPT-3Brown et al. (2020) and GPT4Bubeck et al. (2023). GPT-3, with 175 billion parameters, has displayed impressive results in a wide range of NLP tasks. The most popular open-source LLM is LLaMaTouvron et al. (2023) which showed comparatively good performers with GPT 3.5, and there's a wide range of domain-specific fine-tuned llama modelsWu et al. (2023), Zhang et al. (2023) from 7 billion to 65 billion parameters. However, the usage of LLMs also presents challenges. One such issue is the \"hallucination\" problem Zhou et al. (2023), Zhang et al. (2023), where the model generates outputs that seem plausible but are factually incorrect. Furthermore, due to their size and complexity, these models require substantial computational resources for training and deployment. Despite these challenges, LLMs have ushered in a new era in NLP and are continuously being explored for their potential in a wide range of biomedical concept linking. In-context LearningGenerally, in-context learning necessitates a few examples to create a demonstration contextDong et al. (2023). These examples are typically expressed using natural language templates. Following this, a query question is concatenated with the demonstration context to generate a prompt. This prompt is then processed by the language model to predict an outcome. The definition of in-context learning is continuously evolving, in our proposed method, we not only include the conventional approach of using knowledge examples in the prompt, but we also supply more relevant information related to a given biomedical concept. By doing so, we equip the LLM with the necessary contextual information, thereby LLM learns from extra information rather than just analogy. Unlike supervised learning which necessitates a training stage involving backward gradientsNeumann et al. (2019), Huang et al. (2020) for model parameter updates, ICL eschews parameter updates and makes predictions directly using pre-trained LLMs. The expectation is that the model will discern patterns hidden within the demonstration and make appropriate predictions accordinglyBubeck et al. (2023)."
    },
    {
      "title": "3 Methodology",
      "text": "Formally, we set the objective of concept linking as the development of an algorithm \\(\\mathtt{Link}\\): \\((e_{\\text{source}},C_{\\text{source}})\\rightarrow(e_{\\text{target}},C_{\\text{ target}})\\). This algorithm maps a source entity \\(e_{\\text{source}}\\) within the context \\(C_{\\text{source}}\\) to a unique target entity \\(e_{\\text{target}}\\) with context \\(C_{\\text{target}}\\). The source entity could be derived from free text, a graph, or a source ontology system in ontology matching, and it's worth noting that \\(C_{\\text{source}}\\) may sometimes be absent. Generally, we require the context of the target concept to be provided. A concept is more well-defined when its associated information is supplied. In the process of developing a zero-training algorithm, we operate under the assumption that no access to gold-mention examples or labels is available. Our assumption extends to the availability of a target domain ontology \\(O_{\\text{target}}\\) and an unlabeled text corpus \\(T\\), or a source ontology \\(O_{\\text{source}}\\). Specifically, we necessitate a concept list that provides a unique identifier, a canonical name, and a description for each concept. Our framework also has the capacity to incorporate additional knowledge present in the ontology."
    },
    {
      "title": "Text Embedding",
      "text": "The first stage in our methodology involves transforming textual data into semantic representations. The quality of these embeddings is crucial as it significantly affects downstream tasksLiu et al. (2020). To meet our objective of exploring a training-free framework, we opt for three different embedding models. Our first model of choice is SapBERTLiu et al. (2020), a Self-Aligned Pretrained BERT model specifically designed for the biomedical domain. Serving as a representation of the BERTDevlin et al. (2018) family of models, SapBERT has superior performance in biomedical tasks. Next, we leverage the LLaMa model's embeddings Zhang et al. (2023). LLaMa symbolizes an open-source option for Large Language Model embeddings, boasting high applicability across diverse language tasks. Finally, we utilize GPT-3 embeddings, specifically \"text-embedding-ada-002\", representing one of the most powerful and proprietary embedding methodologies currently available. Considering a target ontology \\(O_{\\text{target}}\\) and an embedding model \\(f_{\\text{emb}}()\\), we generate text embeddings for each entity/concept \\(e_{\\text{target}}\\). This process involves generating embeddings for both the canonical concept name string and a combined version that includes the name string and its context. The purpose of creating an 'entity-name-only' representation is to recall entities that can be easily matched with the string, serving as an efficient approach for exact or simple matches. On the other hand, generating 'entity-name-context' embeddings targets a more complex objective. Despite entities not bearing similarity in appearance, they may be describing the same concept, and this intricate relation can be captured through context-inclusive embeddings. This dual approach caters to both explicit matches and the nuanced equivalences in the realm of biomedical concepts. As we will illustrate in the appendix, embedding with context plays a significant role in the success of our approach."
    },
    {
      "title": "Candidate Generation",
      "text": "Following the generation of contextual embeddings, we persist all embeddings from the ontology into a vector database, alternatively referred to as a long-term memory store Park et al. (2023). This enables efficient computation of cosine similarity between any given query text embedding and all the ontology embeddings. This stored ontology is referred to as'mem'. When a query entity \\((e_{\\text{source}},C_{\\text{source}})\\) is presented, we employ the same embedding process. The top \\(k\\) candidates are then retrieved based on the cosine similarity of their contextual embeddings. The process of memory creation and candidate generation can be outlined in Algorithm 1. Figure 2: Workflow of the proposed methodology for exploring the in-context learning ability of large language models for biomedical concept linking."
    },
    {
      "title": "Rank With Llm",
      "text": "LLMs possess text comprehension capabilities and a degree of logical reasoning abilityBubeck et al. (2023). Consequently, our approach revolves around providing comprehensive contextual information related to the biomedical concept linking task, enabling the model to execute an extensive reading task and subsequently select the most appropriate answer from the given options. When constructing the prompt, we initially define the task and inform the model that our aim is to identify analogous concepts. We then present the candidate concepts retrieved from long-term memory. These candidates are options within the prompt. Further, we fetch the descriptions of these candidates from the ontology and associated text of the source entity. Ultimately, the prompt asks the model to select the concept that aligns best with the options; if none are suitable, the model is to select the 'None' option. The configuration of the prompt is adaptable, accommodating the unique requirements of different tasks. For instance, in entity linking tasks, we may also include related text. The BC5CDR datasetLi et al. (2016), which extracts named entities from PubMed abstracts, would necessitate the addition of abstract tags within the prompt. Similarly, for tasks like graph alignment, we could incorporate neighborhood information into the prompt. The overall workflow of the ontology matching task is illustrated in figure 2. ``` 0: Target domain ontology \\(O_{\\text{target}}\\), Source entity \\(e_{\\text{source}}\\), Source context \\(C_{\\text{source}}\\), Embedding function \\(f_{\\text{emb}}\\), VectorDatabase mem, Number of candidates \\(k\\) 1:Memory Creation 2: Initialize VectorDatabase: mem \\(\\leftarrow\\) VectorDatabase() 3:for\\((e_{\\text{target}},C_{\\text{target}})\\) in \\(O_{\\text{target}}\\)do 4: mem.add(\\(f_{\\text{emb}}(e_{\\text{target}})\\)) 5: mem.add(\\(f_{\\text{emb}}([e_{\\text{target}},C_{\\text{target}}])\\)) 6:endfor 7:Candidate Generation 8:functiongenerate_candidates(\\(e_{\\text{source}},C_{\\text{source}}\\), mem, \\(k\\)) 9:\\(query_{\\text{emb}}\\gets f_{\\text{emb}}([e_{\\text{source}},C_{\\text{ source}}])\\) 10:\\(top\\_k\\_candidates\\leftarrow\\) mem.retrieve_top_k(\\(query_{\\text{emb}},k\\)) 11:return\\(top\\_k\\_candidates\\) 12:endfunction ``` **Algorithm 1** Memory Creation and Candidate Generation"
    },
    {
      "title": "4 Experiments",
      "text": ""
    },
    {
      "title": "Dataset",
      "text": "Choosing an appropriate dataset to benchmark our proposed method and probe the capabilities of LLMs poses a few challenges. Firstly, as LLMs are trained on a vast amount of text data including published papers and webpages, data leakage becomes an inevitable concern for many existing datasets. Estimating the impact of this leakage on performance is not straightforwardBubeck et al. (2023). Moreover, biomedical NLP datasets can be sensitive, with some prohibiting any form of redistribution. This becomes problematic when using the GPT API, as the dataset is exposed to OpenAI, potentially leading to indirect redistribution via the LLM. Another obstacle is the slow inference speed of LLMs. For datasets with over 100,000 samples, the inference could take more than ten days, and with multiple models to benchmark and various ablation tests to conduct, it necessitates a smaller dataset. Consequently, we chose the BC5CDR datasetLi et al. (2016) for benchmarking. This well-known dataset in biomedical entity normalization requires mapping named entities in PubMedRoberts (2001) abstracts to unique MeSH IDs. It encompasses two types of entities - chemicals, and diseases. By using this dataset, we can readily compare our proposed framework with previous supervised or self-supervised training methodsLiu et al. (2020); Zhang et al. (2022). Additionally, the BC5CDR dataset is relatively small, with 4797 mentions in the test set, making it manageable given the slow inference speed of LLMs. For the ontology matching task, we selected the Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching He et al. (2022), published in 2022. Being recently published, unlikely to be accessed by Llama, GPT3, or GPT4. We focused on two challenging sub-tasks from this dataset: OMIM-ORDO and SNOMED-NCIT Neoplas. OMIM (Online Mendelian Inheritance in Man)McKusick (2011) OMIM provides extensive data ongenes and genetic phenotypes and their relationships, curated meticulously from biomedical literature. ORDO (Orphanet Rare Disease Ontology)Vasant et al. (2014)encompasses a classification of rare diseases and establishes relationships between diseases, genes, and epidemiological features. Given that many rare diseases are genetic disorders, ORDO and OMIM share considerable overlap. However, linking these rare disease names poses a significant challenge. Such diseases are typically unfamiliar to individuals without specialized medical knowledge, and their mentions in literature are often infrequent. We selected SNOMED-NCIT Neoplas Stearns et al. (2001) ontology matching, as differentiating neoplasm names is challenging for Bert-based methods. The test sets for OMIM-ORDO and SNOMED-NCIT Neoplas contain 3,721 pairs and 3,804 pairs, respectively."
    },
    {
      "title": "4.1.1 Implementation Details",
      "text": "Unlike many previous studies that utilize somewhat complex systems, such as developing corpora for fine-tuning, and incorporating synonym dictionaries, and abbreviation dictionariesLiu et al. (2020), Zhang et al. (2022), our approach is guided by the principle of simplicity. Our goal is to establish a universal framework for biomedical concept linking, without adding complexity or tailoring our system to a specific task or dataset. The only aspect we modify is the prompt. For instance, in the BC5CDR task, we include the PubMed abstract text and insert the instruction \"read the abstract\" in the prompt. We perform one-shot learning in the ablation test, similar to the application of Chain of ThoughtsWei et al. (2022). However, we do not use the Self-Consistency methodWang et al. (2022) in this paper. The reason is discussed in the appendix. We chose to include GPT-3.5-turbo (ChatGPT) in our study because it is one of the most widely known LLMs and offers the advantages of being both fast and cost-effective. We also decided to incorporate GPT-4, given its exceptional power and performance. Finally, we used a 4-bit quantization of LLama-65b (known as alpaca-lora), which is a highly popular open-source LLM that can be conveniently deployed on a standard desktop computer due to its quantization. For the LLama-65b, we utilized a desktop machine equipped with 64GB of RAM, running llama-cpp for inference. As for GPT-3.5 and GPT-4, we accessed these models through OpenAT's API, conducting our experiments on an ordinary laptop."
    },
    {
      "title": "4.1.2 Evaluation",
      "text": "As our proposed framework does not require training, we have no need for training and development sets. We directly evaluate our framework using the test sets from our chosen datasets. As discussed in the dataset section, benchmarking larger models needs to take data leakage into account, as it may impact the quantitative results. For BC5CDR, we employ accuracy as the metric for evaluation, consistent with previous research, enabling comparison. For comparison, we choose KRISSBERTZhang et al. (2022), BERN2Sung et al. (2022), ScispaCyNeumann et al. (2019), and QuickUMLSSoldaini and Goharian (2016) as baselines. KRISSBERT is representative of self-supervised training methods that, like ours, do not require training and development datasets. BERN2 is a hybrid system that employs both rule-based and BERT models for named entity normalization and claims superior performance. ScispaCy is a BERT-based method.QuickUMLS is a dictionary-based method. For the ontology matching task, we make comparisons with LSMatchSharma et al. (2021), ATMatcherHe et al. (2022), LogMapJimenez-Ruiz and Cuenca Grau (2011), and BERTMapHe et al. (2022). Among these, BERTMap is the most recent and capable contender. And we use Precision, Recall, and F1 score as our evaluation criteria. We also test the effect of using context information or one-shot learning in the prompt. Our primary objective is to delve into the capabilities of LLMs for biomedical concepts linking in with ICL. Consequently, we also undertake extensive qualitative result analysis. We will assess both false positives and false negatives, providing a more comprehensive evaluation of our model's performance. Furthermore, we ask the model to elucidate the rationale behind its concept linking decisions, a practice known as process correctnessBubeck et al. (2023). In the quest to build accurate and trustworthy AI in the biomedical field, achieving the correct predictions is crucial, but equally important is understanding the explanations underpinning these results."
    },
    {
      "title": "5 Results",
      "text": ""
    },
    {
      "title": "Quantitative Results",
      "text": ""
    },
    {
      "title": "5.1.1 Main Results",
      "text": "The results of our framework on the BC5CDR dataset are presented in Table 1. Utilizing GPT-4 as the ranker, our model achieved an accuracy of 90.1% on disease name entity linking and 94.7% on chemical name entity linking. We primarily compared our approach with the self-supervised KRISSBERT method and the more complex hybrid system BERN2. In terms of linking disease names, our model's results surpass KRISSBERT's and are competitive with BERN2's, with just a 3.85% difference. Notably, our results were achieved without the use of any customized rules, abbreviation dictionaries, or synonym dictionaries. For chemical name entity linking, our model's performance is approximately 2% lower than KRISSBERT's and BERN2's. Considering our framework requires no training, these results are quite promising and outperform earlier BERT-based methods like ScispaCy. When we switch to GPT-3 as the ranker, the performance remains reasonably good. However, with the Llama model as a ranker, performance drops significantly for chemical entity linking, even falling behind early BERT models. Table 2 presents the results of ontology matching between OMIM and ORDO and ontology matching between SNOMED and NCIT Neoplas. Our framework, utilizing the ICL capabilities of GPT-4, achieved over a 20 percentage point increase in F1 score in comparison to the previous best-performing method, BERTmap. When GPT-3.5 was employed as the ranker, there was still a notable increase of approximately 10 percentage points in the F1 score. These outcomes underscore the effectiveness of the ICL provided by LLMs. Meanwhile, Llama's performance just marginally surpassed BERTmap in OMIM-ORDO matching but lagged behind in the SNOMED-NCIT Neoplas matching task. Given that we used a 4-bit quantized version of Llama that was not specifically aligned to biomedical tasks, the results remain promising. However, the disparity in performance between Llama and the GPT models indicates that there's significant room for the enhancement of open-source LLMs in the future."
    },
    {
      "title": "5.1.2 Ablation Test",
      "text": "Table 3 presents the results of various prompting methods for rare disease concept matching in OMIM-ORDO (Disease) using GPT-4. The findings indicate that without the use of a one-shot example and no context information about these rare disease concepts, the F1-score is merely 0.698. This is approximately 19 points lower than the proposed method and shows no significant improvement compared to the previous BERTMap method. These results suggest that even the most powerful language model does not automatically perform well on certain biomedical tasks without additional context. The implementation of both one-shot learning and the addition of related concept information significantly improves performance, demonstrating the value of using the ICL ability of large language models for concept-linking tasks.It's interesting to note that adding OMIM context information provides a larger performance increase than one-shot learning without context. When combining both one-shot learning and OMIM context, the performance increase is marginal compared to just using OMIM context. This suggests that introducing the correct and relevant information for each case is more beneficial than providing an analogous example. Interestingly, it's noteworthy to observe that one-shot learning significantly enhances precision to a greater extent than it does recall. \\begin{table} \\begin{tabular}{l c c} \\hline \\hline **Method** & **Accuracy-Disease** & **Accuracy-Chemical** \\\\ \\hline QuickUMLS(dictionary-based) & 0.475 & 0.349 \\\\ ScispaCy(BERT) & 0.640 & 0.853 \\\\ BERN2(Hybrid system) & **0.939** & **0.966** \\\\ KRISSBERT(self-supervised) & 0.855 & 0.965 \\\\ \\hline Retrieve-Rank with LLaMa 65B & 0.726 & 0.728 \\\\ Retrieve-Rank with GPT3.5 & 0.840 & 0.912 \\\\ Retrieve-Rank with GPT4 & **0.901** & **0.947** \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 1: Comparison of Retrieve-Rank with different LLMs with previous methods on BC5CDR dataset. The highest accuracy of our methodology and previous methods are both highlighted. \\begin{table} \\begin{tabular}{l c c c c c c} \\hline \\hline & \\multicolumn{3}{c}{**OMIM-ORDO (Rare disease)**} & \\multicolumn{3}{c}{**SNOMED-NCIT(Neoplas )**} \\\\ \\cline{2-7} & **Precision** & **Recall** & **F1** & **Precision** & **Recall** & **F1** \\\\ \\hline LSMatch & 0.650 & 0.221 & 0.329 & 0.902 & 0.238 & 0.377 \\\\ ATMatcher & **0.940** & 0.247 & 0.391 & 0.866 & 0.284 & 0.428 \\\\ LogMap & 0.827 & 0.498 & 0.622 & **0.947** & 0.520 & 0.671 \\\\ BERMap & 0.730 & **0.572** & **0.641** & 0.815 & **0.709** & **0.759** \\\\ \\hline Retrieve-Rank with LLaMa 65B & 0.797 & 0.543 & 0.646 & 0.699 & 0.665 & 0.679 \\\\ Retrieve-Rank with GPT3.5 & 0.777 & 0.704 & 0.738 & 0.760 & 0.736 & 0.748 \\\\ Retrieve-Rank with GPT4 & **0.906** & **0.859** & **0.882** & **0.916** & **0.893** & **0.904** \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 2: Comparison of different methods."
    },
    {
      "title": "Qualitative Results",
      "text": ""
    },
    {
      "title": "5.2.1 Abbreviations",
      "text": "Abbreviations are a prevalent feature in biomedical text. Previous methodsZhang et al. (2022); Sung et al. (2022) we compared employed an abbreviation dictionary to enhance performance. But does an LLM understand biomedical abbreviations? The answer is affirmative, but LLMs tend to struggle with less common abbreviations. For familiar abbreviations such as AD (Alzheimer's Disease) or PD (Parkinson's Disease), LLMs can easily link them to the correct concept when provided with a medical context. However, for less common abbreviations like MR (Mitral Valve Insufficiency) or VT (Tachycardia, Ventricular), LLMs tend to either choose a \"None' option from the list of candidates or erroneously select an incorrect option. Detailed cases could be checked in the appendix. Therefore, we believe it's still valuable to supply LLMs with abbreviation dictionary information to improve accuracy in more infrequent cases."
    },
    {
      "title": "5.2.2 Disease Subtypes",
      "text": "The task of linking disease subtype concepts presents a significant challenge in the biomedical field. These disease subtypes often share a lot of similarities, particularly for rare diseases in ORPHA. Even human experts might need some time to gather information to discern the differences between these rare disease subtypes. GPT-4 is capable of understanding common disease subtypes, such as different types of diabetes, with ease. However, LLama tends to struggle with identifying these common disease subtypes. Regarding rare disease subtypes, GPT-4 can comprehend most of them when provided with appropriate descriptions. In contrast, LLama fails in most cases involving rare diseases subtypes. In situations where GPT-4 failed, rare disease subtypes constitute a significant portion. For instance, \"Dentinogenesis imperfeta, shields iia 3\" in OMIM corresponds to \"Dentinogenesis imperfeta type 3\". However, GPT chose \"Dentinogenesis imperfeta type 2\". Generally, GPT-4 can provide the correct answer for diseases labeled with \"type n\". However, it does occasionally falter in a few of these cases."
    },
    {
      "title": "5.2.3 Process Correctness",
      "text": "The rationale behind an LLM ranking a candidate first is critical. To construct precise and trustworthy AI in the biomedical domain, we aim for both the prediction and the process to be accurate. We noticed from the LLama results that there are instances where the process was incorrect, yet the final answer was right. For example, in case 9 from the appendix, LLama provided the correct prediction, yet the reasoning appeared to be based on shared keywords between disease concept names. This is not ideal, especially for rare disease concept linking, where many concepts share keywords yet refer to different diseases. GPT-4 exhibits a more accurate and consistent reasoning process than LLaMa, which sometimes even outputs code (as seen in case 8 in the appendix), indicating that the LLama model we utilized may not be well-aligned for this task. Although we are not medical experts and cannot offer an accurate assessment of LLM's process correctness, the process correctness of GPT-4 is generally satisfactory when given the correct concept description. Most of the time, the process is associated with the context we provided, further emphasizing the importance of using LLM's ICL. By qualitatively evaluating the process correctness of LLM, we enhance the interpretability of using large models in concept linking tasks."
    },
    {
      "title": "6 Limitations And Discussion",
      "text": "While our framework holds promise, it also comes with notable limitations. Primarily, the inference speed of LLMs is exceedingly slow, making the process expensive and long. For instance, our experimental setup involving GPT4 inference on 3700 OMIM-ORDO pairs costs approximately $150 USD. When employing locally deployable LLMs, such as LLama 13B, the inference speed is roughly 103 ms/token, processing only a few words per second. Larger \\begin{table} \\begin{tabular}{l c c c} \\hline \\hline **Method** & **Precision** & **Recall** & **F1** \\\\ \\hline No context & 0.783 & 0.629 & 0.698 \\\\ One-shot & 0.871 & 0.708 & 0.781 \\\\ OMIM context only(source concepts) & 0.860 & 0.773 & 0.814 \\\\ OMIM context + One-shot & **0.914** & 0.7495 & 0.824 \\\\ ORDO context only(options) & 0.856 & 0.792 & 0.823 \\\\ Both OMIM and ORDO & 0.906 & **0.859** & **0.882** \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 3: Ablation test results with different prompting methods on OMIM-ORDO (Disease) rear disease concepts matching with GPT4. models like Galantica and LLama 65B are even slower, handling only about one word per second with cpu. In light of these constraints, future research could explore fine-tuning (without supervision) a LLM specifically designed for this task with low resourcesHu et al. (2021). Considering the rigorous hardware requirements, our framework's accessibility is rather constrained. This is further exacerbated by GPT's closed-source nature, leading to diminished transparency. Moreover, even when using open-source LLama for inference, powerful GPUs or large amounts of RAM are required - resources that most researchers and potential users in the biomedical domain do not have readily available. Training and compressing a quantified LLMDettmers et al. (2023) for the biomedical domain is also beneficial in future work. Furthermore, our framework sometimes exhibits unexpected failures. For instance, when two share the same name, our framework may fail to provide the correct answer. This could be due to context embedding - if the accurately labeled name is contextually farther than other candidates, the correct option may not appear. Moreover, this framework also exhibits frequent shortcomings in handling abbreviations. Both of these issues could potentially be mitigated by utilizing dictionaries, suggesting that a hybrid system might be an avenue worth exploring for future concept linking tasks."
    },
    {
      "title": "7 Conclusion",
      "text": "In conclusion, this research explores the use of the in-context learning capabilities of large language models for biomedical concept linking. Our proposed two-stage framework effectively retrieves and ranks biomedical concepts, achieving competitive results without needing any training."
    },
    {
      "title": "References",
      "text": "* Himmelstein et al. [2017] Daniel Scott Himmelstein, Antoine Lizee, Christine Hessler, Leo Brueggeman, Sabrina L Chen, Dexter Hadley, Ari Green, Pouya Khankhanian, and Sergio E Baranzini. Systematic integration of biomedical knowledge prioritizes drugs for repurposing. _Elife_, 6:e26726, 2017. * Gopalakrishnan et al. [2019] Vishrawas Gopalakrishnan, Kishlay Jha, Wei Jin, and Aidong Zhang. A survey on literature based discovery approaches in biomedical domain. _Journal of biomedical informatics_, 93:103141, 2019. * Zeng et al. [2021] Kaisheng Zeng, Chengjiang Li, Lei Hou, Juanzi Li, and Ling Feng. A comprehensive survey of entity alignment for knowledge graphs. _AI Open_, 2:1-13, 2021. * Huang et al. [2020] Ming-Siang Huang, Po-Ting Lai, Pei-Yen Lin, Yu-Ting You, Richard Tzong-Han Tsai, and Wen-Lian Hsu. Biomedical named entity recognition and linking datasets: survey and our recent development. _Briefings in Bioinformatics_, 21(6):2219-2238, 2020. * Ji et al. [2020] Zongcheng Ji, Qiang Wei, and Hua Xu. Bert-based ranking for biomedical entity normalization. _AMIA Summits on Translational Science Proceedings_, 2020:269, 2020. * Li et al. [2019] Fei Li, Yonghao Jin, Weisong Liu, Bhanu Pratap Singh Rawat, Pengshan Cai, Hong Yu, et al. Fine-tuning bidirectional encoder representations from transformers (bert)-based models on large-scale electronic health record notes: an empirical study. _JMIR medical informatics_, 7(3):e14830, 2019. * Lipscomb [2000] Carolyn E Lipscomb. Medical subject headings (mesh). _Bulletin of the Medical Library Association_, 88(3):265, 2000. * Subramanyam Kalyan et al. [2022] Kaikapalli Subramanyam Kalyan, Ajit Rajasekharan, and Sivanesan Sangeetha. Ammu: a survey of transformer-based biomedical pretrained language models. _Journal of biomedical informatics_, 126:103982, 2022. * Harrow et al. [2019] Ian Harrow, Rama Balakrishnan, Ernesto Jimenez-Ruiz, Simon Jupp, Jane Lomax, Jane Reed, Martin Romacker, Christian Senger, Andrea Splendiani, Jabe Wilson, et al. Ontology mapping for semantically enabled applications. _Drug discovery today_, 24(10):2068-2075, 2019. * Song et al. [2021] Bosheng Song, Fen Li, Yuansheng Liu, and Xiangxiang Zeng. Deep learning methods for biomedical named entity recognition: a survey and qualitative comparison. _Briefings in Bioinformatics_, 22(6):bbab282, 2021. * Zhou et al. [2023] Ce Zhou, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, Cheng Ji, Qiben Yan, Lifang He, et al. A comprehensive survey on pretrained foundation models: A history from bert to chatgpt. _arXiv preprint arXiv:2302.09419_, 2023. * Angelis et al. [2023] Luigi De Angelis, Francesco Baglivo, Guglielmo Arzilli, Gaetano Pierpaolo Privitera, Paolo Ferragina, Alberto Eugenio Tozzi, and Caterina Rizzo. Chatgpt and the rise of large language models: the new ai-driven infodemic threat in public health. _Frontiers in Public Health_, 11:1166120, 2023. * Wang et al. (2023) Ding-Qiao Wang, Long-Yu Feng, Jin-Guo Ye, Jin-Gen Zou, and Ying-Feng Zheng. Accelerating the integration of chatgpt and other large-scale ai models into biomedical research and healthcare. _MedComm-Future Medicine_, 2(2):e43, 2023. * Dong et al. (2023) Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. A survey on in-context learning. _arXiv_, 2023. URL [https://arxiv.org/abs/2301.00234](https://arxiv.org/abs/2301.00234). * Neumann et al. (2019) Mark Neumann, Daniel King, Iz Beltagy, and Waleed Ammar. Scispacy: fast and robust models for biomedical natural language processing. _arXiv preprint arXiv:1902.07669_, 2019. * He et al. (2022a) Yuan He, Jiaoyan Chen, Denvar Antonyrajah, and Ian Horrocks. Bertmap: a bert-based ontology alignment system. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 36, pages 5684-5691, 2022a. * Bodenreider (2004) Olivier Bodenreider. The unified medical language system (umls): integrating biomedical terminology. _Nucleic acids research_, 32(suppl_1):D267-D270, 2004. * Demner-Fushman et al. (2017) Dina Demner-Fushman, Willie J Rogers, and Alan R Aronson. Metamap lite: an evaluation of a new java implementation of metamap. _Journal of the American Medical Informatics Association_, 24(4):841-844, 2017. * Soldaini & Goharian (2016) Luca Soldaini and Nazli Goharian. Quickumls: a fast, unsupervised approach for medical concept extraction. In _MedIR workshop, sigir_, pages 1-4, 2016. * Zhang et al. (2022) Sheng Zhang, Hao Cheng, Shikhar Vashishth, Cliff Wong, Jinfeng Xiao, Xiaodong Liu, Tristan Naumann, Jianfeng Gao, and Hoifung Poon. Knowledge-rich self-supervision for biomedical entity linking. In _Findings of the Association for Computational Linguistics: EMNLP 2022_, pages 868-880, 2022. * Liu et al. (2020) Fangyu Liu, Ehsan Shareghi, Zaiqiao Meng, Marco Basaldella, and Nigel Collier. Self-alignment pretraining for biomedical entity representations. _arXiv preprint arXiv:2010.11784_, 2020. * Yi et al. (2022) Hai-Cheng Yi, Zhu-Hong You, De-Shuang Huang, and Chee Keong Kwoh. Graph representation learning in bioinformatics: trends, methods and applications. _Briefings in Bioinformatics_, 23(1):bbab340, 2022. * Anam et al. (2015) Sarawat Anam, Yang Sok Kim, Byeong Ho Kang, and Qing Liu. Review of ontology matching approaches and challenges. _International journal of Computer Science and Network Solutions_, 3(3):1-27, 2015. * He et al. (2022b) Yuan He, Jiaoyan Chen, Hang Dong, Ernesto Jimenez-Ruiz, Ali Hadian, and Ian Horrocks. Machine learning-friendly biomedical datasets for equivalence and subsumption ontology matching. In _The Semantic Web-ISWC 2022: 21st International Semantic Web Conference, Virtual Event, October 23-27, 2022, Proceedings_, pages 575-591. Springer, 2022b. * Lee et al. (2020) Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang. Biobert: a pre-trained biomedical language representation model for biomedical text mining. _Bioinformatics_, 36(4):1234-1240, 2020. * Le-Khac et al. (2020) Phuc H Le-Khac, Graham Healy, and Alan F Smeaton. Contrastive representation learning: A framework and review. _Ieee Access_, 8:193907-193934, 2020. * Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017. * Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. _Advances in neural information processing systems_, 33:1877-1901, 2020. * Bubeck et al. (2023) Sebastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence: Early experiments with gpt-4. _arXiv preprint arXiv:2303.12712_, 2023. * Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. _arXiv preprint arXiv:2302.13971_, 2023. * Wu et al. (2023) Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, and Weidi Xie. Pmc-llama: Further finetuning llama on medical papers. _arXiv preprint arXiv:2304.14454_, 2023. * Zhang et al. (2023a) Renrui Zhang, Jiaming Han, Aojun Zhou, Xiangfei Hu, Shilin Yan, Pan Lu, Hongsheng Li, Peng Gao, and Yu Qiao. Llama-adapter: Efficient fine-tuning of language models with zero-init attention. _arXiv preprint arXiv:2303.16199_, 2023a. * Zhang et al. (2023b) Muru Zhang, Ofir Press, William Merrill, Alisa Liu, and Noah A Smith. How language model hallucinations can snowball. _arXiv preprint arXiv:2305.13534_, 2023b. * Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. _arXiv preprint arXiv:1810.04805_, 2018. * Park et al. (2023) Joon Sung Park, Joseph C O'Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. _arXiv preprint arXiv:2304.03442_, 2023. * Li et al. (2016) Jiao Li, Yueping Sun, Robin J Johnson, Daniela Sciaky, Chih-Hsuan Wei, Robert Leaman, Allan Peter Davis, Carolyn J Mattingly, Thomas C Wiegers, and Zhiyong Lu. Biocreative v cdr task corpus: a resource for chemical disease relation extraction. _Database_, 2016, 2016. * Roberts (2001) Richard J Roberts. Pubmed central: The genbank of the published literature, 2001. * McKusick (2011) Victor McKusick. Omim (online mendelian inheritance in man). 2011. * Vasant et al. (2014) Drashtui Vasant, Laetitia Chanas, James Malone, Marc Hanauer, Annie Olry, Simon Jupp, Peter N Robinson, Helen Parkinson, and Ana Rath. Ordo: an ontology connecting rare disease, epidemiology and genetic data. In _Proceedings of ISMB_, volume 30. researchgate. net, 2014. * Stearns et al. (2001) Michael Q Stearns, Colin Price, Kent A Spackman, and Amy Y Wang. Snomed clinical terms: overview of the development process and project status. In _Proceedings of the AMIA Symposium_, page 662. American Medical Informatics Association, 2001. * Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. _arXiv preprint arXiv:2201.11903_, 2022. * Wang et al. (2022) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. _arXiv preprint arXiv:2203.11171_, 2022. * Sung et al. (2022) Mujeen Sung, Minbyul Jeong, Yonghwa Choi, Donghyeon Kim, Jinhyuk Lee, and Jaewoo Kang. Bern2: an advanced neural biomedical named entity recognition and normalization tool. _Bioinformatics_, 38(20):4837-4839, 2022. * Sharma et al. (2021) Abhisek Sharma, Archana Patel, and Sarika Jain. Lsmatch results for oaei 2021. In _OM@ ISWC_, pages 178-184, 2021. * Jimenez-Ruiz and Grau (2011) Ernesto Jimenez-Ruiz and Bernardo Cuenca Grau. Logmap: Logic-based and scalable ontology matching. In _The Semantic Web-ISWC 2011: 10th International Semantic Web Conference, Bonn, Germany, October 23-27, 2011, Proceedings, Part I 10_, pages 273-288. Springer, 2011. * Hu et al. (2021) Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. _arXiv preprint arXiv:2106.09685_, 2021. * Dettmers et al. (2023) Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning of quantized llms. _arXiv preprint arXiv:2305.14314_, 2023."
    },
    {
      "title": "8 Appendix",
      "text": ""
    },
    {
      "title": "Implementation Details",
      "text": "Techniques such as Chain of Thoughts and Self-Consistency are frequently employed in prompt engineering. We perform a one-shot learning in the ablation test, similar to the application of Chain of Thoughts. However, we do not use the Self-Consistency method in this paper. Here, we would like to discuss the necessity of these techniques. The primary notion of Chain of Thoughts is that by presenting an analogy and requiring the LLM to recount the original process, more computational power is used during the inference, leading to better performance. Self-Consistency, on the other hand, requires even more computational power, as it prompts the model to reason in various ways, ensuring that the results are internally consistent. In the context of our ICL definition, we already include substantial text information in the prompt (a full example can be found in the appendix), which is lengthy and necessitates significant LLM inference time. Furthermore, we consider concept linking as a fundamental, high-usage application. Implementing Self-Consistency would at least triple the inference cost, and given the current high costs and slow speed of inference and Self-Consistency are design of LLM reasoning task, we believe it is not advantageous to use Self-Consistency for such a basic task."
    },
    {
      "title": "Abblation Test",
      "text": "Table 4 demonstrates the performance of different language models in the candidate generation or retrieval stage during the OMIM-ORDO ontology matching. Across all three types of large language models, incorporating concept descriptions from ontologies in the embedding process generally improves performance. It's worth noting that SapBERT's hits@10 is less than 3% compared to GPT-3, which suggests that despite being more cost-efficient and faster, Bert-based embedding methods still have relevance and utility in future. On the other hand, Llama embeddings were significantly less effective, which might be due to the fact that the model wasn't specifically fine-tuned for use in embedding. SapBERT employs contrastive learning for its embedding model, and it's plausible that OpenAI employs a similar method for their models. Future research could explore using open-source LLMs for embeddings, as this could potentially yield better performance than Bert-based models. An experiment involving OMIM context information, ORDO information, and a one-shot example was not conducted, as the resulting prompt would contain too many tokens, making the experiment both time-consuming and costly. Given the minimal improvement observed when adding one-shot learning to the OMIM context, it is likely that any further gains from this additional experiment would be minor."
    },
    {
      "title": "Error Cases",
      "text": ""
    },
    {
      "title": "8.4 Reasoning Process Cases",
      "text": "Case1:bleeding disorder, platelet-type, 8 Il Bleeding disorder due to P2Y12 defect \\begin{table} \\begin{tabular}{|l|l|l|l|} \\hline **Method** & **Hits@1** & **Hits@5** & **Hits@10** \\\\ \\hline sapBert + context & 0.719 & 0.833 & 0.873 \\\\ sapBert & 0.626 & 0.771 & 0.829 \\\\ LLama + context & 0.1274 & 0.2148 & 0.2681 \\\\ LLama & 0.0616 & 0.1021 & 0.1271 \\\\ GPT3+context & 0.764 & 0.875 & 0.908 \\\\ GPT3 & 0.637 & 0.778 & 0.815 \\\\ \\hline \\end{tabular} \\end{table} Table 4: Ablation test of different embedding methods \\begin{table} \\begin{tabular}{|l|l|l|} \\hline **OMIM** & **ORDO** & **Prediction** \\\\ \\hline Angelman syndrome & Angelman syndrome & Christianson syndrome \\\\ \\hline Cheilitis glandularis & Cheilitis glandularis & None. \\\\ \\hline Pyknoachondrogenesis & Pyknoachondrogenesis & None \\\\ \\hline Cleidorhizomic syndrome & Cleidorhizomic syndrome & None \\\\ \\hline Hypochondrolasia & Hypochondrolasia & Achondrolasia \\\\ \\hline Immunodeficiency 8 & Severe combined immunodeficiency due to CORO1 deficiency & Combined immunodeficiency due to DOCK8 deficiency; \\\\ \\hline Immunodeficiency 12 & Combined immunodeficiency due to MALT1 deficiency & None \\\\ \\hline Ceroid lipofuscinosis, neuronal, 6b (kufs type) & CLN4A disease & CLN6 disease \\\\ \\hline Dentinogenesis imperfeta, shields iia 3 & Dentinogenesis imperfeta type 3 & Dentinogenesis imperfeta type 2 \\\\ \\hline Palmoplantar carcinoma, multiple self-healing & Corneal intraepithelial dyskeratosis-palmoplantar hyperkeratosis-laryngeal dyskeratosis syndrome & Multiple self-healing squamous epithelium \\\\ \\hline Mitral valve prolapse, myxomatous & Familial mitral valve prolapse & FLNA-related X-linked myxomatous valvular dysplasia \\\\ \\hline Erythbrokeratordemia aubilis et progressiva & Erythbrokeratordemia aubilis & Progressive symmetric erythrokeratordemia \\\\ \\hline Miyoshi muscular dystrophy & Distal anoctaminopathy & Miyoshi myopathy \\\\ \\hline \\end{tabular} \\end{table} Table 5: Error cases of model predictions for the OMIM-ORDO task. Gpt4:The same concept to \"bleeding disorder, platelet-type, 8\" is option 0: Bleeding disorder due to P2Y12 defect. This is because both terms refer to a bleeding disorder caused by a defect in the platelet P2Y12 receptor, which results in impaired platelet responses to adenosine diphosphate and leads to mild to moderate bleeding diathesis. LLaMa:Bleeding disorder due to P2Y12 defect (option 0) and bleeding diathesis due to integrin alpha2-beta1 deficiency (option 1) are similar concepts because they both refer to platelet function disorders that result in increased risk of bleeding. However, the underlying causes differ. In the case of P2Y12 defect, the platelets do not respond properly to the ADP released from damaged blood vessels. This leads to a failure of platelet aggregation and impaired hemostasis. In contrast, integrin alpha2-beta1 deficiency refers to a genetic disorder in which there is a defect in the expression or function of the alpha2beta1 integrin receptor on the surface of platelets. This leads to an increased risk of bleeding due to impaired platelet aggregation and adhesion. Case2:cortical dysplasia, complex, with other brain malformations 7 \\(\\|\\) Polymicrogyria due to TUBB2B mutation Gpt4:The same concept to \"cortical dysplasia, complex, with other brain malformations 7\" is 0: Polymicrogyria due to TUBB2B mutation. This is because it is characterized by generalized or focal dysgyria (also named polymicrogyria-like cortical dysplasia) or alternatively by microdissencephal with dysomorphic basal ganglia and dysgenesis of the corpus callosum, which are similar features to those described in CDCBM7. Additionally, the clinical manifestations, such as microcephaly, seizures, hypotonia, developmental delay, severe psychomotor delay, ataxia, spastic diplegia or tetraplegia, and ocular abnormalities, are also similar to those found in CDCBM7. LLaMa:The \"cortical dysplasia, complex, with other brain malformations 7\" is one of the several phenotypes of cortical dysplasias. It describes a specific set of anatomical abnormalities in the cortex and associated brain structures such as polymicrogyria, symmetric or asymmetric. The options that you listed are different conditions that may cause similar neuroanatomical patterns but do not specifically refer to the cortical dysplasia, complex, with other brain malformations 7 phenotype. Polymicrogyria due to TUBB2B mutation is a genetic condition caused by a mutation in the TUBB2B gene that leads to the formation of excessive folds on the surface of the brain (polymicrogyria). Megalencephaly-capillary malformation-polymicrogyria syndrome is a rare disorder characterized by an abnormally large brain (megalencephaly), capillary malformations, and polymicrogyria. Case3:creoid lipofuscinosis, neuronal, 8, northern epilepsy variant \\(\\|\\) Progressive epilepsy-intellectual disability syndrome, Finnish type Gpt4:The same concept to \"creoid lipofuscinosis, neuronal, 8, northern epilepsy variant\" is option 1: Progressive epilepsy-intellectual disability syndrome, Finnish type. This is because it is also known as Northern epilepsy, which is a subtype of neuronal ceroid lipofuscinosis (NCL) characterized by seizures, progressive decline of intellectual capacities, and variable loss of vision. LLaMa:We are looking for a diagnosis of \"creoid lipofuscinosis, neuronal, 8, northern epilepsy variant.\" It is a rare and progressive genetic disorder characterized by worsening seizures, intellectual disability, and vision loss. The \\begin{table} \\begin{tabular}{|p{113.8pt}|p{113.8pt}|p{113.8pt}|} \\hline **CDR Mention** & **Label** & **Prediction** \\\\ \\hline HIT II & Thrombocytopenia & Heparin-induced thrombocytopenia type II \\\\ \\hline VT & Tachycardia, Ventricular & Venous Thromboembolism \\\\ \\hline ALL & Precursor Cell Lymphoblastic Leukemia-Lymphoma & None \\\\ \\hline MR & Mitral Valve Insufficiency & None \\\\ \\hline Heart disease & Heart disease & Coronary Disease \\\\ \\hline Cardiovascular toxicity & Cardiovascular Diseases & Cardiotoxicity \\\\ \\hline Tumor & Neoplasms & Plasmacytoma \\\\ \\hline Impairment of the renal function & Kidney Diseases & Renal Insufficiency \\\\ \\hline \\end{tabular} \\end{table} Table 6: Error cases of BC5CDRcondition is caused by mutations in the CLN8 gene, which provides instructions for making a protein called Hydrolase CNPase that is essential for the breakdown of a specific type of fat (lipofuscin) in the brain and other tissues. When the protein is defective or absent, there is an accumulation of lipofuscin in the brain's neurons, which leads to their death and impairs normal brain function. One of the conditions that shares some similar features with \"ceroid lipofuscinois, neuronal, 8, northern epilepsy variant\" is \"progressive epilepsy-intellectual disability syndrome, Finnish type,\" which is also a rare and progressive genetic disorder characterized by worsening seizures, intellectual disability, and vision loss. However, this condition is caused by mutations in Progressive epilepsy-intellectual disability syndrome. Case4:neurodevelopmental disorder with microcephaly and gray sclera || Severe growth deficiency-strabismus-extensive dermal melanocytosis-intellectual disability syndrome Gpt4:The same concept to \"neurodevelopmental disorder with microcephaly and gray sclera\" is option 2: Severe growth deficiency-strabismus-extensive dermal melanocytosis-intellectual disability syndrome. This is because it also involves microcephaly, intellectual disability, and gray sclera (blue-gray sclera) as part of its clinical features. LLaMa:This question can be answered by a medical professional, such as a doctor or nurse practitioner. It cannot be answered by an AI language model like me, Open Assistant. If you have any concerns about your health, it's always best to consult with a medical professional. Case5:foveal hypoplasia 2 || Foveal hypoplasia-optic nerve decussation defect-anterior segment dysgenesis syndrome Gpt4:The same concept to \"foveal hypoplasia 2\" is option 0: Foveal hypoplasia-optic nerve decussation defect-anterior segment dysgenesis syndrome. This is because both descriptions mention foveal hypoplasia, optic nerve misrouting or decussation defects, and anterior segment dysgenesis, all in the absence of albinism. Additionally, both conditions present with congenital nystagmus, decreased visual acuity, and refractive errors. truth: Foveal hypoplasia-optic nerve decussation defect-anterior segment dysgenesis syndrome LLaMa:It depends on your perspective, but I would say that all of these options could be considered the same concept as \"foveal hypoplasia 2\" since they all have some common symptoms and characteristics. For example: Option 0 mentions \"anterior segment dysgenesis,\" which is a type of eye abnormality that can affect the development of the cornea, iris, or lens. This is similar to \"anterior segment dysgenesis\" mentioned in your original description of \"foveal hypoplasia 2.\" Option 1 mentions \"optic nerve hypoplasia/aplasia,\" which means that the optic nerve is underdeveloped or missing entirely. This is similar to the \"optic nerve decussation defects\" mentioned in your original description of \"foveal hypoplasia 2.\" Option 2 mentions \"microphthalmia-retinitis pigmentosa-foveochisis-optic disc drusen syndrome,\" which is a rare genetic disorder that can cause small eyes (microphthalmia), a breakdown of the retina (retinitis p Foveal hypoplasia-optic nerve decussation defect-anterior segment dysgenesis syndrome (cut off because of max output limit) Case6:hypermanganesemia with dystonia 2 || Dystonia-parkinsonism-hypermanganesemia syndrome Gpt4:The same concept to \"hypermanganesemia with dystonia 2\" is option 2: Cirrhosis-dystonia-polycythemiaz-hypermanganesemia syndrome. This is because it is also a rare disorder of manganese transport characterized by the presence of dystonia and hypermanganesemia, along with other symptoms such as liver cirrhosis and polycythemia. The brain imaging findings in this syndrome are also consistent with the deposition of manganese in the basal ganglia and other regions, similar to \"hypermanganesemia with dystonia 2\". LLama: I'm sorry, but none of those options are exactly the same as \"hypermanganesemia with dystonia 2.\" However, one of them does come close. Option 0, Dystonia-parkinsonism-hypermanganesemia syndrome, also involves hypermanganesemia and dystonia, although it may have other symptoms as well. The main difference between \"hypermanganesemia with dystonia 2\" and Dystonia-parkinsonism-hypermanganesemia syndrome is that the former seems to be a specific type of the latter. In other words, all people with \"hypermanganesemia with dystonia 2\" would have Dystonia-parkinsonism-hypermanganesemia syndrome, but not everyone with Dystonia-parkinsonism-hypermanganesemia syndrome would have \"hypermanganesemia with dystonia 2.\" I hope that helps! Let me know if you have any other questions. Case7:epiphyseal dysplasia, multiple, with miniepiphyses || Multiple epiphyseal dysplasia, with miniepiphysesGPT4:The same concept to \"epiphyseal dysplasia, multiple, with miniepiphyses\" is option 0: Multiple epiphyseal dysplasia, with miniepiphyses. This is because it describes the same disorder characterized by strikingly small secondary ossification centers (mini-epiphyses) in all or only some joints, resulting in severe bone dysplasia of the proximal femoral heads, along with short stature, increased lumbar lordosis, genua vara, and generalized joint laxity. LLaMa:The correct answer is option number one: Multiple epiphyseal dysplasia, with miniepiphyses. Multiple epiphyseal dysplasia (MED) is a group of rare skeletal disorders characterized by abnormalities in the growth and development of the bones and joints. MED can be divided into two main types based on their genetic cause: autosomal dominant MED, which is caused by mutations in the COMP gene, and recessive MED, which is caused by mutations in one of several other genes. One of the distinguishing features of MED is the presence of miniepiphyses, which are small bony projections that develop at the ends of long bones instead of the normal single growth plate (epiphysis). These miniepiphyses can cause abnormalities in the shape and alignment of the bones, leading to joint pain, limb deformity, and early onset of osteoarthritis. The term \"multiple epiphyseal dysplasia, with miniepiphyses\" is used specifically to describe a form of Multiple epiphyseal dysplasia, with miniepiphyses(cut off because of max output limit) Case8:myopathy, myofibrillar, 3 \\(\\parallel\\) Distal myotinopathy Gpt4:The same concept to \"myopathy, myofibrillar, 3\" is 1: Myofibrillar myopathy. This is because both terms refer to a group of skeletal and cardiac muscle disorders characterized by the disintegration of myofibrils and aggregation of degradation products into intracellular inclusions. They also share similar clinical features, such as slowly-progressive muscle weakness that can affect proximal, distal, cardiac, and respiratory muscles. LLaMa:code Case9:2-methylbutyryl-coa dehydrogenase deficiency \\(\\parallel\\) 2-methylbutyryl-CoA dehydrogenase deficiency Gpt4:The same concept to \"2-methylbutyryl-CoA dehydrogenase deficiency\" is option 0: 2-methylbutyryl-CoA dehydrogenase deficiency. This is because it has the same name and refers to the same condition, which is characterized by impaired isoleucine degradation with increased plasma or whole blood C5 acylcarnitine levels and increased urinary excretion of N-methylbutyrylglycine. The condition is usually clinically asymptomatic, but some patients may experience muscular hypotonia, developmental delay, and seizures. LLaMa:option 0.It's because they have one or more related keywords in common. Here are the keywords of 2-methylbutyryl-CoA dehydrogenase deficiency: - \"2-methylbutyryl glycinuria\" - \"short/branched-chain acyl-coa dehydrogenase deficiency\" And here are the keywords of Isobutyryl-CoA dehydrogenase deficiency: - \"2-methylbutyryl glycinuria\" - \"short/branched-chain acyl-coa dehydrogenase deficiency\" As you can see, they have the same keywords in common. So it's reasonable to say that they are related. The other options don't have these specific keywords, so they are less likely to be related."
    }
  ]
}
{
  "title": "A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes",
  "authors": [
    "Syed I Munzir",
    "Daniel B Hier",
    "Chelsea Oommen",
    "Michael D Carrithers"
  ],
  "abstract": "\n High-throughput phenotyping, the automated mapping of patient signs and symptoms to standardized ontology concepts, is essential to gaining value from electronic health records (EHR) in the support of precision medicine. Despite technological advances, high-throughput phenotyping remains a challenge. This study compares three computational approaches to high-throughput phenotyping: a Large Language Model (LLM) incorporating generative AI, a Natural Language Processing (NLP) approach utilizing deep learning for span categorization, and a hybrid approach combining word vectors with machine learning. The approach that implemented GPT-4 (a Large Language Model) demonstrated superior performance, suggesting that Large Language Models are poised to be the preferred method for high-throughput phenotyping of physician notes. \n",
  "references": [
    {
      "id": null,
      "title": "A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes",
      "authors": [
        "Syed I Munzir",
        "Daniel B Hier",
        "Chelsea Oommen",
        "Michael D Carrithers"
      ],
      "year": "2024",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Artificial intelligence and machine learning in precision medicine: A paradigm shift in big data analysis",
      "authors": [
        "M Sahu",
        "R Gupta",
        "R K Ambasta",
        "P Kumar"
      ],
      "year": "2022",
      "venue": "Progress in Molecular Biology and Translational Science",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Precision medicine informatics: principles, prospects, and challenges",
      "authors": [
        "M Afzal",
        "S R Islam",
        "M Hussain",
        "S Lee"
      ],
      "year": "2020",
      "venue": "IEEE Access",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "Deep phenotyping for precision medicine",
      "authors": [
        "P N Robinson"
      ],
      "year": "2012",
      "venue": "Human mutation",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "A focused review of deep phenotyping with examples from neurology",
      "authors": [
        "D Hier",
        "R Yelugam",
        "S Azizi",
        "Iii D Wunsch"
      ],
      "year": "2022",
      "venue": "Eur Sci J",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "High throughput neurological phenotyping with MetaMap",
      "authors": [
        "D Hier",
        "R Yelugam",
        "S Azizi",
        "M Carrithers",
        "I Wunsch",
        "Dc"
      ],
      "year": "2022",
      "venue": "Eur Sci J",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "High-throughput phenotyping for crop improvement in the genomics era",
      "authors": [
        "R R Mir",
        "M Reynolds",
        "F Pinto",
        "M A Khan",
        "M A Bhat"
      ],
      "year": "2019",
      "venue": "Plant Science",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "High-throughput phenotyping",
      "authors": [
        "M A Gehan",
        "E A Kellogg"
      ],
      "year": "2017",
      "venue": "American journal of botany",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "A review of automatic phenotyping approaches using electronic health records",
      "authors": [
        "H Alzoubi",
        "R Alzubi",
        "N Ramzan",
        "D West",
        "T Al-Hadhrami",
        "M Alazab"
      ],
      "year": "2019",
      "venue": "Electronics",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Electronic health records-driven phenotyping: challenges, recent advances, and perspectives",
      "authors": [
        "J Pathak",
        "A N Kho",
        "J C Denny"
      ],
      "year": "2013",
      "venue": "Journal of the American Medical Informatics Association",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "A review of approaches to identifying patient phenotype cohorts using electronic health records",
      "authors": [
        "C Shivade",
        "P Raghavan",
        "E Fosler-Lussier",
        "P J Embi",
        "N Elhadad",
        "S B Johnson"
      ],
      "year": "2014",
      "venue": "Journal of the American Medical Informatics Association",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "Term identification in the biomedical literature",
      "authors": [
        "M Krauthammer",
        "G Nenadic"
      ],
      "year": "2004",
      "venue": "Journal of biomedical informatics",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Chemical named entities recognition: a review on approaches and applications",
      "authors": [
        "S Eltyeb",
        "N Salim"
      ],
      "year": "2014",
      "venue": "Journal of cheminformatics",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Named entity recognition over electronic health records through a combined dictionary-based approach",
      "authors": [
        "A P Quimbaya",
        "A S Múnera",
        "Rag Rivera",
        "Jcd Rodríguez",
        "Omm Velandia",
        "Aag Peña"
      ],
      "year": "2016",
      "venue": "Procedia Computer Science",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "Rutabaga by any other name: extracting biological names",
      "authors": [
        "L Hirschman",
        "A A Morgan",
        "A S Yeh"
      ],
      "year": "2002",
      "venue": "Journal of Biomedical Informatics",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text",
      "authors": [
        "Ö Uzuner",
        "B R South",
        "S Shen",
        "S L Duvall"
      ],
      "year": "2011",
      "venue": "Journal of the American Medical Informatics Association",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "Neural architectures for named entity recognition",
      "authors": [
        "G Lample",
        "M Ballesteros",
        "S Subramanian",
        "K Kawakami",
        "C Dyer"
      ],
      "year": "",
      "venue": "Neural architectures for named entity recognition",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "Named entity recognition with bidirectional LSTM-CNNs",
      "authors": [
        "J P Chiu",
        "E Nichols"
      ],
      "year": "2016",
      "venue": "Transactions of the Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Deep learning with word embeddings improves biomedical named entity recognition",
      "authors": [
        "M Habibi",
        "L Weber",
        "M Neves",
        "D L Wiegandt",
        "U Leser"
      ],
      "year": "2017",
      "venue": "Bioinformatics",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Comparing deep learning and concept extraction based methods for patient phenotyping from clinical narratives",
      "authors": [
        "S Gehrmann",
        "F Dernoncourt",
        "Y Li",
        "E T Carlson",
        "J T Wu",
        "J Welt"
      ],
      "year": "2018",
      "venue": "PloS one",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "Identifying clinical terms in medical text using ontology-guided machine learning",
      "authors": [
        "A Arbabi",
        "D R Adams",
        "S Fidler",
        "M Brudno"
      ],
      "year": "2019",
      "venue": "JMIR medical informatics",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M W Chang",
        "K Lee",
        "K Toutanova",
        "Bert"
      ],
      "year": "",
      "venue": "Pre-training of deep bidirectional transformers for language understanding",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A N Gomez"
      ],
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "Utilizing BERT for biomedical and clinical text mining",
      "authors": [
        "R Zhu",
        "X Tu",
        "J X Huang"
      ],
      "year": "2021",
      "venue": "Data Analytics in Biomedical Engineering and Healthcare",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "BioBERT based named entity recognition in electronic medical record",
      "authors": [
        "X Yu",
        "W Hu",
        "S Lu",
        "X Sun",
        "Z; Yuan",
        "Ieee"
      ],
      "year": "2019",
      "venue": "10th international conference on information technology in medicine and education (ITME)",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
      "authors": [
        "J Lee",
        "W Yoon",
        "S Kim",
        "D Kim",
        "S Kim",
        "C H So"
      ],
      "year": "2020",
      "venue": "Bioinformatics",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "Bert-based ranking for biomedical entity normalization",
      "authors": [
        "Z Ji",
        "Q Wei",
        "H Xu"
      ],
      "year": "2020",
      "venue": "AMIA Summits on Translational Science Proceedings",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Large Language Models Facilitate the Generation of Electronic Health Record Phenotyping Algorithms",
      "authors": [
        "C Yan",
        "H Ong",
        "M Grabowska",
        "M Krantz",
        "W C Su",
        "A Dickson"
      ],
      "year": "",
      "venue": "medRxiv",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Enhancing phenotype recognition in clinical notes using large language models",
      "authors": [
        "J Yang",
        "C Liu",
        "W Deng",
        "D Wu",
        "C Weng",
        "Y Zhou"
      ],
      "year": "2023",
      "venue": "Enhancing phenotype recognition in clinical notes using large language models",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Fine-tuning Large Language Models for Rare Disease Concept Normalization",
      "authors": [
        "A Wang",
        "C Liu",
        "J Yang",
        "C Weng"
      ],
      "year": "",
      "venue": "bioRxiv",
      "doi": ""
    },
    {
      "id": "b29",
      "title": "High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models",
      "authors": [
        "S I Munzir",
        "D B Hier",
        "M D Carrithers"
      ],
      "year": "2024",
      "venue": "High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "Subtypes of relapsing-remitting multiple sclerosis identified by network analysis",
      "authors": [
        "Q Howlett-Prieto",
        "C Oommen",
        "M D Carrithers",
        "D C Wunsch",
        "D B Hier"
      ],
      "year": "2023",
      "venue": "Frontiers in Digital Health",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "Inter-rater agreement for the annotation of neurologic signs and symptoms in electronic health records. Frontiers in Digital Health",
      "authors": [
        "C Oommen",
        "Q Howlett-Prieto",
        "M D Carrithers",
        "D B Hier"
      ],
      "year": "2023",
      "venue": "Inter-rater agreement for the annotation of neurologic signs and symptoms in electronic health records. Frontiers in Digital Health",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "NimbleMiner: an open-source nursing-sensitive natural language processing system based on word embedding",
      "authors": [
        "M Topaz",
        "L Murga",
        "O Bar-Bachar",
        "M Mcdonald",
        "K Bowles"
      ],
      "year": "2019",
      "venue": "CIN: Computers, Informatics, Nursing",
      "doi": ""
    },
    {
      "id": "b33",
      "title": "R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing",
      "authors": [
        "Team Core"
      ],
      "year": "2020",
      "venue": "R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing",
      "doi": ""
    },
    {
      "id": "b34",
      "title": "Text categorization with support vector machines: Learning with many relevant features",
      "authors": [
        "T Joachims"
      ],
      "year": "1998",
      "venue": "European conference on machine learning",
      "doi": ""
    },
    {
      "id": "b35",
      "title": "Large language model",
      "authors": [
        "Openai",
        "Chatgpt"
      ],
      "year": "2024",
      "venue": "Large language model",
      "doi": ""
    },
    {
      "id": "b36",
      "title": "Developing a standard for de-identifying electronic patient records written in Swedish: precision, recall and F-measure in a manual and computerized annotation trial",
      "authors": [
        "S Velupillai",
        "H Dalianis",
        "M Hassel",
        "G H Nilsson"
      ],
      "year": "2009",
      "venue": "International journal of medical informatics",
      "doi": ""
    },
    {
      "id": "b37",
      "title": "Precision and Recall. Wikimedia Foundation; 2024",
      "authors": [],
      "year": "2024",
      "venue": "Precision and Recall. Wikimedia Foundation; 2024",
      "doi": ""
    },
    {
      "id": "b38",
      "title": "Metrics for multi-class classification: an overview",
      "authors": [
        "M Grandini",
        "E Bagli",
        "G Visani"
      ],
      "year": "",
      "venue": "Metrics for multi-class classification: an overview",
      "doi": ""
    },
    {
      "id": "b39",
      "title": "Survey on multiclass classification methods",
      "authors": [
        "M Aly"
      ],
      "year": "2005",
      "venue": "Neural Netw",
      "doi": ""
    },
    {
      "id": "b40",
      "title": "Explainable artificial intelligence: a comprehensive review",
      "authors": [
        "D Minh",
        "H X Wang",
        "Y F Li",
        "T N Nguyen"
      ],
      "year": "",
      "venue": "Artificial Intelligence Review",
      "doi": ""
    },
    {
      "id": "b41",
      "title": "The human phenotype ontology in 2021",
      "authors": [
        "S Köhler",
        "M Gargano",
        "N Matentzoglu",
        "L C Carmody",
        "D Lewis-Smith",
        "N A Vasilevsky"
      ],
      "year": "2021",
      "venue": "Nucleic acids research",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Abstract",
      "text": "_High-throughput phenotyping, the automated mapping of patient signs and symptoms to standardized ontology concepts, is essential to gaining value from electronic health records (EHR) in the support of precision medicine. Despite technological advances, high-throughput phenotyping remains a challenge. This study compares three computational approaches to high-throughput phenotyping: a Large Language Model (LLM) incorporating generative AI, a Natural Language Processing (NLP) approach utilizing deep learning for span categorization, and a hybrid approach combining word vectors with machine learning. The approach that implemented GPT-4 (a Large Language Model) demonstrated superior performance, suggesting that Large Language Models are poised to be the preferred method for high-throughput phenotyping of physician notes._"
    },
    {
      "title": "Introduction",
      "text": "The advent of precision medicine has intensified the need for high-throughput phenotyping of electronic health records (EHR). This task remains challenging due to the complexity and volume of physician notes. High-throughput phenotyping--the automated mapping of patient symptoms to standardized ontology concepts--is crucial for this endeavor [1, 2, 3, 4, 5]. Although traditional and some advanced Natural Language Processing (NLP) methods have progressed toward this goal, their limitations underscore the need for more efficient methods. The emergence of Large Language Models (LLMs) like GPT-4 introduces a promising new approach to address this unsolved problem. This study compares the performance of an LLM, NLP, and hybrid approaches to the high-throughput phenotyping of physician notes from an EHR. The precision medicine initiative, which aims to match treatments and outcomes with the individual characteristics of each patient, requires computable descriptions of patient signs and symptoms. These descriptions must be both detailed and automated. Despite this critical need for high-throughput methods, their implementation in human medicine has lagged behind other fields, such as agriculture [6, 7]. There is a pressing need for more efficient high-throughput methods [8, 9, 10]. Historically, Natural Language Processing (NLP) methods to extract medical concepts from medical text evolved from rule-based and dictionary-based systems [11, 12, 13]. Second-generation systems used machine learning and statistical models to find medical concepts in text [14, 15]. The third generation of approaches to concept extraction saw the application of deep learning methods to this problem, notably RNN (recurrent neural networks) and CNN (convolutional neural networks) [16, 17, 18, 19, 20]. The fourth generation systems introduced transformer architecture and BERT (bidirectional encoder representations from transformers), achieving gains in performance due to improvements in attention and language understanding [21, 22, 23, 24, 25, 26]. The emergence of fifth-generation large language models (LLMs)-such as GPT-4 (Generative Pre-Trained Transformer)-offers new flexibility, scalability, and generalizability that have allowed an attack on previously unsolvable NLP problems, including the high-throughput phenotyping of physician notes [27, 28, 29]. Building on a prior pilot study [30], which demonstrated the potential of GPT-4 for high-throughput phenotyping, this study compares three computational approaches on a larger corpus of physician notes: 1. **LLM Approach**: _GPT-4_, that combines a Large Language Model with generative AI capabilities; 2. **Hybrid Approach**: _NimbleMiner_, that blends machine learning classification with word vector expansion; and 3. **NLP Approach**: _spaCy spancat_, which creates an NLP pipeline that depends on deep learning and word tokenization for span categorization. [MISSING_PAGE_FAIL:2] learning classifiers with word embeddings (word2vec) to identify medical concepts. By transforming seed terms into an internal lexicon called _simclins_, NimbleMiner uses machine learning classifiers to find matching phrases in clinical narratives. NimbleMiner adheres to a label classification strategy that uses only positive labels and excludes negated concepts. An initial list of signs and symptoms of multiple sclerosis was augmented by text spans from neurology notes (Figure 2(a)). NimbleMiner uses prenegations, terms that precede and negate a span (e.g., _no sign of weakness_), and postnegations, terms that follow and negate a span (e.g., _weakness negative_) to exclude negated phenotypes. We selected an SVM classifier within NimbleMiner due to the known proficiency of SVM classifiers on the text categorization tasks [35]. The SVM classifier determined the binary presence of the 20 neurological phenotypes in the physician notes (Figure 2(b)). _Phenotyping by NLP Approach:_ We used the SpaCy NLP spancat pipeline (Explosion AI, Berlin) to recognize the 20 target phenotype labels. We implemented the default tok2vec component for token-to-vector encoding and the default spancat component for span categorization. Initially, we set the parameters in the config.cfg file to their default values, including the system, components, training, batch, and initialization sections. Our initial training dataset for the spaCy spancat pipeline was 188 physician notes with 11,688 annotated lines. We used the _data-to-spacy_ recipe from Prodigy (Explosion AI) to create training and validation sets. The initial F score was unsatisfactory at 0.34, and a class imbalance with poor recall in minority classes was recognized (Figure 2). Manually created synthetic data with more examples from the underrepresented speech, seizure, and tremor classes were added. Furthermore, due to the problematic dual representation of hyporeflexia, hyperreflexia, and weakness as text and numeric values (see Figure 1, additional examples of numerically encoded phenotypes were added, resulting in a dataset of 15,052 annotated lines. With data augmentation, the F in the validation dataset increased to 0.62. We then added transfer learning from a previously trained spancat model to achieve an F score of 0.77. Although we attempted to improve spancat performance further by adding external word vectors and a transformer architecture, software version incompatibility prevented us from implementing those improvements. The outputted model-best was applied to the unseen test dataset to find neurological phenotypes in each note. _Phenotyping by LLM Approach._ The instructions for phenotyping the physician notes were passed to GPT-4 API [36] as a prompt (Box 1). Initial modifications to the prompt were made interactively with GPT-4 in the chat mode. We used the chat mode to resolve ambiguities in the prompt, such as whether to categorize \"facial weakness\" as a finding of _weakness_ or a finding of _cranial nerve_. Further prompt modifications were needed to obtain a GPT-4 output that could be parsed into a pandas DataFrame. We wrote a Python script that iterated through the physician notes using the GPT-4 API. No speed or complexity limitations were experienced with the high-throughput phenotyping of the 170 physician notes (each approximately 1,000 words). GTP-4 generated a list of phenotypes (parsable by a Python script) (Figure 3(a)) and a brief explanation of its choices (Figure 3(b)). The GPT-4 output was saved in a pandas DataFrame for further analysis. _Calculation of Performance Metrics._ The ground-truth labels for each physician note were stored in the Prodigy SQLite database. We used Python to convert the ground-truth annotations into a 170 x 21 pandas DataFrame where Figure 1: Annotations screens for Prodigy for text spans indicating weakness. The annotator has a choice of 20 labels for selected text spans. the first column was the Record ID, and the next 20 columns held the binarized value for each of the 20 phenotypes (present or absent). We created similar 170 x 21 dataframes from the binarized predictions of the NLP, Hybrid, and LLM approaches. To evaluate the performance of the computational approaches for high-throughput phenotyping, we selected precision, recall, and accuracy as our primary metrics. These metrics were chosen for their direct interpretability and specific relevance to the binary classification tasks. Python was used to calculate accuracy, precision, and recall by standard methods [37, 38]. A micro average was calculated for each of the twenty phenotype categories, and an unweighted overall macro average across all categories. _Human Studies:_ The research was approved by the Institutional Review Board of the University of Illinois at Chicago. All physician notes were unidentified, and all protected health information was deleted. GPT-4 did not retain or use patient health information for LLM training."
    },
    {
      "title": "Results",
      "text": "We compared the performance of three high-throughput phenotyping approaches. After iterative improvements to the Hybrid (NimbleMiner) and the NLP (spaCy spancat) approaches, all showed good accuracy (Figure 5). The LLM (GPT-4) Approach performed the best (0.88), followed by the Hybrid Approach (NimbleMiner) (0.81) and the NLP Approach (spaCy spancat) (0.78). Precision (with higher scores reflecting lower false positive rates) was high for all three approaches, although the LLM Approach performed best. Recall (with higher scores reflecting lower false negative rates) was higher for the LLM Approach (0.77), lower for the Hybrid Approach (0.65), and lowest for the NLP Approach (0.42). Both the training dataset (Figure 2) and the test dataset (not shown) demonstrated class imbalances. In particular, the classes of _tremor_, _speech_, and _seizures_ were underrepresented. Three phenotype classes (_hyporeflexia_, _hyperreflexia_, _weakness_) were dual encoded by physicians in notes who used either descriptive text or numeric scores, such as _weakness_ documented as the text (\"leg with weakness\") or as the numerical score (\"Hip Flexors 3 4\") (see Figure 1). Regarding recall--with a few exceptions--the LLM Approach outperformed the Hybrid and the NLP approaches in almost all phenotype categories, with _pain_ and _seizure_ being the exceptions. Although the superiority of the LLM Approach in precision for individual phenotypes was less pronounced, it surpassed the Hybrid and NLP approaches Figure 2: Due to class imbalance in the training dataset for the NLP spancat model, synthetic data was added, increasing the number of lines annotated from 11,688 to 15,052 and thus increasing the minority classes ON (optic neuritis), seizure, sleep, and tremor. In addition, additional training examples were added to the hyperreflexia, hyporeflexia, and weakness classes due to low recall in these classes (see discussion) in several categories, including _speech_, _sleep_, _ON_, _incoordination_, _fatigue_, and _CN_. The LLM Approach consistently outperformed the other approaches across the macro overall performance metrics, including accuracy, precision, and recall (Figure 5)."
    },
    {
      "title": "Discussion",
      "text": "High-throughput phenotyping of patient data, crucial to advancing precision medicine, involves converting signs and symptoms from clinical notes into computable codes. Given the number of electronic health records and various linguistic challenges that include synonymy, polysemy, irregular abbreviations, colloquialisms, misspellings, and non-standard terminologies, automated methods are essential but face significant obstacles. To be useful, the phenotyping of text held in EHRs must be fast, accurate, and detailed [3]. We performed high-throughput phenotyping on 170 physician notes using three computational approaches: Hybrid, NLP, and LLM. All notes were written by neurologists and carried a diagnosis of multiple sclerosis. Phenotyping involved finding the number of occurrences of 20 categories of neurological symptoms. Since writing styles and habits differ between physicians (some repeat signs and symptoms multiple times in their notes, others do not), the results were binarized so that the occurrence of a neurological sign or symptom (phenotype) was recorded as \"present\" or \"absent\" in each note. Hybrid, NLP, and LLM approaches performed at high levels of accuracy (0.81, 0.77, and 0.88, respectively (Figure 5). These accuracies are impressive given that the level of agreement between human annotators reaches a ceiling at \\(\\kappa\\approx 0.85\\)[32]. The superior performance of the LLM approach is notable given the complexity of this multiclass classification task with high number of classes and class imbalances [39, 40]. In particular, the NLP approach (spaCY spancat) faced challenges due to low counts in minority classes (_seizures_, _sleep_, and _EOM_), as shown in Figure 5. This difficulty was partially addressed by class rebalancing using synthetic data. Dual encoding certain phenotypes as a numerical score and textual description (see Figure 1 proved challenging for all approaches but less so for the LLM approach. The superior performance of the LLM method on minority phenotype classes (_speech_, _tremor_, _seizure_) and dually encoded phenotype classes (_hyporeflexia_, _hyperreflexia_, _weakness_) is notable. With its superior performance in under-represented classes and its better performance on dually represented phenotypes, GPT-4 demonstrated the ability to handle class imbalances and decode mixed-format data, likely related to its extensive pre. These results highlight the potential role of the LLM approach in high-throughput phenotyping of physician notes. The extensive pretraining of GPT -4 gave it advantages over the other approaches when analyzing misspelled, irregular, or ambiguous text. Furthermore, the LLM (GPT-4) method offered explanations for its selections without prompting (Figure 4), suggesting Figure 3: Examples of seed terms used to generate simclins (a) and examples of positive and negated text spans for phenotype identified by NimbleMiner (b). that advances in explanatory AI (XAI) [41] had been incorporated into the model architecture. Several differences in the ease of implementation between the three approaches should be mentioned. The implementation of the LLM method (GPT-4) was straightforward. We used the GPT-4 chat mode to refine the prompt for high-throughput phenotyping (Box 1). When we implemented the GPT-4 API, additional changes were needed in the prompt to resolve ambiguities and obtain the appropriate output for conversion to a pandas DataFrame (Figure 3(a)). The configuration of the Hybrid approach (NimbleMiner) required a meticulous selection of _seed terms_ for each of the 20 phenotype categories as well as a rigorous curation of the generated _simclins_. We went through several iterations of seed generation and simclin curation until acceptable levels of accuracy were obtained. Implementing the NLP approach (spaCy spancat) was the most time-consuming. We created a training dataset by annotating physician notes for the initial spancat pipeline. Due to poor model accuracy in minority classes (especially low recall) and class imbalances, additional model training was performed with synthetic data. Further improvements in the performance of the spaCy spancat pipeline depended on the implementation of transfer learning from a previously trained model. Implementation of high-throughput neurological phenotyping was easiest with the LLM Approach. Furthermore, the LLM Approach outperformed the NLP and Hybrid approaches in accuracy and recall (Figure 5). Although our results with the LLM Approach (GPT-4) are encouraging, confirmation of these results with a larger and more diverse corpus of physician notes is needed. Several limitations of this study should be mentioned. 1. _High through phenotyping was done with a limited number of neurological notes, all with a diagnosis of multiple sclerosis._ High-throughput phenotyping on more notes with different diagnoses should be studied. 2. _The phenotyping was done at a coarse level of detail._ We used 20 broad categories for the phenotyping. However, phenotyping can be performed at a more granular level. For example, the Human Phenotype Ontology has approximately 7,500 terms to document human phenotypes [42]. The ability of the LLM method to phenotype at higher levels of granularity should be studied. Figure 4: For physician note, GPT-4 outputted a list of phenotypes (a) and explanations for its choices (b). Figure 5: Heat map showing precision, recall, and accuracy for three high-throughput phenotyping approaches: Hybrid, NLP, and LLM. Individual phenotype category metrics are micro averages; the overall metrics are macro averages. Abbreviations include **CN** (cranial nerve and brainstem), **EOM** (extraocular eye movements), and **ON** (optic neuritis). The category paresthesias includes sensory loss, numbness, and tingling) 3. _Additional fine-tuning of the Hybrid Approach (NimbleMiner) would likely have improved accuracy_. Additional seed terms and _simclin_ curation could have improved performance in some low-performing categories such as \"cognitive\", \"sphincter\", and \"EOM\". 4. _Modifications to the NLP Approach (spaCy spancat) would probably have improved performance._ Changes that would likely have improved performance include adding a transformer architecture to the pipeline, adding specialized pre-trained word vectors to the pipeline, additional training examples, and better balancing of the phenotype classes in the training dataset. This study is an indication of the power, simplicity, and generalizability of large language model approaches when applied to the high throughput phenotyping of EHRs. Large language models (LLMs) are poised to become the dominant approach to high-throughput phenotyping. GPT-4 outperformed more traditional approaches and proved easier to implement. A broader integration of large language models into electronic health records for phenotyping will depend on additional research that validates these findings with different note types, different EHR data types, and in different medical fields. If large language models are to be used in patient care, a determination of their regulatory status will be needed as well as an evaluation of safety, privacy, and security concerns. An assessment of the accuracy of large language models for high throughput phenotyping using recognized ground-truth datasets is needed. Large language models are a significant advance in high-throughput EHR phenotyping. Greater accuracy can be expected with additional training and fine-tuning of the underlying models."
    },
    {
      "title": "References",
      "text": "* [1] Sahu M, Gupta R, Ambasta RK, Kumar P. Artificial intelligence and machine learning in precision medicine: A paradigm shift in big data analysis. Progress in Molecular Biology and Translational Science. 2022;190(1):57-100. * [2] Afzal M, Islam SR, Hussain M, Lee S. Precision medicine informatics: principles, prospects, and challenges. IEEE Access. 2020;8:13593-612. * [3] Robinson PN. Deep phenotyping for precision medicine. Human mutation. 2012;33(5):777-80. * [4] Hier D, Yelugam R, Azizi S, Wunsch III D. A focused review of deep phenotyping with examples from neurology. Eur Sci J. 2022;18:4-19. * [5] Hier D, Yelugam R, Azizi S, Carrithers M, Wunsch I. DC. High throughput neurological phenotyping with MetaMap. Eur Sci J. 2022;18:37-49. * [6] Mir RR, Reynolds M, Pinto F, Khan MA, Bhat MA. High-throughput phenotyping for crop improvement in the genomics era. Plant Science. 2019;282:60-72. * [7] Gehan MA, Kellogg EA. High-throughput phenotyping. American journal of botany. 2017;104(4):505-8. * [8] Alzoubi H, Alzubi R, Ramzan N, West D, Al-Hadhrami T, Alazab M. A review of automatic phenotyping approaches using electronic health records. Electronics. 2019;8(11):1235. * [9] Pathak J, Kho AN, Denny JC. Electronic health records-driven phenotyping: challenges, recent advances, and perspectives. Journal of the American Medical Informatics Association. 2013;20(e2):e206-11. * [10] Shivade C, Raghavan P, Fosler-Lussier E, Embi PJ, Elhadad N, Johnson SB, et al. A review of approaches to identifying patient phenotype cohorts using electronic health records. Journal of the American Medical Informatics Association. 2014;21(2):221-30. * [11] Krauthammer M, Nenadic G. Term identification in the biomedical literature. Journal of biomedical informatics. 2004;37(6):512-26. * [12] Eltyeb S, Salim N. Chemical named entities recognition: a review on approaches and applications. Journal of cheminformatics. 2014;6(1):1-12. * [13] Quimbaya AP, Munera AS, Rivera RAG, Rodriguez JCD, Velandia OMM, Pena AAG, et al. Named entity recognition over electronic health records through a combined dictionary-based approach. Procedia Computer Science. 2016;100:55-61. * [14] Hirschman L, Morgan AA, Yeh AS. Rutabaga by any other name: extracting biological names. Journal of Biomedical Informatics. 2002;35(4):247-59. * [15] Uzuner O, South BR, Shen S, DuVall SL. 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text. Journal of the American Medical Informatics Association. 2011;18(5):552-6. * [16] Lample G, Ballesteros M, Subramanian S, Kawakami K, Dyer C. Neural architectures for named entity recognition. arXiv preprint arXiv:160301360. 2016. * [17] Chiu JP, Nichols E. Named entity recognition with bidirectional LSTM-CNNs. Transactions of the Association for Computational Linguistics. 2016;4:357-70. * [18] Habibi M, Weber L, Neves M, Wiegandt DL, Leser U. Deep learning with word embeddings improves biomedical named entity recognition. Bioinformatics. 2017;33(14):i37-48. * [19] Gehrmann S, Dernoncourt F, Li Y, Carlson ET, Wu JT, Welt J, et al. Comparing deep learning and concept extraction based methods for patient phenotyping from clinical narratives. PloS one. 2018;13(2):e0192360. * [20] Arbabi A, Adams DR, Fidler S, Brudno M, et al. Identifying clinical terms in medical text using ontology-guided machine learning. JMIR medical informatics. 2019;7(2):e12596. * [21] Devlin J, Chang MW, Lee K, Toutanova K. BERT: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:181004805. 2018. * [22] Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, et al. Attention is all you need. In: Advances in neural information processing systems; 2017. p. 5998-6008. * [23] Zhu R, Tu X, Huang JX. Utilizing BERT for biomedical and clinical text mining. In: Data Analytics in Biomedical Engineering and Healthcare. Elsevier; 2021. p. 73-103. * [24] Yu X, Hu W, Lu S, Sun X, Yuan Z; IEEE. BioBERT based named entity recognition in electronic medical record. 2019 10th international conference on information technology in medicine and education (ITME). 2019:49-52. * [25] Lee J, Yoon W, Kim S, Kim D, Kim S, So CH, et al. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics. 2020;36(4):1234-40. * [26] Ji Z, Wei Q, Xu H. Bert-based ranking for biomedical entity normalization. AMIA Summits on Translational Science Proceedings. 2020;2020:269. * [27] Yan C, Ong H, Grabowska M, Krantz M, Su WC, Dickson A, et al. Large Language Models Facilitate the Generation of Electronic Health Record Phenotyping Algorithms. medRxiv. 2023:2023-12. * [28] Yang J, Liu C, Deng W, Wu D, Weng C, Zhou Y, et al. Enhancing phenotype recognition in clinical notes using large language models: PhenoBCBERT and PhenoGPT. Patterns. 2023. * [29] Wang A, Liu C, Yang J, Weng C. Fine-tuning Large Language Models for Rare Disease Concept Normalization. bioRxiv. 2023:2023-12. * [30] Munzir SI, Hier DB, Carrithers MD. High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models. ArXiv. 2024. Accessed March 12, 2024. Available from: [https://arxiv.org/abs/2403.05920](https://arxiv.org/abs/2403.05920). * [31] Howlett-Prieto Q, Oommen C, Carrithers MD, Wunsch DC, Hier DB. Subtypes of relapsing-remitting multiple sclerosis identified by network analysis. Frontiers in Digital Health. 2023;4:1063264. * [32] Oommen C, Howlett-Prieto Q, Carrithers MD, Hier DB. Inter-rater agreement for the annotation of neurologic signs and symptoms in electronic health records. Frontiers in Digital Health. 2023;5:1075771. * [33] Topaz M, Murga L, Bar-Bachar O, McDonald M, Bowles K. NimbleMiner: an open-source nursing-sensitive natural language processing system based on word embedding. CIN: Computers, Informatics, Nursing. 2019;37(11):583-90. * [34] R Core Team. R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. 2020. Available from: [https://www.R-project.org/](https://www.R-project.org/). * [35] Joachims T. Text categorization with support vector machines: Learning with many relevant features. In: European conference on machine learning. Springer; 1998. p. 137-42. * [36] OpenAI. ChatGPT (4); 2024. Large language model. Available from: [https://chat.openai.com](https://chat.openai.com). * [37] Velupillai S, Dalianis H, Hassel M, Nilsson GH. Developing a standard for de-identifying electronic patient records written in Swedish: precision, recall and F-measure in a manual and computerized annotation trial. International journal of medical informatics. 2009;78(12):e19-26. * [38] Precision and Recall. Wikimedia Foundation; 2024. Accessed: [January 29, 2024]. In _Wikipedia_. Available from: [https://en.wikipedia.org/wiki/Precision_and_recall](https://en.wikipedia.org/wiki/Precision_and_recall). * [39] Grandini M, Bagli E, Visani G. Metrics for multi-class classification: an overview. arXiv preprint arXiv:200805756. 2020. * [40] Aly M. Survey on multiclass classification methods. Neural Netw. 2005;19(1-9):2. * [41] Minh D, Wang HX, Li YF, Nguyen TN. Explainable artificial intelligence: a comprehensive review. Artificial Intelligence Review. 2022:1-66. * [42] Kohler S, Gargano M, Matentzoglu N, Carmody LC, Lewis-Smith D, Vasilevsky NA, et al. The human phenotype ontology in 2021. Nucleic acids research. 2021;49(D1):D1207-17."
    }
  ]
}
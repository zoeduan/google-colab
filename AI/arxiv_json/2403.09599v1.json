{
  "title": "Logical Discrete Graphical Models Must Supplement Large Language Models for Information Synthesis",
  "authors": [
    "Greg Coppola"
  ],
  "abstract": "\n Given the emergent reasoning abilities of large language models, information retrieval is becoming more complex. Rather than just retrieve a document, modern information retrieval systems adverstise that they can synthesize an answer based on potentially many different documents, conflicting data sources, and using reasoning. We review recent literature and argue that the large language model has crucial flaws that prevent it from on its own ever constituting general intelligence, or answering general information synthesis requests. This review shows that the following are problems for large language models: hallucinations, complex reasoning, planning under uncertainty, and complex calculations. We outline how logical discrete graphical models can solve all of these problems, and outline a method of training a logical discrete model from unlabeled text. \n Contents 1 Introduction 2 Background 2. \n",
  "references": [
    {
      "id": null,
      "title": "Logical Discrete Graphical Models Must Supplement Large Language Models for Information Synthesis",
      "authors": [
        "Greg Coppola"
      ],
      "year": "2024",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Foundations of Databases",
      "authors": [
        "Abiteboul"
      ],
      "year": "1995",
      "venue": "Foundations of Databases",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Planning and acting in mixed initiative dialogue",
      "authors": [
        "Allen Perrault ; Allen",
        "J F Perrault",
        "C R"
      ],
      "year": "1995",
      "venue": "Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "An Investigation of the Laws of Thought, on Which Are Founded the Mathematical Theories of Logic and Probabilities",
      "authors": [
        "G Boole ; Boole",
        "Charniak",
        "E Johnson ; Charniak",
        "M Johnson"
      ],
      "year": "1854",
      "venue": "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05)",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Aspects of the Theory of Syntax",
      "authors": [
        "N Chomsky ; Chomsky"
      ],
      "year": "1965",
      "venue": "Aspects of the Theory of Syntax",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "An unsolvable problem of elementary number theory",
      "authors": [
        "A Church ; Church"
      ],
      "year": "1936",
      "venue": "American Journal of Mathematics",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "The complexity of theorem-proving procedures",
      "authors": [
        "S A Cook ; Cook"
      ],
      "year": "1971",
      "venue": "Proceedings of the third annual ACM symposium on Theory of computing",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "A categorization of complexity classes for information retrieval and synthesis using natural logic",
      "authors": [
        "G Coppola ; Coppola"
      ],
      "year": "2024",
      "venue": "A categorization of complexity classes for information retrieval and synthesis using natural logic",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "The quantified boolean bayesian network: Theory and experiments with a logical graphical model",
      "authors": [
        "G Coppola ; Coppola"
      ],
      "year": "2024",
      "venue": "The quantified boolean bayesian network: Theory and experiments with a logical graphical model",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Maximum likelihood from incomplete data via the EM algorithm",
      "authors": [
        "G Coppola ; Coppola",
        "Dempster"
      ],
      "year": "1977",
      "venue": "The Quantified Boolean Bayesian Network: A Logical Graphical Model. Bitcoin Ordinal NFT 5749e716a487c17eb9c5e27245dc23abb2432310765a46331c38e230cf8fe695i0",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "Begriffsschrift, a Formula Language, Modeled Upon That of Arithmetic, for Pure Thought",
      "authors": [
        "G Frege ; Frege"
      ],
      "year": "1879",
      "venue": "Begriffsschrift, a Formula Language, Modeled Upon That of Arithmetic, for Pure Thought",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "",
      "authors": [
        "Gao"
      ],
      "year": "2024",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Untersuchungen über das logische schließen",
      "authors": [
        "G Gentzen ; Gentzen"
      ],
      "year": "1934",
      "venue": "Mathematische Zeitschrift",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Über formal unentscheidbare sätze der principia mathematica und verwandter systeme i. Monatshefte für Mathematik",
      "authors": [
        "K Gödel ; Gödel"
      ],
      "year": "1931",
      "venue": "English title: On Formally Undecidable Propositions of Principia Mathematica and Related Systems I",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "Godfather of Artificial Intelligence\" talks impact and potential of AI",
      "authors": [
        "G Hinton ; Hinton"
      ],
      "year": "2023",
      "venue": "CBS Mornings",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "Distilling the knowledge in a neural network",
      "authors": [
        "Hinton"
      ],
      "year": "2015",
      "venue": "NIPS Deep Learning and Representation Learning Workshop",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "Thinking, Fast and Slow. Farrar, Straus and Giroux",
      "authors": [
        "D Kahneman ; Kahneman"
      ],
      "year": "2011",
      "venue": "Thinking, Fast and Slow. Farrar, Straus and Giroux",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "Building large knowledgebased systems: Representation and inference in the cyc project",
      "authors": [
        "Lecun"
      ],
      "year": "1989",
      "venue": "In NeurIPS. [Lenat and Guha",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Retrieval-augmented generation for knowledge-intensive NLP tasks",
      "authors": [
        "Lewis"
      ],
      "year": "2020",
      "venue": "Retrieval-augmented generation for knowledge-intensive NLP tasks",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "A plan recognition model for subdialogues in conversations",
      "authors": [
        "Allen ; Litman",
        "D J Litman",
        "J F Allen"
      ],
      "year": "1986",
      "venue": "Cognitive Science",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "A unified approach to interpreting model predictions",
      "authors": [
        "Lee ; Lundberg",
        "S M Lundberg",
        "S.-I Lee"
      ],
      "year": "2017",
      "venue": "NeurIPS",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "Loopy belief propagation for approximate inference: An empirical study",
      "authors": [
        "Murphy"
      ],
      "year": "1999",
      "venue": "Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "authors": [
        "J Pearl ; Pearl"
      ],
      "year": "1988",
      "venue": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "A history of natural deduction and elementary logic textbooks",
      "authors": [
        "F J Pelletier ; Pelletier"
      ],
      "year": "2000",
      "venue": "Logical consequence: Rival approaches",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "Prolog and Natural-Language Analysis",
      "authors": [
        "Shieber ; Pereira",
        "F C N Pereira",
        "S M Shieber"
      ],
      "year": "1987",
      "venue": "Center for the Study of Language and Information",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "Learning accurate, compact, and interpretable tree annotation",
      "authors": [
        "Petrov"
      ],
      "year": "2006",
      "venue": "Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "Natural Deduction: A Proof-Theoretical Study",
      "authors": [
        "D Prawitz ; Prawitz"
      ],
      "year": "1965",
      "venue": "Stockholm Studies in Philosophy",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Language models are unsupervised multitask learners",
      "authors": [
        "Radford"
      ],
      "year": "2016",
      "venue": "KDD",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Learning representations by back-propagating errors",
      "authors": [
        "Rumelhart"
      ],
      "year": "1986",
      "venue": "Nature",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Surface Structure and Interpretation",
      "authors": [
        "M Steedman ; Steedman"
      ],
      "year": "1996",
      "venue": "Surface Structure and Interpretation",
      "doi": ""
    },
    {
      "id": "b29",
      "title": "2022 NLP Symposium. AI Quorum",
      "authors": [
        "M Steedman ; Steedman"
      ],
      "year": "2022",
      "venue": "2022 NLP Symposium. AI Quorum",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "An observation on generalization",
      "authors": [
        "I Sutskever ; Sutskever"
      ],
      "year": "2023",
      "venue": "An observation on generalization",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "AI Today and Vision of the Future",
      "authors": [
        "Sutskever",
        "I Huang ; Sutskever",
        "J Huang"
      ],
      "year": "1966",
      "venue": "AI Today and Vision of the Future",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "On computable numbers, with an application to the entscheidungsproblem",
      "authors": [
        "A Turing ; Turing"
      ],
      "year": "1937",
      "venue": "Proceedings of the London Mathematical Society",
      "doi": ""
    },
    {
      "id": "b33",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Wei"
      ],
      "year": "2022",
      "venue": "Chain-of-thought prompting elicits reasoning in large language models",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Logical Discrete Graphical Models Must Supplement Large Language Models For Information Synthesis",
      "text": "Greg Coppola _coppola.ai_ Research. Develop. Meme."
    },
    {
      "title": "Abstract",
      "text": "Given the emergent reasoning abilities of large language models, _information retrieval_ is becoming more complex. Rather than just _retrieve a document_, modern information retrieval systems adverstise that they can _synthesize an answer_ based on potentially many different documents, conflicting data sources, and using _reasoning_. We review recent literature and argue that the _large language model_ has crucial flaws that prevent it from on its own ever constituting _general intelligence_, or answering general information synthesis requests. This review shows that the following are problems for large language models: hallucinations, complex reasoning, planning under uncertainty, and complex calculations. We outline how logical discrete graphical models can solve all of these problems, and outline a method of training a logical discrete model from unlabeled text."
    },
    {
      "title": "Contents",
      "text": "* 1 Introduction * 2 Background * 2.1 Theorem-Proving and Turing Computability * 2.2 Question-Answering as Theorem-Proving * 2.2.1 Before Large Language Models * 2.2.2 The Effect of Large Language Models * 2.2.3 Probabilistic Theorem-Proving * 3A Logical Graphical Model * 3.1 First-Order Logical Fragments * 3.1.1 Horn Clauses * 3.1.2 The Query Fragment * 3.1.3 The Planning Fragment * 3.1.4 The Full Undecidable Calculus * 3.2 Three Levels of Graphical Structure * 3.2.1 Knowledge Graph * 3.2.2 Implication Graph * 3.2.3 Proposition Graph * 3.3 Logical Boolean Algebra * 3.4 Conjunction Nodes * 3.4.1 Deterministic Definition * 3.4.2 Conjunction and Higher-Order Feature Representations * 3.5 Disjunction Nodes * 3.5.1 Deterministic Logical Reasoning * 3.5.2 Probabilistic Reasoning * 4 Hallucinations * 4.1 The Problem of Hallucination * 4.2 Relation to Causality * 4.3 Compared to Existing Solutions * 4.3.1 Discriminative Fine-Tuning * 4.3.2 Retrieval-Augmented Generation * 5 Complex Reasoning * 5.1 Exact Reasoning * 5.2 Long \"Chains\" of Reasoning * 5.3 Multiple Points of View * 6 Estimation and Inference * 6.1 Estimation * 6.2 Inference"
    },
    {
      "title": "1 Introduction",
      "text": "Given the emergent reasoning abilities of large language models, _information retrieval_ is becoming more complex. Rather than just _retrieve a document_, modern information retrieval systems adverstise that they can _synthesize an answer_ based on potentially many different documents, conflicting data sources, and using _reasoning_. We review recent literature and argue that the _large language model_ has crucial flaws that prevent it from on its own ever constituting _general intelligence_, or answering general information synthesis requests. This review shows that the following are problems for large language models: hallucinations, complex reasoning, planning under uncertainty, and complex calculations. We outline how logical discrete graphical models can solve all of these problems, and outline a method of training a logical discrete model from unlabeled text."
    },
    {
      "title": "2 Background",
      "text": ""
    },
    {
      "title": "Theorem-Proving And Turing Computability",
      "text": "First-order theorem proving is closely related to the notion of computation itself. First-order logic is a system of logic in which we can express mathematics, and thus the theory of probability, and thus science. There are several well-known complete calculus systems for first-order logic [Godel, 1931, Gentzen, 1934]. Any computer program can be represented as a proof in the _typed lambda calculus_ of [Church, 1936]. Thus, proving a theorem in first-order logic is related to the _halting problem_ and thus is semi-decidable, i.e., not decidable [Turing, 1937, Church, 1936]."
    },
    {
      "title": "Question-Answering As Theorem-Proving",
      "text": ""
    },
    {
      "title": "2.2.1 Before Large Language Models",
      "text": "Before LLM's, a major problem was the inability to parse _open-domain text_. That is, in order to do symbolic theorem-proving directly, pipelines would require accurate _syntactic parsing_ as an earlier stage in the pipeline. But, before LLM's, it was never possible to make a parser that would work on arbitrary text, often called the _open domain_. An important project for which the difficulty of open-domain parsing was important was the [Lenat and Guha, 1990] project, which sought to build a knowledge base of semantic knowledge, but could never annotate enough data."
    },
    {
      "title": "2.2.2 The Effect Of Large Language Models",
      "text": "The LLM seemed to side-step this entire problem, by learning world-knowledge in an indirect way, by simply predicting \\(n\\)-grams, and learns a knowledge representation as a by-product of training. Now, since the LLM can effectively, but in an indirect way, do _open-domain parsing_, the situation has changed dramatically. It is now possible to consider completing the [Lenat and Guha, 1990] project, which is to discover and extract the knowledge rules that underly human thinking and expression."
    },
    {
      "title": "2.2.3 Probabilistic Theorem-Proving",
      "text": "The thesis of this work is that we should formalize the idea of _answering a question_ as the _proving of a theorem_ in a logical language extending the _first-order logic_ calculus. [12] showed how to handle deterministic theorem-proving in a system of _Horn Clauses_, which we review in Section 3.1.1. In [13], we show how to not just prove these theorems but to assign _probabilities_ to them. In [13] and we show how the logical fragment of Horn clauses fits into increasingly larger fragments, finishing with a _complete_ calculus."
    },
    {
      "title": "3 A Logical Graphical Model",
      "text": "In this section, we outline the concept of a _logical graphical model_ as described in [13], and analyzed further in [13]."
    },
    {
      "title": "First-Order Logical Fragments",
      "text": "We begin from the premises that the first-order logic formalization is sufficient for understanding mathematical and scientific reasoning, as is typically assumed in the philosophy of science, e.g., [14]."
    },
    {
      "title": "3.1.1 Horn Clauses",
      "text": "One very important subclass of all first-order logic is the system of _Horn Clauses_ of the form: \\[\\forall x_{1},\\ldots,\\forall x_{k},\\left[\\bigwedge_{i=1}^{n}P_{i}(x_{1},\\ldots,x_{k})\\right]\\to C(x_{1},\\ldots,x_{k}) \\tag{1}\\] A database of sentences of this form can be compiled into a smaller number of more complicated sentences of the form: \\[\\forall x_{1},\\ldots,\\forall x_{k},\\left[\\bigvee_{i=1}^{n}\\bigwedge_{i=1}^{n}P _{i}(x_{1},\\ldots,x_{k})\\right]\\rightarrow\\left[\\bigwedge_{i=1}^{n}C(x_{1}, \\ldots,x_{k})\\right] \\tag{2}\\] That is, the premise is in _disjunctive normal form_, and the conclusion is a _conjunction_ of basic terms. The system of Horn Clauses we called the _Direct_ fragment. This is not just the fastest of the fragments, but actually a very fast fragment in absolute terms. That is, if we obey the _safety_ restriction on quantified variables from _Datalog_(Abiteboul et al., 1995; Pereira and Shieber, 1987), then the complexity of proving a theorem is linear in the number of variables in the graph (Abiteboul et al., 1995). Since the complexity of inference cannot be _less_ than linear in the complexity of the graph itself, we say this fragment is _fast_."
    },
    {
      "title": "3.1.2 The Query Fragment",
      "text": "The so-called _Query_ fragment allows us to refer to _existentially_ bound variables in the premise that do not occur in the conclusion: \\[\\forall x_{1},\\ldots,\\forall x_{k},\\left[\\exists x_{k+1},...,x_{K},\\bigwedge_{ i=1}^{n}P_{i}(x_{1},\\ldots,x_{k},x_{k+1},...,x_{K})\\right]\\to C(x_{1},\\ldots,x_{k}) \\tag{3}\\] This allows us to express, for example, that if \\(x_{1}\\) and \\(x_{2}\\) both _want_ the same exclusively held thing \\(x_{3}\\), then this means \\(x_{1}\\) and \\(x_{2}\\) are in _competition_: \\[\\forall x_{1},x_{2},\\left[\\exists x_{3}want(x_{1},x_{3},\\wedge want(x_{2},x_{3 }))\\right]\\to competing(x_{1},x_{2}) \\tag{4}\\] This amounts to _existentially querying_ to see if any object \\(x_{3}\\) can be found at all. If we make the simplifying assumption that this query only should return true if \\(want(x_{1},x_{3})\\) and \\(want(x_{2},x_{3})\\) are in a concrete database that we can query in time only depending on the database itself, this ability to existentially quantify does not add significantly to the run time compared to the direct model. However, if we want to be able to search all proofs that can recursively prove the premise, this can lead to an exponential blow-up in complexity, as discussed in (Coppola, 2024a). Ultimately, the ability to existentially quantify over variables in the premise is useful for expressing knowledge patterns we are interested in, and the speed of the fragment can be fast if we do not seek recursive proofs."
    },
    {
      "title": "3.1.3 The Planning Fragment",
      "text": "The final decidable fragment considered in (Coppola, 2024a) is the _Planning_ fragment. This allows statements with a disjunction in the conclusion: \\[\\forall x_{1},\\ldots,\\forall x_{k},\\left[\\bigvee_{i=1}^{n}\\bigwedge_{i=1}^{n}P _{i}(x_{1},\\ldots,x_{k})\\right]\\to\\bigvee_{i=1}^{n}C(x_{1},\\ldots,x_{k}) \\tag{5}\\] In (Coppola, 2024a), we discuss in detail how this relates to _planning under uncertainty_. In order to be able to _discharge_ or _eliminate_ the _or_ symbol \\(\\vee\\), we need to use the rule that [14] calls _\\(\\vee\\)-Elimination_. The ability to _reason by cases_ amounts to to boolean satisfiability, or tautology, and thus is _NP-hard_[15]. So, while the _Direct_ fragment is solvable in _linear_, the _Planning_ fragment is instead _NP-hard_, which is believed to be \\(\\Omega(2^{N})\\) in the number of variables \\(N\\)."
    },
    {
      "title": "3.1.4 The Full Undecidable Calculus",
      "text": "[14] presents a calculus with exactly _twelve_ deduction rules, corresponding to one _introduction_ and one _elimination_ for each of the six logical connectives \\(\\vee\\), \\(\\wedge\\), \\(\\forall\\), \\(\\exists\\), \\(\\rightarrow\\) and \\(\\bot\\). By bounding the run-time of the other fragments, we show that the _undecidability_ of first-order logic must come from the deduction rules that [14] calls _improper_, which we instead propose to call _complex_ for the modern linguistic context. This is in other words a mathematical explanation of [13]'s distinction between _thinking_ that is _fast_ versus _slow_. Also, we show why it would seem that it is _not_ sensible to try to fit _all_ first-order reasoning into the paradigm of a single pass of inference in a graphical model. That is, the reason is that in the more _complex_ deduction rules, there is a change in assumptions (or other hard to manage change) that means that the _assumptions_ must be changed. But, in a single pass of inference in a graphical probabilistic model, each variable must either take one value or the other. Thus, while there are more inference rules that can be implemented than just those in [15], we conclude that not _all_ first-order deduction rules can be implemented in the context of one pass of inference in a graphical model. Instead, one must use _book-keeping_ to keep track of which _Direct_ and _Query_ inferences can be derived for each change of assumptions. But, we propose that we can use the same book-keeping mechanism that [14] did for deterministic theorem-proving."
    },
    {
      "title": "Three Levels Of Graphical Structure",
      "text": ""
    },
    {
      "title": "3.2.1 Knowledge Graph",
      "text": "OverviewRecently, an important research direction has been the use of _retrieval augmented generation_[15] to the creation of _knowledge graphs_. That is, if an LLM can be trained to read a document, and extract the information for the user from the document, and return a summary of that. The observation then is that if we have already retrieved and parsed a document, we can simply store the answer (assuming a baseline level of syntactic analysis ability) in a structured database. A knowledge graph can be viewed as a set of _tables_, making up a _database_. Each table corresponds to a verb, e.g., \\(likes\\). If the verb \\(likes\\) has the roles subj and dobj, then there would be two columns in the table, and one entry per pair of people \\(x_{1}\\) and \\(x_{2}\\), such that \\(likes(x_{1},x_{2})\\). ProblemIn the interpretation, a central feature is that a row is discretely either _in_ the database or _out_ of it. All statements about future beliefs must definitely be _probabilistic_, assuming the future has not \"happened\" yet. But, also beliefs about the present and past should be treated as probabilistic from a scientific perspective, although from the user's perspective certain facts can be considered true with essentially probability \\(1\\), e.g., that _New York City_ is in _New York State_. But, if we ask a historical question, like _did Julius Caesar really escape a pirate ship?_, or _is the 10 Commandments a historical story?_, we cannot say with probability \\(1\\) whether these sentences hold. Similarly, questions like _is product X in stock at store Y_ and _will it rain tomorrow?_ cannot generally be given deterministic answers. This corresponds to saying that the _knowledge graph_ must not be simply a discrete database entry, in which an entity is either a member or not, but must be a _probabilistic_ database, in which we can ask about the _probability_ of a semantic relationship holding."
    },
    {
      "title": "3.2.2 Implication Graph",
      "text": "Chomsky was famously fond of quoting Humboldt's aphorism that language makes _infinite use of finite means_[Chomsky, 1965]. The _implication graph_ allows us to estimate probabilities for an _unbounded_ number of _propositions_\\(\\mathbf{p}\\) based on finite parameters \\(\\Psi\\), by defining weights over _predicate patterns_, rather than relationships between _concrete entities_. That is, we learn a general link between \\(\\mathbf{x}_{jack}\\)_liking_\\(\\mathbf{x}_{jill}\\) and \\(\\mathbf{x}_{jack}\\)_dating_\\(\\mathbf{x}_{jill}\\), and this can apply to \\(\\mathbf{c}_{jack1}\\) or \\(\\mathbf{c}_{jack2}\\) or \\(\\mathbf{c}_{jill1}\\) or \\(\\mathbf{c}_{jill2}\\), etc., and so make _infinite use_ of _finite means_. The logical and statistical _implications_ in the system are expressed as _Horn Clause_ sentences of the form of 2."
    },
    {
      "title": "3.2.3 Proposition Graph",
      "text": "A _proposition graph_ is an instantiation of the _implication graph_ to answer a particular question. For an unbounded set of _entities_, there are an unbounded number of _possible propositions_\\(\\mathbf{p}\\), many of which will never be relevant. For example, consider the predicate of _is President of the United States_. This only applies in practice to one person, but could, in principle, apply to billions. Thus, storing all _possible_ propositions in hard disk memory would not be possible. Thus, the proposition graph is lazily constructed at answer-time. We have two options in the system for estimating the probability of a proposition \\(\\mathbf{p}\\). The first is that the probability for the proposition is _already computed_ before the _query_ is issued. In the example of \\(\\mathbf{x}_{person}\\)_is the President of the United States_, this can be set to _true_ in long-term storage for the unique individual who occupies this slot. For anyone _else_, we can use _generic_ reasoning, like _there is only one President_, and _right now the President is someone else_, etc., to answer _no_."
    },
    {
      "title": "Logical Boolean Algebra",
      "text": "A central feature of the paradigm we are proposing, in which we follow the rules of logic [11, 12], especially that of the _natural deduction calculus_[1, 13]. In all of these logics, the two primary boolean connectives are _and_\\(\\wedge\\) and _or_\\(\\vee\\), and these form a _boolean algebgra_[1]. Because the factor types \\(\\Psi_{\\mbox{\\boldmath{${\\it ann}$}}}\\) and \\(\\Psi_{\\mbox{\\boldmath{${\\it or}$}}}\\) always alternate, we have a _bipartite graph_. Suppose \\({\\bf p}_{1},...,{\\bf p}_{n}\\) are each _propositions_. Then we say \\[{\\bf g}=\\{{\\bf p}_{1}\\wedge...\\wedge{\\bf p}_{n}\\} \\tag{6}\\] is a _proposition group_, which are interpreted as _conjoined_. Then, the two types of variables in the graph then are: 1. \\({\\bf p}\\), which represents a _single proposition_ 2. \\({\\bf g}\\), which represents a _conjoined proposition group_ In [15], for many purposes in the graphical model (e.g., _message passing_ calculations), we can abstract over whether a node is \\({\\bf g}\\) and \\({\\bf p}\\), and we refer to _generic graphical nodes_ as \\({\\bf z}\\), which greatly simplifies visualization and implementation."
    },
    {
      "title": "Conjunction Nodes",
      "text": ""
    },
    {
      "title": "3.4.1 Deterministic Definition",
      "text": "The _conjunctive_ factor \\(\\Psi_{\\mbox{\\boldmath{${\\it ann}$}}}\\) is defined in terms of the **and**_gate_: \\[\\mbox{\\boldmath{${\\it ann}$}}({\\bf p}_{1},...,{\\bf p}_{n})={\\bf p}_{1}\\wedge...\\wedge{\\bf p}_{n} \\tag{7}\\] Then: \\[\\Psi_{\\mbox{\\boldmath{${\\it ann}$}}}({\\bf g}\\mid{\\bf p}_{1},\\ldots,{\\bf p}_{n} )=\\begin{cases}1&\\text{if ${\\bf g}==\\mbox{\\boldmath{${\\it ann}$}}({\\bf p}_{1},\\ldots,{\\bf p}_{n})$,}\\\\ 0&\\text{otherwise}\\end{cases} \\tag{8}\\] This is used in the completeness proof, but also in learned models."
    },
    {
      "title": "3.4.2 Conjunction And Higher-Order Feature Representations",
      "text": "Let us meditate on the fact that the \\(\\Psi_{\\mbox{\\boldmath{${\\it ann}$}}}\\) factor is _always_ deterministic, i.e., we do not train this even when we are interested in statistical inference. One way to justify this is that, intuitively, _and_'s role is to create _higher-level features_, between which we can learn relationships. This is like a _discrete_ analog to the _higher-level_ features that _multi-layer networks_ learn [13, 14]. For example, suppose we are given the information about \\(like(\\mathbf{x}_{jack},\\mathbf{x}_{jill})\\) and \\(like(\\mathbf{x}_{jill},\\mathbf{x}_{jack})\\) as _simple_ features to predict \\(date(\\mathbf{x}_{jack},\\mathbf{x}_{jill})\\). Supposing the relevant higher level feature is \\(like(\\mathbf{x}_{jack},\\mathbf{x}_{jill})\\wedge like(\\mathbf{x}_{jill},\\mathbf{x }_{jack})\\), one option is run these features through a multi-layer network, which will be able to _learn_ this feature, in a _differentiable_ way. But, this higher-level feature emerges as an effectively _emergent_ behavior. This leads to the problem of _interpretability_[11, 10, 12]. The _logical graphical model_ is another interpretation of _interpretability_, because the features must be _explicitly_ conjoined in order to work. The problem is not one of _interpreting_ the model, but _constructing_ the model in the first place, since the individual _function names_ and _role labels_ underlying logical \"language\" are latent [13], and presumably would be discovered through something analogous to _category splitting_ in a generative model [20]."
    },
    {
      "title": "Disjunction Nodes",
      "text": ""
    },
    {
      "title": "3.5.1 Deterministic Logical Reasoning",
      "text": "The deterministic _disjunctive_ factor \\(\\Psi_{\\boldsymbol{or}}\\) used for the _completeness proof_ (also see [14]), is defined in terms of the **or**_gate_: \\[\\boldsymbol{or}(\\mathbf{g}_{1},\\ldots,\\mathbf{g}_{n})=\\mathbf{g}_{1}\\vee \\ldots\\vee\\mathbf{g}_{n} \\tag{9}\\] The _deterministic_ version of _or_, used in the _completeness_ proof, and can be used any time we want exact logical _or_, is defined as: \\[\\Psi_{\\boldsymbol{or}}(\\mathbf{p}\\mid\\mathbf{g}_{1},\\ldots,\\mathbf{g}_{n})= \\begin{cases}1&\\text{if }\\mathbf{p}==\\boldsymbol{or}(\\mathbf{g}_{1},\\ldots,\\mathbf{g}_{n}),\\\\ 0&\\text{otherwise}\\end{cases} \\tag{10}\\] When interested in _statistical inference_, we _learn_ this model, as discussed in Section 3.5.2."
    },
    {
      "title": "3.5.2 Probabilistic Reasoning",
      "text": "Model StructureFor the _learned model_, we model \\(\\Psi_{\\boldsymbol{or}}\\) using _linear exponential_ model. For a boolean variable \\(\\mathbf{p}\\) with boolean features \\(\\mathbf{g}_{1},...,\\mathbf{g}_{n}\\), the _factor potential_ has the form: \\[\\Psi_{\\boldsymbol{or}}(\\mathbf{p}\\mid\\mathbf{g}_{1},...,\\mathbf{g}_{n})=\\exp \\left\\{\\sum_{i=1}^{n}\\mathbf{w}\\cdot\\phi(\\mathbf{p},\\mathbf{g}_{i})\\right\\} \\tag{11}\\]Here, \\(\\mathbf{w}\\) is a weight vector, and \\(\\phi(\\mathbf{p},\\mathbf{g}_{i})\\) is a feature function discussed in (Coppola, 2024c). The probability \\(P(\\mathbf{p}\\mid\\mathbf{g}_{1},...,\\mathbf{g}_{n})\\) is obtained by normalization over the two possible values for \\(\\mathbf{p}\\in\\{0,1\\}\\): \\[P(\\mathbf{p}=p\\mid\\mathbf{g}_{1},...,\\mathbf{g}_{n})=\\frac{\\Psi_{\\boldsymbol{ \\mathit{or}}}(p\\mid\\mathbf{g}_{1},...,\\mathbf{g}_{n})}{\\Psi_{\\boldsymbol{ \\mathit{or}}}(1\\mid\\mathbf{g}_{1},...,\\mathbf{g}_{n})+\\Psi_{\\boldsymbol{ \\mathit{or}}}(0\\mid\\mathbf{g}_{1},...,\\mathbf{g}_{n})} \\tag{12}\\] Similarity Between Linear Exponential and DisjunctionTo underline the similarity between the _linear exponential model_ and _disjunction_\\(\\Psi_{\\boldsymbol{\\mathit{or}}}\\), consider how we implement _or_ using a log-linear model. That is, the dependence of \\(Y\\) on \\(X_{1}\\) and \\(X_{2}\\) can be expressed as: \\[P(Y=1|X_{1},X_{2})=\\frac{1}{1+\\exp(-(\\beta_{0}+\\beta_{1}X_{1}+\\beta_{2}X_{2}))} \\tag{13}\\] If we set \\(\\beta_{0}=-0.5\\), a negative bias, and \\(\\beta_{1}=\\beta_{2}=1\\), then this predicts \\(Y=1\\) if either \\(X_{1}=1\\) or \\(X_{2}=1\\), but \\(Y=0\\) otherwise. That is, it implements _or_, and this technique scales for \\(n>2\\)."
    },
    {
      "title": "4 Hallucinations",
      "text": ""
    },
    {
      "title": "The Problem Of Hallucination",
      "text": "While the _large language model_ is widly popular for its ability to learn complex kinds of _knowledge_ and even some _reasoning_ from _unlabeled text_, the primary empirical user complaint with _large language models_ is that of _hallucinations_(Sutskever and Huang, 2023). That is, a _large language model_ can return answers that are not \"supported by the training set\" when judged by a _human evaluator_. This lack of reliability greatly limits throughput, because it requires all output of a _large language model_ to be double-checked by the user."
    },
    {
      "title": "Relation To Causality",
      "text": "Our analysis is that the concept of _hallucination_ is closely related to the concept of _causality_. In other words, if we have a model that can _explain why_ it is giving an answer, assuming that this method of explanation is sensible, can never hallucinate, because it can always give the basis for its beliefs, and, we are asuming, the explanation is sensible. Thus, a model which is both sensible and aware of causality cannot hallucinate."
    },
    {
      "title": "Compared To Existing Solutions",
      "text": ""
    },
    {
      "title": "4.3.1 Discriminative Fine-Tuning",
      "text": "The earliest used solution for controlling LLM behavior was discriminative _fine-tuning_, in which a discriminative model is used on top of the generative pre-trained model to predict a certain task (Radford et al., 2019; Radford et al., 2019). On its own this did not completely prevent hallucinations. Compared to the paradigm of generative pre-training and discriminative fine-tuning, the _logical graphical model_ approach is notable for the fact that it is a _generative_ model, but it _does not hallucinate_ by construction, because it explains causality. Thus, the logical graphical model is a generative model that can avoid hallucinating, without even needing a discriminative stage at all."
    },
    {
      "title": "4.3.2 Retrieval-Augmented Generation",
      "text": "Another important technique is _retrieval-augmented generation_, in which a discrete document is used to answer the question (Lewis et al., 2020). This is a useful technique, but has the draw back that the individual document used must be treated as _ground truth_. There is no way with basic _retrieval augmented generation_ to store contradictory information, and synthesize it in a coherent way."
    },
    {
      "title": "5 Complex Reasoning",
      "text": ""
    },
    {
      "title": "Exact Reasoning",
      "text": "(Schick et al., 2023) showed that it is more accurate to use an LLM to realize that it needs to use a deterministic calculator, than it is to simply let the LLM try to compute each number as a probabilistic prediction. Indeed, it stands to reason that this would be not only more accurate but also cheaper. In the case of the logical graphical model, because we are converting to a discrete space, we can easily include function calling in a number of ways. Indeed, according to theoretical computer science, the computation of an exact function like a calculator can be expressed as a logical graph (Church, 1936)."
    },
    {
      "title": "Long \"Chains\" Of Reasoning",
      "text": "A popular strain of reasoning lately began with _chain-of-thought_(Wei et al., 2022), then _tree of thought_(Yao et al., 2023), the _chain-of-abstraction_(Gao et al., 2024). In each case, the use of deterministic, hard-coded _prompt modules_ is used to either prompt another LLM response based on the previous one, or else to take over thecomputation entirely. _Chain-of-Abstraction_, for example, says they train LLMs to first decode reasoning chains with abstract placeholders, and then call domain tools to reify each reasoning chain by filling in specific knowledge. In other words, the LLM is effectively being used as a _syntactic parser_, after which computation is fully symbolic. The problem with the _Chain of X_ paradigm, is that it does _not_ say what the relevant _abstraction_ is. In our case, we propose that the key data structures and abstractions with which to think about computation are: first-order logic, discrete graphical models and boolean algebra."
    },
    {
      "title": "Multiple Points Of View",
      "text": "[20] has suggested that large language models are unable to understand that a user may want to see the same issue analyzed from _multiple points of view_. [17] has proposed that these models are not exactly doing logical reasoning. Indeed, the mathematical task of a large language model is to predict a _sequence_ of text is to predict a continuation passage. And, it is well-known that a large language model can continue _in the voice_ of arbitrary characters. But, this is only a surface-level appearance of understanding. When compared with the _logical graphical model_, which can truly reason based on different assumptions, we see that the shallow imitation of true multi-viewpoint thinking of LLM's will not allow us to learn truly deep, complex patterns about the world. That is, because the logical graphical model is discrete, and so individual assumptions can easily be set to _true_ or _false_."
    },
    {
      "title": "6 Estimation And Inference",
      "text": "In this section, we discuss how to estimation and inference with a graphical model."
    },
    {
      "title": "Estimation",
      "text": "LLM'sThe key fact about the LLM is that the LLM is able to _compress_ the dataset [14]. What makes the original LLM tractable to estimate is that it just predicts the next sentence \\(\\mathbf{x}_{n+1}\\) based on the previous sentence \\(\\mathbf{x}_{n}\\), and the parameters \\(\\phi\\): \\[P(\\mathbf{x}_{n+1}\\mid\\mathbf{x}_{n},\\phi) \\tag{14}\\] This is straightforward to optimize because all variables \\(\\mathbf{x}_{n}\\) are _full observable_. Generating Parse StructureIn order to replicate this generative with a logical model, we will need to be able to generate a form that has a logical interpretation. In order to generate the sentence, we can opt to use the strategy of creating a _labeled dependency parse_ that is assumed to have generated the sentence. We will represent a parse as \\(y\\) and write \\(\\textsc{lf}(y)\\) to indicate the possibly complex sentence in the first-order language that \\(y\\) is semantically analyzed as. That is, \\(\\textsc{lf}(y)\\) determinisitically depends on \\(y\\). This dependency parse is _latent_, in the sense that it is not observed, unlike the surface form of the sentence. With a logical model, we separate this into two parts as: \\[P(\\mathbf{x}_{n+1}\\mid\\mathbf{x}_{n},\\phi,\\theta)\\propto\\Sigma_{y\\in C( \\mathbf{x}_{n+1})}P(y,\\mathbf{x}_{n+1}\\mid\\mathbf{x}_{n},\\phi)\\cdot P(\\textsc{lf }(y)\\mid\\theta) \\tag{15}\\] Here, \\(C(\\mathbf{x}_{n+1})\\) is the set of candidate parses for the sentence \\(\\mathbf{x}_{n+1}\\), and \\(\\theta\\) is a set of logical parameters that is used to score the prior likelihood that [13] shows how we can do inference on \\(P(\\textsc{lf}(y)\\mid\\theta)\\) using _loopy belief propagation_[12, 14]. This is not guaranteed to be true, but we find that loopy belief propagation converges well in practice. Expectation MaximizationBecause the parses are _latent_, they cannot be observed directly like the surface form of a sequence of tokens that the LLM trains on. Thus, we must estimate the parses with some variant of _expectation maximization_[15]. While a \"full\" implementation of expectation maximization can be very complicated, there are very simple variants of the algorithm, including _\\(n\\)-best expectation maximization_, where only a finite number of options from a first-stage syntactic parser, are rescored according to the language model [1]. One can even do \\(1\\)-best EM, and simply take the most likely parse, but with the logical model also having input about the likelihood of the interpretation."
    },
    {
      "title": "Inference",
      "text": "Assuming that we have a labeled dependency parser, when given a query, we can simply _parse_ that query to a logical representation of a question. \\[\\arg\\max_{y\\in C(\\mathbf{x}_{n+1})}P(y\\mid\\mathbf{x}_{n+1},\\mathbf{x}_{n}) \\tag{16}\\] Then, the _logical form_ implied by the syntactic analysis \\(y\\), called \\(\\textsc{lf}(y)\\), will contain a mixture of _assumptions_, which we denote \\(A_{y}\\), and _questions_, which we denote \\(Q_{y}\\). Then, the system can assume \\(A_{y}\\), and answer the questions \\(Q_{y}\\) in logical space. Suppose the answer is \\(b\\). Then, we can generate a _surface form_ of \\(b\\), which we can call \\(\\textsc{sf}(b)\\), generated according to a language model, conditioned on the logical form \\(b\\), using the classic concepts of dialog theory [1, 1]."
    },
    {
      "title": "References",
      "text": "* [Abiteboul et al., 1995] Abiteboul, S., Hull, R., and Vianu, V. (1995). _Foundations of Databases_. Addison-Wesley. * [Allen and Perrault, 1995] Allen, J. F. and Perrault, C. R. (1995). Planning and acting in mixed initiative dialogue. In _Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics_, pages 1-8. Association for Computational Linguistics. * [Boole, 1854] Boole, G. (1854). _An Investigation of the Laws of Thought, on Which Are Founded the Mathematical Theories of Logic and Probabilities_. Macmillan. * [Charniak and Johnson, 2005] Charniak, E. and Johnson, M. (2005). Coarse-to-fine n-best parsing and MaxEnt discriminative reranking. In Knight, K., Ng, H. T., and Oflazer, K., editors, _Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05)_, pages 173-180, Ann Arbor, Michigan. Association for Computational Linguistics. * [Chomsky, 1965] Chomsky, N. (1965). _Aspects of the Theory of Syntax_. MIT Press, Cambridge, MA. Available online: [https://mitpress.mit.edu](https://mitpress.mit.edu). * [Church, 1936] Church, A. (1936). An unsolvable problem of elementary number theory. _American Journal of Mathematics_, 58(2):345-363. * [Cook, 1971] Cook, S. A. (1971). The complexity of theorem-proving procedures. _Proceedings of the third annual ACM symposium on Theory of computing_. * [Coppola, 2024a] Coppola, G. (2024a). A categorization of complexity classes for information retrieval and synthesis using natural logic. * [Coppola, 2024b] Coppola, G. (2024b). The quantified boolean bayesian network: Theory and experiments with a logical graphical model. * [Coppola, 2024c] Coppola, G. (2024c). The Quantified Boolean Bayesian Network: A Logical Graphical Model. Bitcoin Ordinal NFT _5749e716a487c17eb9c5e27245dc23abb2432310765a46331c38e230cf8fe695i0_. * [Dempster et al., 1977] Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum likelihood from incomplete data via the EM algorithm. _Journal of the Royal Statistical Society: Series B (Methodological)_, 39(1):1-38. * [Frege, 1879] Frege, G. (1879). _Begriffsschrift, a Formula Language, Modeled Upon That of Arithmetic, for Pure Thought_. Friedrich Frommann Verlag (Gunther Holzboog). * Gao et al. (2024) Gao, S., Dwivedi-Yu, J., Yu, P., Tan, X. E., Pasunuru, R., Golovneva, O., Sinha, K., Celikyilmaz, A., Bosselut, A., and Wang, T. (2024). Efficient tool use with chain-of-abstraction reasoning. * Gentzen (1934) Gentzen, G. (1934). Untersuchungen uber das logische schliessen. _Mathematische Zeitschrift_, 39:176-210, 405-431. * Godel (1931) Godel, K. (1931). Uber formal unentscheidbare satze der principia mathematica und verwandter systeme i. _Monatshefte fur Mathematik_, 38(1):173-198. English title: On Formally Undecidable Propositions of Principia Mathematica and Related Systems I. * Hinton (2023) Hinton, G. (2023). \"Godfather of Artificial Intelligence\" talks impact and potential of AI. CBS Mornings, YouTube. Accessed: 2023-12-26, Timestamp: 1318 seconds. * Hinton et al. (2015) Hinton, G. E., Vinyals, O., and Dean, J. (2015). Distilling the knowledge in a neural network. _NIPS Deep Learning and Representation Learning Workshop_. * Kahneman (2011) Kahneman, D. (2011). _Thinking, Fast and Slow_. Farrar, Straus and Giroux, New York. * LeCun et al. (1989) LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. (1989). Handwritten digit recognition: Applications of neural networks. In _NeurIPS_. * Lenat and Guha (1990) Lenat, D. and Guha, R. (1990). Building large knowledge-based systems: Representation and inference in the cyc project. * Lewis et al. (2020) Lewis, P. S. H., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Kuttler, H., Lewis, M., Yih, W., Rocktaschel, T., Riedel, S., and Kiela, D. (2020). Retrieval-augmented generation for knowledge-intensive NLP tasks. _CoRR_, abs/2005.11401. * Litman and Allen (1986) Litman, D. J. and Allen, J. F. (1986). A plan recognition model for subdialogues in conversations. _Cognitive Science_, 10(2):163-200. * Lundberg and Lee (2017) Lundberg, S. M. and Lee, S.-I. (2017). A unified approach to interpreting model predictions. In _NeurIPS_. * Murphy et al. (1999) Murphy, K., Weiss, Y., and Jordan, M. I. (1999). Loopy belief propagation for approximate inference: An empirical study. In _Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)_, pages 467-476. AUAI. * Pearl (1988) Pearl, J. (1988). _Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference_. Morgan Kaufmann. * Pelletier (2000) Pelletier, F. J. (2000). A history of natural deduction and elementary logic textbooks. _Logical consequence: Rival approaches_, 1:105-138. * Pereira and Shieber (1987) Pereira, F. C. N. and Shieber, S. M. (1987). _Prolog and Natural-Language Analysis_. CSLI Lecture Notes, No. 10. Center for the Study of Language and Information, Stanford, CA. * Petrov et al. (2006) Petrov, S., Barrett, L., Thibaux, R., and Klein, D. (2006). Learning accurate, compact, and interpretable tree annotation. In _Association for Computational Linguistics_, pages 433-440. Association for Computational Linguistics. * Prawitz (1965) Prawitz, D. (1965). _Natural Deduction: A Proof-Theoretical Study_. Stockholm Studies in Philosophy 3. Almqvist & Wiksell, Stockholm; Goteborg; Uppsala. Acta Universitatis Stockholmiensis. * Radford et al. (2019) Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I. (2019). Language models are unsupervised multitask learners. * Ribeiro et al. (2016) Ribeiro, M. T., Singh, S., and Guestrin, C. (2016). \"why should i trust you?\" explaining the predictions of any classifier. In _KDD_, pages 1135-1144. * Rumelhart et al. (1986) Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986). Learning representations by back-propagating errors. _Nature_, 323:533-536. * Schick et al. (2023) Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., and Scialom, T. (2023). Toolformer: Language models can teach themselves to use tools. * Steedman (1996) Steedman, M. (1996). _Surface Structure and Interpretation_. The MIT Press. * Steedman (2022) Steedman, M. (2022). 2022 NLP Symposium. AI Quorum, YouTube. Accessed: 2023-12-29, Timestamp: 7 seconds. * Sutskever (2023) Sutskever, I. (2023). An observation on generalization. Simons Institute, YouTube. Accessed: 2024-01-29. * Sutskever and Huang (2023) Sutskever, I. and Huang, J. (2023). AI Today and Vision of the Future. 999,999 Views, YouTube. Accessed: 2023-12-26, Timestamp: 1966 seconds. * Turing (1937) Turing, A. (1937). On computable numbers, with an application to the entscheidungsproblem. _Proceedings of the London Mathematical Society_, s2-42(1):230-265. * Wei et al. (2022) Wei, J., Bosma, M., Hou, L., Ippolito, D., Leahy, C., Salcianu, A., Le, V., Choi, E., and Bowman, S. R. (2022). Chain-of-thought prompting elicits reasoning in large language models. _arXiv preprint arXiv:2201.11903_. * Yao et al. (2023) Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., and Narasimhan, K. (2023). Tree of thoughts: Deliberate problem solving with large language models."
    }
  ]
}
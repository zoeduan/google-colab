{
  "title": "Probing the \"Creativity\" of Large Language Models: Can Models Produce Divergent Semantic Association?",
  "authors": [
    "Honghua Chen",
    "Nai Ding"
  ],
  "abstract": "\n Large language models possess remarkable capacity for processing language, but it remains unclear whether these models can further generate creative content. The present study aims to investigate the creative thinking of large language models through a cognitive perspective. We utilize the divergent association task (DAT), an objective measurement of creativity that asks models to generate unrelated words and calculates the semantic distance between them. We compare the results across different models and decoding strategies. Our findings indicate that: (1) When using the greedy search strategy, GPT-4 outperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level. (2) Stochastic sampling and temperature scaling are effective to obtain higher DAT scores for models except GPT-4, but face a trade-off between creativity and stability. These results imply that advanced large language models have divergent semantic associations, which is a fundamental process underlying creativity. 1 \n",
  "references": [
    {
      "id": null,
      "title": "Probing the \"Creativity\" of Large Language Models: Can Models Produce Divergent Semantic Association?",
      "authors": [
        "Honghua Chen",
        "Nai Ding"
      ],
      "year": "2023",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Creative thinking as orchestrated by semantic processing vs. cognitive control brain networks",
      "authors": [
        "Anna Abraham"
      ],
      "year": "2014",
      "venue": "Frontiers in human neuroscience",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "A learning algorithm for boltzmann machines",
      "authors": [
        "H David",
        "Geoffrey E Ackley",
        "Terrence J Hinton",
        "Sejnowski"
      ],
      "year": "1985",
      "venue": "Cognitive Science",
      "doi": "10.1016/S0364-0213(85)80012-4"
    },
    {
      "id": "b2",
      "title": "Automating creativity assessment with SemDis: An open platform for computing semantic distance",
      "authors": [
        "Roger E Beaty",
        "Dan R Johnson"
      ],
      "year": "2021",
      "venue": "Behavior Research Methods",
      "doi": "10.3758/s13428-020-01453-w"
    },
    {
      "id": "b3",
      "title": "Automating creativity assessment with semdis: An open platform for computing semantic distance",
      "authors": [
        "Roger E Beaty",
        "Dan Richard",
        "Johnson"
      ],
      "year": "2020",
      "venue": "Behavior Research Methods",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "The roles of associative and executive processes in creative cognition",
      "authors": [
        "Roger E Beaty",
        "Paul J Silvia",
        "Emily C Nusbaum",
        "Emanuel Jauk",
        "Mathias Benedek"
      ],
      "year": "2014",
      "venue": "Memory & Cognition",
      "doi": "10.3758/s13421-014-0428-8"
    },
    {
      "id": "b5",
      "title": "Forward flow and creative thought: Assessing associative cognition and its role in divergent thinking. Thinking Skills and Creativity",
      "authors": [
        "Roger E Beaty",
        "Daniel C Zeitlen",
        "Brendan S Baker",
        "Yoed N Kenett"
      ],
      "year": "2021",
      "venue": "Forward flow and creative thought: Assessing associative cognition and its role in divergent thinking. Thinking Skills and Creativity",
      "doi": "10.1016/j.tsc.2021.100859"
    },
    {
      "id": "b6",
      "title": "Using cognitive psychology to understand GPT-3",
      "authors": [
        "Marcel Binz",
        "Eric Schulz"
      ],
      "year": "2023",
      "venue": "Proceedings of the National Academy of Sciences",
      "doi": "10.1073/pnas.2218523120"
    },
    {
      "id": "b7",
      "title": "Enriching word vectors with subword information",
      "authors": [
        "Piotr Bojanowski",
        "Edouard Grave",
        "Armand Joulin",
        "Tomas Mikolov"
      ],
      "year": "2016",
      "venue": "Transactions of the Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
      "authors": [
        "Sébastien Bubeck",
        "Varun Chandrasekaran",
        "Ronen Eldan",
        "Johannes Gehrke",
        "Eric Horvitz",
        "Ece Kamar",
        "Peter Lee",
        "Yin Tat Lee",
        "Yuanzhi Li",
        "Scott Lundberg",
        "Harsha Nori",
        "Hamid Palangi",
        "Marco Tulio Ribeiro",
        "Yi Zhang"
      ],
      "year": "2023",
      "venue": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
      "doi": "10.48550/arXiv.2303.12712"
    },
    {
      "id": "b9",
      "title": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* Chat-GPT Quality",
      "authors": [
        "Wei-Lin Chiang",
        "Zhuohan Li",
        "Zi Lin",
        "Ying Sheng",
        "Zhanghao Wu",
        "Hao Zhang",
        "Lianmin Zheng",
        "Siyuan Zhuang",
        "Yonghao Zhuang",
        "Joseph E Gonzalez",
        "Ion Stoica",
        "Eric P Xing"
      ],
      "year": "2023",
      "venue": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* Chat-GPT Quality",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "BLOOM: Creativity and Affinity in Artificial Lyrics and Art",
      "authors": [
        "Evan Crothers",
        "L Herna",
        "Nathalie Viktor",
        "Japkowicz"
      ],
      "year": "2023",
      "venue": "BLOOM: Creativity and Affinity in Artificial Lyrics and Art",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans",
      "authors": [
        "Alexandra Delucia",
        "Aaron Mueller",
        "Xiang",
        "Lisa Li",
        "João Sedoc"
      ],
      "year": "2021",
      "venue": "Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",
      "doi": "10.1038/s41598-023-32248-6"
    },
    {
      "id": "b12",
      "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling",
      "authors": [
        "Zhengxiao Du",
        "Yujie Qian",
        "Xiao Liu",
        "Ming Ding",
        "Jiezhong Qiu",
        "Zhilin Yang",
        "Jie Tang"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2022.acl-long.26"
    },
    {
      "id": "b13",
      "title": "Hierarchical Neural Story Generation",
      "authors": [
        "Angela Fan",
        "Mike Lewis",
        "Yann Dauphin"
      ],
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/P18-1082"
    },
    {
      "id": "b14",
      "title": "Intelligence and creativity share a common cognitive and neural basis",
      "authors": [
        "Emily Frith",
        "Daniel B Elbich",
        "Alexander P Christensen",
        "Monica D Rosenberg",
        "Qunlin Chen",
        "Michael J Kane",
        "Paul J Silvia",
        "Paul Seli",
        "Roger E Beaty"
      ],
      "year": "2021",
      "venue": "Journal of Experimental Psychology: General",
      "doi": "10.1037/xge0000958"
    },
    {
      "id": "b15",
      "title": "Evolutionary approaches to creativity",
      "authors": [
        "Liane Gabora",
        "Scott Barry Kaufman"
      ],
      "year": "2010",
      "venue": "The Cambridge Handbook of Creativity",
      "doi": "10.1017/CBO9780511763205.018"
    },
    {
      "id": "b16",
      "title": "Some new looks at the nature of creative processes. Contributions to mathematical psychology",
      "authors": [
        "J Pv Guilford"
      ],
      "year": "1964",
      "venue": "Some new looks at the nature of creative processes. Contributions to mathematical psychology",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Artificial muses: Generative artificial intelligence chatbots have risen to human-level creativity",
      "authors": [
        "Jennifer Haase",
        "H P Paul",
        "Hanel"
      ],
      "year": "2023",
      "venue": "Artificial muses: Generative artificial intelligence chatbots have risen to human-level creativity",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Do Androids Laugh at Electric Sheep? Humor \"Understanding\" Benchmarks from The New Yorker Caption Contest",
      "authors": [
        "Jack Hessel",
        "Ana Marasovic",
        "Jena D Hwang",
        "Lillian Lee",
        "Jeff Da",
        "Rowan Zellers",
        "Robert Mankoff",
        "Yejin Choi"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2023.acl-long.41"
    },
    {
      "id": "b19",
      "title": "The curious case of neural text degeneration",
      "authors": [
        "Ari Holtzman",
        "Jan Buys",
        "Li Du",
        "Maxwell Forbes",
        "Yejin Choi"
      ],
      "year": "2020",
      "venue": "International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "Chatgpt is fun, but it is not funny! humor is still challenging large language models",
      "authors": [
        "Sophie Jentzsch",
        "Kristian Kersting"
      ],
      "year": "2023",
      "venue": "Chatgpt is fun, but it is not funny! humor is still challenging large language models",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Challenges and Applications of Large Language Models",
      "authors": [
        "Jean Kaddour",
        "Joshua Harris",
        "Maximilian Mozes",
        "Herbie Bradley",
        "Roberta Raileanu",
        "Robert Mchardy"
      ],
      "year": "2023",
      "venue": "Challenges and Applications of Large Language Models",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "OpenAssistant Conversations -Democratizing Large Language Model Alignment",
      "authors": [
        "Andreas Köpf",
        "Yannic Kilcher",
        "Sotiris Dimitri Von Rütte",
        "Zhi-Rui Anagnostidis",
        "Keith Tam",
        "Abdullah Stevens",
        "Barhoum",
        "Minh Nguyen",
        "Oliver Duc",
        "Richárd Stanley",
        "Nagyfi",
        "E S Shahul",
        "Sameer Suri",
        "David Glushkov",
        "Arnav Dantuluri",
        "Andrew Maguire",
        "Christoph Schuhmann",
        "Huu Nguyen",
        "Alexander Mattick"
      ],
      "year": "2023",
      "venue": "OpenAssistant Conversations -Democratizing Large Language Model Alignment",
      "doi": "10.48550/arXiv.2304.07327"
    },
    {
      "id": "b23",
      "title": "Word meaning in minds and machines",
      "authors": [
        "M Brenden",
        "Gregory L Lake",
        "Murphy"
      ],
      "year": "2020",
      "venue": "Word meaning in minds and machines",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "On the probability-quality paradox in language generation",
      "authors": [
        "Clara Meister",
        "Gian Wiher",
        "Tiago Pimentel",
        "Ryan Cotterell"
      ],
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
      "doi": "10.18653/v1/2022.acl-short.5"
    },
    {
      "id": "b25",
      "title": "Distributed representations of words and phrases and their compositionality",
      "authors": [
        "Tomas Mikolov",
        "Ilya Sutskever",
        "Kai Chen",
        "Gregory S Corrado",
        "Jeffrey Dean"
      ],
      "year": "2013",
      "venue": "Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "WordNet: a lexical database for English",
      "authors": [
        "George A Miller"
      ],
      "year": "1995",
      "venue": "Communications of the ACM",
      "doi": "10.1145/219717.219748"
    },
    {
      "id": "b27",
      "title": "Boosting Theory-of-Mind Performance in Large Language Models via Prompting",
      "authors": [
        "Rahimi Shima",
        "Christopher J Moghaddam",
        "Honey"
      ],
      "year": "2023",
      "venue": "Boosting Theory-of-Mind Performance in Large Language Models via Prompting",
      "doi": "10.48550/arXiv.2304.11490"
    },
    {
      "id": "b28",
      "title": "Naming unrelated words predicts creativity",
      "authors": [
        "Jay A Olson",
        "Johnny Nahas",
        "Denis Chmoulevitch",
        "Simon J Cropper",
        "Margaret E Webb"
      ],
      "year": "2021",
      "venue": "Proceedings of the National Academy of Sciences",
      "doi": "10.1073/pnas.2022340118"
    },
    {
      "id": "b29",
      "title": "Introducing ChatGPT",
      "authors": [
        "Openai"
      ],
      "year": "2022",
      "venue": "Introducing ChatGPT",
      "doi": "10.48550/arXiv.2303.08774"
    },
    {
      "id": "b30",
      "title": "Training language models to follow instructions with human feedback",
      "authors": [
        "Long Ouyang",
        "Jeffrey Wu",
        "Xu Jiang",
        "Diogo Almeida",
        "Carroll Wainwright",
        "Pamela Mishkin",
        "Chong Zhang",
        "Sandhini Agarwal",
        "Katarina Slama",
        "Alex Ray",
        "John Schulman",
        "Jacob Hilton",
        "Fraser Kelton",
        "Luke Miller",
        "Maddie Simens",
        "Amanda Askell",
        "Peter Welinder",
        "Paul F Christiano",
        "Jan Leike",
        "Ryan Lowe"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "Can chatgpt be used to generate scientific hypotheses?",
      "authors": [
        "Yang Jeong Park",
        "Daniel Kaplan",
        "Zhichu Ren",
        "Chia-Wei Hsu",
        "Changhao Li",
        "Haowei Xu",
        "Sipei Li",
        "Ju Li"
      ],
      "year": "2023",
      "venue": "Can chatgpt be used to generate scientific hypotheses?",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "Glove: Global Vectors for Word Representation",
      "authors": [
        "Jeffrey Pennington",
        "Richard Socher",
        "Christopher Manning"
      ],
      "year": "2014",
      "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.3115/v1/D14-1162"
    },
    {
      "id": "b33",
      "title": "Language models are unsupervised multitask learners",
      "authors": [
        "Alec Radford",
        "Jeffrey Wu",
        "Rewon Child",
        "David Luan",
        "Dario Amodei",
        "Ilya Sutskever"
      ],
      "year": "2019",
      "venue": "OpenAI blog",
      "doi": ""
    },
    {
      "id": "b34",
      "title": "Hierarchical textconditional image generation with clip latents",
      "authors": [
        "Aditya Ramesh",
        "Prafulla Dhariwal",
        "Alex Nichol",
        "Casey Chu",
        "Mark Chen"
      ],
      "year": "2022",
      "venue": "Hierarchical textconditional image generation with clip latents",
      "doi": ""
    },
    {
      "id": "b35",
      "title": "The Standard Definition of Creativity",
      "authors": [
        "Mark A Runco",
        "Garrett J Jaeger"
      ],
      "year": "2012",
      "venue": "Creativity Research Journal",
      "doi": "10.1080/10400419.2012.650092"
    },
    {
      "id": "b36",
      "title": "Evaluation methods for unsupervised word embeddings",
      "authors": [
        "Tobias Schnabel",
        "Igor Labutov",
        "David Mimno",
        "Thorsten Joachims"
      ],
      "year": "2015",
      "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
      "doi": "10.18653/v1/D15-1036"
    },
    {
      "id": "b37",
      "title": "The curse of recursion: Training on generated data makes models forget",
      "authors": [
        "Ilia Shumailov",
        "Zakhar Shumaylov",
        "Yiren Zhao",
        "Yarin Gal",
        "Nicolas Papernot",
        "Ross Anderson"
      ],
      "year": "2023",
      "venue": "The curse of recursion: Training on generated data makes models forget",
      "doi": ""
    },
    {
      "id": "b38",
      "title": "Mastering the game of go with deep neural networks and tree search",
      "authors": [
        "David Silver",
        "Aja Huang",
        "Chris J Maddison",
        "Arthur Guez",
        "Laurent Sifre",
        "George Van Den Driessche",
        "Julian Schrittwieser",
        "Ioannis Antonoglou",
        "Veda Panneershelvam",
        "Marc Lanctot",
        "Sander Dieleman",
        "Dominik Grewe",
        "John Nham",
        "Nal Kalchbrenner",
        "Ilya Sutskever",
        "Timothy Lillicrap",
        "Madeleine Leach",
        "Koray Kavukcuoglu",
        "Thore Graepel",
        "Demis Hassabis"
      ],
      "year": "2016",
      "venue": "Nature",
      "doi": "10.1038/nature16961"
    },
    {
      "id": "b39",
      "title": "Brainstorm, then Select: A Generative Language Model Improves Its Creativity Score",
      "authors": [
        "Douglas Summers-Stay",
        "Clare R Voss",
        "Stephanie M Lukin"
      ],
      "year": "2023",
      "venue": "The AAAI-23 Workshop on Creative AI Across Modalities",
      "doi": ""
    },
    {
      "id": "b40",
      "title": "LLaMA: Open and Efficient Foundation Language Models",
      "authors": [
        "Hugo Touvron",
        "Thibaut Lavril",
        "Gautier Izacard",
        "Xavier Martinet",
        "Marie-Anne Lachaux",
        "Timothée Lacroix",
        "Baptiste Rozière",
        "Naman Goyal",
        "Eric Hambro",
        "Faisal Azhar",
        "Aurelien Rodriguez",
        "Armand Joulin",
        "Edouard Grave",
        "Guillaume Lample"
      ],
      "year": "2023",
      "venue": "LLaMA: Open and Efficient Foundation Language Models",
      "doi": "10.48550/arXiv.2302.13971"
    },
    {
      "id": "b41",
      "title": "Trading Off Diversity and Quality in Natural Language Generation",
      "authors": [
        "Hugh Zhang",
        "Daniel Duckworth",
        "Daphne Ippolito",
        "Arvind Neelakantan"
      ],
      "year": "2021",
      "venue": "Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval)",
      "doi": ""
    },
    {
      "id": "b42",
      "title": "Retrieval flexibility links to creativity: evidence from computational linguistic measure",
      "authors": [
        "Jingyi Zhang",
        "Kaixiang Zhuang",
        "Jiangzhou Sun",
        "Cheng Liu",
        "Li Fan",
        "Xueyang Wang",
        "Jing Gu",
        "Jiang Qiu"
      ],
      "year": "2023",
      "venue": "Cerebral Cortex",
      "doi": "10.1093/cercor/bhac392"
    }
  ],
  "sections": [
    {
      "title": "Abstract",
      "text": "Large language models possess remarkable capacity for processing language, but it remains unclear whether these models can further generate creative content. The present study aims to investigate the creative thinking of large language models through a cognitive perspective. We utilize the divergent association task (DAT), an objective measurement of creativity that asks models to generate unrelated words and calculates the semantic distance between them. We compare the results across different models and decoding strategies. Our findings indicate that: (1) When using the greedy search strategy, GPT-4 outperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level. (2) Stochastic sampling and temperature scaling are effective to obtain higher DAT scores for models except GPT-4, but face a trade-off between creativity and stability. These results imply that advanced large language models have divergent semantic associations, which is a fundamental process underlying creativity.1 Footnote 1: We release our code at [https://github.com/DingNLab/probing_creativity](https://github.com/DingNLab/probing_creativity)"
    },
    {
      "title": "1 Introduction",
      "text": "Large language models (LLMs) have exhibited unparalleled mastery of natural language Bubeck et al. (2023). The primary capacity of producing the most probable next word is broadly generalizable to many language tasks, suggesting underlying cognitive abilities beyond specialized linguistic rules and patterns. There is observation that LLMs may possess reasoning abilities which is a core aspect of intelligence, including decision-making Binz and Schulz (2023) and theory of mind Moghaddam and Honey (2023). Meanwhile, there is also increasing interest in exploring LLMs' creativity, which is closely related to intelligence Frith et al. (2021). Creative use of language, such as metaphor and humor, is important during communication. OpenAI (2023) has reported GPT-4's ability to understand jokes, while subsequent works show limited capacity for LLMs to generate or explain humor Jentzsch and Kersting (2023); Hessel et al. (2023). As creativity is essential to the development of art, science, and everyday life for human Gabora and Kaufman (2010), it is non-trivial if models could produce creative content. Regarding to the curse of recursion for LLMs that training on generated data makes models collapse, one promising solution might be the novel language distribution through creative generation Shumailov et al. (2023). But since LLMs represent word meaning and predict the next word in context, it seems paradoxical that such models could create ideas not seen in training. Here, we empirically investigate the creativity of LLMs by examining models' ability to generate divergent concepts. A general definition of creativity is the ability to create something both novel and valuable Runco and Jaeger (2012). According to the dual-process theory of creativity Beaty et al. (2014), creative thinking relies on remote association while inhibiting common ideas (Figure 1). Because of the intrinsic complexity, creativity is universally accepted to be unique to human beings, while models are Figure 1: Creativity from the perspective of language distribution. Creative thoughts need to be novel and valuable, which need cognitive control to inhibit common tokens and remote association to find valuable tokens. regarded as great predictors to master the existing distribution but not qualified creators to generate new distribution. However, there have been evidences of models possessing creativity in different domains. For artistic creation, deep generative models reveals exquisite painting skills (Ramesh et al., 2022). For algorithms, models are able to generate original and superhuman strategies in board game (Silver et al., 2016). As for language models, creativity is an emerging concern. Since GPT-2 (Radford et al., 2019), language models are able to naturally produce answers given a prompt, even for open-ended and creative generation tasks (Kaddour et al., 2023). However, when generating texts from these probabilistic models, decoding strategy has a prominent effect on the quality of result. Decoding strategies that search for the highest-probability words tend to produce texts that is dull and repetitive (Zhang et al., 2021), while stochastic strategies, which randomly sample from models, generate texts with better human preference (DeLucia et al., 2021; Holtzman et al., 2020). These texts have human-like information distribution, which are viewed as informative and interesting (Meister et al., 2022). Despite this, stochastic strategies are distinct from human. The decoding process is probabilistic and independent, while humans produce language under elaborated cognitive control, especially for creative generation. Creative and nonsense contents are both infrequent during next word prediction that cannot be simply distinguished via sampling strategies (Figure 1). Thus, it is unclear whether LLMs genuinely have creativity during modeling, and whether decoding strategies help. To answer both of these questions, we evaluate the creativity of LLMs. Specifically, we use an objective semantic measurement, the divergent association task (DAT), which asks models to generate unrelated nouns and compute the pairwise semantic distance between them (Olson et al., 2021). In summary, we make the following contributions: * Investigate the creativity of LLMs and compare the results with human. * Explore the effect of decoding strategies on the creative generation of LLMs."
    },
    {
      "title": "2 Measuring Creativity",
      "text": "A direct measure of creativity is relying on experts to judge the creative quality of products. Several studies assessed LLMs' creativity on artistic and scientific creation (Crothers et al., 2023; Park et al., 2023). However, two elements of creativity, novelty and value, are both relative and ambiguous during evaluation. Human ratings are affected by subjective surprise and domain knowledge, and thus differ from each other. There are other methods based on domain-general cognitive process of creativity.2 Divergent thinking, i.e., generating a large variety of solutions from an open-ended point, is an indicator for creative thinking (Beaty et al., 2014). One of the most widely used tasks on divergent thinking is the alternate use task (AUT), which asks participants to generate unusual uses of objects (e.g., a brick) (Guilford, 1964). Previous studies used AUT to measure the creativity of LLMs (Summers-Stay et al., 2023; Haase and Hanel, 2023), but the evaluation is sample-dependent that the scores are various across the selected objects. AUT also relies on humans to rate the creativity of generated uses. Moreover, AUT has the the risk of data leakage that the answers are confounded by the uses recorded in the training data. Creativity has long been linked to the flexibility of semantic retrieval (Zhang et al., 2023). An alternative to probe creativity is through the structure of semantic memory, which can be automatically and reproducibly assessed (Beaty et al., 2021; Beaty and Johnson, 2021). The DAT, among these methods, is valid and reliable that closely correlates with other metrics of creativity (Olson et al., 2021). Different from measuring semantic similarity as usual, the DAT prompts participants to reject related associations and produce unrelated nouns (Figure 2). Formally, given \\(n\\) words and their word embed Figure 2: The DAT paradigm and example responses. dings \\(\\{\\mathbf{v_{1}},\\dots,\\mathbf{v_{n}}\\}\\), the DAT can be calculated as the average cosine distance as follows: \\[\\text{DAT}=\\frac{100}{n(n-1)}\\sum_{\\begin{subarray}{c}i,j\\\\ i\\neq j\\end{subarray}}^{n}\\left(1-\\text{cos}\\left(\\mathbf{v_{i}},\\mathbf{v_{j}}\\right)\\right) \\tag{1}\\] In this study, we apply the DAT to assess the creativity of LLMs, but before that it is necessary to evidence the applicability of this method. Basically, the validity of DAT for humans comes with the bias that humans retrieve semantics exploiting their semantic networks. The semantic networks of humans reveal the semantic representations about the world, which are also reflected in the language distribution of human corpus. Thus, LLMs pre-trained on the corpus should exhibit the similar bias. The semantic networks are also needed for LLMs to accomplish general language tasks. Empirically, previous studies showed that language models have similar patterns of semantic activations with humans Lake and Murphy (2020); Digutsch and Kosinski (2023). Additionally, considering these studies assessing the semantic activations differently from the present study, we provide another analysis to validate the DAT for LLMs. It is noteworthy that possessing similar semantic networks is not equivalent to being equally creative. Although the semantic networks of humans are roughly consistent, the ability to produce remote associations is challenging and largely varies among humans."
    },
    {
      "title": "3 Experiment Setup",
      "text": ""
    },
    {
      "title": "Models",
      "text": "We studied five recent LLMs with different sizes, including GPT-4 (OpenAI, 2023) and GPT-3.5-Turbo (OpenAI, 2022) from OpenAI, Oasst-Llama-30B (Kopf et al., 2023) and Vicuna-13B (Chiang et al., 2023) fine-tuned from Llama (Touvron et al., 2023), and ChatGLM-6B based on GLM Du et al. (2022).3 GPT-4 and GPT-3.5-Turbo have advanced performance through pre-train and RLHF Ouyang et al. (2022), while other models are trained by fine-tuning foundation models on collected instructions. Footnote 3: Specifically, we use the following versions: gpt-4-0314, gpt-3.5-turbo-0301, oasst-sft-7-llama-30b, Vicuna-13b-delta-v1.1 and chatglm-6b-v1.0."
    },
    {
      "title": "Decoding Strategy",
      "text": "For deterministic algorithms, we use greedy search that choose the most probable token at each decoding step. For stochastic algorithms, we use top-\\(p\\) sampling (Holtzman et al., 2020) that limit the sampling space to the top-\\(p\\) most likely tokens at each decoding step, truncating the undesirable tail of distribution. We set \\(p=0.9\\) with temperature \\(t=0.7\\) for top-\\(p\\) sampling. Then we adjust different settings of \\(t\\) to study the effect of temperature. For each model, we collect enough samples to ensure the results convergent (Appendix A)."
    },
    {
      "title": "Dat",
      "text": "In DAT, we ask models to generate 10 unrelated nouns. we constrain the models to generate only nouns to isolate the semantical distances from syntactic effects. We use the zero-shot prompt in Figure 2 that is consistent with the study for humans Olson et al. (2021). We filter out the answers with invalid words, e.g., verbs. Then we select the first seven valid words that models provide, and compute the DAT score via Eq. (1).4 Footnote 4: The number of seven is consistent with Olson et al. 2021 because most answers have at least seven valid words, and results are stable using over seven words. We use GLoVe Pennington et al. (2014) to calculate semantic distance (Figure 2(a)). In previous studies which also used semantic space to evaluate creativity, GLoVe was proved to be effective Beaty and Johnson (2020). We have also experimented Word2Vec Mikolov et al. (2013) and Fasttext Bojanowski et al. (2016), and found results similar (with the correlation coefficient of 0.82 and 0.91 respectively). The word vectors also encode word frequency that rare words have unstable semantic distance for the lack of training Schnabel et al. (2015). Thus, we also compute the average surprisal (negative log word frequency) to study this potential effect. To compare the result of models with humans, we use the data collected on 8572 participants.5 We also randomly sample nouns from Wordnet Miller (1995) as a situation without the bias of semantic network. Footnote 5: The data and code of DAT for human is available at [https://osf.io/vjazn/](https://osf.io/vjazn/)."
    },
    {
      "title": "Validating Dat",
      "text": "As mentioned in Section 2, we set two additional prompts for comparison: (1) **Base**: write 10 nouns, and (2) **Random**: write 10 nouns randomly. We hypothesize that LLMs generate semantically associated words if not instructed, but can also have divergent associations under the DAT prompt."
    },
    {
      "title": "4 Result",
      "text": "The DAT results are shown in Figure 3. Using greedy search, GPT-4 achieves the highest DAT of 89.1, surpassing 96.1% of humans, and GPT-3.5-Turbo attains a DAT of 80.8 that is above the average human-level (Figure 3c). Other models perform less well with lower DAT, which are roughly proportional to the size of models. When using top-\\(p\\) sampling, models other than GPT-4 are capable of getting the DAT much higher than greedy search, but they also become unstable that probably generate answers with low DAT scores (Figure 3b). We also report the relation between the DAT and surprisal in Figure 4.6 Theoretically, surprisal is corresponding to the novelty that is an element of creativity, and the original DAT metric including word frequency effect is valid for human as well (Olson et al., 2021). But as mentioned in Section 3.3, word frequency might be a confounding variable when calculating semantic distance. Indeed, we find two variables highly relevant for human and random baselines (also see Appendix B). For models, the results of top-\\(p\\) sampling have homogeneous slopes with two baselines, but their intercepts and surprisal distributions are different. GPT-4 and GPT-3.5-Turbo exceed the average human DAT under the same surprisal, while other models fall short. Despite Vicuna-13B and Chatglm-6B have similar distributions of surprisal, the former generates words more divergently. Oasst-Llama-30B defeats Vicuna-13B on the DAT, but this might be explained by the capacity or tendency to generate rarer words. To clarify this effect, we control the surprisal for DAT in Appendix D. The results are similar that GPT-4 and GPT-3.5-Turbo outperform average human performance, but the superiority of GPT-4 is attenuated. Figure 4: Relationship between the DAT and surprisal. Rimmed points show the results of greedy search. The contour indicates the 95% confidence interval of humans. Figure 3: The DAT for humans and models. (a) The distance matrix of words generated by GPT-4 and GPT-3.5-turbo. The average distance is defined as the DAT. (b) The DAT of models and human. (c) The percentile of models’ DAT against human results. We further investigate the effect of temperature (Figure 5). Temperature is a widely deployed parameter for creative or original generation in practice that high temperature skews the distribution shape towards low-probability tokens (Ackley et al., 1985; Fan et al., 2018). We vary the temperature from 0.1 to 1 and found its positive effect for models except GPT-4. However, the effect is limited, and high temperature will also bring instability and produce invalid answers. As for GPT-4, high-probability tokens are well aligned with high-quality answers. In the relationship between the DAT and surprisal, we find a naive algorithm that samples nouns from Wordnet can outperform the majority of humans and models (Figure 4). It is because the algorithm has no constrains of the language distribution, which also means it can barely accomplish general language tasks. Although LLMs have exhibited striking mastery of natural language, we wonder whether they process the semantics differently with humans and the DAT test is accordingly invalid as well. Thus, we compare the DAT with Base and Random conditions (figure 6). We show that if not instructed, LLMs tend to produce more related words. When instructed with the prompts of Random and the DAT, LLMs can modulate the language distributions to be more divergent. These results indicate that LLMs have the potential to generate divergent content with instruction, but with the flaw of not inhibiting common words. Stochastic decoding strategy is helpful for promoting remote association, but since the creative and nonsense content are both infrequent, it cannot accurately produce high-quality content.7 However, advanced LLMs show the implicit control of modulating the probability distribution and stably generating divergent answers. Stochastic decoding strategy may even degrade performances for introduced randomness. Footnote 7: Previous psychological researches reported similar result that mild imperfection of attention is related to higher creativity (Abraham, 2014)."
    },
    {
      "title": "5 Conclusion",
      "text": "In this work, we provide a creativity evaluation using a divergent semantic task. This task reveals distinguishable results across various LLMs and decoding strategies. We find GPT-4 demonstrates advanced human-level creativity stably, while GPT-3.5-turbo exceeds the average human level. For decoding methods, stochastic decoding strategy is effective but not enough for creative generation."
    },
    {
      "title": "Limitation",
      "text": "Creativity is a deeply debated concept. We selectively evaluate the \"little-C\" (creativity in everyday life) that is a general capacity, instead of the \"big-C\" (marvelous creative product) which is rare even for human. Measuring creativity is also controversial that requires evaluations from multiple perspectives, principles, and analysis. Thus, the results of this study cannot be directly generalized to all language generation tasks. We also limited the range of this study within self-contained creativity, whereas another crucial aspect of AI's creativity is human-AI co-creation. We leave these for future work."
    },
    {
      "title": "Acknowledgement",
      "text": "We thank Mark Sun and the anonymous reviews for their thoughtful helps and suggestions. This work was supported by STI2030-Major Projects 2021ZD0204105 and Fundamental Research Funds for the Central Universities 226-2023-00091. Figure 5: Effect of temperature tuning. The bands indicate the standard deviations. Figure 6: The DAT scores of 3 conditions."
    },
    {
      "title": "References",
      "text": "* A. Abraham (2014)Creative thinking as orchestrated by semantic processing vs. cognitive control brain networks. Frontiers in human neuroscience8, pp. 95. Cited by: SS1. * D. H. Ackley, G. E. Hinton, and T. J. Sejnowski (1985)A learning algorithm for boltzmann machines. Cognitive Science9 (1), pp. 147-169. Cited by: SS1. * R. E. Beaty and D. R. Johnson (2021)Automating creativity assessment with semDis: an open platform for computing semantic distance. Behavior Research Methods53 (2), pp. 757-780. Cited by: SS1. * R. E. Beaty, P. J. Silvia, E. C. Nusbaum, E. Jauk, and M. Benedek (2014)The roles of associative and executive processes in creative cognition. Memory & Cognition42 (7), pp. 1186-1197. Cited by: SS1. * R. E. Beaty, D. C. Zeitlen, B. S. Baker, and Y. N. Kenett (2021)Forward flow and creative thought: assessing associative cognition and its role in divergent thinking. Thinking Skills and Creativity41, pp. 100859. Cited by: SS1. * M. Binz and E. Schulz (2023)Using cognitive psychology to understand GPT-3. Proceedings of the National Academy of Sciences120 (6), pp. e2218523120. Cited by: SS1. * P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov (2016)Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics5, pp. 135-146. Cited by: SS1. * S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg, H. Nori, H. Palangi, M. Tulio Ribeiro, and Y. Zhang (2023)Sparks of Artificial General Intelligence: early experiments with GPT-4. arXiv e-prints, pp. arXiv:2303.12712. Cited by: SS1. * W. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E. Gonzalez, I. Stoica, and E. P. Xing (2023)Vicuna: an Open-Source chatbot Impressing GPT-4 with 90%* Chat-GPT Quality. Cited by: SS1. * E. Crothers, H. L. Viktor, and N. Japkowicz (2023)In BLOOM: creativity and Affinity in Artificial Lyrics and Art. In The AAAI-23 Workshop on Creative AI Across Modalities, Cited by: SS1. * A. DeLucia, A. Mueller, X. L. Li, and J. Sedoc (2021)Decoding Methods for Neural Narrative Generation. In Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), Online, pp. 166-185. Cited by: SS1. * J. Digutsch and M. Kosinski (2023)Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans. Scientific Reports13 (1), pp. 5035. Cited by: SS1. * Z. Du, Y. Qian, X. Liu, M. Ding, J. Qiu, Z. Yang, and J. Tang (2022)GLM: general language model pretraining with autoregressive blank infilling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Dublin, Ireland, pp. 320-335. Cited by: SS1. * A. Fan, M. Lewis, and Y. Dauphin (2018)Hierarchical neural story generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Melbourne, Australia, pp. 889-898. Cited by: SS1. * E. Frith, D. B. Elbich, A. P. Christensen, M. D. Rosenberg, Q. Chen, M. J. Kane, P. J. Silvia, P. Seli, and R. E. Beaty (2021)Intelligence and creativity share a common cognitive and neural basis. Journal of Experimental Psychology: General150, pp. 609-632. Cited by: SS1. * L. Gabora and S. Barry Kaufman (2010)Evolutionary approaches to creativity. In The Cambridge Handbook of Creativity, Cambridge University Press, New York, NY, USA, pp. 279-300. Cited by: SS1. * J. P. Guilford (1964)Some new looks at the nature of creative processes. Contributions to mathematical psychology. New York: Holt, Rinehart & Winston. Cited by: SS1. * J. Haase and P. H. P. Hanel (2023)Artificial muses: generative artificial intelligence chatbots have risen to human-level creativity. Cited by: SS1. * J. Hessel, A. Marasovic, J. D. Hwang, L. Lee, J. Da, R. Zellers, R. Mankoff, and Y. Choi (2023)Do Androids Laugh at Electric Sheep?? Humor \"Understanding\" benchmarks from The New Yorker Caption Contest. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Toronto, Canada, pp. 688-714. Cited by: SS1. * A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi (2020)The curious case of neural text degeneration. In International Conference on Learning Representations, Cited by: SS1. * S. Jentzsch and K. Kersting (2023)Chatgpt is fun, but it is not funny! humor is still challenging large language models. Cited by: SS1. * J. Kaddour, J. Harris, M. Mozes, H. Bradley, R. Railenau, and R. McHardy (2023)Challenges and applications of large language models. ArXiv:2307.10169 [cs]. Andreas Kopf, Yannic Kilcher, Dimitri von Rutte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen Minh Duc, Oliver Stanley, Richard Nagyff, Shahul ES, Sameer Suri, David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and Alexander Mattick. 2023. OpenAssistant Conversations - Democratizing Large Language Model Alignment. ArXiv:2304.07327 [cs]. * Lake and Murphy (2020) Brenden M. Lake and Gregory L. Murphy. 2020. Word meaning in minds and machines. _Psychological review_. * Meister et al. (2022) Clara Meister, Gian Wiher, Tiago Pimentel, and Ryan Cotterell. 2022. On the probability-quality paradox in language generation. In _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)_, pages 36-45, Dublin, Ireland. Association for Computational Linguistics. * Mikolov et al. (2013) Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. 2013. Distributed representations of words and phrases and their compositionality. In _Neural Information Processing Systems_. * Miller (1995) George A. Miller. 1995. WordNet: a lexical database for English. _Communications of the ACM_, 38(11):39-41. * Moghaddam and Honey (2023) Shima Rahimi Moghaddam and Christopher J. Honey. 2023. Boosting Theory-of-Mind Performance in Large Language Models via Prompting. * Olson et al. (2021) Jay A. Olson, Johnny Nahas, Denis Chmoulevitch, Simon J. Cropper, and Margaret E. Webb. 2021. Naming unrelated words predicts creativity. _Proceedings of the National Academy of Sciences_, 118(25). * OpenAI (2022) OpenAI. 2022. Introducing ChatGPT. * OpenAI (2023) OpenAI. 2023. GPT-4 Technical Report. ArXiv:2303.08774 [cs]. * Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. _Advances in Neural Information Processing Systems_, 35:27730-27744. * Park et al. (2023) Yang Jeong Park, Daniel Kaplan, Zhichu Ren, Chia-Wei Hsu, Changhao Li, Haowei Xu, Sipei Li, and Ju Li. 2023. Can chatgpt be used to generate scientific hypotheses? * Pennington et al. (2014) Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global Vectors for Word Representation. In _Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)_, pages 1532-1543, Doha, Qatar. Association for Computational Linguistics. * Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. _OpenAI blog_, 1(8):9. * Ramesh et al. (2022) Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022. Hierarchical text-conditional image generation with clip latents. * Runco and Jaeger (2012) Mark A. Runco and Garrett J. Jaeger. 2012. The Standard Definition of Creativity. _Creativity Research Journal_, 24(1):92-96. * Schnabel et al. (2015) Tobias Schnabel, Igor Labutov, David Mimno, and Thorsten Joachims. 2015. Evaluation methods for unsupervised word embeddings. In _Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing_, pages 298-307, Lisbon, Portugal. Association for Computational Linguistics. * Shumailov et al. (2023) Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. 2023. The curse of recursion: Training on generated data makes models forget. * Silver et al. (2016) David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. 2016. Mastering the game of go with deep neural networks and tree search. _Nature_, 529(7587):484-489. Number: 7587 Publisher: Nature Publishing Group. * Summers-Stay et al. (2023) Douglas Summers-Stay, Clare R. Voss, and Stephanie M. Lukin. 2023. Brainstorm, then Select: A Generative Language Model Improves Its Creativity Score. In _The AAAI-23 Workshop on Creative AI Across Modalities_. * Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. LLaMA: Open and Efficient Foundation Language Models. ArXiv:2302.13971 [cs]. * Zhang et al. (2021) Hugh Zhang, Daniel Duckworth, Daphne Ippolito, and Arvind Neelakantan. 2021. Trading Off Diversity and Quality in Natural Language Generation. In _Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval)_, pages 25-33, Online. Association for Computational Linguistics. * Zhang et al. (2023) Jingyi Zhang, Kaixiang Zhuang, Jiangzhou Sun, Cheng Liu, Li Fan, Xueyang Wang, Jing Gu, and Jiang Qiu. 2023. Retrieval flexibility links to creativity: evidence from computational linguistic measure. _Cerebral Cortex_, 33(8):4964-4976. Selecting sample size for each model Figure 7 shows the sample size to generate stable results using top-\\(p\\) sampling for each model. With confidence coefficient \\(\\alpha=0.05\\), standard deviation \\(\\hat{\\sigma}\\) and error \\(\\epsilon=1\\), we choose \\(N>(\\lambda_{\\alpha}\\times\\hat{\\sigma}/\\epsilon)^{2}=1.96^{2}\\times\\hat{\\sigma}^ {2}\\). We find larger models (GPT-4 and GPT-3.5-Turbo) generate answers more stably."
    },
    {
      "title": "Appendix B Results Of The Dat And Surprisal On Human And Random And Baselines",
      "text": "Figure 8 shows the results of the DAT and surprisal on human and random baselines. We find positive relationship between surprisal and the DAT. Random baseline is a strong baseline that has maximal remote association (uniform distribution) despite without inhibition. Even so, we find some people surpass random baseline and approach ceiling DAT at specific section of surprisal."
    },
    {
      "title": "Appendix C Result Of The Dat And Surprisal For More Models Using Greedy Search",
      "text": "Figure 9 shows the results of the DAT and surprisal for more LLMs using greedy search."
    },
    {
      "title": "Appendix D Controlling Surprisal As A Confounding Variable",
      "text": "Considering the potential influence of word frequency on measuring semantic distance, we control surprisal (Figure 10 ). The results are similar as before that GPT-4 and GPT-3.5-Turbo outperform average human performance, while other models are below average human level. However, GPT-4 as well as Oasst-Llama-30B lose their superiorities because their high DAT scores partially depend on generating rarer words. Figure 8: Results of the DAT and surprisal on human and random baseline. Contours indicate the 95% confidence intervals. Figure 10: Results of the DAT when controlling surprisal as a confounding variable. Figure 7: Results of the DAT across different sample sizes. The bands indicate the standard deviations. Figure 9: Results of the DAT and surprisal for more LLMs. The contour indicate the 95% confidence interval."
    }
  ]
}
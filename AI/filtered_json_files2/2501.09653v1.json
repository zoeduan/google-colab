{
  "title": "The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models",
  "authors": [
    "Jonathan Katzy",
    "Razvan Mihai Popescu",
    "Arie Van Deursen",
    "Maliheh Izadi"
  ],
  "abstract": "\n The recent rise in the popularity of large language models has spurred the development of extensive code datasets needed to train them. This has left limited code available for collection and use in the downstream investigation of specific behaviors, or evaluation of large language models without suffering from data contamination. To address this problem, we release The Heap, a large multilingual dataset covering 57 programming languages that has been deduplicated with respect to other open datasets of code, enabling researchers to conduct fair evaluations of large language models without significant data cleaning overhead. \n",
  "references": [
    {
      "id": null,
      "title": "The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models",
      "authors": [
        "Jonathan Katzy",
        "Razvan Mihai Popescu",
        "Arie Van Deursen",
        "Maliheh Izadi"
      ],
      "year": "2025",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Leandro von Werra, and Harm de Vries. The stack: 3 tb of permissively licensed source code",
      "authors": [
        "Denis Kocetkov",
        "Raymond Li",
        "Loubna Ben Allal",
        "Jia Li",
        "Chenghao Mou",
        "Carlos Muñoz Ferrandis",
        "Yacine Jernite",
        "Margaret Mitchell",
        "Sean Hughes",
        "Thomas Wolf",
        "Dzmitry Bahdanau"
      ],
      "year": "2022",
      "venue": "Leandro von Werra, and Harm de Vries. The stack: 3 tb of permissively licensed source code",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Redpajama: An open source recipe to reproduce llama training dataset",
      "authors": [
        "Together Computer"
      ],
      "year": "2023",
      "venue": "Redpajama: An open source recipe to reproduce llama training dataset",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "Starcoder 2 and the stack v2: The next generation",
      "authors": [
        "Anton Lozhkov",
        "Raymond Li",
        "Loubna Ben Allal",
        "Federico Cassano",
        "Joel Lamy-Poirier",
        "Nouamane Tazi",
        "Ao Tang",
        "Dmytro Pykhtar",
        "Jiawei Liu",
        "Yuxiang Wei"
      ],
      "year": "2024",
      "venue": "Starcoder 2 and the stack v2: The next generation",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "A catalog of data smells for coding tasks",
      "authors": [
        "Antonio Vitale",
        "Rocco Oliveto",
        "Simone Scalabrino"
      ],
      "year": "2024",
      "venue": "ACM Trans. Softw. Eng. Methodol",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Leandro Von Werra, and Harm de Vries. The stack: 3 TB of permissively licensed source code",
      "authors": [
        "Denis Kocetkov",
        "Raymond Li",
        "Loubna Ben",
        "L I Jia",
        "Chenghao Mou",
        "Yacine Jernite",
        "Margaret Mitchell",
        "Carlos Muñoz Ferrandis",
        "Sean Hughes",
        "Thomas Wolf",
        "Dzmitry Bahdanau"
      ],
      "year": "2023",
      "venue": "Transactions on Machine Learning Research",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "The pile: An 800gb dataset of diverse text for language modeling",
      "authors": [
        "Leo Gao",
        "Stella Biderman",
        "Sid Black",
        "Laurence Golding",
        "Travis Hoppe",
        "Charles Foster",
        "Jason Phang",
        "Horace He",
        "Anish Thite",
        "Noa Nabeshima"
      ],
      "year": "2020",
      "venue": "The pile: An 800gb dataset of diverse text for language modeling",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "",
      "authors": [
        "Thomas Wolf",
        "Leandro Von Werra",
        "Lewis Tunstall"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "An interpretability illusion for bert",
      "authors": [
        "Tolga Bolukbasi",
        "Adam Pearce",
        "Ann Yuan",
        "Andy Coenen",
        "Emily Reif",
        "Fernanda Viégas",
        "Martin Wattenberg"
      ],
      "year": "2021",
      "venue": "An interpretability illusion for bert",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "An exploratory investigation into code license infringements in large language model training datasets",
      "authors": [
        "Jonathan Katzy",
        "Razvan Popescu",
        "Arie Van Deursen",
        "Maliheh Izadi"
      ],
      "year": "2024",
      "venue": "Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering, FORGE '24",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "",
      "authors": [
        "Raymond Li",
        "Loubna Ben Allal",
        "Yangtian Zi",
        "Niklas Muennighoff",
        "Denis Kocetkov",
        "Chenghao Mou",
        "Marc Marone",
        "Christopher Akiki",
        "L I Jia",
        "Jenny Chim",
        "Qian Liu",
        "Evgenii Zheltonozhskii",
        "Terry Yue Zhuo",
        "Thomas Wang",
        "Olivier Dehaene",
        "Joel Lamy-Poirier",
        "Joao Monteiro",
        "Nicolas Gontier",
        "Ming-Ho Yee",
        "Logesh Kumar Umapathi",
        "Jian Zhu",
        "Ben Lipkin",
        "Muhtasham Oblokulov",
        "Zhiruo Wang",
        "Rudra Murthy",
        "Jason T Stillerman",
        "Sankalp Siva",
        "Dmitry Patel",
        "Marco Abulkhanov",
        "Manan Zocca",
        "Zhihan Dey",
        "Urvashi Zhang",
        "Wenhao Bhattacharyya",
        "Sasha Yu",
        "Paulo Luccioni",
        "Fedor Villegas",
        "Tony Zhdanov",
        "Nadav Lee",
        "Jennifer Timor",
        "Claire S Ding",
        "Hailey Schlesinger",
        "Jan Schoelkopf",
        "Tri Ebert",
        "Mayank Dao",
        "Mishra"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "Mining of Massive Datasets",
      "authors": [
        "Jure Leskovec",
        "Anand Rajaraman",
        "Jeffrey David Ullman"
      ],
      "year": "2014",
      "venue": "Mining of Massive Datasets",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "The adverse effects of code duplication in machine learning models of code",
      "authors": [
        "Miltiadis Allamanis"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, Onward! 2019",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Open code models based on gemma",
      "authors": [
        "Codegemma Team",
        "Heri Zhao",
        "Jeffrey Hui",
        "Joshua Howland",
        "Nam Nguyen",
        "Siqi Zuo",
        "Andrea Hu",
        "Christopher A Choquette-Choo",
        "Jingyue Shen",
        "Joe Kelley"
      ],
      "year": "2024",
      "venue": "Open code models based on gemma",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "Documenting large webtext corpora: A case study on the colossal clean crawled corpus",
      "authors": [
        "Jesse Dodge",
        "Maarten Sap",
        "Ana Marasović",
        "William Agnew",
        "Gabriel Ilharco",
        "Dirk Groeneveld",
        "Margaret Mitchell",
        "Matt Gardner"
      ],
      "year": "2021",
      "venue": "Documenting large webtext corpora: A case study on the colossal clean crawled corpus",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "Is this code written in english? a study of the natural language of comments and identifiers in practice",
      "authors": [
        "Timo Pawelka",
        "Elmar Juergens"
      ],
      "year": "2015",
      "venue": "2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "Part of speech tagging: a systematic review of deep learning and machine learning approaches",
      "authors": [
        "Alebachew Chiche",
        "Betselot Yitagesu"
      ],
      "year": "2022",
      "venue": "Journal of Big Data",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "The data provenance initiative: A large scale audit of dataset licensing & attribution in ai",
      "authors": [
        "Shayne Longpre",
        "Robert Mahari",
        "Anthony Chen",
        "Naana Obeng-Marnu",
        "Damien Sileo",
        "William Brannon",
        "Niklas Muennighoff",
        "Nathan Khazam",
        "Jad Kabbara",
        "Kartik Perisetla"
      ],
      "year": "2023",
      "venue": "The data provenance initiative: A large scale audit of dataset licensing & attribution in ai",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Llm dataset inference: Did you train on my dataset? arXiv preprint",
      "authors": [
        "Pratyush Maini",
        "Hengrui Jia",
        "Nicolas Papernot",
        "Adam Dziedzic"
      ],
      "year": "2024",
      "venue": "Llm dataset inference: Did you train on my dataset? arXiv preprint",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "The Heap: A Contamination-Free Multilingual Code Dataset For Evaluating Large Language Models",
      "text": "Jonathan Katzy _Delft University of Technology Delft University of Technology Delft, The Netherlands_ 0009-0005-9574-2414 Razvan Mihai Popescu _Delft University of Technology Delft University of Technology Delft, The Netherlands_ 0009-0003-6251-770X Arie van Deursen _Delft University of Technology Delft University of Technology Delft, The Netherlands_ 0009-0003-6251-770X Malieh Izadi Delft, The Netherlands 0000-0003-4850-3312"
    },
    {
      "title": "Abstract",
      "text": "The recent rise in the popularity of large language models has spurred the development of extensive code datasets needed to train them. This has left limited code available for collection and use in the downstream investigation of specific behaviors, or evaluation of large language models without suffering from data contamination. To address this problem, we release _The Heap_, a large multilingual dataset covering \\(57\\) programming languages that has been deduplicated with respect to other open datasets of code, enabling researchers to conduct fair evaluations of large language models without significant data cleaning overhead. Dataset, Evaluation, Large Language Models, Open Science, Data Contamination, Multilingual"
    },
    {
      "title": "I Introduction",
      "text": "The data-intensive training process of Large Language Models (LLMs) has driven the release of numerous large-scale datasets, particularly for code, to facilitate the development of new models. This rapid increase in the amount of training data used to pre-train LLMs has resulted in extensive datasets covering almost all publicly available code [1, 2, 3]. To assess the success of such LLMs in downstream tasks, _fresh_ data not seen during training is needed. Otherwise such evaluations are _contaminated_, possibly resulting in overly optimistic results. Unfortunately, obtaining such non-contaminated data is increasingly difficult. In fact, a recent study establishes that only 10% of investigations involving LLMs deduplicate their data with respect to the training data in order to avoid contamination [4]. To address this, we propose _The Heap_, a dataset of not previously used code that can be used for contamination-free multilingual evaluation of LLMs in downstream tasks. We address contamination in two ways. First, we select code with a _non-permissive_ license, such as the GNU General Public License. Using such code for _training_ is unattractive, as it may require the end user to publicly release _all_ code in their code bases. Second, we pre-conduct computationally expensive near and exact _deduplication_, removing code that is used in other datasets widely used for training such as The Stack [1]."
    },
    {
      "title": "Ii Collection",
      "text": "Using the search API, we collect our dataset from GitHub, a commonly used online platform for sharing code repositories. This collection process mimics the data distribution of other large-scale datasets [5, 3, 6, 7, 8], minimizing the probability of including confounding factors in the dataset, such as drifts in the representations of data [9]."
    },
    {
      "title": "_Programming Languages_",
      "text": "We aim to compile a representative dataset that encompasses a wide range of programming languages. To achieve this, we select languages based on several criteria. Our selection includes languages with diverse syntactic structures, such as LISP, C, Python, Haskell, and Assembly. We also select different programming paradigms, such as COBOL, Pascal, and C for procedural languages, Java, C#, Python, for object-oriented languages, and Haskell and Clojure for functional languages. To cover more specific use cases, we also include domain-specific languages such as Mathematica, Emacs-Lisp, and Coq. A complete list of all languages included in the dataset is presented in Table I."
    },
    {
      "title": "_Query_",
      "text": "We focus on repositories that have one of the targeted languages as the main language of the repository. We further select only repositories that are licensed under non-permissive licenses. We choose non-permissive licenses as an initial filter for repositories, as many large-scale datasets focus on exclusively unlicensed or permissively licensed code [2, 3, 5]. The reasons for the exclusion of non-permissively licensed code in other datasets come from potential licensing issues that may be related to the output of models trained on non-permissively licensed data [10]. _The Heap_ is not intended for pre-training models that are aimed at end users, but rather for exclusive use in a research setting. The inclusion of exclusively non-permissively licensed code has the added benefit that it acts as a deterrent for developers to train LLMs on _The Heap_, ensuring it remains a relevant source of data for downstream tasks. We provide an overview of the licenses used in this work in Table II."
    },
    {
      "title": "_Scraping_",
      "text": "For each programming language, we scrape up to 50,000 repositories or as many as are available. Our dataset contains code from repositories created between January 2008 and August 2024. For each selected language, we extract repositories sorted by star count in descending order; this has been used as a loose quality metric before [11]. Tomaximize extraction efficiency and avoid GitHub's rate limits, we employ pagination and repository creation date filtering. When the number of repositories within a specified time frame exceeds the rate limit, we narrow the time interval and apply a tumbling window approach to ensure comprehensive coverage. We guide the file extraction based on a list of file extensions from The Stack [5]."
    },
    {
      "title": "_Cleaning_",
      "text": "After collecting the data from online sources, we perform some cleaning steps. First, we exclude files containing fewer than 10 words or exceeding \\(10\\) MB in size. We also remove exact duplicates from our own dataset. We use the same approach as the exact deduplication with respect to other datasets described in Section III-A."
    },
    {
      "title": "Iii Deduplication",
      "text": "An important aspect of fairly evaluating downstream tasks is preventing data leakage [4]. This is often done through a deduplication process. Although there should be no overlap between our non-permissively licensed dataset and permissively licensed datasets due to our selection procedure, it does not completely prevent overlap [10]. Our deduplication strategy consists of exact deduplication and near deduplication. Before each deduplication strategy, we remove all comments (using a regex, based on the programming language) and whitespace from each file. This ensures that small changes to files, such as the removal of a license comment or changes in whitespace characters, still result in the detection of an exact duplicate. The final files included in _The Heap_ are the unaltered versions scraped from GitHub. Exact DeduplicationFor exact deduplication, we calculate the SHA-256 hash of each file to identify exact duplicates between _The Heap_ and publicly available datasets. We selected this hash function for its low collision probability, which reduces the risk of false positives. Near DeduplicationWe also perform near-deduplication between our scraped dataset and the publicly available ones. To achieve this, we utilize the MinHash Locality-Sensitive Hashing (LSH) approach, implemented using the datasketch2 library. We apply the same SHA-256 hashing function as before, with \\(128\\) permutations and a precision-recall weight distribution of \\(40\\%-60\\%\\). These design choices help mitigate hash collisions while maintaining a balanced trade-off, hence favoring higher recall at the expense of a controlled increase in false positives (removing files that were not duplicates). Footnote 2: [https://ekzhu.com/datasetetch/lsh.html](https://ekzhu.com/datasetetch/lsh.html) We use a single size of \\(7\\) characters, as code files typically use a smaller set of characters compared to large research articles, where \\(k=9\\)[12]. This reduces the likelihood of overly common singles, which could otherwise inflate similarity scores, as would occur with smaller values of \\(k\\). Files with a Jaccard similarity above \\(0.7\\) are flagged as near duplicates, a threshold shown to be effective for duplicate detection [13]. We identify and flag duplicates between our dataset and all publicly available datasets to facilitate a more flexible approach to LLM evaluation, prioritizing both reproducibility and ease of use. This setup minimizes time and computational overhead by removing the burden of duplicate detection from researchers. Users can seamlessly filter data by language or by exact and near-duplicate files, tailoring the dataset to their specific requirements. Table I provides a comprehensive summary of the languages extracted. The third column lists the number of files collected after filtering based on file size and word count. The last column indicates the number of files obtained after removing exact duplicates within our dataset, with exact and near duplicates from other datasets flagged among the remaining files. For more detailed information on the dataset creation process, please refer to the dataset page3. Footnote 3: [https://huggingface.co/datasets/WizzF/Heap-Forge](https://huggingface.co/datasets/WizzF/Heap-Forge)"
    },
    {
      "title": "_Datasets_",
      "text": "Our selection of datasets for deduplication is based on previously curated lists [10], with the addition of The Stack V2 [3], which is the only new dataset that has been released since the publication of previous works. We give an overview of all potential datasets in Table III. Due to the comment removal being based on the programming languages of the files, we are not able to infer the correct language for two datasets. The Pile [6], which has been removed and re-uploaded, has lost information about the programming language of a file. Furthermore, due to a known issue with the curation of CodeClippy4, the languages and names of files are misaligned in the dataset. We also exclude this dataset from deduplication. Although we could predict the languages used in the files in these datasets, the tools that provide this functionality do return incorrect predictions, which could result in a duplicate not being removed. As we aim to provide a guarantee that there is no data contamination in our dataset, we remove these two datasets from consideration. Footnote 4: [https://github.com/CodedO4/fypt-code-clippy/issues/71](https://github.com/CodedO4/fypt-code-clippy/issues/71)"
    },
    {
      "title": "Iv Layout",
      "text": "_The Heap_ is organized into multiple subsets, each of them corresponding to one programming language. In each subset, the entries included in the dataset can be summarized into 3 groups: file content and metadata, quality indicators, and duplicates. We give an example of one entry in Figure 1. Fig. 1: Example of final dataset structure for one entry File Content and MetadataFor the file content and metadata, we list the actual content of the file, which is the main information to be used in downstream tasks. We also include information about filename and path, as this has been included in the pre-training procedure of some LLMs [3, 11, 17]. Quality IndicatorsTo facilitate the selection of files for downstream use, we incorporated several quality indicators previously utilized in related works, ensuring the dataset can be easily filtered and selected. We included numerical statistics about the file such as the _total_lines_, _avg_line_length_, _max_line_length_ and _alphanumeric fraction_, as well as repository-wide statistics such as _repo stars_, _repo forks_, _open issues_ and the _extraction date of the repo_. The repository star count will be artificially inflated for languages where more than \\(50,000\\) repositories exist, due to the ordering of the repositories in the collection steps. DuplicatesAs we deduplicate _The Heap_ with respect to a number of other publicly available datasets, we incorporate two columns for every dataset. One column contains a Boolean value, whether there is an exact duplicate of the given file in the dataset, and the other column contains a Boolean value describing whether there is a near duplicate of the given file in the dataset. We choose not to remove files but to use a Boolean mask in order to maximize the amount of available data for each available dataset."
    },
    {
      "title": "V Future Improvements",
      "text": "In future iterations of this dataset, several potential improvements could be made. These include enhancing the deduplication process, releases of new training datasets, providing detailed information about the natural languages represented in the dataset, and tracking the evolution of codebases. New DatasetsThe main goal of this dataset is to reduce the burden of deduplicating a dataset used for downstream tasks for future research. This is only effective if the dataset is deduplicated against all available datasets. As new datasets are released we intend to pass them through the same pipeline to ensure _The Heap_ remains relevant for the future. DeduplicationWe addressed the deduplication of datasets using two widely adopted methods: exact deduplication based on hashing and near-deduplication leveraging locality-sensitive hashing. However, there is limited research on what constitutes an effective deduplication strategy. There could be issues with duplicates at a lower granularity level than file-based deduplications, as well as possible issues with the provenance of code fragments. Once studies are conducted on the impact of various deduplication approaches, we plan to incorporate these strategies as a new entry in the dataset. CleaningWe include all files that we scraped that were not duplicates, while this gives us a dataset of deduplicated files, there is still the question of file \"quality\". In NLP research, keywords have been used for filtering websites, such as lorem ipsum or TODOs [18], and code datasets have been cleaned of autogenerated files using a similar approach [3]. We believe that this may also affect the quality of code datasets. Specifically, languages that rely heavily on boiler plating, such as Java, may benefit from removing certain common phrases from their corpus. This will be included as a further filtering step in a future release of the dataset. Topic ModelingWhile languages can be used to loosely select an area that is being analyzed (Mathematica for mathematics, or JavaScript for web-based projects), many languages can be used in multiple specializations/areas. Adopting the FineWeb topic modeling approach for code datasets would create interesting annotations for the code files, as well as show any form of topic-based imbalances in the dataset. Natural LanguageAn under-explored research area involves the presence of multiple natural languages within code. As natural languages are often mixed within one file [19], we plan to adopt a Parts of Speech-like tagging [20] system for the natural languages present in each file. This can give information about the performance of code LLMs when the code is not in English. This will both help the development of non-English code LLMs, as well as aid English-focused LLMs, as they can be evaluated on only English."
    },
    {
      "title": "Vi Limitations/Challenges",
      "text": "The limitations and challenges faced by this dataset are two-fold. First, other actors may decide to train their models on this data, removing the benefits, and second, developers may object to their code being present in this dataset. We address these problems as follows. TrainingIn order to use _The Heap_ for a fair evaluation of an LLM, the researcher must be sure that the target LLM has not been trained on _The Heap_. Aside from our deduplication ensuring this fact for current existing LLMs, our collection process also adds a layer of protection from the inclusion of _The Heap_ in the training procedure. The trend of training LLMs has shifted to only training on permissively licensed data, which would exclude _The Heap_. Furthermore, the restriction of _The Heap_ to research only, alleviates the problems with author attribution in LLM generations as trained models are not intended to be used by end-users [10, 21]. Furthermore, existing works such as membership inference attacks, have been extended to the scale of entire datasets [22]. This should make it possible in the near future to retroactively test for the inclusion of _The Heap_ in the training procedures of a model. EthicsWith the rapid rise of public repositories being used to train code language models, many authors of older repositories were unaware that their code could be utilized for such purposes, leaving them unable to opt-out. Moreover, there is currently no consensus on how developers can opt in or out of having their code included in datasets. We acknowledge these ethical concerns regarding the use of code in deep learning practices and offer the ability for repository owners to opt out of having their code included in our dataset. Although this approach is not ideal, as it places the burden of exclusion on the authors, it aligns with the current best practices [3]."
    },
    {
      "title": "Vii Conclusion",
      "text": "We present _The Heap_, a multilingual dataset of source code that we deduplicated against datasets commonly used in the (pre-)training of large language models. _The Heap_ enables researchers to conduct investigations into the behavior and performance of code large language models without the need to perform extensive deduplication with other datasets. This addresses the shortcomings of LLM investigations not testing for data leakage in 90% of all investigations [4] allowing for more robust conclusions to be made. We release the dataset (only for research purposes) and outline a road map for future features such as natural language annotation, topic annotations, and further cleaning procedures to be incorporated into the dataset, to make higher-quality evaluations easier and more available for all researchers."
    },
    {
      "title": "References",
      "text": "* [1] Denis Koeckov, Raymond Li, Loubna Ben Allal, Jia Li, Chenghao Mou, Carlos Munoz Ferrandis, Yacine Jernite, Margaret Mitchell, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro von Werra, and Harm de Vries. The stack: 3 tb of permissively licensed source code, 2022. * [2] Together Computer. Redpajama: An open source recipe to reproduce llama training dataset, 2023. * [3] Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-Foiretti, Noumarane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei, et al. Starcoder 2 and the stack v2: The next generation. _arXiv preprint arXiv:2402.19173_, 2024. * [4] Antonio Vitale, Rocco Oliveto, and Simone Scalabrino. A catalog of data smells for coding tasks. _ACM Trans. Softw. Eng. Methodol._, December 2024. Just Accepted. * [5] Denis Koeckov, Raymond Li, Loubna Ben allal, Jia Li, Chenghao Mou, Yacine Jernite, Margaret Mitchell, Carlos Munoz Ferrandis, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro Von Werra, and Harm de Vries. The stack: 3 TB of permissively licensed source code. _Transactions on Machine Learning Research_, 2023. * [6] Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et al. The pile: An 800gb dataset of diverse text for language modeling. _arXiv preprint arXiv:2101.00027_, 2020. * [7] Thomas Wolf, Leandro von Werra, and Lewis Tunstall. Codeparrot dataset. _[https://huggingface.co/datasets/transformersbook/codeparrot_](https://huggingface.co/datasets/transformersbook/codeparrot_). * [8] github-code. _[https://huggingface.co/datasets/codeparrot/github-code_](https://huggingface.co/datasets/codeparrot/github-code_). * [9] Tolga Bolukbasi, Adam Pearce, Ann Yuan, Andy Coenen, Emily Reif, Fernanda Viegas, and Martin Wattenberg. An interpretability illusion for bert. _arXiv preprint arXiv:2104.07143_, 2021. * [10] Jonathan Katzy, Razvan Popescu, Arie Van Deursen, and Maliheh Izadi. An exploratory investigation into code license infringements in large language model training datasets. In _Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering_, FORGE '24, page 74-85, New York, NY, USA, 2024. Association for Computing Machinery. * [11] Raymond Li, Loubna Ben allal, Yangtian Zi, Niklas Muennighoff, Denis Koeckov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia LI, Jenny Chim, Qian Liu, Evgeni Zhelchonzhosik, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Joel Lamy-Poiter, Joao Monteiro, Nicolas Gontier, Ming-Ho Ye, Logesh Kumar Umapathi, Jian Zhu, Ben Lipkin, Muthatham Obokulov, Zhiruo Wang, Rudra Murthy, Jason T Stillerman, Siva Sankalp Patel, Dmitry Abukhanov, Wacharo Zocco, Manan Dey, Zhihan Zhang, Ursvish Bhattachaya, Weehu Yao, Sasha Luccioni, Paulo Villegas, Fedor Zhdanov, Tony Lee, Nadav Timor, Jennifer Ding, Claire S Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Munoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro Von Werra, and Harm de Vries. Starcoder: may the source be with you! _Transactions on Machine Learning Research_, 2023. Reproducibility Certification. * [12] Jure Leskovec, Anand Rajaraman, and Jeffrey David Ullman. _Mining of Massive Datasets_. Cambridge University Press, USA, 2nd edition, 2014. * [13] Militadis Allamanis. The adverse effects of code duplication in machine learning models of code. In _Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software_, Onward! 2019, page 143-153, New York, NY, USA, 2019. Association for Computing Machinery. * [14] software heritage. _[https://docs.softwareheritage.org/index.html_](https://docs.softwareheritage.org/index.html_). * [15] garchive. _[https://www.harchris.org/_](https://www.harchris.org/_). * [16] google bigquery. _[https://cloud.google.com/bigquery/public-data_](https://cloud.google.com/bigquery/public-data_). * [17] CodeGemma Team, Heri Zhao, Jeffrey Hui, Joshua Howland, Nam Nguyen, Siqi Zuo, Andrea Hu, Christopher A Choquette-Choo, Jingyue Shen, Joe Kelley, et al. Codecgemma: Open code models based on gemma. _arXiv preprint arXiv:2406.11409_, 2024. * [18] Jesse Dodge, Maarten Sap, Ana Marasovic, William Agnew, Gabriel Illarco, Dirk Groeneveld, Margaret Mitchell, and Matt Gardner. Documenting large webster corpora: A case study on the colossal clean crawled corpus. _arXiv preprint arXiv:2104.08758_, 2021. * [19] Timo Pawelka and Elmar Juergens. Is this code written in english? a study of the natural language of comments and identifiers in practice. In _2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)_, pages 401-410. IEEE, 2015. * [20] Altebachev Chiche and Betsidev Tirages. Part of speech tagging: a systematic review of deep learning and machine learning approaches. _Journal of Big Data_, 9(1):10, 2022. * [21] Shayne Longpre, Robert Mahari, Anthony Chen, Naana Obeng-Marnu, Danjen Sileo, William Branon, Niklas Muennighoff, Nathan Khazam, Jad Kabbara, Kartik Perisetla, et al. The data provenance initiative: A large scale audit of dataset licensing & attribution in ai. _arXiv preprint arXiv:2310.16787_, 2023. * [22] Pratyush Maini, Hengrui Jia, Nicolas Papernot, and Adam Dziedzic. Llim dataset inference: Did you train on my dataset? _arXiv preprint arXiv:2406.06443_, 2024."
    }
  ]
}
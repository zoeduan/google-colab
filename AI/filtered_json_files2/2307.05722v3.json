{
  "title": "Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations",
  "authors": [
    "Likang Wu",
    "Zhaopeng Qiu",
    "Zhi Zheng",
    "Hengshu Zhu",
    "Enhong Chen"
  ],
  "abstract": "\n Large Language Models (LLMs) have revolutionized natural language processing tasks, demonstrating their exceptional capabilities in various domains. However, their potential for graph semantic mining in job recommendations remains largely unexplored. This paper focuses on unveiling the capability of large language models in understanding behavior graphs and leveraging this understanding to enhance recommendations in online recruitment, including promoting out-of-distribution (OOD) applications. We present a novel framework that harnesses the rich contextual information and semantic representations provided by large language models to analyze behavior graphs and uncover underlying patterns and relationships. Specifically, we propose a meta-path prompt constructor that aids LLM recommender in grasping the semantics of behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias introduced by path-based sequence input. By facilitating this capability, our framework enables personalized and accurate job recommendations for individual users. We evaluate the effectiveness of our approach on comprehensive real-world datasets and demonstrate its ability to improve the relevance and quality of recommended results. This research not only sheds light on the untapped potential of large language models but also provides valuable insights for developing advanced recommendation systems in the recruitment market. The findings contribute to the growing field of natural language processing and offer practical implications for enhancing job search experiences. We release the code â€¡ . \n",
  "references": [
    {
      "id": null,
      "title": "Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations",
      "authors": [
        "Likang Wu",
        "Zhaopeng Qiu",
        "Zhi Zheng",
        "Hengshu Zhu",
        "Enhong Chen"
      ],
      "year": "2023",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation",
      "authors": [
        "K Bao",
        "J Zhang",
        "Y Zhang",
        "W Wang",
        "F Feng",
        "X He"
      ],
      "year": "2023",
      "venue": "TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Learning to match jobs with resumes from sparse interaction data using multi-view co-teaching network",
      "authors": [
        "S Bian",
        "X Chen",
        "W X Zhao",
        "K Zhou",
        "Y Hou",
        "Y Song",
        "T Zhang",
        "J.-R Wen"
      ],
      "year": "2020",
      "venue": "Proceedings of the 29th ACM International Conference on Information & Knowledge Management",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems",
      "authors": [
        "Z Cui",
        "J Ma",
        "C Zhou",
        "J Zhou",
        "H Yang"
      ],
      "year": "2022",
      "venue": "M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers",
      "authors": [
        "D Dai",
        "Y Sun",
        "L Dong",
        "Y Hao",
        "Z Sui",
        "F Wei"
      ],
      "year": "2022",
      "venue": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "",
      "authors": [
        "Corr"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "Beyond matching: Modeling two-sided multibehavioral sequences for dynamic person-job fit",
      "authors": [
        "B Fu",
        "H Liu",
        "Y Zhu",
        "Y Song",
        "T Zhang",
        "Z Wu",
        "Springer",
        "Y Hou",
        "J Zhang",
        "Z Lin",
        "H Lu",
        "R Xie",
        "J J Mcauley",
        "W X Zhao"
      ],
      "year": "2021",
      "venue": "Database Systems for Advanced Applications: 26th International Conference",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "Lora: Low-rank adaptation of large language models",
      "authors": [
        "E J Hu",
        "Y Shen",
        "P Wallis",
        "Z Allen-Zhu",
        "Y Li",
        "S Wang",
        "L Wang",
        "W Chen"
      ],
      "year": "2021",
      "venue": "Lora: Low-rank adaptation of large language models",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "Heterogeneous graph transformer",
      "authors": [
        "Z Hu",
        "Y Dong",
        "K Wang",
        "Y Sun"
      ],
      "year": "2020",
      "venue": "Proceedings of the web conference 2020",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "BELLE: Be Everyone's Large Language model Engine",
      "authors": [
        "Y Ji",
        "Y Deng",
        "Y Gong",
        "Y Peng",
        "Q Niu",
        "B Ma",
        "X Li"
      ],
      "year": "2023",
      "venue": "BELLE: Be Everyone's Large Language model Engine",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "Knowledge-Aware Cross-Semantic Alignment for Domain-Level Zero-Shot Recommendation",
      "authors": [
        "J Jiang",
        "H Zhao",
        "M He",
        "L Wu",
        "K Zhang",
        "J Fan"
      ],
      "year": "2023",
      "venue": "Proceedings of the 32nd ACM International Conference on Information and Knowledge Management",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction",
      "authors": [
        "W Kang",
        "J Ni",
        "N Mehta",
        "M Sathiamoorthy",
        "L Hong",
        "E H Chi",
        "D Z Cheng"
      ],
      "year": "2023",
      "venue": "Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Personalized Job Recommendation System at LinkedIn: Practical Challenges and Lessons Learned",
      "authors": [
        "K Kenthapadi",
        "B Le",
        "G Venkataraman",
        "D P Kingma",
        "J Ba"
      ],
      "year": "2014",
      "venue": "Proceedings of the Eleventh ACM Conference on Recommender Systems",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Towards effective and interpretable person-job fitting",
      "authors": [
        "R Le",
        "W Hu",
        "Y Song",
        "T Zhang",
        "D Zhao",
        "R Yan"
      ],
      "year": "2019",
      "venue": "Proceedings of the 28th ACM International Conference on Information and Knowledge Management",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "Resumegan: An optimized deep representation learning framework for talent-job fit via adversarial learning",
      "authors": [
        "Y Liu",
        "M Ott",
        "N Goyal",
        "J Du",
        "M Joshi",
        "D Chen",
        "O Levy",
        "M Lewis",
        "L Zettlemoyer",
        "V Stoyanov",
        "Y Lu",
        "S El Helou",
        "D Gillet",
        "Y Luo",
        "H Zhang",
        "Y Wen",
        "X Zhang"
      ],
      "year": "2013",
      "venue": "Proceedings of the 28th ACM international conference on information and knowledge management",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "What does BERT know about books, movies and music? Probing BERT for Conversational Recommendation",
      "authors": [
        "G Penha",
        "C Hauff",
        "Acm",
        "C Qin",
        "H Zhu",
        "T Xu",
        "C Zhu",
        "L Jiang",
        "E Chen",
        "H Xiong"
      ],
      "year": "2018",
      "venue": "The 41st international ACM SIGIR conference on research & development in information retrieval",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "U-BERT: Pretraining User Representations for Improved Recommendation",
      "authors": [
        "Z Qiu",
        "X Wu",
        "J Gao",
        "W Fan"
      ],
      "year": "2021",
      "venue": "AAAI",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "Towards deep and representation learning for talent search at linkedin",
      "authors": [
        "R Ramanath",
        "H Inan",
        "G Polatkan",
        "B Hu",
        "Q Guo",
        "C Ozcaglar",
        "X Wu",
        "K Kenthapadi",
        "S C Geyik"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th ACM International Conference on Information and Knowledge Management",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "A joint learning approach to intelligent job interview assessment",
      "authors": [
        "D Shen",
        "H Zhu",
        "C Zhu",
        "T Xu",
        "C Ma",
        "H Xiong"
      ],
      "year": "2018",
      "venue": "IJCAI",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Contrastive user model pre-training",
      "authors": [
        "C Wu",
        "F Wu",
        "Y Yu",
        "T Qi",
        "Y Huang",
        "X Xie"
      ],
      "year": "2021",
      "venue": "Contrastive user model pre-training",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "Learning the implicit semantic representation on graph-structured data",
      "authors": [
        "L Wu",
        "Z Li",
        "H Zhao",
        "Q Liu",
        "J Wang",
        "M Zhang",
        "E Chen"
      ],
      "year": "2021",
      "venue": "Database Systems for Advanced Applications: 26th International Conference, DAS-FAA 2021",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "A Survey on Large Language Models for Recommendation",
      "authors": [
        "L Wu",
        "Z Zheng",
        "Z Qiu",
        "H Wang",
        "H Gu",
        "T Shen",
        "C Qin",
        "C Zhu",
        "H Zhu",
        "Q Liu"
      ],
      "year": "2023",
      "venue": "A Survey on Large Language Models for Recommendation",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Interview Choice Reveals Your Preference on the Market: To Improve Job-Resume Matching through Profiling Memories",
      "authors": [
        "R Yan",
        "R Le",
        "Y Song",
        "T Zhang",
        "X Zhang",
        "D Zhao"
      ],
      "year": "2019",
      "venue": "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "Modeling Two-Way Selection Preference for Person-Job Fit",
      "authors": [
        "C Yang",
        "Y Hou",
        "Y Song",
        "T Zhang",
        "J.-R Wen",
        "W X Zhao"
      ],
      "year": "2022",
      "venue": "Sixteenth ACM Conference on Recommender Systems",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "Untargeted attack against federated recommendation systems via poisonous item embeddings and the defense",
      "authors": [
        "Y Yu",
        "Q Liu",
        "L Wu",
        "R Yu",
        "S L Yu",
        "Z Zhang"
      ],
      "year": "2023",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach",
      "authors": [
        "J Zhang",
        "R Xie",
        "Y Hou",
        "W X Zhao",
        "L Lin",
        "J Wen"
      ],
      "year": "2023",
      "venue": "Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "Prompt Learning for News Recommendation",
      "authors": [
        "Z Zhang",
        "B Wang"
      ],
      "year": "2023",
      "venue": "Prompt Learning for News Recommendation",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Cross-Domain Recommendation via Progressive Structural Alignment",
      "authors": [
        "C Zhao",
        "H Zhao",
        "X Li",
        "M He",
        "J Wang",
        "J Fan"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Knowledge and Data Engineering",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Generative Job Recommendations with Large Language Model",
      "authors": [
        "Z Zheng",
        "Z Qiu",
        "X Hu",
        "L Wu",
        "H Zhu",
        "H Xiong"
      ],
      "year": "2023",
      "venue": "Generative Job Recommendations with Large Language Model",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Exploring Large Language Model For Graph Data Understanding",
      "text": "in Online Job Recommendations Likang Wu,\\({}^{1,2}\\) Zhaopeng Qiu,\\({}^{2}\\) Zhi Zheng,\\({}^{1,2}\\) Hengshu Zhu,\\({}^{2}\\) Enhong Chen,\\({}^{1}\\) Corresponding Author. \\({}^{1}\\) University of Science and Technology of China \\({}^{2}\\) Career Science Lab, BOSS Zhipin {wulk,zhengzhi97}@mail.ustc.edu.cn, {zhpengqiu,zhuhengshu}@gmail.com, cheneh@ustc.edu.cn"
    },
    {
      "title": "Abstract",
      "text": "Large Language Models (LLMs) have revolutionized natural language processing tasks, demonstrating their exceptional capabilities in various domains. However, their potential for graph semantic mining in job recommendations remains largely unexplored. This paper focuses on unveiling the capability of large language models in understanding behavior graphs and leveraging this understanding to enhance recommendations in online recruitment, including promoting out-of-distribution (OOD) applications. We present a novel framework that harnesses the rich contextual information and semantic representations provided by large language models to analyze behavior graphs and uncover underlying patterns and relationships. Specifically, we propose a meta-path prompt constructor that aids LLM recommender in grasping the semantics of behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias introduced by path-based sequence input. By facilitating this capability, our framework enables personalized and accurate job recommendations for individual users. We evaluate the effectiveness of our approach on comprehensive real-world datasets and demonstrate its ability to improve the relevance and quality of recommended results. This research not only sheds light on the untapped potential of large language models but also provides valuable insights for developing advanced recommendation systems in the recruitment market. The findings contribute to the growing field of natural language processing and offer practical implications for enhancing job search experiences. We release the code1. Footnote 1: [https://github.com/WLiK/GLRec](https://github.com/WLiK/GLRec)"
    },
    {
      "title": "Introduction",
      "text": "Online recruitment recommendations aim to suggest relevant job opportunities to job seekers based on their preferences and qualifications, improving the chances of matching the right employment. With the exponential growth of online recruitment platforms and the need for efficient and personalized job search experiences, the development of effective job recommendation systems has become crucial. In online recruitment systems, job postings and resumes are written in natural language. Traditional approaches have treated job-resume matching as a supervised text-matching problem using paired data for training Qin et al. (2018); Shen et al. (2018). However, online recruitment platforms often suffer from sparse interaction data, with job postings attracting only a few candidates on average Ramanath et al. (2018). To address this, recent studies Bian et al. (2020); Yang et al. (2022) have explored the use of behavior graphs to capture high-order interactions and alleviate the sparse interaction issue. These behavior graphs leverage message passing to enhance the understanding of user preferences. Unlike many general recommendation tasks, it is easy to find that textual understanding forms the backbone of job recommendation, and behavior modeling contributes to the personalized module. In our work, we strive to overcome the accuracy limitations of job recommenders by enhancing the semantic richness of textual representations. Inspired by several recent successful recommendations based on text pre-training Wu et al. (2023), we introduce a large language model (LLM) as the foundational framework for job recommendation that directly generates targets. Adopting this approach is not only beneficial but also intuitive. For instance, out-of-distribution items usually appear in recruitment markets since new job demands are constantly emerging, such as prompt engineers for generative models. This issue is more complex than traditional cross-domain tasks Zhao et al. (2023); Jiang et al. (2023); Yu et al. (2023). The powerful semantic mining ability and extensive external knowledge of LLMs augment the generation and associative power of recommenders, which is able to generate reasonable recommendation results for the hard OOD items. However, the existing learning schema of LLM recommender cannot understand the non-textual behavior graph which weakens the personalized recommendation ability for different job seekers. To tackle this challenge, we propose a meta-path prompt constructor to encode the interaction information of graph into the natural language prompt. Specifically, in such a heterogeneous behavior graph, each meta-path composed of various types of nodes and edges can be transferred into a description naturally since each type indicates a specific and meaningful interaction, e.g., interview, conversation, etc. Along this line, for each job seeker, the LLM captures the high-order interaction feature to augment her personality with the meta-path prompt. Based on the above analysis, we explore the inclusion of graph data understanding in large language model-based recommendations for the first time. An efficient large language model named GLRec (Graph-understanding LLM Recommender) is proposed to optimize the recommended quality of job recommendation, which is fine-tuned with LoRa [12] on our constructed instruction dataset for aligning the gap between pre-trained knowledge and actual recruitment domain. Especially, our exploration presents two valuable and important findings that largely influence the graph understanding strategy of LLM: (i). Different paths would present different weights for the model decision. (ii). The position bias of the order of path prompts brings unstable answers. For these issues, we carefully design path shuffling, adaptive path selector, and their hybrid path augmentation mechanism to mitigate the adverse effects posed by varying path prompts. The main contributions could be summarized as follows: * To our best knowledge, we are the first to implement the fine-tuned large language model as job recommender, which promotes matching accuracy via the semantic richness and massive knowledge of LLM. * We propose the meta-path prompt constructor that leverages LLM recommender to comprehend behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias. * We conduct sufficient experiments on real-world recruitment datasets, and the experimental results and visualization cases show the superiority of our model."
    },
    {
      "title": "Related Work",
      "text": ""
    },
    {
      "title": "Job Recommendation",
      "text": "Job Recommendation, especially job-resume matching is a necessary task in online recruitment, and it has been extensively studied in the literature [13]. Early methods handled this problem [12] relying on collaborative filtering assumptions. However, recent research focused more on text-matching technology. Various techniques have been proposed to encode job and resume information. For example, [2] utilized CNN for encoding, while [14] leveraged RNN and BiLSTM to capture sequential information. [20] introduced a profiling memory to learn latent preference representation by interacting with both job and resume. [15] explored the effectiveness of adversarial training for job-resume matching. In addition to the aforementioned research, there were also researches that considered multi-granularity interactions. The ranking-based loss can be used to capture multi-level interactions as supervision signals [16]. [17] proposed a bilateral multi-behavior sequence model to describe users' dynamic preferences. These approaches highlighted the importance of considering various interaction patterns and incorporating additional user information to improve the quality of job recommendations. However, online recruitment platforms frequently encounter challenges due to sparse interaction data, resulting in job postings attracting only a limited number of candidates on average [1]. Recent studies [18, 20] have investigated the utilization of behavior graphs to capture high-order interactions and alleviate the problem of sparse interactions."
    },
    {
      "title": "Large Language Models For Recommendation",
      "text": "LLMs offer the potential to extract high-quality representations of textual features and leverage extensive external knowledge to enhance recommendation systems. [19] conducted a systematic review and analysis of existing LLM-based recommendation systems. Existing work can be divided into two categories: discriminative models and generative models. Most discriminative models align the representations of pre-trained models like BERT with domain-specific data through fine-tuning. For example, [19, 18] proposed pre-training and fine-tuning-based approach to learn users' representation, which leveraged content-rich domains to complement those users' features with insufficient behavior data. Additionally, some research explored training strategies like prompt tuning. [10] leveraged BERT's Masked Language Modeling (MLM) head to uncover its understanding of item genres using cloze-style prompts. Prompt4NR [18] pioneered the application of the prompt learning paradigm for news recommendation. Generative models usually translate recommendation tasks as natural language tasks, and then apply techniques such as in-context learning [12, 13], prompt tuning [14, 15], and instruction tuning [18, 19] to adapt LLMs to directly generate the recommendation results. Compared to discriminative models, generative models have better natural language generation capabilities. In the recruitment area, there was a generative model which developed LLM with RLHF to generate potential JDs for more explainable recommendations [18]. However, despite their successes, LLM recommenders have a glaring limitation: they lack the ability to comprehend graph data, which impedes their potential for personalized adaptation."
    },
    {
      "title": "Methodology",
      "text": "In this section, the technical detail of GLRec in Figure 1 would be introduced progressively."
    },
    {
      "title": "Preliminary",
      "text": ""
    },
    {
      "title": "Problem Formulation",
      "text": "Consider a set of candidates \\(C=\\{c_{1},c_{2},\\dots,c_{n_{1}}\\}\\) and a set of jobs \\(\\mathcal{J}=\\{j_{1},j_{2},\\dots,j_{n_{2}}\\}\\), where \\(n_{1}\\) and \\(n_{2}\\) represent the total number of candidates (job seekers) and jobs, respectively. Each candidate and job are associated with textual documents that describe their resumes and job requirements. They are also linked to a collection of directed interaction records (such as interviewing and discussing) within the recruitment platform. These interactions are formally represented as \\(\\mathcal{A}c_{i}=\\{c_{i}\\to j^{\\prime}|c_{i}\\in C,j^{\\prime}\\in\\mathcal{J}\\}\\) and \\(\\mathcal{A}j_{k}=\\{j_{k}\\to c^{\\prime}|j_{k}\\in\\mathcal{J},c^{\\prime}\\in C\\}\\), indicating the directed interactions initiated by candidate \\(c_{i}\\) or employer \\(j_{k}\\) (referred to as a job). Our objective is to predict the compatibility between a job posting and a candidate."
    },
    {
      "title": "Generative Large Language Models",
      "text": "Generative LLMs are powerful language models capable of generating coherent and contextually relevant text. Models like GPT-3 and GPT-4 are trained on vast amounts of text data, enabling them to produce human-like text in response to a given prompt or input. Fine-tuning is a common adaption strategy to align the target of pre-trained model and domain-specific applications, such as two popular paradigms of prompt tuning, and instruction tuning. For all these tuning methods, they have an equal final objective loss of autoregressive training as follows: \\[\\mathcal{L}_{f}=\\max_{\\Theta}\\sum_{(x,y)\\in\\mathcal{T}}\\sum_{t=1}^{|y|}\\log \\left(\\mathcal{P}_{\\Theta}\\left(y_{t}\\mid x,y_{<t}\\right)\\right), \\tag{1}\\] Taking instruction tuning as an example, which designs and constructs instruction data to restrict the output scope and format. \\(x\\) and \\(y\\) represent the \"Instruction Input\" and \"Instruction Output\" in the self-instruct data, respectively, e.g., _Instruction Input: \"Do you like this item?\", Instruction Output: \"Yes.\"_. And \\(y_{t}\\) is the \\(t\\)-th token of the \\(y\\), \\(y_{<t}\\) represents the tokens before \\(y_{t}\\), \\(\\Theta\\) is the original parameters of LLM, and \\(\\mathcal{T}\\) is the training set."
    },
    {
      "title": "Task-Specific Instruction",
      "text": "In our work, we design two job recommendation tasks to test the LLM recommender following existing related work [1], i.e., point-wise and pair-wise job matching. Here we introduce our designed template for the sample in our dataset, where information related to privacy and business has been filtered. Assume there is a job seeker called candidate whose Candidate Profile Prompt and recommended JD Prompt are defined as: **Candidate Profile Prompt:**_Age: 25, Education: Bachelor's degree, Graduation School: XXX University, Major: Computer Applied Science, Work Experience: 2 years_. **JD Prompt:**_Position Title: Full Stack Engineer, Educational Requirement: Bachelor's degree, Work Experience: 1-3 years, Skill Requirements: HTML/JAVA/Spring Boot/SQL._ For the point-wise task, we let the LLM recommender learn to predict the satisfaction of a candidate with a recommended job. The instruction is designed as: **Point-wise Instruction:**_You are a recommender, determining whether a candidate would be satisfied with the recommended job position. Please answer with \"Yes.\" or \"No.\"_. For the pair-wise task, we let the LLM recommender learn to justify the preference of a candidate for a recommended job pair. Given two jobs' JD Prompt \"A\" and \"B\", the instruction is designed as: **Pair-wise Instruction:**_You are a recommender, determining which position will match the candidate. Please answer with \"[A].\" or \"[B].\"_. With the above-designed prompts and instruction, LLM is able to adapt to a domain recommendation situation. Note that, to ensure the stability of training, we append the JD prompt to the end of the ground truth to increase the predicted length. To further fuse interaction knowledge, in the next section, we will illustrate the understanding part of graph data for LLM: behavior meta-path prompt generation."
    },
    {
      "title": "Behavior Meta-Path Prompt Generation",
      "text": "To equip LLM with the ability to comprehend interactive relationships in graph data, we propose a meta-path-based prompt constructor to obtain prompt inputs that represent local subgraphs. Before delving into the details of our approach, it is necessary to provide a formal introduction to heterogeneous graph and meta-path [23]. **Definition 1**.: _Heterogeneous Graph. \\(\\mathcal{G}=(V,E),\\) consists of an object set \\(V\\) and a link set \\(E\\). \\(\\mathcal{G}\\) is also associated with a node type mapping function \\(\\phi:V\\rightarrow\\mathcal{V}\\) and a link type mapping function \\(\\psi:E\\rightarrow\\mathcal{E}\\). \\(\\mathcal{V}\\) and \\(\\mathcal{E}\\) denote the sets of predefined object types and link types, where \\(|\\mathcal{V}|+|\\mathcal{E}|>2\\)._ **Definition 2**.: _Meta-path. A meta-path \\(P\\) is defined as a path in the form of \\(\\mathcal{V}_{1}\\xrightarrow{\\mathcal{E}_{1}}\\mathcal{V}_{2}\\xrightarrow{ \\mathcal{E}_{2}}\\cdots\\xrightarrow{\\mathcal{E}_{l}}\\mathcal{V}_{l+1}\\) (abbreviated as \\(\\mathcal{V}_{1}\\mathcal{V}_{2}\\cdots\\mathcal{V}_{l+1}\\)), which describes a composite relation \\(\\mathcal{E}_{1}\\circ\\mathcal{E}_{2}\\circ\\cdots\\circ\\mathcal{E}_{l}\\) between objects \\(\\mathcal{V}_{1}\\) and \\(\\mathcal{V}_{l+1}\\), where \\(\\circ\\) denotes the composition operator on relations._ Figure 1: The framework of GLRec for job recommendation. Heterogeneous graphs are more diverse and complex in terms of their semantics compared to homogeneous graphs. Meta-paths are commonly used techniques to mine and represent the interaction semantics within them. In the context of online recruitment, the interactions between job seekers and job positions, which involve different types of behaviors, form a behavior graph. This behavior graph is a typical heterogeneous graph, where different node types include Candidate, JD, and different edge types include messaging, interviewing, matching, and more. Due to the unique and defined semantics of each type of edge in the behavior graph, it is natural to consider transferring the graph data format meta-path to a natural language description which is acceptable for the large language model. We only need to predefine the prompt template according to the appeared edges in a path and then fill in the template with the resume or job description information. For instance, given a typical meta-path \\(c_{1}\\xrightarrow{interview}j_{1}\\xrightarrow{message}c_{2}\\). The prompt template is constructed as: **Meta-path Prompt: \\(c_{1}\\)**_interviewed for position \\(j_{1}\\). This position discussed with a job seeker \\(c_{2}\\)._ The node information, i.e., the description of candidates or JD, then will be filled in the meta-path prompt template to generate the final prompt data in our dataset. The real case can be referred to in Figure 2. In addition, to avoid too similar meta-paths leading to redundancy, we define a simple similarity metric as follows, \\[\\mathcal{S}_{i,j}=\\frac{\\left|P_{i}\\cap P_{j}\\right|}{\\left|P_{i}\\cup P_{j} \\right|},\\quad P_{i},P_{j}\\in\\Phi_{P}, \\tag{2}\\] where \\(\\Phi_{P}\\) denotes the set of sampled paths for a candidate. \\(P_{i}\\), \\(P_{j}\\) indicates two meta-paths in \\(\\Phi_{P}\\). \\(\\left|P_{i}\\cap P_{j}\\right|\\) is the number of tokens that exist simultaneously in two paths, \\(P_{i}\\cup P_{j}\\) is the union of them. We ensure that \\(\\mathcal{S}_{i,j}\\leq\\gamma\\) between the final selected \\(M\\) paths and \\(0\\leq\\gamma\\leq 1\\) is a hyperparameter. Path Debiasing and Soft SelectionDifferent from the traditional network embedding, sequence-based meta-path prompts would lead to two challenges for LLM to understand the candidates' behavior sub-graph. **Challenge 1. _Influence of Path Weight. Different meta-paths would present different weights for the model decision._**Challenge 2. _Position Bias of Path Prompt. The position bias of the order of path prompts brings unstable answers._** These two challenges appeared when recognizing the pre-trained large language model as a recommender, which hinders the effective modeling of semantic relationships in the graph by LLM recommendation models. To provide a more intuitive explanation, we extracted a real-world case from the log of a popular recruitment platform and visualized them in Figure 2. Specifically, for a job seeker in the IT industry, given his Candidate Profile Prompt, Meta-path Prompt 1, and Meta-path Prompt 2, we further feed the LLM with a Task-specific Instruction belonging to point-wise recommendation. The LLM recommender is expected to output the decision of \"Yes\" or \"No\" to present the preference of the candidate. Challenge 1 corresponds to Case 1 and Case 2 in this figure. We can find that the same profile and task description with different behavior meta-paths forces LLM to make different predictions. Obviously, the diversity of technology stacks in Path 1 reveals the candidate's preference for full-stack development, and compared to Path 2, the background of path-related job seeker is more close to our candidate. Therefore, for this candidate, Path 1 is evidently more important for the final decision. For Challenge 2, if we construct the input sequence as Case 3, i.e., the order is meta-path prompt 1 \\(\\rightarrow\\) meta-path prompt 2, the LLM outputs the wrong answer \"No\". But with a reverse path prompt order, the LLM is able to provide an accurate prediction. Similar to the widely known position bias of candidate items [23], the position of context prompt clearly misleads the model to generate unstable outputs. To address the negative impact of these two challenges on the recommendation results, we carefully design an augmentation module specifically for the meta-path prompt, which consists of three concise but effective strategies. The first strategy is **Shuffle Mechanism**. When preparing domain data for the model's supervised fine-tuning (SFT), for each sample that contains multiple paths, we randomly shuffle the meta-path prompts in the sample \\(m\\) times. Here \\(m\\) denotes the conducted times of shuffling. This data augmentation technique allows the model to learn semantic invariance patterns from different combinations of paths, leading to more stable results. It enhances the robustness of the model without introducing redundant information. The second strategy is **Path Soft Selector**. In this work, we regard the path sampling process in Behavior Meta-path Prompt Generation as a hard selection to heuristic selects semantically rich paths. The Path Soft Selector is used to further adaptively assign a learned weight distribution to the constructed meta-path prompts. Firstly, for a given meta-path prompt \\(\\mathcal{M}_{i},i\\in\\{1,2,...,M\\}\\) (\\(M\\) denotes the number of paths), we obtain the LLM word embedding \\(e_{t}\\) of each token \\(t\\in\\mathcal{M}_{i}\\). So, the meta-path embedding \\(H_{i}\\) of \\(\\mathcal{M}_{i}\\) can be Figure 2: The real cases of path weight and position bias of meta-path prompt input for LLM. obtained via a mean pooling as follows, \\[H_{i}=\\frac{1}{|\\mathcal{M}_{i}|}\\sum_{t\\in\\mathcal{M}_{i}}e_{t}, \\quad i\\in\\{1,2,...,M\\}. \\tag{3}\\] Then we propose a soft selector to calculate the weight for each meta-path embedding as: \\[\\alpha_{i}=\\mathrm{softmax}(W_{a}H_{i})=\\frac{\\exp(W_{a}H_{i})}{ \\sum_{j=1}^{M}\\exp(W_{a}H_{j})}, \\tag{4}\\] where \\(W_{a}\\in\\mathcal{R}^{1\\times d_{x}}\\) is a trainable parameter, and \\(d_{e}\\) denotes the dimension of \\(E_{i}\\). To avoid the training collapse caused by changed value scale, we utilize a controller parameter \\(\\lambda\\in(0,0.5]\\) to update word embeddings in Eq. (5). \\[\\hat{e}_{t}=e_{t}+\\lambda\\cdot\\alpha_{i}e_{t},\\quad t\\in\\mathcal{M}_{i}, \\tag{5}\\] Compared with most existing tuned or non-tuned LLM models, our prompt augmentation mechanism considers phrase-based attention to distinguish different paths. Actually, this simple solution can be transferred to other similar situations, such as weighed sentence embeddings. What's more, the third strategy is the **Hybrid Mechanism** which implements Shuffle Mechanism and Path Soft Selector simultaneously. This hybrid module is expected to address the both two challenges. We will evaluate these three strategies in the experiment section."
    },
    {
      "title": "Llm Instruction Tuning And Recommendation",
      "text": "In this subsection, we will introduce the instruction tuning and recommendation process, which aims to align the used LLM with the recommendation task effectively and efficiently. For instruction tuning, we follow the general supervised fine-tuning method to minimize the autoregressive loss calculated by ground truth and corresponding LLM output. In our work, we mask the loss position of the prompt part. Specific prompt format, task-specific instruction, and ground truth have been introduced in the Preliminary section. However, direct fine-tuning of the entire model can be computationally intensive and time-consuming. To address this, we propose a lightweight fine-tuning strategy using LoRA, which involves freezing the pre-trained model parameters and introducing trainable rank decomposition matrices into each layer of the Transformer architecture. This approach facilitates lightweight fine-tuning while reducing GPU memory consumption. And the final learning objective can be computed as follows: \\[\\mathcal{L}_{f}=\\max_{\\Theta_{L}}\\sum_{(x,y)\\in\\mathcal{T}}\\sum_{t =1}^{|y|}\\log\\left(P_{\\Theta+\\Theta_{L}}\\left(y_{t}\\mid e_{x},y_{<t}\\right) \\right), \\tag{6}\\] where \\(\\Theta_{L}\\) is the LoRA parameters and we only update LoRA parameters during the training process. Note that, different from existing fine-tuning frameworks for recommendation systems, we replace their token input \\(x\\) by the embedding \\(e_{x}\\) in Eq. (6), since we update the prompt token embedding in the soft selector. As for the recommendation process, since the trained model has learned the output format of our defined ground truth after several SFT alignment steps. So our designed answer parsing is a simple way. We catch the softmax probability of label generation (the token used to denote label, such as \"Yes./No.\" or \"[A]/[B]\" in our work ) in the position of model's output corresponding to that in the ground truth. Along this line, the final prediction probability is calculated."
    },
    {
      "title": "Experiments",
      "text": ""
    },
    {
      "title": "Experimental Settings",
      "text": "Datasets.We conduct experiments on two datasets RecrX and RecrY with different scales which are collected from a real-world and large online recruitment platform in China to assess recommendation methods. The datasets were constructed from the online logs and contained two kinds of behavior: Match and Interaction, corresponding to the matching set and interaction set mentioned in Problem Formulation. Besides, each candidate (and job) is associated with a descriptive text (i.e., resume or job description). The overall statistics are shown in Table 1. From the statistical data, it can be seen that job recommendation is a sparsely interactive scenario. The segmentation ratio of the training set and testing set is 5:1. Note that all sensitive or private information has been filtered out from the data. Baseline.To provide a comprehensive evaluation of our GLRec model, we compare it against both LLM-based and related representative job recommendation methods. **RobertaRec**Liu et al. (2019): Candidate resume and JD text are encoded into fixed-length vectors using RoBERTa and then used to calculate similarity scores, enabling personalized recommendations. **HGT**Hu et al. (2020): Heterogeneous Graph Transformer is a powerful graph learning model which propagates the embeddings (initialized by RoBERTa) of candidates and jobs on graph to capture high-order interactions. **DPGNN**Yang et al. (2022): The advanced job recommender Dual-Perspective GNN incorporates two different nodes for each candidate (or job) to model the two-way selection preference. **TALLrec**Bao et al. (2023): An advanced fine-tuned LLM recommender that uses instruction tuning on self-instruct data with users' historical interactions. The original backbone of its pre-trained model is LLMA, and we change it by BELLE as the same as ours for the Chinese corpus. Evaluation Metric.We evaluate the two tasks using the conventional metric: Area Under the Receiver Operating Characteristic (AUC), as our two tasks can be transferred to binary classification problems and the metric captures the similarity between our setting and predicting user interest in a target item. We do not employ ranking-based metrics because, during the fine-tuning process, the text sequence output of LLM requires ground truth for item order sequences, which, in reality, doesn't exist. \\begin{table} \\begin{tabular}{l|c c c c} \\hline \\hline **Dataset** & **\\# Candidates** & **\\# Jobs** & **\\# Match** & **\\# Interaction** \\\\ \\hline RecrX & 12,440 & 19,318 & 23,879 & 54,147 \\\\ RecrY & 18,260 & 26,576 & 47,725 & 119,529 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 1: The statistics of datasets. **Implementation Details.** In this paper, we utilize BELLE-LLaMA-7B [11] as the pre-trained LLM backbone due to its expanded Chinese vocabulary. The instruction-tuning and model inference, using LoRa, are conducted on 4 Tesla A100 80G GPUs. To ensure consistent sequence inputs within each batch (batch size is 32), we apply padding to sequences with a maximum length of 512. Our approach incorporates the meta-path prompt and user-specific task instructions as model inputs for personalized recommendations. In our experiments, we investigate the impact of different numbers of paths, specifically \\(M\\in[0,1,2,3]\\), for GLRec, and the shuffled times \\(m=2\\) for \\(M\\geq 2\\). In our work, we select paths with 3 nodes because they offer a balance between meaningful semantics and minimal redundancy with the experimental feedback. Further details regarding the path prompt and instructions can be found in the Methodology section. Additionally, both RobertaRec and HGT have a token embedding dimension of 768, and HGT utilizes mean pooling to obtain the initial node embedding. For all methods, we optimize model parameters using the Adam [12] optimizer with a default learning rate of 1e-4, minimizing the MSE loss as the optimization objective. For the hyperparameters of update controller \\(\\lambda\\) and similarity threshold \\(\\gamma\\), we set \\(\\lambda=0.1\\) and \\(\\gamma=0.3\\) according to the experimental feedback."
    },
    {
      "title": "Performance Comparison",
      "text": "**Quantitative Comparison.** We conduct quantitative performance experiments on two datasets. As mentioned in the task definition in Section Methodology, the point-wise and pair-wise settings are implemented for evaluation. We also explore the influence of the OOD situation on different models. The experimental split settings of Random, OOD_position, and OOD_JD are introduced below: * **Random**: We randomly split the training and testing dataset based on the interaction records of each user. * **OOD_position**: The intersection on JD's \"job position\" feature between training set and testing set is empty. * **OOD_JD**: The intersection on JD items between the training set and the testing set is empty. Our experimental results are reported in Table 2. Overall, our proposed GLRec model achieves the best performance among all baselines. There are distinctive score gaps between GLRec and all baselines according to the improvement in Table 2. It demonstrates the superiority and adaptability of the large-scale model framework that incorporates relationship understanding and extensive semantic knowledge in the job recommendation scenario. What's even more exciting is that GLRec demonstrates impressive performance on OOD tasks. While its performance may decline slightly compared to the random setting, our model achieves a significant breakthrough compared to other models, which essentially results in near-random guessing. This phenomenon illustrates the necessity of utilizing knowledge association for model generalization. Going deeper into the part of baselines, the graph-based HGT and DPGNN outperform the conventional dual-tower matching model (RobertaRec) in the context of job recommendation, which further proves the significance of learning relationships. What's more, we find that most models perform better on the pair-wise task than that of point-wise task. That is to say, directly determining whether an item is suitable is more challenging than comparing its priority with another item. **Qualitative Comparison.** To give a more intuitive visualization, some qualitative comparison results produced by models are shown in Table 3, where the true (false) prediction is highlighted in blue (red) font. Specifically, the first two rows are straightforward, allowing multiple models to predict accurately. In the third row, solely using the user's profile isn't sufficient for prediction. It's crucial to note that the JAVA position (Node 1) the user interacted with aligns well with the target job in skill requirements. Consequently, only TALLrec and GLRec produced correct predictions. The final row emphasizes the significance of higher-order interactions, i.e., path, in LLM recommendations. Although there's a perceived mismatch between the candidate's finance major and the target job, interactions within the testing engineer and fintech sectors provide nuanced hints. For such complex cases, while the TALLrec model, relying on past behaviors, errs, only the GLRec model predicts correctly."
    },
    {
      "title": "The Impact Of Meta-Path Number",
      "text": "We investigate the impact of meta-path number on the effectiveness of GLRec. Here we evaluate the point-wise per \\begin{table} \\begin{tabular}{c|c|c c|c c|c c} \\hline \\hline Task & \\multicolumn{4}{c|}{Point-wise} & \\multicolumn{2}{c}{Pair-wise} \\\\ \\hline Split & Random & OOD\\_position & OOD\\_JD & Random \\\\ \\hline Dataset & RX & RY & RX & RY & RX & RX & RY \\\\ \\hline RobertaRec & 0.710 & 0.734 & 0.503 & 0.528 & 0.506 & 0.536 & 0.727 & 0.740 \\\\ HGT & 0.744 & 0.756 & 0.572 & 0.595 & 0.576 & 0.593 & 0.747 & 0.751 \\\\ DPGNN & 0.727 & 0.743 & 0.596 & 0.603 & 0.588 & 0.617 & 0.744 & 0.756 \\\\ TALLrec & 0.842 & 0.829 & 0.770 & 0.788 & 0.766\\({}^{*}\\) & 0.798\\({}^{*}\\) & 0.849\\({}^{*}\\) & 0.825\\({}^{*}\\) \\\\ **GLRec** & **0.891** & **0.876** & **0.810** & **0.843** & **0.814** & **0.852** & **0.905** & **0.883** \\\\ \\hline Improve \\(\\uparrow\\) & 18.48 & 14.14 & 25.26 & 28.39 & 26.44 & 29.88 & 15.54 & 13.24\\% \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 2: Job recommendation performance of AUC on test set, where * indicates the best result among baselines. Improve \\(\\uparrow\\) refers to the average enhancement achieved by GLRec in comparison to the baseline models. RX (RY) indicates RecrX (RecrY). Figure 3: The impact of meta-path number on model performance. [MISSING_PAGE_FAIL:7]"
    },
    {
      "title": "Acknowledgments",
      "text": "This research was partially supported by grants from National Key Research and Development Program of China (Grant No. 2021YFF0901003)."
    },
    {
      "title": "References",
      "text": "* K. Bao, J. Zhang, Y. Zhang, W. Wang, F. Feng, and X. He (2023)TALLRec: an effective and efficient tuning framework to align large language model with recommendation. CoRRabs/2305. External Links: Link, 2305.00447 Cited by: SS1. * S. Bian, X. Chen, W. X. Zhao, K. Zhou, Y. Hou, Y. Song, T. Zhang, and J. Wen (2020)Learning to match jobs with resumes from sparse interaction data using multi-view co-teaching network. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management, pp. 65-74. Cited by: SS1. * Z. Cui, J. Ma, C. Zhou, J. Zhou, and H. Yang (2022)M6-rec: generative pretrained language models are open-ended recommender systems. CoRRabs/2205.08084. External Links: Link, 2005.08084 Cited by: SS1. * D. Dai, Y. Sun, L. Dong, Y. Hao, Z. Sui, and F. Wei (2022)Why can GPT learn n-context? language models secretly perform gradient descent as meta-optimizers. CoRRabs/2212.10559. External Links: Link, 2105.0591 Cited by: SS1. * B. Fu, H. Liu, Y. Zhu, Y. Song, T. Zhang, and Z. Wu (2021)Beyond matching: modeling two-sided multi-behavioral sequences for dynamic person-job fit. In Database Systems for Advanced Applications: 26th International Conference, DASFAA 2021, Taipei, Taiwan, April 11-14, 2021, Proceedings, Part II 26, pp. 359-375. External Links: Link, 2105.08084 Cited by: SS1. * Y. Hou, J. Zhang, Z. Lin, H. Liu, R. Xie, J. J. McAuley, and W. X. Zhao (2023)Large language models are zero-shot rankers for recommender systems. CoRRabs/2305.08845. External Links: Link, 2305.08845 Cited by: SS1. * E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, and W. Chen (2021)Lora: low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685. Cited by: SS1. * Z. Hu, Y. Dong, K. Wang, and Y. Sun (2020)Heterogeneous graph transformer. In Proceedings of the web conference 2020, pp. 2704-2710. Cited by: SS1. * Y. Ji, Y. Deng, Y. Gong, Y. Peng, Q. Niu, B. Ma, and X. Li (2023)BELLE: be everyone's large language model engine. External Links: Link, 2305.08845 Cited by: SS1. * J. Jiang, H. Zhao, M. He, L. Wu, K. Zhang, and J. Fan (2023)Knowledge-aware cross-semantic alignment for domain-level zero-shot recommendation. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, pp. 965-975. Cited by: SS1. * W. Kang, J. Ni, N. Mehta, M. Sathiamoorthy, L. Hong, E. H. Chi, and D. Z. Cheng (2023)Do LLMs understand user preferences? evaluating LLMs on user rating prediction. CoRRabs/2305.06474. External Links: Link, 2305.06474 Cited by: SS1. * K. Kenthapadi, B. Le, and G. Venkataraman (2017)Personalized job recommendation system at linkedin: practical challenges and lessons learned. In Proceedings of the Eleventh ACM Conference on Recommender Systems, Cited by: SS1. * D. P. Kingma and J. Ba (2014)Adam: a method for stochastic optimization. arXiv preprint arXiv:1412.6980. Cited by: SS1. * R. Le, W. Hu, Y. Song, T. Zhang, D. Zhao, and R. Yan (2019)Towards effective and interpretable person-job fitting. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management, pp. 1883-1892. Cited by: SS1. * Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov (2019)Roberta: a robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692. Cited by: SS1. * Y. Lu, S. El Helou, and D. Gillet (2013)A recommender system for job seeking and recruiting website. In Proceedings of the 22nd International Conference on World Wide Web, Cited by: SS1. * Y. Luo, H. Zhang, Y. Wen, and X. Zhang (2019)Re-sumegan: an optimized deep representation learning framework for talent-job fit via adversarial learning. In Proceedings of the 28th ACM international conference on information and knowledge management, pp. 1101-1110. Cited by: SS1. * G. Penha and C. Hauff (2020)What does bert know about books, movies and music? probing bert for conversational recommendation. In RecSys, pp. 388-397. Cited by: SS1. * C. Qin, H. Zhu, T. Xu, C. Zhu, L. Jiang, E. Chen, and H. Xiong (2018)Enhancing person-job fit for talent recruitment: an ability-aware neural network approach. In The 41st international ACM SIGIR conference on research & development in information retrieval, pp. 25-34. Cited by: SS1. * Z. Qiu, X. Wu, J. Gao, and W. Fan (2021)U-BERT: pre-training user representations for improved recommendation. In AAAI, pp. 4320-4327. Cited by: SS1. * R. Ramanath, H. Inan, G. Polatkan, B. Hu, Q. Guo, C. Ozcaglar, X. Wu, K. Kenthapadi, and S. C. Geyik (2018)Towards deep and representation learning for talent search at linkedin. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management, pp. 2253-2261. Cited by: SS1. * D. Shen, H. Zhu, C. Zhu, T. Xu, C. Ma, and H. Xiong (2018)A joint learning approach to intelligent job interview assessment. In IJCAI, pp. 3542-3548. Cited by: SS1. * C. Wu, F. Wu, Y. Yu, T. Qi, Y. Huang, and X. Xie (2021)Userbert: contrastive user model pre-training. arXiv preprint arXiv:2109.01274. Cited by: SS1. * L. Wu, Z. Li, H. Zhao, Q. Liu, J. Wang, M. Zhang, and E. Chen (2021)Learning the implicit semantic representation on graph-structured data. In Database Systems for Advanced Applications: 26th International Conference, DASFAA 2021, Taipei, Taiwan, April 11-14, 2021, Proceedings, Part I 26, pp. 3-19. External Links: Link, 2105.08808 Cited by: SS1. * L. Wu, Z. Zheng, Z. Qiu, H. Wang, H. Gu, T. Shen, C. Qin, C. Zhu, H. Zhu, Q. Liu, et al. (2023)A survey on large language models for recommendation. arXiv preprint arXiv:2305.19860. Cited by: SS1. * R. Yan, R. Le, Y. Song, T. Zhang, X. Zhang, and D. Zhao (2019)Interview choice reveals your preference on the market: to improve job-resume matching through profiling memories. In Proceedings of the 25th ACM SIGKDD International Conference on Information and Knowledge Management, pp. 1-10. Cited by: SS1. *International Conference on Knowledge Discovery & Data Mining_. * Yang et al. (2022) Yang, C.; Hou, Y.; Song, Y.; Zhang, T.; Wen, J.-R.; and Zhao, W. X. 2022. Modeling Two-Way Selection Preference for Person-Job Fit. In _Sixteenth ACM Conference on Recommender Systems_. * Yu et al. (2023) Yu, Y.; Liu, Q.; Wu, L.; Yu, R.; Yu, S. L.; and Zhang, Z. 2023. Untargeted attack against federated recommendation systems via poisonous item embeddings and the defense. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 37, 4854-4863. * Zhang et al. (2023) Zhang, J.; Xie, R.; Hou, Y.; Zhao, W. X.; Lin, L.; and Wen, J. 2023. Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach. _CoRR_, abs/2305.07001. * Zhang and Wang (2023) Zhang, Z.; and Wang, B. 2023. Prompt Learning for News Recommendation. _arXiv preprint arXiv:2304.05263_. * Zhao et al. (2023) Zhao, C.; Zhao, H.; Li, X.; He, M.; Wang, J.; and Fan, J. 2023. Cross-Domain Recommendation via Progressive Structural Alignment. _IEEE Transactions on Knowledge and Data Engineering_. * Zheng et al. (2023) Zheng, Z.; Qiu, Z.; Hu, X.; Wu, L.; Zhu, H.; and Xiong, H. 2023. Generative Job Recommendations with Large Language Model. arXiv:2307.02157."
    }
  ]
}
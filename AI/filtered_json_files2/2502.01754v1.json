{
  "title": "Evaluation of Large Language Models via Coupled Token Generation",
  "authors": [
    "Nina Corvelo Benz",
    "Stratis Tsirtsis",
    "Eleni Straitouri",
    "Ivi Chatzi",
    "Artola Ander",
    "Suhas Velasco",
    "Manuel Thejaswi",
    "Gomez-Rodriguez"
  ],
  "abstract": "\n State of the art large language models rely on randomization to respond to a prompt. As an immediate consequence, a model may respond differently to the same prompt if asked multiple times. In this work, we argue that the evaluation and ranking of large language models should control for the randomization underpinning their functioning. Our starting point is the development of a causal model for coupled autoregressive generation, which allows different large language models to sample responses with the same source of randomness. Building upon our causal model, we first show that, on evaluations based on benchmark datasets, coupled autoregressive generation leads to the same conclusions as vanilla autoregressive generation but using provably fewer samples. However, we further show that, on evaluations based on (human) pairwise comparisons, coupled and vanilla autoregressive generation can surprisingly lead to different rankings when comparing more than two models, even with an infinite amount of samples. This suggests that the apparent advantage of a model over others in existing evaluation protocols may not be genuine but rather confounded by the randomness inherent to the generation process. To illustrate and complement our theoretical results, we conduct experiments with several large language models from the Llama family. We find that, across multiple knowledge areas from the popular MMLU benchmark dataset, coupled autoregressive generation requires up to 40% fewer samples to reach the same conclusions as vanilla autoregressive generation. Further, using data from the LMSYS Chatbot Arena platform, we find that the win-rates derived from pairwise comparisons by a strong large language model to prompts differ under coupled and vanilla autoregressive generation. 1 Tokens are the units that make up sentences and paragraphs, e.g., (sub-)words, numbers, and special end-of-sequence tokens. \n",
  "references": [
    {
      "id": null,
      "title": "Evaluation of Large Language Models via Coupled Token Generation",
      "authors": [
        "Nina Corvelo Benz",
        "Stratis Tsirtsis",
        "Eleni Straitouri",
        "Ivi Chatzi",
        "Artola Ander",
        "Suhas Velasco",
        "Manuel Thejaswi",
        "Gomez-Rodriguez"
      ],
      "year": "2025",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
      "authors": [
        "Sébastien Bubeck",
        "Varun Chandrasekaran",
        "Ronen Eldan",
        "Johannes Gehrke",
        "Eric Horvitz",
        "Ece Kamar",
        "Peter Lee",
        "Yin Tat Lee",
        "Yuanzhi Li",
        "Scott Lundberg",
        "Harsha Nori",
        "Hamid Palangi",
        "Marco Tulio Ribeiro",
        "Yi Zhang"
      ],
      "year": "2023",
      "venue": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming",
      "authors": [
        "Hussein Mozannar",
        "Gagan Bansal",
        "Adam Fourney",
        "Eric Horvitz"
      ],
      "year": "2024",
      "venue": "Proceedings of the Conference on Human Factors in Computing Systems",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "AI-Generated Medical Advice-GPT and Beyond",
      "authors": [
        "Claudia E Haupt",
        "Mason Marks"
      ],
      "year": "2023",
      "venue": "Journal of American Medical Association",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Mathematical Discoveries from Program Search with Large Language Models",
      "authors": [
        "Bernardino Romera-Paredes",
        "Mohammadamin Barekatain",
        "Alexander Novikov",
        "Matej Balog",
        "M Pawan Kumar",
        "Emilien Dupont",
        "J R Francisco",
        "Jordan S Ruiz",
        "Pengming Ellenberg",
        "Omar Wang",
        "Pushmeet Fawzi",
        "Alhussein Kohli",
        "Fawzi"
      ],
      "year": "2023",
      "venue": "Nature",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts",
      "authors": [
        "Stephen Bach",
        "Victor Sanh",
        "Zheng Xin Yong",
        "Albert Webson",
        "Colin Raffel",
        "V Nihal",
        "Abheesht Nayak",
        "Taewoon Sharma",
        "M Kim",
        "Thibault Saiful Bari",
        "Zaid Fevry",
        "Manan Alyafeai",
        "Andrea Dey",
        "Zhiqing Santilli",
        "Srulik Sun",
        "Canwen Ben-David",
        "Gunjan Xu",
        "Han Chhablani",
        "Jason Wang",
        "Maged Fries",
        "Shanya Al-Shaibani",
        "Urmish Sharma",
        "Khalid Thakker",
        "Xiangru Almubarak",
        "Dragomir Tang",
        "Mike Radev",
        "Tian-Jian",
        "Alexander Jiang",
        "Rush"
      ],
      "year": "2022",
      "venue": "Proceedings of the Association for Computational Linguistics: System Demonstrations",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "Finetuned Language Models are Zero-Shot Learners",
      "authors": [
        "Jason Wei",
        "Maarten Bosma",
        "Vincent Zhao",
        "Kelvin Guu",
        "Adams Wei Yu",
        "Brian Lester",
        "Nan Du",
        "Andrew M Dai",
        "Quoc V Le"
      ],
      "year": "2022",
      "venue": "Proceedings of the International Conference on Learning Representations. ICLR",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge",
      "authors": [
        "Alon Talmor",
        "Jonathan Herzig",
        "Nicholas Lourie",
        "Jonathan Berant"
      ],
      "year": "2019",
      "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions",
      "authors": [
        "Swaroop Mishra",
        "Daniel Khashabi",
        "Chitta Baral",
        "Hannaneh Hajishirzi"
      ],
      "year": "2022",
      "venue": "Proceedings of the Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Evaluating Large Language Models Trained on Code",
      "authors": [
        "Mark Chen",
        "Jerry Tworek",
        "Heewoo Jun",
        "Qiming Yuan",
        "Henrique Ponde De Oliveira Pinto",
        "Jared Kaplan",
        "Harri Edwards",
        "Yuri Burda",
        "Nicholas Joseph",
        "Greg Brockman",
        "Alex Ray",
        "Raul Puri",
        "Gretchen Krueger",
        "Michael Petrov",
        "Heidy Khlaaf",
        "Girish Sastry",
        "Pamela Mishkin",
        "Brooke Chan",
        "Scott Gray",
        "Nick Ryder",
        "Mikhail Pavlov",
        "Alethea Power",
        "Lukasz Kaiser",
        "Mohammad Bavarian",
        "Clemens Winter",
        "Philippe Tillet",
        "Felipe Petroski Such",
        "Dave Cummings",
        "Matthias Plappert",
        "Fotios Chantzis",
        "Elizabeth Barnes",
        "Ariel Herbert-Voss",
        "William Hebgen Guss",
        "Alex Nichol",
        "Alex Paino",
        "Nikolas Tezak",
        "Jie Tang",
        "Igor Babuschkin",
        "Suchir Balaji",
        "Shantanu Jain",
        "William Saunders",
        "Christopher Hesse",
        "Andrew N Carr",
        "Jan Leike",
        "Josh Achiam",
        "Vedant Misra",
        "Evan Morikawa",
        "Alec Radford",
        "Matthew Knight",
        "Miles Brundage",
        "Mira Murati",
        "Katie Mayer",
        "Peter Welinder",
        "Bob Mcgrew",
        "Dario Amodei",
        "Sam Mccandlish",
        "Ilya Sutskever",
        "Wojciech Zaremba"
      ],
      "year": "2021",
      "venue": "Evaluating Large Language Models Trained on Code",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "",
      "authors": [
        "Percy Liang",
        "Rishi Bommasani",
        "Tony Lee",
        "Dimitris Tsipras",
        "Dilara Soylu",
        "Michihiro Yasunaga",
        "Yian Zhang",
        "Deepak Narayanan",
        "Yuhuai Wu",
        "Ananya Kumar",
        "Benjamin Newman",
        "Binhang Yuan",
        "Bobby Yan",
        "Ce Zhang",
        "Christian Alexander Cosgrove",
        "Christopher D Manning",
        "Christopher Re",
        "Diana Acosta-Navas",
        "Drew Arad Hudson",
        "Eric Zelikman",
        "Esin Durmus",
        "Faisal Ladhak",
        "Frieda Rong",
        "Hongyu Ren",
        "Huaxiu Yao",
        "Wang Jue",
        "Keshav Santhanam",
        "Laurel Orr",
        "Lucia Zheng",
        "Mert Yuksekgonul",
        "Mirac Suzgun",
        "Nathan Kim",
        "Neel Guha",
        "Niladri S Chatterji",
        "Omar Khattab",
        "Peter Henderson",
        "Qian Huang",
        "Ryan Andrew Chi",
        "Sang Michael Xie",
        "Shibani Santurkar",
        "Surya Ganguli",
        "Tatsunori Hashimoto",
        "Thomas Icard",
        "Tianyi Zhang",
        "Vishrav Chaudhary",
        "William Wang",
        "Xuechen Li",
        "Yifan Mai",
        "Yuhui Zhang",
        "Yuta Koreeda"
      ],
      "year": "2023",
      "venue": "Holistic Evaluation of Language Models. Transactions on Machine Learning Research",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "The flan collection: Designing data and methods for effective instruction tuning",
      "authors": [
        "Shayne Longpre",
        "Le Hou",
        "Tu Vu",
        "Albert Webson",
        "Hyung Won Chung",
        "Yi Tay",
        "Denny Zhou",
        "V Quoc",
        "Barret Le",
        "Jason Zoph",
        "Adam Wei",
        "Roberts"
      ],
      "year": "2023",
      "venue": "Proceedings of the International Conference on Machine Learning",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Measuring Massive Multitask Language Understanding",
      "authors": [
        "Dan Hendrycks",
        "Collin Burns",
        "Steven Basart",
        "Andy Zou",
        "Mantas Mazeika",
        "Dawn Song",
        "Jacob Steinhardt"
      ],
      "year": "2021",
      "venue": "Proceedings of the International Conference on Learning Representations. ICLR",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "authors": [
        "Yizhong Wang",
        "Yeganeh Kordi",
        "Swaroop Mishra",
        "Alisa Liu",
        "Noah A Smith",
        "Daniel Khashabi",
        "Hannaneh Hajishirzi"
      ],
      "year": "2023",
      "venue": "Proceedings of the Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "Training Language Models to Follow Instructions with Human Feedback",
      "authors": [
        "Long Ouyang",
        "Jeffrey Wu",
        "Xu Jiang",
        "Diogo Almeida",
        "Carroll Wainwright",
        "Pamela Mishkin",
        "Chong Zhang",
        "Sandhini Agarwal",
        "Katarina Slama",
        "Alex Gray",
        "John Schulman",
        "Jacob Hilton",
        "Fraser Kelton",
        "Luke Miller",
        "Maddie Simens",
        "Amanda Askell",
        "Peter Welinder",
        "Paul Christiano",
        "Jan Leike",
        "Ryan Lowe"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "Aligning Large Language Models with Human: A Survey",
      "authors": [
        "Yufei Wang",
        "Wanjun Zhong",
        "Liangyou Li",
        "Fei Mi",
        "Xingshan Zeng",
        "Wenyong Huang",
        "Lifeng Shang",
        "Xin Jiang",
        "Qun Liu"
      ],
      "year": "2023",
      "venue": "Aligning Large Language Models with Human: A Survey",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "Chatbot arena: an open platform for evaluating LLMs by human preference",
      "authors": [
        "Wei-Lin Chiang",
        "Lianmin Zheng",
        "Ying Sheng",
        "Anastasios N Angelopoulos",
        "Tianle Li",
        "Dacheng Li",
        "Banghua Zhu",
        "Hao Zhang",
        "Michael I Jordan",
        "Joseph E Gonzalez",
        "Ion Stoica"
      ],
      "year": "2025",
      "venue": "Proceedings of the International Conference on Machine Learning",
      "doi": ""
    },
    {
      "id": "b16",
      "title": "Stanford Alpaca: An instruction-following LLaMA model",
      "authors": [
        "Rohan Taori",
        "Ishaan Gulrajani",
        "Tianyi Zhang",
        "Yann Dubois",
        "Xuechen Li",
        "Carlos Guestrin",
        "Percy Liang",
        "Tatsunori B Hashimoto"
      ],
      "year": "2023",
      "venue": "Stanford Alpaca: An instruction-following LLaMA model",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena",
      "authors": [
        "Lianmin Zheng",
        "Wei-Lin Chiang",
        "Ying Sheng",
        "Siyuan Zhuang",
        "Zhanghao Wu",
        "Yonghao Zhuang",
        "Zi Lin",
        "Zhuohan Li",
        "Dacheng Li",
        "Eric P Xing",
        "Hao Zhang",
        "Joseph E Gonzalez",
        "Ion Stoica"
      ],
      "year": "2023",
      "venue": "Advances in Neural Information Processing Systems, data track",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Generative Judge for Evaluating Alignment",
      "authors": [
        "Junlong Li",
        "Shichao Sun",
        "Weizhe Yuan",
        "Run-Ze Fan",
        "Hai Zhao",
        "Pengfei Liu"
      ],
      "year": "2024",
      "venue": "Proceedings of the International Conference on Learning Representations. ICLR",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations",
      "authors": [
        "Ruosen Li",
        "Teerth Patel",
        "Xinya Du"
      ],
      "year": "",
      "venue": "Transactions on Machine Learning Research",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "Elo uncovered: Robustness and best practices in language model evaluation",
      "authors": [
        "Meriem Boubdir",
        "Edward Kim",
        "Beyza Ermis",
        "Sara Hooker",
        "Marzieh Fadaee"
      ],
      "year": "2024",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Large Language Models Encode Clinical Knowledge",
      "authors": [
        "Karan Singhal",
        "Shekoofeh Azizi",
        "Tao Tu",
        "S Sara Mahdavi",
        "Jason Wei",
        "Hyung Won Chung",
        "Nathan Scales",
        "Ajay Tanwani",
        "Heather Cole-Lewis",
        "Stephen Pfohl",
        "Perry Payne",
        "Martin Seneviratne",
        "Paul Gamble",
        "Chris Kelly",
        "Abubakr Babiker",
        "Nathanael Schärli",
        "Aakanksha Chowdhery",
        "Philip Mansfield",
        "Dina Demner-Fushman ;",
        "Greg S Corrado",
        "Yossi Matias",
        "Katherine Chou",
        "Juraj Gottweis",
        "Nenad Tomasev",
        "Yun Liu",
        "Alvin Rajkomar",
        "Joelle Barral",
        "Christopher Semturs",
        "Alan Karthikesalingam",
        "Vivek Natarajan"
      ],
      "year": "2023",
      "venue": "Nature",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "Adding error bars to evals: A statistical approach to language model evaluations",
      "authors": [
        "Evan Miller"
      ],
      "year": "2024",
      "venue": "Adding error bars to evals: A statistical approach to language model evaluations",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "Pontus Stenetorp, Sharan Narang, and Dieuwke Hupkes. Quantifying variance in evaluation benchmarks",
      "authors": [
        "Lovish Madaan",
        "K Aaditya",
        "Rylan Singh",
        "Andrew Schaeffer",
        "Sanmi Poulton",
        "Koyejo"
      ],
      "year": "2024",
      "venue": "Pontus Stenetorp, Sharan Narang, and Dieuwke Hupkes. Quantifying variance in evaluation benchmarks",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "The Llama 3 herd of models",
      "authors": [
        "Abhimanyu Dubey"
      ],
      "year": "2024",
      "venue": "The Llama 3 herd of models",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "authors": [
        "Jon Saad-Falcon",
        "Omar Khattab",
        "Christopher Potts",
        "Matei Zaharia"
      ],
      "year": "",
      "venue": "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.18653/v1/2024.naacl-long.20"
    },
    {
      "id": "b26",
      "title": "AutoEval Done Right: Using Synthetic Data for Model Evaluation",
      "authors": [
        "Pierre Boyeau",
        "Nir Anastasios N Angelopoulos",
        "Jitendra Yosef",
        "Michael I Malik",
        "Jordan"
      ],
      "year": "2024",
      "venue": "AutoEval Done Right: Using Synthetic Data for Model Evaluation",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Prediction-powered ranking of large language models",
      "authors": [
        "Ivi Chatzi",
        "Eleni Straitouri",
        "Suhas Thejaswi",
        "Manuel Gomez Rodriguez"
      ],
      "year": "2024",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Limits to scalable evaluation at the frontier: LLM as judge won't beat twice the data",
      "authors": [
        "Florian E Dorner",
        "Vivian Y Nastl",
        "Moritz Hardt"
      ],
      "year": "2024",
      "venue": "Limits to scalable evaluation at the frontier: LLM as judge won't beat twice the data",
      "doi": ""
    },
    {
      "id": "b29",
      "title": "Justrank: Benchmarking LLM judges for system ranking",
      "authors": [
        "Ariel Gera",
        "Odellia Boni",
        "Yotam Perlitz",
        "Roy Bar-Haim",
        "Lilach Eden",
        "Asaf Yehudai"
      ],
      "year": "2024",
      "venue": "Justrank: Benchmarking LLM judges for system ranking",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "A neural probabilistic language model",
      "authors": [
        "Yoshua Bengio",
        "Réjean Ducharme",
        "Pascal Vincent"
      ],
      "year": "2000",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "Language models are unsupervised multitask learners",
      "authors": [
        "Alec Radford",
        "Jeffrey Wu",
        "Rewon Child",
        "David Luan",
        "Dario Amodei",
        "Ilya Sutskever"
      ],
      "year": "2019",
      "venue": "OpenAI blog",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "The curious case of neural text degeneration",
      "authors": [
        "Ari Holtzman",
        "Jan Buys",
        "Li Du",
        "Maxwell Forbes",
        "Yejin Choi"
      ],
      "year": "2020",
      "venue": "Proceedings of the International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b33",
      "title": "Counterfactual token generation in large language models",
      "authors": [
        "Ivi Chatzi",
        "Nina Corvelo Benz",
        "Eleni Straitouri",
        "Stratis Tsirtsis",
        "Manuel Gomez-Rodriguez"
      ],
      "year": "2024",
      "venue": "Counterfactual token generation in large language models",
      "doi": ""
    },
    {
      "id": "b34",
      "title": "Counterfactual generation from language models",
      "authors": [
        "Shauli Ravfogel",
        "Anej Svete",
        "Vésteinn Snaebjarnarson",
        "Ryan Cotterell"
      ],
      "year": "2024",
      "venue": "Counterfactual generation from language models",
      "doi": ""
    },
    {
      "id": "b35",
      "title": "Counterfactual off-policy evaluation with Gumbel-Max structural causal models",
      "authors": [
        "Michael Oberst",
        "David Sontag"
      ],
      "year": "2019",
      "venue": "Proceedings of the International Conference on Machine Learning",
      "doi": ""
    },
    {
      "id": "b36",
      "title": "Counterfactual explanations in sequential decision making under uncertainty",
      "authors": [
        "Stratis Tsirtsis",
        "Abir De",
        "Manuel Rodriguez"
      ],
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b37",
      "title": "Counterfactual temporal point processes",
      "authors": [
        "Kimia Noorbakhsh",
        "Manuel Gomez-Rodriguez"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b38",
      "title": "Counterfactual inference of second opinions",
      "authors": [
        "Nina L",
        "Corvelo Benz",
        "Manuel Gomez Gomez-Rodriguez"
      ],
      "year": "2022",
      "venue": "Uncertainty in Artificial Intelligence",
      "doi": ""
    },
    {
      "id": "b39",
      "title": "A Survey on Evaluation of Large Language Models",
      "authors": [
        "Yupeng Chang",
        "Xu Wang",
        "Jindong Wang",
        "Yuan Wu",
        "Linyi Yang",
        "Kaijie Zhu",
        "Hao Chen",
        "Xiaoyuan Yi",
        "Cunxiang Wang",
        "Yidong Wang",
        "Wei Ye",
        "Yue Zhang",
        "Yi Chang",
        "Philip S Yu",
        "Qiang Yang",
        "Xing Xie"
      ],
      "year": "2024",
      "venue": "ACM Transactions on Intelligent Systems and Technology",
      "doi": ""
    },
    {
      "id": "b40",
      "title": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality",
      "authors": [
        "Wei-Lin Chiang",
        "Zhuohan Li",
        "Zi Lin",
        "Ying Sheng",
        "Zhanghao Wu",
        "Hao Zhang",
        "Lianmin Zheng",
        "Siyuan Zhuang",
        "Yonghao Zhuang",
        "Joseph E Gonzalez",
        "Ion Stoica",
        "Eric P Xing"
      ],
      "year": "2023",
      "venue": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality",
      "doi": ""
    },
    {
      "id": "b41",
      "title": "General Language Assistant as a Laboratory for Alignment",
      "authors": [
        "Amanda Askell",
        "Yuntao Bai",
        "Anna Chen",
        "Dawn Drain",
        "Deep Ganguli",
        "Tom Henighan",
        "Andy Jones",
        "Nicholas Joseph",
        "Ben Mann",
        "Nova Dassarma",
        "Nelson Elhage",
        "Zac Hatfield-Dodds",
        "Danny Hernandez",
        "Jackson Kernion",
        "Kamal Ndousse",
        "Catherine Olsson",
        "Dario Amodei",
        "Tom Brown",
        "Jack Clark",
        "Sam Mccandlish",
        "Chris Olah",
        "Jared Kaplan"
      ],
      "year": "2021",
      "venue": "General Language Assistant as a Laboratory for Alignment",
      "doi": ""
    },
    {
      "id": "b42",
      "title": "QLoRA: Efficient Finetuning of Quantized LLMs",
      "authors": [
        "Tim Dettmers",
        "Artidoro Pagnoni",
        "Ari Holtzman",
        "Luke Zettlemoyer"
      ],
      "year": "2024",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b43",
      "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback",
      "authors": [
        "Yuntao Bai",
        "Andy Jones",
        "Kamal Ndousse",
        "Amanda Askell",
        "Anna Chen",
        "Nova Dassarma",
        "Dawn Drain",
        "Stanislav Fort",
        "Deep Ganguli",
        "Tom Henighan",
        "Nicholas Joseph",
        "Saurav Kadavath",
        "Jackson Kernion",
        "Tom Conerly",
        "Sheer El-Showk",
        "Nelson Elhage",
        "Zac Hatfield-Dodds",
        "Danny Hernandez",
        "Tristan Hume",
        "Scott Johnston",
        "Shauna Kravec",
        "Liane Lovitt",
        "Neel Nanda",
        "Catherine Olsson",
        "Dario Amodei",
        "Tom Brown",
        "Jack Clark",
        "Sam Mccandlish",
        "Chris Olah",
        "Ben Mann",
        "Jared Kaplan"
      ],
      "year": "2022",
      "venue": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback",
      "doi": ""
    },
    {
      "id": "b44",
      "title": "Multi-Agent Language Game Environments for Large Language Models",
      "authors": [
        "Yuxiang Wu",
        "Zhengyao Jiang",
        "Akbir Khan",
        "Yao Fu",
        "Laura Ruis",
        "Edward Grefenstette",
        "Tim Rocktäschel",
        "Chatarena"
      ],
      "year": "2023",
      "venue": "Multi-Agent Language Game Environments for Large Language Models",
      "doi": ""
    },
    {
      "id": "b45",
      "title": "LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models",
      "authors": [
        "Yen-Ting Lin",
        "Yun-Nung Chen"
      ],
      "year": "2023",
      "venue": "Proceedings of the Workshop on NLP for Conversational AI",
      "doi": ""
    },
    {
      "id": "b46",
      "title": "The USCF Rating System: Its Development, Theory, and Applications",
      "authors": [
        "E Arpad",
        "Elo"
      ],
      "year": "1966",
      "venue": "The USCF Rating System: Its Development, Theory, and Applications",
      "doi": ""
    },
    {
      "id": "b47",
      "title": "On the Limitations of the Elo, Real-World Games are Transitive, Not Additive",
      "authors": [
        "Quentin Bertrand",
        "Wojciech",
        "Marian Czarnecki",
        "Gauthier Gidel"
      ],
      "year": "2023",
      "venue": "International Conference on Artificial Intelligence and Statistics",
      "doi": ""
    },
    {
      "id": "b48",
      "title": "Elements of causal inference: foundations and learning algorithms",
      "authors": [
        "Jonas Peters",
        "Dominik Janzing",
        "Bernhard Schölkopf"
      ],
      "year": "2017",
      "venue": "Elements of causal inference: foundations and learning algorithms",
      "doi": ""
    },
    {
      "id": "b49",
      "title": "Pytorch: An imperative style, high-performance deep learning library",
      "authors": [
        "Adam Paszke",
        "Sam Gross",
        "Francisco Massa",
        "Adam Lerer",
        "James Bradbury",
        "Gregory Chanan",
        "Trevor Killeen",
        "Zeming Lin",
        "Natalia Gimelshein",
        "Luca Antiga"
      ],
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b50",
      "title": "Measuring massive multitask language understanding",
      "authors": [
        "Dan Hendrycks",
        "Collin Burns",
        "Steven Basart",
        "Andy Zou",
        "Mantas Mazeika",
        "Dawn Song",
        "Jacob Steinhardt"
      ],
      "year": "2021",
      "venue": "Proceedings of the International Conference on Learning Representations",
      "doi": ""
    },
    {
      "id": "b51",
      "title": "A law of comparative judgment",
      "authors": [
        "L L Thurstone"
      ],
      "year": "1927",
      "venue": "Psychological Review",
      "doi": "10.1037/h0070288"
    },
    {
      "id": "b52",
      "title": "Rank analysis of incomplete block designs: I. the method of paired comparisons",
      "authors": [
        "Ralph Allan",
        "Bradley",
        "Milton E Terry"
      ],
      "year": "1952",
      "venue": "Biometrika",
      "doi": ""
    },
    {
      "id": "b53",
      "title": "Individual choice behavior",
      "authors": [
        "Luce Duncan"
      ],
      "year": "1959",
      "venue": "Individual choice behavior",
      "doi": ""
    },
    {
      "id": "b54",
      "title": "A probabilistic calculus of actions",
      "authors": [
        "Judea Pearl"
      ],
      "year": "1994",
      "venue": "Proceedings of the Annual Conference on Uncertainty in Artificial Intelligence",
      "doi": ""
    },
    {
      "id": "b55",
      "title": "Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings",
      "authors": [
        "Lmsys"
      ],
      "year": "2024",
      "venue": "Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings",
      "doi": ""
    },
    {
      "id": "b56",
      "title": "Lmsys-chat-1m: A large-scale real-world LLM conversation dataset",
      "authors": [
        "Lianmin Zheng",
        "Wei-Lin Chiang",
        "Ying Sheng",
        "Tianle Li",
        "Siyuan Zhuang",
        "Zhanghao Wu",
        "Yonghao Zhuang",
        "Zhuohan Li",
        "Zi Lin",
        "Eric P Xing",
        "Joseph E Gonzalez",
        "Ion Stoica",
        "Hao Zhang"
      ],
      "year": "2024",
      "venue": "Lmsys-chat-1m: A large-scale real-world LLM conversation dataset",
      "doi": ""
    },
    {
      "id": "b57",
      "title": "LLMs-as-judges: A comprehensive survey on LLM-based evaluation methods",
      "authors": [
        "Haitao Li",
        "Qian Dong",
        "Junjie Chen",
        "Huixue Su",
        "Yujia Zhou",
        "Qingyao Ai",
        "Ziyi Ye",
        "Yiqun Liu"
      ],
      "year": "2024",
      "venue": "LLMs-as-judges: A comprehensive survey on LLM-based evaluation methods",
      "doi": ""
    },
    {
      "id": "b58",
      "title": "Counterfactual analysis in dynamic latent state models",
      "authors": [
        "B Martin",
        "Raghav Haugh",
        "Singal"
      ],
      "year": "2023",
      "venue": "International Conference on Machine Learning",
      "doi": ""
    },
    {
      "id": "b59",
      "title": "Learning generalized gumbel-max causal mechanisms",
      "authors": [
        "Guy Lorberbom",
        "Chris J Daniel D Johnson",
        "Daniel Maddison",
        "Tamir Tarlow",
        "Hazan"
      ],
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b60",
      "title": "Estimating categorical counterfactuals via deep twin networks",
      "authors": [
        "Athanasios Vlontzos",
        "Bernhard Kainz",
        "Ciarán M Gilligan-Lee"
      ],
      "year": "2023",
      "venue": "Nature Machine Intelligence",
      "doi": ""
    },
    {
      "id": "b61",
      "title": "A review of the Gumbel-Max trick and its extensions for discrete stochasticity in machine learning",
      "authors": [
        "A M Iris",
        "Wouter Huijben",
        "Max B Kool",
        "Paulus",
        "J G Ruud",
        "Van Sloun"
      ],
      "year": "2023",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "doi": "10.1109/TPAMI.2022.3157042"
    },
    {
      "id": "b62",
      "title": "Bits and Bytes Foundation. Bits and bytes quantisation library",
      "authors": [],
      "year": "2024",
      "venue": "Bits and Bytes Foundation. Bits and bytes quantisation library",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Evaluation Of Large Language Models",
      "text": "via Coupled Token Generation Nina Corvelo Benz, Stratis Tsirtsis, Eleni Straitouri, Ivi Chatzi, Ander Artola Velasco, Suhas Thejaswi, and Manuel Gomez-Rodriguez Max Planck Institute for Software Systems Kaiserslautern, Germany {ninacobe, stsirtsis, estraitouri, ichatzi, avelasco, thejaswi, manuel}@mpi-sws.org"
    },
    {
      "title": "Abstract",
      "text": "State of the art large language models rely on randomization to respond to a prompt. As an immediate consequence, a model may respond differently to the same prompt if asked multiple times. In this work, we argue that the evaluation and ranking of large language models should control for the randomization underpinning their functioning. Our starting point is the development of a causal model for coupled autoregressive generation, which allows different large language models to sample responses with the same source of randomness. Building upon our causal model, we first show that, on evaluations based on benchmark datasets, coupled autoregressive generation leads to the same conclusions as vanilla autoregressive generation but using provably fewer samples. However, we further show that, on evaluations based on (human) pairwise comparisons, coupled and vanilla autoregressive generation can surprisingly lead to different rankings when comparing more than two models, even with an infinite amount of samples. This suggests that the apparent advantage of a model over others in existing evaluation protocols may not be genuine but rather confounded by the randomness inherent to the generation process. To illustrate and complement our theoretical results, we conduct experiments with several large language models from the Llama family. We find that, across multiple knowledge areas from the popular MMLU benchmark dataset, coupled autoregressive generation requires up to 40% fewer samples to reach the same conclusions as vanilla autoregressive generation. Further, using data from the LMSYS Chatbot Arena platform, we find that the win-rates derived from pairwise comparisons by a strong large language model to prompts differ under coupled and vanilla autoregressive generation."
    },
    {
      "title": "1 Introduction",
      "text": "One of the most celebrated aspects of state of the art large language models (LLMs) is that they can solve open-ended, complex tasks across many different application domains such as coding, healthcare and scientific discovery [1, 2, 3, 4]. However, this is crucially what also makes the evaluation and comparison of LLMs very challenging--it is very difficult, if not impossible, to create a single benchmark. As a consequence, in recent years, there has been a flurry of papers introducing different benchmarks [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]. In fact, one of the flagship conferences in machine learning has even created a separate datasets and benchmarks track! In this context, it is somehow surprising that, in comparison, there has been a paucity of work understanding, measuring or controlling for the different sources of uncertainty present in the evaluations and comparisons of LLMs based on these benchmarks [23, 24, 25, 26, 27, 28, 29, 30]. In our work, we focus on one source of uncertainty that has been particularly overlooked, the uncertainty in the outputs of the LLMs under comparison. Given an input prompt, LLMs generate a sequence of tokens1 as output using an autoregressive process [31, 32]. At each time step, they first use a neural network to map the prompt and the (partial) sequence of tokensgenerated so far to a token distribution. Then, they use a sampler to draw the next token at random from the token distribution.2 Finally, they append the next token to the (partial) sequence of tokens, and continue until a special end-of-sequence token is sampled. To understand why, in the context of LLM evaluation and ranking, the above autoregressive process may lead to inconsistent conclusions, we will use a stylized example. Footnote 2: If an LLM is forced to output tokens deterministically, multiple lines of evidence suggest that its performance worsens [33]. Consider we are given three LLMs \\(m_{1}\\), \\(m_{2}\\) and \\(m_{3}\\), and we need to rank them according to their ability to answer correctly two types of input prompts, \\(q\\) and \\(q^{\\prime}\\), picked uniformly at random. Moreover, assume that the true probability that each LLM answers correctly each type of input prompt is given by: \\begin{tabular}{c c c c} \\hline \\hline & \\(m_{1}\\) & \\(m_{2}\\) & \\(m_{3}\\) \\\\ \\hline \\(q\\) & 0.4 & 0.48 & 0.5 \\\\ \\(q^{\\prime}\\) & 1 & 0.9 & 0.89 \\\\ \\hline \\hline \\end{tabular} Then, one may argue that \\(m_{1}\\) is the best LLM, followed closely by \\(m_{3}\\), and \\(m_{2}\\) is the worst, because the average probabilities that they answer a query picked uniformly at random correctly are 0.7, 0.695 and 0.69, respectively. However, if we conduct pairwise comparisons between outputs by two different LLMs to the same input prompt, as commonly done in practice, we may instead argue that \\(m_{3}\\) is the best LLM, followed by \\(m_{2}\\), and \\(m_{1}\\) is the worst, because the probability that an LLM is preferred over others--the win-rates--are 0.16225, 0.15675, and 0.1545, respectively.3 In our work, we argue that controlling for the randomization of the autoregressive processes underpinning the LLMs under comparison can, at least in certain cases, avoid such inconsistencies and lead to more intuitive conclusions. Along the way, we also show that it can reduce the number of samples required to reliably compare the performance of LLMs. Footnote 3: Refer to Appendix B.6 for the detailed calculation of the average win-rates. **Our contributions.** Our key idea is to couple the autoregressive processes underpinning a set of LLMs under comparison, particularly their samplers, by means of sharing the same source of randomness. To this end, we treat the sampler of each LLM as a causal mechanism that receives as input the distribution of the next token and the same set of noise values, which determine the sampler's (stochastic) state. By doing so, at each time step of the generation, we can expect that, if different LLMs map the prompt and the (partial) sequence of tokens generated so far to the same token distribution, they will sample the same next token. Loosely speaking, in the context of LLM evaluation and ranking, coupled autoregressive generation ensures that no LLM will have better luck than others. More formally, on evaluations based on benchmark datasets, we show that the difference in average performance of each pair of LLMs under comparison is asymptotically the same under coupled and vanilla autoregressive generation, but coupled autoregressive generation provably leads to a reduction in the required sample size. On evaluations based on (human) pairwise comparisons, we show that the win-rates of the LLMs under comparison can be asymptotically different under coupled and vanilla autoregressive generation and, perhaps surprisingly, the resulting rankings can actually differ. This suggests that the apparent advantage of an LLM over others in existing evaluation protocols may not be genuine but rather confounded by the randomness inherent to the generation process. To illustrate and complement our theoretical results, we conduct experiments with several LLMs of the Llama family, namely Llama-3.1-8B-Instruct, Llama-3.2-{1B, 3B}-Instruct, and Llama-3.1-8B-Instruct-{AWQ-INT4, bnb-4bit, bnb-8bit}. We find that, across multiple knowledge areas from the popular MMLU benchmark dataset, coupled autoregressive leads to a reduction of up to 40% in the required number of samples to reach the same conclusions as vanilla autoregressive generation. Further, using data from the LMSYS Chatbot Arena platform, we find that the win-rates derived from pairwise comparisons by a strong LLM differ under coupled and vanilla autoregressive generation. We conclude with a comprehensive discussion of the limitations of our theoretical results and experiments, including additional avenues for future work. An open-source implementation of coupled autoregressive generation is available at [https://github.com/Networks-Learning/coupled-llm-evaluation](https://github.com/Networks-Learning/coupled-llm-evaluation). **Further related work.** Our work builds upon a very recent work on counterfactual token generation by Chatzi et al. [34], which also treats the sampler of an LLM as a causal mechanism. However, their focus is different to ours; they augment a single LLM with the ability to reason counterfactually about alternatives to its own outputs if individual tokens had been different. Our work also shares technical elements with a recent work by Ravfogel et al. [35], which develops a causal model to generate counterfactual strings resulting from interventions within (the network of) an LLM. However, their work does not study counterfactual generation for the purposes of model evaluation. In this context, it is also worth pointing out that the specific class of causal models used in the aforementioned works and our work, called the Gumbel-max structural causal model [36], has also been used to enable counterfactual reasoning in Markov decision processes [37], temporal point processes [38], and expert predictions [39]. Our work also builds upon the rapidly increasing literature on evaluation and comparison of LLMs [40]. Within this literature, LLMs are evaluated and compared using: (i) benchmark datasets with manually hand-crafted inputs and ground-truth outputs [5, 6, 7, 8, 9, 10, 11] and (ii) the level of alignment with human preferences, as elicited by means of pairwise comparisons [16, 17, 18, 19, 20, 21, 22]. However, it has become increasingly clear that oftentimes rankings derived from benchmark datasets do not match those derived from human preferences [16, 18, 19, 20, 41]. Within the literature on ranking LLMs from pairwise comparisons, most studies use the Elo rating system [42, 43, 44, 45, 46], originally introduced for chess tournaments [47]. However, Elo-based rankings are sensitive to the order of pairwise comparisons, as newer comparisons have more weight than older ones, which leads to unstable rankings [21]. To address this limitation, several studies have instead used the Bradley-Terry model [16, 27], which weighs pairwise comparisons equally regardless of their order. Nevertheless, both the Elo rating system and the Bradley-Terry model have faced criticism, as pairwise comparisons often fail to satisfy the fundamental axiom of transitivity, upon which both approaches rely [21, 48]. Recently, several studies have used the win-rate [16, 18, 27], which weighs comparisons equally regardless of their order and does not require the transitivity assumption. In our work, we focus on win-rates. However, we believe that it may be possible to extend our theoretical and empirical results to rankings based on Elo ratings and the Bradley-Terry model. Figure 1: **Example of coupled autoregressive generation for**Llama 1B and**Llama 8B. Boxes represent endogenous random variables and circles represent exogenous random variables. The value of each endogenous variable is given by a function of the values of its ancestors in the causal graph, as defined by Eq. 1. The value of the coupled noise variable \\(U_{1}\\) (purple) is sampled independently from a given distribution \\(P_{U}\\), and it determines the stochastic state of the samplers used by both Llama 1B and Llama 8B during the generation of token \\(T_{1}\\). A Causal Model for Coupled Autoregressive Generation Let \\(V\\) denote a vocabulary (set) of tokens, including an end-of-sequence token \\(\\bot\\), \\(V^{*}=V\\cup V^{2}\\cup\\dots\\cup V^{K}\\) be the set of sequences of tokens up to length \\(K\\), and \\(\\varnothing\\) be the empty token.4 An LLM \\(m\\in\\mathcal{M}\\) takes as input a prompt sequence \\(s_{q}\\in V^{*}\\) and responds with an output sequence \\(s\\in V^{*}\\), generated using an autoregressive process. At each time step \\(i\\in[K]\\) of the process, the LLM first takes as input the concatenation of the prompt sequence \\(s_{q}\\) and the (partial) output sequence \\(s_{i-1}\\), and generates a distribution over tokens \\(d_{i}\\in\\Delta(V)\\). Then, it samples the next token \\(t_{i}\\sim d_{i}\\) from the distribution \\(d_{i}\\) and creates the output sequence \\(s_{i}=s_{i-1}\\circ t_{i}\\), where \\(\\circ\\) denotes the concatenation of a token or sequence with another sequence. If \\(t_{i}=\\bot\\), it terminates and returns \\(s=s_{i}\\), otherwise, it continues to the next step \\(i+1\\) in the generation. Once the process is completed, the output sequence \\(s\\) is assigned a score \\(r\\), which is subsequently used for model evaluation. Footnote 4: Here, \\(V^{j}\\) denotes the set of all sequences of length \\(j\\) that can be constructed from the tokens in \\(V\\). We restrict our attention to sequences of finite length (\\(\\leq K\\)) because, in practice, the context window of LLMs is finite. Following the recent work by Chatzi et al. [34], we augment the above autoregressive process using a structural causal model (SCM) [49, 50], which we denote as \\(\\mathcal{C}\\). The SCM \\(\\mathcal{C}\\) is defined by the following structural equations:5 Footnote 5: We use capital letters to denote random variables and lowercase letters to denote their realizations. \\[S_{0}=S_{q},\\quad D_{i}=\\begin{cases}f_{D}(S_{i-1},M)&\\text{if }\\texttt{last}(S_{i-1})\\neq\\bot,\\\\ P_{\\varnothing}&\\text{otherwise}\\end{cases},\\quad T_{i}=\\begin{cases}f_{T}(D_{i},U _{i})&\\text{if }D_{i}\\neq P_{\\varnothing},\\\\ \\varnothing&\\text{otherwise}\\end{cases}, \\tag{1}\\] \\[S_{i}=S_{i-1}\\circ T_{i},\\quad S=S_{K},\\quad\\text{and }R=f_{R}(S,Z).\\] In the above equations, \\(M,S_{q},\\boldsymbol{U}=(U_{i})_{i\\in\\{1,\\dots,K\\}}\\), and \\(Z\\) are independent exogenous random variables, with \\(M\\sim P_{M}\\), \\(S_{q}\\sim P_{Q}\\), \\(U_{i}\\sim P_{U}\\), and \\(Z\\sim P_{Z}\\). Moreover, \\(f_{D}\\), \\(f_{T}\\) and \\(f_{R}\\) are given functions, \\(P_{\\varnothing}\\) denotes the point mass distribution on \\(\\varnothing\\), and \\(\\texttt{last}(S_{i-1})\\) denotes the last token of the sequence \\(S_{i-1}\\). Here, the function \\(f_{D}\\) maps an input sequence \\(S_{i-1}\\) to a distribution \\(D_{i}\\) for the next token, using the architecture and network weights of the LLM \\(M\\), the function \\(f_{T}\\) and distribution \\(P_{U}\\) specify the sampling mechanism that is used to sample the next token at each step of the generation process, following the distribution \\(D_{i}\\), and the function \\(f_{R}\\) and distribution \\(P_{Z}\\) specify the exact scoring process by which the score \\(R\\) is assigned to an output sequence \\(S\\) during the evaluation of the LLM \\(M\\). Throughout the paper, we focus on sampling mechanisms that satisfy counterfactual stability [34, 36, 37]--an intuitive form of consistency between the next token \\(T_{i}\\), its distribution \\(D_{i}\\), and the corresponding noise variable \\(U_{i}\\).6 Moreover, we allow the score \\(R\\) to be observable or unobservable, and its semantic meaning and support of its distribution to vary depending on the evaluation protocol. For example, in multiple-choice questions [52], \\(R\\in\\{0,1\\}\\) may represent whether an LLM outputs a correct (\\(R=1\\)) or an incorrect (\\(R=0\\)) response. In pairwise comparisons [16], \\(R\\in\\mathbb{R}^{+}\\) may represent the level of user's satisfaction with the response provided by an LLM. In this context, the noise variable \\(Z\\) models any potential sources of uncertainty in the scoring process, _e.g._, uncertainty in users' preferences [53, 54, 55]. Footnote 6: The default categorical sampler in PyTorch[51], one of the most popular libraries used by state of the art LLMs, is an implementation of the Gumbel-Max SCM [36], which satisfies counterfactual stability. For a formal definition of counterfactual stability, refer to Appendix A. Building upon the above causal model, we can now formally express what it means to sample (and evaluate) output sequences by different LLMs using the same source of randomness,7 a process we refer to as **coupled autoregressive generation**. Consider a specific model \\(m\\), a prompt \\(s_{q}\\), and fixed noise values \\(\\mathbf{u}\\) and \\(z\\). It is easy to see that specifying these values is sufficient to (deterministically) specify and compute the exact value of the output sequence \\(S\\) and its score \\(R\\) using the autoregressive generation and scoring process given by Eq. 1. Then, we can formally express the coupled output sequences by two models \\(m\\) and \\(m^{\\prime}\\) and their corresponding scores as the result of _interventions_\\(do(M=m)\\) and \\(do(M=m^{\\prime})\\), respectively, where the \\(do(\\cdot)\\) operator forcibly sets the value of \\(M\\) while keeping the prompt \\(s_{q}\\) and the noise values \\(\\mathbf{u}\\), \\(z\\) fixed [56]. In what follows, we denote the respective scores \\(R_{m}(\\mathbf{u},s_{q},z)\\) and \\(R_{m^{\\prime}}(\\mathbf{u},s_{q},z)\\), following standard notation [49]. For an illustration of coupled autoregressive generation against independent autoregressive generation--the vanilla generation approach--refer to Figure 1. In practice, one run of coupled autoregressive generation consists of two or more runs of autoregressive generation with the same prompt \\(s_{q}\\) and noise values \\(\\mathbf{u}\\) and \\(z\\), one per LLM.8 From a causal perspective, we can view these runs as realizations of possible worlds where everything is equal except for the (architecture and network weights of the) LLM. Or we can also view one of these runs as a realization of the factual world and the other runs as realizations of different counterfactual worlds. Consequently, this lends support to attribute any difference in the scores \\(R_{m}(\\mathbf{u},s_{q},z)\\) across models \\(m\\in\\mathcal{M}\\) to the models' architectures and weights rather than the randomness in their autoregressive generation processes. In the following sections, we will investigate both theoretically and empirically the differences between coupled and independent autoregressive generation in the context of evaluations based on benchmark datasets and pairwise comparisons. Footnote 8: In practice, we may not always have control over the noise value \\(z\\) (_e.g._, when the scoring process is performed by an end user). However, even in such cases, we can still implement coupled autoregressive generation if the scoring processes occur simultaneously for each run, such as in pairwise comparisons."
    },
    {
      "title": "3 Evaluation Based On Benchmark Datasets",
      "text": "In this section, we focus on the evaluation and comparison of LLMs based on benchmark datasets, _e.g._, multiple-choice questions [52], and theoretically investigate under which conditions coupled autoregressive generation requires fewer samples than independent autoregressive generation to reliably estimate the competitive advantage of one LLM over another. Given a benchmark dataset characterized by an input prompt distribution \\(P_{Q}\\), for each prompt \\(s_{q}\\sim P_{Q}\\), let \\(\\mathrm{c}(s_{q})\\subset V^{*}\\) denote the set of correct output sequences.9 In what follows, for ease of exposition, we consider binary scores \\(R_{m}(\\mathbf{u},s_{q})=\\mathbf{1}\\left\\{S_{m}(\\mathbf{u},s_{q})\\in\\mathrm{c }(s_{q})\\right\\}\\in\\{0,1\\}\\), where \\(S_{m}(\\mathbf{u},s_{q})\\) denotes the output sequence of a model \\(m\\) given a prompt \\(s_{q}\\) under a realized sequence of noise values \\(\\mathbf{u}\\) and \\(\\mathbf{1}\\{\\cdot\\}\\) is the indicator function.10 Footnote 9: In multiple-choice questions, \\(c(s_{q})\\) may consist of all sequences that include the correct choice. Footnote 10: Our theoretical results can be extended to real-valued scores in a bounded interval. The standard approach to comparing the performance of any pair of LLMs \\(m,m^{\\prime}\\in\\mathcal{M}\\) using a benchmark dataset reduces to estimating the difference in their expected score, _i.e._, \\[\\mathbb{E}_{\\boldsymbol{U}\\sim P_{\\boldsymbol{U}},\\boldsymbol{U} ^{\\prime}\\sim P_{U},S_{q}\\sim P_{Q}}[R_{m}(\\boldsymbol{U},S_{q})-R_{m^{\\prime }}(\\boldsymbol{U}^{\\prime},S_{q})],\\] (2) \\[\\uparrow\\uparrow\\uparrow\\] Independent generation where note that we use different noise variables \\(\\boldsymbol{U}\\) and \\(\\boldsymbol{U}^{\\prime}\\) for each LLM because, in the standard approach, each LLM generates outputs to each query independently (_i.e._, using independent autoregressive generation). At first, one may think that, in this context, coupled autoregressive generation will not be helpful. Under coupled autoregressive generation, the difference in the expected score adopts the following form: \\[\\mathbb{E}_{\\boldsymbol{U}\\sim P_{\\boldsymbol{U}},S_{q}\\sim P_{ Q}}[R_{m}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}(\\boldsymbol{U},S_{q})].\\] (3) \\[\\uparrow\\uparrow\\] Coupled generation Therefore, based on the linearity of expectation and the fact that, under independent generation, both \\(\\boldsymbol{U}\\) and \\(\\boldsymbol{U}^{\\prime}\\) are sampled from the same distribution \\(P_{\\boldsymbol{U}}\\), it is easy to see that Eqs. 2 and 3 are equivalent. However, as we will show next, coupled autoregressive generation allows us to reliably estimate the difference in the two LLMs' scores from finite samples faster. More formally, we first start by characterizing the relation between the variances of the difference of scores between LLMs using the following proposition:11 Footnote 11: All proofs can be found in Appendix B. **Proposition 1**: _For any pair of LLMs \\(m,m^{\\prime}\\in\\mathcal{M}\\), it holds that_ \\[\\mathrm{Var}[R_{m}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}(\\boldsymbol{U}^{ \\prime},S_{q})]=\\mathrm{Var}[R_{m}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}( \\boldsymbol{U},S_{q})]+2\\cdot\\mathrm{Cov}[R_{m}(\\boldsymbol{U},S_{q}),R_{m^{ \\prime}}(\\boldsymbol{U},S_{q})] \\tag{4}\\]This result immediately implies that, if the scores achieved by the LLMs under comparison are positively correlated, _i.e._, the LLMs tend to generate a (in-)correct output sequence on the same prompts under the same noise values, then the variance of the difference in scores is lower under coupled generation than under independent generation, and thus we can expect a reduction in the sample size required to obtain equivalent estimation errors. In what follows, we will analyze two canonical settings in which this condition holds and, in Section 5, we will provide empirical evidence that, in a well-known benchmark dataset, this condition also holds. In the first canonical setting, the correct response to each prompt is one of two given single-token sequences, the LLMs \\(m\\) and \\(m^{\\prime}\\) under comparison always output a response that is either of these two sequences, and the sampling mechanism used by the LLMs satisfies counterfactual stability. While this setting may seem restrictive, it is found in real-world scenarios. For example, think of true/false questions (or multiple-choice questions with two options) and evaluation protocols in which the LLMs are explicitly instructed to always output true/false (or one of the two options) via their system prompt.12 The following proposition shows that the variance of the difference in scores is lower under coupled autoregressive generation: Footnote 12: Here, our goal is to illustrate that there exist natural conditions under which coupled autoregressive generation is provably beneficial in comparison to independent autoregressive generation. However, in practice, in this canonical setting, one could directly use the LLMs’ probabilities for the two tokens in each prompt to estimate the average difference of scores exactly. **Proposition 2**: _Consider a benchmark dataset such that \\(c(s_{q})\\subsetneq\\{t_{1},t_{2}\\}\\) for all \\(s_{q}\\sim P_{Q}\\), where \\(t_{1}\\) and \\(t_{2}\\) are two single-token sequences. Let \\(m\\) and \\(m^{\\prime}\\) be two LLMs that assign positive probability to the sequences \\(t_{1}\\) and \\(t_{2}\\) and zero probability to any other sequence. If the sampling mechanism defined by \\(f_{T}\\) and \\(P_{U}\\) satisfies counterfactual stability, then, it holds that_ \\[\\mathrm{Var}[R_{m}(\\mathbf{U},S_{q})-R_{m^{\\prime}}(\\mathbf{U}^{\\prime},S_{q})]> \\mathrm{Var}[R_{m}(\\mathbf{U},S_{q})-R_{m^{\\prime}}(\\mathbf{U},S_{q})]. \\tag{5}\\] In the second canonical setting, the correct response to each prompt is a single-token sequence, the LLMs \\(m\\) and \\(m^{\\prime}\\) under comparison always output a single-token response, and the sampling mechanism used by the LLMs is given by the Gumbel-Max SCM13. Similarly as in the first canonical setting, this second setting is also found in real-world scenarios, particularly taking into account that the default categorical sampler in the library PyTorch[51] implements the Gumbel-Max SCM. The following proposition shows that, as long as the model \\(m^{\\prime}\\) is _similar enough_ to \\(m\\), the variance of the difference in scores is lower under coupled generation: Footnote 13: The Gumbel-Max SCM is defined as \\(f_{T}(D_{i},U_{i})=\\operatorname*{argmax}_{t\\in V}\\left\\{\\log\\left(D_{i,t} \\right)+U_{i,t}\\right\\}\\), where \\(U_{i,t}\\sim\\operatorname*{Gumbel}(0,1)\\) are i.i.d. noise variables associated with each token [34]. **Proposition 3**: _Consider a benchmark dataset such that \\(|c(s_{q})|=1\\) for all \\(s_{q}\\sim P_{Q}\\). Let \\(m\\) be an LLM that assigns positive probability to every single-token sequence and zero probability to any other sequence. If the sampling mechanism defined by \\(f_{T}\\) and \\(P_{U}\\) is given by the Gumbel-Max SCM, then, there exists a constant \\(\\varepsilon(m)>0\\) such that, for every LLM \\(m^{\\prime}\\) that assigns positive probability to every single-token sequence and zero probability to any other sequence and satisfies \\(d(m,m^{\\prime})=\\sup_{s_{q}}\\left\\|f_{D}(s_{q},m)-f_{D}(s_{q},m^{\\prime}) \\right\\|_{\\infty}<\\varepsilon(m)\\), it holds that_ \\[\\mathrm{Var}[R_{m}(\\mathbf{U},S_{q})-R_{m^{\\prime}}(\\mathbf{U}^{\\prime},S_{q})]> \\mathrm{Var}[R_{m}(\\mathbf{U},S_{q})-R_{m^{\\prime}}(\\mathbf{U},S_{q})].\\] Based on the above proposition, we hypothesize that coupled autoregressive generation will reduce the number of samples required to reliably compare the performance of LLMs whenever these are sufficiently _similar_, _e.g._, whenever we compare fine-tuned or quantized versions of the same pre-trained LLM."
    },
    {
      "title": "4 Evaluation Based On Pairwise Comparisons",
      "text": "In this section, we focus on the evaluation and comparison of LLMs according to their level of alignment with human preferences, as elicited by pairwise comparisons between outputs of different LLMs to the same prompts. Such an evaluation protocol has become particularly popular to evaluate and compare LLMs in open-ended, complex tasks in which, in contrast to benchmark datasets, there are no structured ground-truthoutputs. In what follows, we provably show that, perhaps surprisingly, different LLMs may compare differently under coupled autoregressive generation and under independent autoregressive generation. One of the standard approaches to evaluate and compare different LLMs according to their level of alignment with human pairwise preferences reduces to estimating the win-rate achieved by each LLM \\(m\\) against any other LLM \\(m^{\\prime}\\neq m\\), _i.e._,14 Footnote 14: We believe that our theoretical results can be extended to other popular performance metrics based on the Elo rating system [42, 43, 44, 45, 46] and the Bradley-Terry model [16, 27], as discussed in Section 6. \\[\\mathbb{E}_{\\mathbf{U}\\sim P_{U},\\mathbf{U}^{\\prime}\\sim P_{U},S_{q}\\sim P _{Q}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},S_{q})>R_{m^{\\prime}}(\\mathbf{U}^{\\prime},S_{q})\\}]\\] (6) \\[\\uparrow\\uparrow\\] Independent generation where \\(\\mathbf{1}\\{R_{m}(\\mathbf{u},s_{q})>R_{m^{\\prime}}(\\mathbf{u},s_{q})\\}=1\\left(0\\right)\\) means that, for prompt \\(s_{q}\\) and realized sequence of noise values \\(\\mathbf{u}\\), the output of \\(m\\) is (not) preferred over the output of \\(m^{\\prime}\\).15 Footnote 15: For simplicity, we assume that human preferences are deterministic and thus \\(R_{m}(\\mathbf{u},s_{q},z)=R_{m}(\\mathbf{u},s_{q})\\). We lift this assumption in our experiments in Section 5. Here, similarly as in Eq. 2 in the evaluation based on benchmark datasets, we use different noise variables \\(\\mathbf{U}\\) and \\(\\mathbf{U}^{\\prime}\\) because, in this standard approach, each LLM generates outputs to each prompt independently (_i.e._, using independent autoregressive generation). Conversely, under coupled autoregressive generation, the win-rate adopts the following form: \\[\\mathbb{E}_{\\mathbf{U}\\sim P_{U},S_{q}\\sim P_{Q}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},S_{q})>R_{m ^{\\prime}}(\\mathbf{U},S_{q})\\}]\\] (7) \\[\\uparrow\\uparrow\\] Coupled generation However, in contrast with the comparison of the expected difference in scores under independent and coupled autoregressive generation in the evaluation based on benchmark datasets, we cannot directly claim that Eqs. 6 and 7 are equivalent because the win-rate is non-linear with respect to \\(R_{m}(\\mathbf{u},s_{q})\\) and \\(R_{m^{\\prime}}(\\mathbf{u}^{\\prime},s_{q})\\). In what follows, we will further analyze the difference between win-rates in two canonical settings similar to those we used in Section 3. In the first canonical setting, for each prompt, the response can only be one of two given single-token sequences and one of these sequences is preferred over the other by the user. Further, the LLMs under comparison always output one of them as a response and the sampling mechanism used by the LLMs satisfies counterfactual stability. Then, we can compute the win-rates achieved by each LLM \\(m\\) against any other LLM \\(m^{\\prime}\\neq m\\) under independent and coupled autoregressive generation using the following proposition: **Proposition 4**: _Given a fixed prompt \\(s_{q}\\sim P_{Q}\\), assume that \\(f_{R}(s_{+})>f_{R}(s_{-})\\) for \\(s_{+}=s_{q}\\circ t_{+}\\) and \\(s_{-}=s_{q}\\circ t_{-}\\), where \\(t_{+}\\) and \\(t_{-}\\) are single-token sequences. Further, assume that the LLMs \\(m\\) and \\(m^{\\prime}\\) respond \\(t_{+}\\) with probability \\(p_{m}\\) and \\(p_{m^{\\prime}}\\), respectively, and \\(t_{-}\\) with probability \\(1-p_{m}\\) and \\(1-p_{m^{\\prime}}\\), and the sampling mechanism defined by \\(f_{T}\\) and \\(P_{U}\\) satisfies counterfactual stability. Without loss of generality, assume \\(p_{m^{\\prime}}>p_{m}\\). Then, under coupled autoregressive generation, we have that_ \\[\\mathbb{E}_{\\mathbf{U}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s_{q})>R_{m^{ \\prime}}(\\mathbf{U},s_{q})\\}] =0, \\tag{8}\\] \\[\\mathbb{E}_{\\mathbf{U}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s_{q})<R_{m^{ \\prime}}(\\mathbf{U},s_{q})\\}] =p_{m^{\\prime}}-p_{m}.\\] _Conversely, under independent autoregressive generation, we have that_ \\[\\mathbb{E}_{\\mathbf{U},\\mathbf{U}^{\\prime}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{ U},s_{q})>R_{m^{\\prime}}(\\mathbf{U}^{\\prime},s_{q})\\}] =p_{m}(1-p_{m^{\\prime}}), \\tag{9}\\] \\[\\mathbb{E}_{\\mathbf{U},\\mathbf{U}^{\\prime}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\bm {U},s_{q})<R_{m^{\\prime}}(\\mathbf{U}^{\\prime},s_{q})\\}] =p_{m^{\\prime}}(1-p_{m})\\] From the above proposition, we can readily conclude that, in general, the win-rates do differ under independent and coupled autoregressive generation. Nevertheless, we may be tempted to conclude that, for ranking LLMs, this difference appears inconsequential because, for each fixed prompt \\(s_{q}\\), we have that \\[\\mathbb{E}_{\\mathbf{U}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s_{q})<R_{m^{ \\prime}}(\\mathbf{U},s_{q})\\}]-\\mathbb{E}_{\\mathbf{U}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s _{q})>R_{m^{\\prime}}(\\mathbf{U},s_{q})\\}]\\] \\[=\\mathbb{E}_{\\mathbf{U},\\mathbf{U}^{\\prime}\\sim P_{U}}[\\mathbf{1}\\{R_{m}( \\mathbf{U},s_{q})<R_{m^{\\prime}}(\\mathbf{U}^{\\prime},s_{q})\\}]-\\mathbb{E}_{\\mathbf{U},\\mathbf{ U}^{\\prime}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s_{q})>R_{m^{\\prime}}(\\mathbf{U}^{\\prime},s_{q})\\}].\\]However, whenever one needs to rank more than two LLMs, the difference in win-rates can be actually consequential--the rankings derived from the win-rates can be different under independent and coupled autoregressive generation, as illustrated by the following simple example. Consider we are given three LLMs \\(m_{1}\\), \\(m_{2}\\), and \\(m_{3}\\), and we need to rank them according to the average win-rate they achieve against each other on two input prompts \\(q\\) and \\(q^{\\prime}\\), each with a preferred single-token response out of two single-token responses. Assume that the probability that each LLM outputs the preferred single-token response for \\(q\\) and \\(q^{\\prime}\\) is given by the table of the example introduced in Section 1. Under independent autoregressive generation, the average win-rates of \\(m_{1}\\), \\(m_{2}\\) and \\(m_{3}\\) are 0.1545, 0.15675 and 0.16225, respectively. Therefore, \\(m_{3}\\) is ranked at the top, followed by \\(m_{2}\\), and \\(m_{1}\\) is ranked last. In contrast, under coupled autoregressive generation, the average win-rates of \\(m_{1}\\), \\(m_{2}\\) and \\(m_{3}\\) are 0.0525, 0.0225, and 0.03, respectively, and thus \\(m_{1}\\) is ranked at the top, followed by \\(m_{3}\\), and \\(m_{2}\\) is ranked last.16 Interestingly, the ranking obtained under coupled autoregressive generation aligns with the ranking obtained in Section 1 using the average accuracy of each LLM. More crucially, this case illustrates how rankings obtained using coupled and independent autoregressive generation can differ, leading to opposite conclusions regarding the LLMs' performance. Footnote 16: Refer to Appendix B.6 for the detailed calculation of the average win-rates. In the second canonical setting, for each prompt, the response can be one of any single-token sequences, and each of the sequences may provide a different level of user's satisfaction (_i.e._, achieve a different score). Further, the LLMs under comparison always output one of them as a response and the sampling mechanism used by the LLMs is given by the Gumbel-Max SCM. The following proposition shows that the number of ties between an LLM \\(m\\) and any other _sufficiently similar_ LLM \\(m^{\\prime}\\neq m\\) are higher under coupled autoregressive generation than under independent autoregressive generation: **Proposition 5**: _Given a fixed prompt \\(s_{q}\\sim P_{Q}\\), assume, without loss of generality, that \\(f_{R}(s_{q}\\circ t_{1})\\geq f_{R}(s_{q}\\circ t_{2})\\geq\\ldots\\geq f_{R}(s_{q} \\circ t_{|V|})\\). Let \\(m\\) be an LLM that assigns positive probability to every single-token sequence and zero probability to any other sequence. If the sampling mechanism defined by \\(f_{T}\\) and \\(P_{U}\\) is given by the Gumbel-Max SCM, then, there exists a constant \\(\\varepsilon(m)>0\\) such that, for every LLM \\(m^{\\prime}\\) that assigns positive probability to every single-token sequence and zero probability to any other sequence and satisfies \\(d(m,m^{\\prime})=\\sup_{s_{q}}\\left\\|f_{D}(s_{q},m)-f_{D}(s_{q},m^{\\prime}) \\right\\|_{\\infty}<\\varepsilon(m)\\), it holds that_ \\[\\mathbb{E}_{\\mathbf{U}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s_{q})=R_{m^{\\prime}}(\\mathbf{ U},s_{q})\\}]>\\mathbb{E}_{\\mathbf{U},\\mathbf{U}^{\\prime}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{ U},s_{q})=R_{m^{\\prime}}(\\mathbf{U}^{\\prime},s_{q})\\}].\\] The above proposition implies that the win-rates under independent and coupled autoregressive generation are different and, similarly as in the first canonical setting, rankings derived from the win-rates may differ under independent and coupled autoregressive generation. We investigate this further in our experiments in Section 5."
    },
    {
      "title": "5 Experiments",
      "text": "In this section, we evaluate several large language models from the Llama family under coupled and independent autoregressive generation using: (i) the benchmark dataset MMLU [52] and (ii) pairwise comparisons between outputs of the LLMs when prompted using open-ended questions from the LMSYS Chatbot Arena platform [57]. In all our experiments, the LLMs use an implementation of the Gumbel-Max SCM [34] as a sampler both under coupled and independent autoregressive generation. For details on hardware, datasets and models used for experiments, refer to Appendix C."
    },
    {
      "title": "Evaluation On The Mmlu Dataset",
      "text": "In this section, we compare three LLMs of different sizes, namely, Llama-3.1-8B-Instruct and Llama-3.2-{1B, 3B}-Instruct, using the MMLU benchmark dataset [52], which comprise 14,042 multiple choice questions covering 52 knowledge areas. Recall that our theoretical results in Section 3 suggest that coupled autoregressive generation requires fewer samples than independent generation to reliably estimate the competitive advantage of one LLM against another in certain canonical settings. Here, our goal is to empirically investigate to what extent these results generalize to evaluations based on the MMLU dataset. **Experimental setup.** In our experiments, for each multiple choice question in the MMLU benchmark dataset, we provide the question itself together with the available options (4 for each question, indexed from A to D) as an input prompt to the LLMs. Further, we instruct the LLMs to generate an output sequence comprising only the index of the selected option through a system prompt--refer to Appendix C for the exact prompt. To evaluate the outputs provided by each LLM, we use a binary score \\(R\\in\\{0,1\\}\\), which indicates whether the LLM output is the (single) correct (\\(R=1\\)) or incorrect (\\(R=0\\)) answer of the given options. To obtain reliable conclusions, we experiment with each multiple choice question 10 times, each time using a (different) random seed to generate the Gumbel noise variables used by the sampler. Due to space constraints, in what follows, we compare Llama-3.2-1B-Instruct and Llama-3.2-3B-Instruct on the knowledge area \"college computer science\". In Appendix D, we provide further results on other knowledge areas and other pairs of LLMs. **Results.** Figures 1(a) and 1(b) show that the scores of the LLMs are positively correlated under coupled generation and thus the variance of the difference in scores is lower under coupled generation than under independent, in agreement with Proposition 1. Further, we compute the error in the estimation of the expected difference in scores resulting from using the two approaches as a function of the available sample size. To this end, we first estimate the expected score difference using 1,000 samples and consider this as (a proxy of) the ground truth. Then, we compute the absolute estimation error achieved by independent and coupled generation while sub-sampling the original samples across various sample sizes. Figure 1(c) summarizes the results, which show that, as expected from our theoretical analysis, a lower variance of the difference in scores under coupled generation leads to a reduction in the number of samples required to achieve equivalent error in the estimation of the expected difference between the scores of the LLMs. Perhaps surprisingly, we find that this reduction can, in practice, be quite large. For example, to achieve an estimation error of \\(\\approx\\)0.034, coupled generation needs 40% fewer samples than independent generation. Figure 2: **Comparison between Llama-3.2-1B-Instruct and Llama-3.2-3B-Instruct on multiple-choice questions from the MMLU dataset. Panel (a) shows the kernel density estimate (KDE) of the covariance between the scores of the two LLMs on each question under coupled generation; the dashed line corresponds to the average value. Panel (b) shows the KDE of the variance of the difference between the scores of the LLMs on each question under coupled and independent generation; the highlighted point corresponds to the median value. Panel (c) shows the absolute error in the estimation of the expected difference between the scores of the LLMs against the number of samples; for each point on the x-axis, we perform 1,000 sub-samplings and shaded areas correspond to 95% confidence intervals. Across all panels, we use all questions from the knowledge area “college computer science” of MMLU. We obtained qualitatively similar results for other knowledge areas (refer to Appendix D).**"
    },
    {
      "title": "Evaluation On The Lmsys-Chat-1M Dataset",
      "text": "In this section, we compare the same three LLMs as in the previous section as well as three quantized variants17, namely, Llama-3.1-8B-Instruct-{AWQ-INT4, bnb-4bit, bnb-8bit}, using pairwise comparisons between their outputs by a strong LLM, when prompted with open-ended questions from the LMSYS Chatbot Arena platform [57]. Similarly as in the previous section, here, our goal is to investigate to what extent the theoretical results derived in Section 4, which show that the win-rates under coupled and independent autoregressive generation are different in certain canonical settings, generalize. Footnote 17: Refer to Appendix C for more details on the quantized variants. **Experimental setup.** We experiment with 500 questions from the LMSYS-Chat-1M dataset [58]. We provide the question itself as an input prompt to the LLMs, and instruct them to generate a concise response as an output through a system prompt. Further, similarly as elsewhere [18, 19, 27, 28, 30, 59], we use a strong LLM, namely, GPT-4o-2024-11-20, as a judge. More specifically, for each question and pair of outputs provided by two different LLMs, we prompt the judge to respond which of the two outputs it prefers, but allowing the judge to declare a tie--for the exact prompts we use, refer to Appendix C. Given these pairwise comparisons, to evaluate the outputs provided by each LLM, we use the win-rate achieved by each LLM against each other. To obtain reliable conclusions, similarly as in the previous section, we repeat each experiment 10 times, each time using a (different) random seed to generate the Gumbel noise variables used by the Gumbel-Max SCM. **Results.** We find that the empirical win-rate of each LLM against any other LLM is generally lower under coupled generation than under independent generation, as shown in Figure 3 for Llama-3.1-8B-Instruct-bnb-8bit and Figure 6 in Appendix E for other LLMs. Moreover, whenever the LLMs under comparison are _sufficiently_ similar, the difference between win-rates is statistically significant, suggesting that our theoretical results may generalize beyond the canonical setting discussed in Section 4. We hypothesize that this is partially due to an increase in the number of ties under coupled autoregressive generation. For example, for Llama-3.1-8B-Instruct-bnb-8bit, we observe a 24%, 11%, 15% increase in the number of ties in the pairwise comparisons against Llama-3.1-8B-Instruct, Llama-3.1-8B-Instruct-bnb-4bit, and Llama-3.1-8B-Instruct-AWQ-INT4. Remarkably, the difference in empirical win-rates leads to differences in the rankings derived from the average win-rates, as shown in Table 1. Under independent generation, the average win-rates achieved by Llama-3.1-8B-Instruct and Llama-3.1-8B-Instruct-bnb-8bit are Figure 3: **Empirical win-rate of Llama-3.1-8B-Instruct-bnb-8bit against any other LLM on questions from the LMSYS-Chat-1M dataset.** Each empirical win-rate is computed using pairwise comparisons between the outputs to 500 questions with 10 (different) random seeds under both coupled and independent generation. The error bars correspond to 95% confidence intervals. For each pair of empirical win-rates under coupled and independent generation, we conduct a two-tailed z-test, to test the null hypothesis that the empirical win-rates are the same; (****, ***) indicate \\(p\\)-values (\\(<0.0001\\), \\(<0.001\\)). We obtain qualitatively similar results for other LLMs (refer to Appendix E). statistically indistinguishable and thus they are both ranked at the top. However, under coupled generation, Llama-3.1-8B-Instruct has a competitive advantage against Llama-3.1-8B-Instruct-bnb-8bit, and it is ranked at the top."
    },
    {
      "title": "6 Discussion And Limitations",
      "text": "In this section, we discuss several aspects of our work, which we believe are important to consider and may serve as a basis for future research. **Model assumptions.** Our theoretical analysis of coupled autoregressive generation focuses on sampling mechanisms that satisfy counterfactual stability [36]. Although counterfactual stability has been shown to be a desirable property for causal mechanisms in SCMs and, more specifically, for causal mechanisms used for sampling in LLMs [34], counterfactual stability may not always be appropriate and should be justified by domain specific knowledge [60]. In this context, it is also worth mentioning that the Gumbel-Max SCM is not the only SCM that satisfies counterfactual stability [60, 61]. Therefore, it would be interesting to understand the sensitivity of coupled autoregressive generation to this specific choice of SCM as well as extending our theoretical analysis to sampling mechanisms satisfying other alternative properties [62]. **Practical considerations.** Our experimental results and theoretical analysis suggest that coupled autoregressive generation is most advantageous over independent autoregressive generation whenever the LLMs under comparison are sufficiently close in terms of their next-token distributions. Motivated by this observation, it would be important to identify which parts of the LLM development pipeline (_e.g._, the LLMs' architectures, training data, or fine-tuning process) lead, in practice, to sufficiently small changes in the next-token distributions for coupled autoregressive generation to be most beneficial. Our causal model for coupled autoregressive generation assumes that the LLMs under comparison share the same vocabulary. However, in practice, this may not hold since models use different tokenizers--different families of tokenizers may even use different low-level representations for tokens that appear to be the same at the string level.18 One could think of naively lifting this assumption by merging the vocabularies of different LLMs, however, we empirically found that, using this strategy, different LLMs end up using different tokens (and thus noise values) to generate the same responses and thus coupled autoregressive generation provides significantly lower gains. Extending our causal model for coupled autoregressive generation to LLMs with different tokenizers is an interesting, albeit challenging, direction for future work. Footnote 18: For example, certain tokenizers represent spaces between words with the unicode character U+2581, while others use U+0120. **Evaluation.** We have conducted experiments using LLMs from the Llama family, namely Llama-3.1-8B-Instruct and Llama-3.2-{1B, 3B}-Instruct, and quantized versions thereof. It would be interesting to conduct experiments with LLMs from other families and also consider fine-tuned versions of them to understand how coupled autoregressive generation behaves in different settings. Furthermore, we have \\begin{table} \\begin{tabular}{l c c c c} \\hline \\hline & \\multicolumn{2}{c}{Coupled} & \\multicolumn{2}{c}{Independent} \\\\ \\cline{2-5} LLM & Rank & Avg. win-rate & Rank & Avg. win-rate \\\\ \\hline 8B & 1 & 0.3670 \\(\\pm\\)0.0020 & 1 & 0.3863 \\(\\pm\\)0.0020 \\\\ bnb-8bit & 2 & 0.3562 \\(\\pm\\)0.0020 & 1 & 0.3825 \\(\\pm\\)0.0020 \\\\ bnb-4bit & 3 & 0.3339 \\(\\pm\\)0.0020 & 3 & 0.3463 \\(\\pm\\)0.0020 \\\\ AWQ-INT4 & 4 & 0.3164 \\(\\pm\\)0.0019 & 4 & 0.3310 \\(\\pm\\)0.0019 \\\\ 3B & 5 & 0.2787 \\(\\pm\\)0.0019 & 5 & 0.2828 \\(\\pm\\)0.0019 \\\\ 1B & 6 & 0.1650 \\(\\pm\\)0.0015 & 6 & 0.1664 \\(\\pm\\)0.0015 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 1: **Average win-rate and ranking of each LLM on questions from the LMSYS-Chat-1M dataset.** To estimate the average win-rate of each LLM, along with 95% confidence intervals, we use the pairwise comparisons between the outputs of all pairs of LLMs using all 500 questions with 10 (different) random seeds under both coupled and independent generation. To derive the rankings, for each LLM, we choose the lowest ranking provided by the method of Chatzi et al. [28]. experimented with (i) a single benchmark dataset (_i.e._, MMLU) and (ii) a single dataset of prompts for pairwise comparisons (_i.e._, LMSYS Chatbot Arena), where we have used a strong LLM as a judge (_i.e._, GPT-4o-2024-11-20) and win-rate as an evaluation metric. To better understand the benefits of coupled autoregressive generation, it would be important to experiment with additional datasets, pairwise comparisons made by humans, and additional evaluation metrics based on, _e.g._, the Elo rating system [42, 43, 44, 45, 46] and the Bradley-Terry model [16, 27]."
    },
    {
      "title": "7 Conclusions",
      "text": "In this work, we have introduced a causal model of coupled autoregressive generation that enables the evaluation and comparison of different LLMs under the same source of randomness. In several canonical settings, we have shown that, in evaluations based on benchmark datasets, coupled autoregressive generation can provably reduce the number of samples required to reliably compare the performance of LLMs and, in evaluations based on pairwise comparisons, it can provably lead to different and, perhaps more intuitive, rankings of LLMs in comparison with independent autoregressive generation. Lastly, we have empirically demonstrated that our theoretical results generalize to several state of the art LLMs and datasets commonly used for the evaluation and ranking of LLMs. **Acknowledgements.** Gomez-Rodriguez acknowledges support from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No. 945719)."
    },
    {
      "title": "References",
      "text": "* [1] Sebastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, and Yi Zhang. Sparks of Artificial General Intelligence: Early experiments with GPT-4. _arXiv preprint arXiv:2303.12712_, 2023. * [2] Hussein Mozannar, Gagan Bansal, Adam Fourney, and Eric Horvitz. Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming. In _Proceedings of the Conference on Human Factors in Computing Systems_. Association for Computing Machinery, 2024. * [3] Claudia E Haupt and Mason Marks. AI-Generated Medical Advice--GPT and Beyond. _Journal of American Medical Association_, 329(16):1349-1350, 2023. * [4] Bernardino Romera-Paredes, Mohammad Barekatain, Alexander Novikov, Matej Balog, M. Pawan Kumar, Emilien Dupont, Francisco J. R. Ruiz, Jordan S. Ellenberg, Pengming Wang, Omar Fawzi, Pushmeet Kohli, and Alhussein Fawzi. Mathematical Discoveries from Program Search with Large Language Models. _Nature_, 625 (7995):468-475, 2023. * [5] Stephen Bach, Victor Sanh, Zheng Xin Yong, Albert Webson, Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry, Zaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-david, Canwen Xu, Gunjan Chhablani, Han Wang, Jason Fries, Maged Al-shaibani, Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Dragomir Radev, Mike Tian-jian Jiang, and Alexander Rush. PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts. In _Proceedings of the Association for Computational Linguistics: System Demonstrations_, pages 93-104. Association for Computational Linguistics, May 2022. * [6] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V Le. Finetuned Language Models are Zero-Shot Learners. In _Proceedings of the International Conference on Learning Representations_. ICLR, 2022. * [7] Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge. In _Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)_, pages 4149-4158. ACL, 2019. * [8] Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. In _Proceedings of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 3470-3487, Dublin, Ireland, May 2022. ACL. * [9] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating Large Language Models Trained on Code. _arXiv preprint arXiv:2107.03374_, 2021. * [10] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Alexander Cosgrove, Christopher D Manning, Christopher Re, Diana Acosta-Navas, Drew Arad Hudson, Eric Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue WANG, Keshav Santhanam, Laurel Orr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri S. Chatterji, Omar Khattab, Peter Henderson, Qian Huang, Ryan Andrew Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, and Yuta Koreeda. Holistic Evaluation of Language Models. _Transactions on Machine Learning Research_, 2023. * [11] Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, and Adam Roberts. The final collection: Designing data and methods for effective instruction tuning. In _Proceedings of the International Conference on Machine Learning_, pages 22631-22648. PMLR, Jul 2023. * [12] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring Massive Multitask Language Understanding. In _Proceedings of the International Conference on Learning Representations_. ICLR, 2021. * [13] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. Self-Instruct: Aligning Language Models with Self-Generated Instructions. In _Proceedings of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 13484-13508. ACL, 2023. * [14] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. Training Language Models to Follow Instructions with Human Feedback. In _Advances in Neural Information Processing Systems_, pages 27730-27744. Curran Associates, Inc., 2022. * [15] Yufei Wang, Wanjun Zhong, Liangyou Li, Fei Mi, Xingshan Zeng, Wenyong Huang, Lifeng Shang, Xin Jiang, and Qun Liu. Aligning Large Language Models with Human: A Survey. _arXiv preprint arXiv:2307.12966_, 2023. * [16] Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios N. Angelopoulos, Tianle Li, Dacheng Li, Banghua Zhu, Hao Zhang, Michael I. Jordan, Joseph E. Gonzalez, and Ion Stoica. Chatbot arena: an open platform for evaluating LLMs by human preference. In _Proceedings of the International Conference on Machine Learning_, 2025. * [17] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. Stanford Alpaca: An instruction-following LLaMA model. [https://github.com/tatsulab/stanford_alpaca](https://github.com/tatsulab/stanford_alpaca), 2023. Online; accessed 21 May 2024. * [18] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena. In _Advances in Neural Information Processing Systems, data track_, pages 46595-46623. Curran Associates, Inc., 2023. * [19] Junlong Li, Shichao Sun, Weizhe Yuan, Run-Ze Fan, Hai Zhao, and Pengfei Liu. Generative Judge for Evaluating Alignment. In _Proceedings of the International Conference on Learning Representations_. ICLR, 2024. * [20] Ruosen Li, Teerth Patel, and Xinya Du. PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations. _Transactions on Machine Learning Research (TMLR)_, 2024. * [21] Meriem Boubdir, Edward Kim, Beyza Ermis, Sara Hooker, and Marzieh Fadaee. Elo uncovered: Robustness and best practices in language model evaluation. In _Advances in Neural Information Processing Systems_, 2024. * [22] Karan Singhal, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, Perry Payne, Martin Seneviratne, Paul Gamble, Chris Kelly, Abubakr Babiker, Nathanael Scharli, Aakanksha Chowdhery, Philip Mansfield, Dina Demner-Fushman, Blaise Aguera y Arcas, Dale Webster, Greg S. Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev, Yun Liu, Alvin Rajkomar, Joelle Barral, Christopher Semturs, Alan Karthikesalingam, and Vivek Natarajan. Large Language Models Encode Clinical Knowledge. _Nature_, 620(7972):172-180, July 2023. * [23] Evan Miller. Adding error bars to evals: A statistical approach to language model evaluations. _arXiv preprint arXiv:2411.00640_, 2024. * [24] Lovish Madaan, Aaditya K Singh, Rylan Schaeffer, Andrew Poulton, Sanmi Koyejo, Pontus Stenetorp, Sharan Narang, and Dieuwke Hupkes. Quantifying variance in evaluation benchmarks. _arXiv preprint arXiv:2406.10229_, 2024. * [25] Abhimanyu Dubey et al. The Llama 3 herd of models. _arXiv preprint arXiv:2407.21783_, 2024. * [26] Jon Saad-Falcon, Omar Khattab, Christopher Potts, and Matei Zaharia. ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems. In _Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)_, pages 338-354. ACL, 2024. doi: 10.18653/v1/2024.naacl-long.20. URL [https://doi.org/10.18653/v1/2024.naacl-long.20](https://doi.org/10.18653/v1/2024.naacl-long.20). * [27] Pierre Boyeau, Anastasios N Angelopoulos, Nir Yosef, Jitendra Malik, and Michael I Jordan. AutoEval Done Right: Using Synthetic Data for Model Evaluation. _arXiv preprint arXiv:2403.07008_, 2024. * [28] Ivi Chatzi, Eleni Straitouri, Suhas Thejaswi, and Manuel Gomez Rodriguez. Prediction-powered ranking of large language models. In _Advances in Neural Information Processing Systems_, 2024. * [29] Florian E. Dorner, Vivian Y. Nastl, and Moritz Hardt. Limits to scalable evaluation at the frontier: LLM as judge won't beat twice the data. _arXiv preprint arXiv:2410.13341_, 2024. * [30] Ariel Gera, Odellia Boni, Yotam Perlitz, Roy Bar-Haim, Lilach Eden, and Asaf Yehudai. Justrank: Benchmarking LLM judges for system ranking. _arXiv preprint arXiv:2412.09569_, 2024. * [31] Yoshua Bengio, Rejean Ducharme, and Pascal Vincent. A neural probabilistic language model. _Advances in Neural Information Processing Systems_, 13, 2000. * [32] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. _OpenAI blog_, 1(8):9, 2019. * [33] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. The curious case of neural text degeneration. In _Proceedings of the International Conference on Learning Representations_, 2020. * [34] Ivi Chatzi, Nina Corvelo Benz, Eleni Straitouri, Stratis Tsirtsis, and Manuel Gomez-Rodriguez. Counterfactual token generation in large language models. _arXiv preprint arXiv:2409.17027_, 2024. * [35] Shauli Ravfogel, Anej Svete, Vesteinn Sneabjarnarson, and Ryan Cotterell. Counterfactual generation from language models. _arXiv preprint arXiv:2411.07180_, 2024. * [36] Michael Oberst and David Sontag. Counterfactual off-policy evaluation with Gumbel-Max structural causal models. In _Proceedings of the International Conference on Machine Learning_, pages 4881-4890. PMLR, 2019. * [37] Stratis Tsirtsis, Abir De, and Manuel Rodriguez. Counterfactual explanations in sequential decision making under uncertainty. In _Advances in Neural Information Processing Systems_, 2021. * [38] Kimia Noorbakhsh and Manuel Gomez-Rodriguez. Counterfactual temporal point processes. In _Advances in Neural Information Processing Systems_, 2022. * [39] Nina L Corvelo Benz and Manuel Gomez Gomez-Rodriguez. Counterfactual inference of second opinions. In _Uncertainty in Artificial Intelligence_, 2022. * [40] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie. A Survey on Evaluation of Large Language Models. _ACM Transactions on Intelligent Systems and Technology_, 2024. * [41] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality. [https://vicuna.lmsys.org](https://vicuna.lmsys.org), 2023. Online; accessed 21 May 2024. * [42] Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Jackson Kernion, Kamal Ndousse, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, and Jared Kaplan. A General Language Assistant as a Laboratory for Alignment. _arXiv preprint arXiv:2112.00861_, 2021. * [43] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. QLoRA: Efficient Finetuning of Quantized LLMs. In _Advances in Neural Information Processing Systems_, pages 10088-10115. Curran Associates, Inc., 2024. * [44] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback. _arXiv preprint arXiv:2204.05862_, 2022. * [45] Yuxiang Wu, Zhengyao Jiang, Akbir Khan, Yao Fu, Laura Ruis, Edward Grefenstette, and Tim Rocktaschel. ChatArena: Multi-Agent Language Game Environments for Large Language Models. [https://github.com/chatarena/chatarena](https://github.com/chatarena/chatarena), 2023. * [46] Yen-Ting Lin and Yun-Nung Chen. LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models. In _Proceedings of the Workshop on NLP for Conversational AI_, pages 47-58. ACL, July 2023. * [47] Arpad E. Elo. _The USCF Rating System: Its Development, Theory, and Applications._ United States Chess Federation, 1966. * [48] Quentin Bertrand, Wojciech Marian Czarnecki, and Gauthier Gidel. On the Limitations of the Elo, Real-World Games are Transitive, Not Additive. In _International Conference on Artificial Intelligence and Statistics_, pages 2905-2921. PMLR, 2023. * [49] Judea Pearl. _Causality_. Cambridge university press, 2009. * [50] Jonas Peters, Dominik Janzing, and Bernhard Scholkopf. _Elements of causal inference: foundations and learning algorithms_. The MIT Press, 2017. * [51] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. _Advances in Neural Information Processing Systems_, 32, 2019. * [52] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. In _Proceedings of the International Conference on Learning Representations_, 2021. * [53] L. L. Thurstone. A law of comparative judgment. _Psychological Review_, 34(4):273-286, 1927. doi: 10.1037/h0070288. * [54] Ralph Allan Bradley and Milton E Terry. Rank analysis of incomplete block designs: I. the method of paired comparisons. _Biometrika_, 39(3/4):324-345, 1952. * [55] R Duncan Luce. _Individual choice behavior_, volume 4. Wiley New York, 1959. * [56] Judea Pearl. A probabilistic calculus of actions. In _Proceedings of the Annual Conference on Uncertainty in Artificial Intelligence_, 1994. * [57] LMSYS. Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings. [https://lmsys.org/](https://lmsys.org/), 2023. Online; accessed 21 May 2024. * [58] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, Eric P. Xing, Joseph E. Gonzalez, Ion Stoica, and Hao Zhang. Lmsys-chat-1m: A large-scale real-world LLM conversation dataset, 2024. * [59] Haitao Li, Qian Dong, Junjie Chen, Huixue Su, Yujia Zhou, Qingyao Ai, Ziyi Ye, and Yiqun Liu. LLMs-as-judges: A comprehensive survey on LLM-based evaluation methods. _arXiv preprint arXiv:2412.05579_, 2024. * [60] Martin B Haugh and Raghav Singal. Counterfactual analysis in dynamic latent state models. In _International Conference on Machine Learning_, 2023. * [61] Guy Lorberbom, Daniel D Johnson, Chris J Maddison, Daniel Tarlow, and Tamir Hazan. Learning generalized gumbel-max causal mechanisms. In _Advances in Neural Information Processing Systems_, 2021. * [62] Athanasios Vlontzos, Bernhard Kainz, and Ciaran M Gilligan-Lee. Estimating categorical counterfactuals via deep twin networks. _Nature Machine Intelligence_, 5(2):159-168, 2023. * [63] Iris A. M. Huijben, Wouter Kool, Max B. Paulus, and Ruud J. G. van Sloun. A review of the Gumbel-Max trick and its extensions for discrete stochasticity in machine learning. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 45(2):1353-1371, 2023. doi: 10.1109/TPAMI.2022.3157042. * [64] Bits and Bytes Foundation. Bits and bytes quantisation library. [https://huggingface.co/docs/bitsandbytes/main/en/index](https://huggingface.co/docs/bitsandbytes/main/en/index), 2024. Online; accessed 28 Jan 2025. Formal Definition of Counterfactual Stability Counterfactual stability is a desirable property of SCMs [36] that has previously been used in the context of autoregressive generation of LLMs [34]. In the following, we provide its formal definition along with a simple example to explain the intuition behind it. Throughout this section, \\(P^{\\mathcal{C}\\,;\\,do(\\cdot)}\\) denotes the probability of the interventional distribution entailed by an SCM \\(\\mathcal{C}\\) under an intervention \\(do(\\cdot)\\). Moreover, \\(P^{\\mathcal{C}\\,|\\,\\star\\,;\\,do(\\cdot)}\\) denotes the probability of the counterfactual distribution entailed by an SCM \\(\\mathcal{C}\\) under an intervention \\(do(\\cdot)\\) given that an observed event \\(\\star\\) has already occurred. **Definition 1**: _A sampling mechanism defined by \\(f_{T}\\) and \\(P_{U}\\) satisfies counterfactual stability if for all LLMs \\(m,m^{\\prime}\\in\\mathcal{M}\\), \\(i\\in\\{1,2,\\ldots,K\\}\\) and tokens \\(t_{1},t_{2}\\in V\\) with \\(t_{1}\\neq t_{2}\\), the condition_ \\[\\frac{P^{\\mathcal{C}\\,;\\,do(M=m^{\\prime})}[T_{i}=t_{1}\\,|\\,D_{i}]}{P^{\\mathcal{ C}\\,;\\,do(M=m)}[T_{i}=t_{1}\\,|\\,D_{i}]}\\geq\\frac{P^{\\mathcal{C}\\,;\\,do(M=m^{ \\prime})}[T_{i}=t_{2}\\,|\\,D_{i}]}{P^{\\mathcal{C}\\,;\\,do(M=m)}[T_{i}=t_{2}\\,| \\,D_{i}]} \\tag{10}\\] _implies that \\(P^{\\mathcal{C}\\,|\\,D_{i},M=m,T_{i}=t_{1}\\,;\\,do(M=m^{\\prime})}[T_{i}=t_{2}]=0\\)._ The property of counterfactual stability has an intuitive interpretation that can be best understood via a simple example. Assume that the vocabulary contains 2 tokens \"A\" and \"B\" and, using LLM \\(m\\), the next-token distribution at a time step \\(i\\) assigns values 0.6, 0.4 to the two tokens, respectively. Moreover, the realized noise value \\(\\mathbf{u}_{i}\\) is such that the token \"A\" is sampled. Now, consider that, while keeping the noise value \\(\\mathbf{u}_{i}\\) fixed, we change the LLM to \\(m^{\\prime}\\), resulting in a next-token distribution that assigns values 0.7, 0.3 to the two tokens, respectively. Counterfactual stability ensures that, since the noise value \\(\\mathbf{u}_{i}\\) led to \"A\" being sampled under \\(m\\) at 0.6 to 0.4 odds, the same value cannot lead to \"B\" being sampled under \\(m^{\\prime}\\) where its relative odds are lower (_i.e._, 0.3 to 0.7)."
    },
    {
      "title": "Appendix B Proofs",
      "text": ""
    },
    {
      "title": "Proof Of Proposition 1",
      "text": "We can rewrite the variance of the difference in scores under independent generation in terms of the variance of the difference in scores under coupled generation as follows: \\[\\mathrm{Var}[R_{m}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}(\\boldsymbol {U}^{\\prime},S_{q})]] =\\mathrm{Var}[R_{m}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}( \\boldsymbol{U},S_{q})+R_{m^{\\prime}}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}( \\boldsymbol{U}^{\\prime},S_{q})]]\\] \\[=\\mathrm{Var}[R_{m}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}( \\boldsymbol{U},S_{q})]+\\mathrm{Var}[R_{m^{\\prime}}(\\boldsymbol{U},S_{q})-R_{m^ {\\prime}}(\\boldsymbol{U}^{\\prime},S_{q})]\\] \\[+2\\cdot\\mathrm{Cov}[R_{m}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}( \\boldsymbol{U},S_{q}),R_{m^{\\prime}}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}( \\boldsymbol{U}^{\\prime},S_{q})].\\] For the variance of the difference in scores for the same LLM under independent noise values, we have that \\[\\mathrm{Var}[R_{m^{\\prime}}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}} (\\boldsymbol{U}^{\\prime},S_{q})] \\stackrel{{(a)}}{{=}}\\mathbb{E}[(R_{m^{\\prime}}( \\boldsymbol{U},S_{q})-R_{m^{\\prime}}(\\boldsymbol{U}^{\\prime},S_{q}))^{2}]- \\mathbb{E}[R_{m^{\\prime}}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}(\\boldsymbol{U }^{\\prime},S_{q})]^{2}\\] \\[\\stackrel{{(b)}}{{=}}\\mathbb{E}[R_{m^{\\prime}}( \\boldsymbol{U},S_{q})^{2}-2\\cdot R_{m^{\\prime}}(\\boldsymbol{U},S_{q})R_{m^{ \\prime}}(\\boldsymbol{U}^{\\prime},S_{q})+R_{m^{\\prime}}(\\boldsymbol{U}^{ \\prime},S_{q})^{2}]\\] \\[\\stackrel{{(c)}}{{=}}2\\cdot\\mathbb{E}[R_{m^{\\prime}} (\\boldsymbol{U},S_{q})^{2}]-2\\cdot\\mathbb{E}[R_{m^{\\prime}}(\\boldsymbol{U},S_{ q})R_{m^{\\prime}}(\\boldsymbol{U}^{\\prime},S_{q})],\\] where (a) holds by the definition of variance, (b) is due to the subtraction term being 0, and (c) is due to the linearity of expectation. Further, for the covariance of the difference in scores under independent generation and the difference in scores under coupled generation, we have that \\[\\mathrm{Cov}[R_{m}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}( \\boldsymbol{U},S_{q}),R_{m^{\\prime}}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}( \\boldsymbol{U}^{\\prime},S_{q})]\\] \\[\\stackrel{{(a)}}{{=}}\\mathbb{E}[(R_{m}(\\boldsymbol {U},S_{q})-R_{m^{\\prime}}(\\boldsymbol{U},S_{q}))\\cdot(R_{m^{\\prime}}( \\boldsymbol{U},S_{q})-R_{m^{\\prime}}(\\boldsymbol{U}^{\\prime},S_{q}))]\\] \\[\\qquad-\\mathbb{E}[R_{m}(\\boldsymbol{U},S_{q})-R_{m^{\\prime}}( \\boldsymbol{U},S_{q})]\\cdot\\mathbb{E}[R_{m^{\\prime}}(\\boldsymbol{U},S_{q})-R_{ m^{\\prime}}(\\boldsymbol{U}^{\\prime},S_{q})]\\]\\[\\stackrel{{(b)}}{{=}} \\mathbb{E}[R_{m}(\\mathbf{U},S_{q})R_{m^{\\prime}}(\\mathbf{U},S_{q})]-\\mathbb{E} [R_{m}(\\mathbf{U},S_{q})R_{m^{\\prime}}(\\mathbf{U}^{\\prime},S_{q})]\\] \\[-\\mathbb{E}[R_{m^{\\prime}}(\\mathbf{U},S_{q})R_{m^{\\prime}}(\\mathbf{U},S_{q })]+\\mathbb{E}[R_{m^{\\prime}}(\\mathbf{U},S_{q})R_{m^{\\prime}}(\\mathbf{U}^{\\prime},S_{q })]\\] \\[\\stackrel{{(c)}}{{=}} \\text{Cov}[R_{m}(\\mathbf{U},S_{q}),R_{m^{\\prime}}(\\mathbf{U},S_{q})]- \\mathbb{E}[R_{m^{\\prime}}(\\mathbf{U},S_{q})^{2}]+\\mathbb{E}[R_{m^{\\prime}}(\\mathbf{U},S _{q})R_{m^{\\prime}}(\\mathbf{U}^{\\prime},S_{q})]]\\] where (a) and (c) hold by the definition of covariance and (b) is due to the last term being zero and by the expansion of the first term. Putting all the above results together, it follows that \\[\\text{Var}[R_{m}(\\mathbf{U},S_{q})-R_{m^{\\prime}}(\\mathbf{U}^{\\prime},S_{ q})]] =\\text{Var}[R_{m}(\\mathbf{U},S_{q})-R_{m^{\\prime}}(\\mathbf{U},S_{q})]+2 \\cdot\\text{Cov}\\left[R_{m}(\\mathbf{U},S_{q}),R_{m^{\\prime}}(\\mathbf{U},S_{q})\\right]\\] \\[\\quad+2\\cdot\\mathbb{E}[R_{m^{\\prime}}(\\mathbf{U},S_{q})R_{m^{\\prime}} (\\mathbf{U}^{\\prime},S_{q})]-2\\cdot\\mathbb{E}[R_{m^{\\prime}}(\\mathbf{U},S_{q})^{2}]+2 \\cdot\\mathbb{E}[R_{m^{\\prime}}(\\mathbf{U},S_{q})^{2}]\\] \\[\\quad-2\\cdot\\mathbb{E}[R_{m^{\\prime}}(\\mathbf{U},S_{q})R_{m^{\\prime} }(\\mathbf{U}^{\\prime},S_{q})]\\] \\[=\\text{Var}[R_{m}(\\mathbf{U},S_{q})-R_{m^{\\prime}}(\\mathbf{U},S_{q})]+2 \\cdot\\text{Cov}[R_{m}(\\mathbf{U},S_{q}),R_{m^{\\prime}}(\\mathbf{U},S_{q})]\\] which concludes the proof."
    },
    {
      "title": "Proof Of Proposition 2",
      "text": "Due to Proposition 1, to show that Eq. 5 holds, it suffices to show that the covariance between the scores of the different LLMs under coupled generation is non-negative, _i.e._, \\(\\text{Cov}[R_{m}(\\mathbf{U},S_{q}),R_{m^{\\prime}}(\\mathbf{U},S_{q})]\\geq 0\\). To this end, we first rewrite the covariance as \\[\\text{Cov}[R_{m}(\\mathbf{U},S_{q}),R_{m^{\\prime}}(\\mathbf{U},S_{q})]=P[R_ {m}(\\mathbf{U},S_{q})=1,R_{m^{\\prime}}(\\mathbf{U},S_{q})=1]-P[R_{m}(\\mathbf{U},S_{q})=1] \\cdot P[R_{m^{\\prime}}(\\mathbf{U},S_{q})=1]\\] \\[\\quad=\\sum_{s_{q}}P[S_{q}=s_{q}]\\cdot(P[R_{m}(\\mathbf{U},s_{q})=1,R_{ m^{\\prime}}(\\mathbf{U},s_{q})=1]-P[R_{m}(\\mathbf{U},s_{q})=1]\\cdot P[R_{m^{\\prime}}(\\bm {U},s_{q})=1]) \\tag{11}\\] Next, we note that the event \\(R_{m}(\\mathbf{U},s_{q})=1\\) is equivalent to LLM \\(m\\) sampling the ground truth token for prompt \\(s_{q}\\). Without loss of generality, assume \\(t_{1}\\) is the ground truth token, _i.e._, \\(\\text{c}(s_{q})=t_{1}\\). Then, since only tokens \\(\\{t_{1},t_{2}\\}\\) have positive probability under \\(m\\) and \\(m^{\\prime}\\), it must hold that either (i) one LLM assigns a greater probability to \\(t_{1}\\) and the other LLM assigns a greater probability to \\(t_{2}\\), or (ii) both LLMs assign the same probabilities. Further, since the sampling mechanism defined by \\(f_{T}\\) and \\(P_{U}\\) satisfies counterfactual stability, we have that the condition in Eq. 10 holds in both (i) and (ii) and, under coupled generation, the LLM with greater (or equal) probability for \\(t_{1}\\) will always sample \\(t_{1}\\) when the LLM with lower (or equal) probability does. This implies that \\[P[R_{m}(\\mathbf{U},s_{q})=1,R_{m^{\\prime}}(\\mathbf{U},s_{q})=1]=\\min\\{P[R_{m}(\\mathbf{U},s_ {q})=1],P[R_{m^{\\prime}}(\\mathbf{U},s_{q})=1]\\} \\tag{12}\\] Finally, since it holds that \\[\\min\\{P[R_{m}(\\mathbf{U},s_{q})=1],P[R_{m^{\\prime}}(\\mathbf{U},s_{q})=1]\\}\\geq P[R_{m} (\\mathbf{U},s_{q})=1]P[R_{m^{\\prime}}(\\mathbf{U},s_{q})=1] \\tag{13}\\] because \\(P[R_{m}(\\mathbf{U},s_{q})=1]\\in(0,1)\\) and \\(P[R_{m^{\\prime}}(\\mathbf{U},s_{q})=1]\\in(0,1)\\) by assumption, we can conclude from Eq. 11 that \\[\\text{Cov}[R_{m}(\\mathbf{U},S_{q}),R_{m^{\\prime}}(\\mathbf{U},S_{q})]>0. \\tag{14}\\]"
    },
    {
      "title": "Proof Of Proposition 3",
      "text": "Using Proposition 1, we have that \\[\\text{Cov}[R_{m}(\\mathbf{U},S_{q}),R_{m^{\\prime}}(\\mathbf{U},S_{q})] =\\mathbb{E}[R_{m}(\\mathbf{U},S_{q})\\cdot R_{m^{\\prime}}(\\mathbf{U},S_{q} )]-\\mathbb{E}[R_{m}(\\mathbf{U},S_{q})]\\cdot\\mathbb{E}[R_{m^{\\prime}}(\\mathbf{U},S_{q})]\\] \\[=\\underbrace{P[R_{m}(\\mathbf{U},S_{q})=1,R_{m^{\\prime}}(\\mathbf{U},S_{q} )=1]}_{(i)}-\\underbrace{P[R_{m}(\\mathbf{U},S_{q})=1)\\cdot P[R_{m^{\\prime}}(\\mathbf{U},S_ {q})=1]}_{(ii)}.\\]In the remainder of the proof, we will bound each term (i) and (ii) separately and, since \\(|\\mathrm{C}(s_{q})|=1\\) for all \\(s_{q}\\sim P_{Q}\\), assume without loss of generality that the correct token is single-token sequence \\(t_{1}\\). To bound the term (ii), first note that, using the definition of the Gumbel-Max SCM, we have that, for each \\(k\\in\\{2,\\ldots,|V|\\}\\), it holds that \\[R_{m}(\\mathbf{U},s_{q}) =1\\iff U_{1}+\\log([f_{D}(s_{q},m)]_{t_{1}})\\geq U_{k}+\\log([f_{D} (s_{q},m)]_{t_{k}}),\\] \\[R_{m^{\\prime}}(\\mathbf{U},s_{q}) =1\\iff U_{1}+\\log([f_{D}(s_{q},m^{\\prime})]_{t_{1}})\\geq U_{k}+ \\log([f_{D}(s_{q},m^{\\prime})]_{t_{k}}).\\] Next, let \\(\\varepsilon^{*}>0\\) be an arbitrary constant that we will determine later such that \\[|\\log([f_{D}(S_{q},m)]_{t_{k}})-\\log([f_{D}(S_{q},m^{\\prime})]_{t_{k}})|\\leq \\varepsilon^{*}, \\tag{15}\\] and note that since, by assumption, \\(D_{t_{k}}>0\\) for all \\(k\\in\\{1,\\ldots,|V|\\}\\), any bound on the absolute difference of log-probabilities \\(|\\log([f_{D}(S_{q},m)]_{t_{k}})-\\log([f_{D}(S_{q},m^{\\prime})]_{t_{k}})|\\) uniformly implies a bound on the difference of probabilities \\(|[f_{D}(S_{q},m)]_{t_{k}}-[f_{D}(S_{q},m^{\\prime})]_{t_{k}}|\\) and vice versa. For simplicity, we prove the result in the log-domain. Now, using the bound defined by Eq. 15, we have that \\[\\bigcap_{k\\neq 1}\\left\\{U_{1}+\\log([f_{D}(S_{q},m^{\\prime})]_{t_{ 1}})\\geq U_{k}+\\log([f_{D}(S_{q},m^{\\prime})]_{t_{k}})\\right\\}\\\\ \\subset\\bigcap_{k\\neq 1}\\left\\{U_{1}+\\log([f_{D}(S_{q},m)]_{t_{1}} )+\\varepsilon^{*}\\geq U_{k}+\\log([f_{D}(S_{q},m)]_{t_{k}})-\\varepsilon^{*} \\right\\},\\] and we can then bound the term (ii) as follows: \\[P[R_{m}(\\mathbf{U},S_{q})=1]\\cdot P[R_{m^{\\prime}}(\\mathbf{U},S_{q})=1]\\] \\[=P[\\cap_{k\\neq 1}\\{U_{1}+\\log([f_{D}(S_{q},m)]_{t_{1}})\\geq U_{k }+\\log([f_{D}(S_{q},m)]_{t_{k}})\\}]\\] \\[\\qquad\\times P[\\cap_{k\\neq 1}\\{U_{1}+\\log([f_{D}(S_{q},m^{ \\prime})]_{t_{1}})\\geq U_{k}+\\log([f_{D}(S_{q},m^{\\prime})]_{t_{k}})\\}]\\] \\[\\qquad\\times P[\\cap_{k\\neq 1}\\{U_{1}+\\log([f_{D}(S_{q},m)]_{t_{1}}) +\\varepsilon^{*}\\geq U_{k}+\\log([f_{D}(S_{q},m)]_{t_{k}})-\\varepsilon^{*}\\}].\\] To bound the term (i), first note that, using the bound defined by Eq. 15, we have that \\[\\bigcap_{k\\neq 1}\\left\\{U_{1}+\\log([f_{D}(S_{q},m^{\\prime})]_{t_{1 }})\\geq U_{k}+\\log([f_{D}(S_{q},m^{\\prime})]_{t_{k}})\\right\\}\\\\ \\supset\\bigcap_{k\\neq 1}\\left\\{U_{1}+\\log([f_{D}(S_{q},m)]_{t_{1}})- \\varepsilon^{*}\\geq U_{k}+\\log([f_{D}(S_{q},m)]_{t_{k}})+\\varepsilon^{*} \\right\\}.\\] Thus, we can bound the term (i) as follows: \\[P[R_{m}(\\mathbf{U},S_{q})=1,R_{m^{\\prime}}(\\mathbf{U},S_{q})=1] =P\\Big{[}\\cap_{k\\neq 1}\\left\\{U_{1}+\\log([f_{D}(S_{q},m)]_{t_{1}}) \\geq U_{k}+\\log([f_{D}(S_{q},m)]_{t_{k}})\\right\\}\\] \\[\\qquad\\cap\\left\\{U_{1}+\\log([f_{D}(S_{q},m^{\\prime})]_{t_{1}}) \\geq U_{k}+\\log([f_{D}(S_{q},m^{\\prime})]_{t_{k}})\\right\\}\\Big{]}\\] \\[\\geq P\\Big{[}\\cap_{k\\neq 1}\\left\\{U_{1}+\\log([f_{D}(S_{q},m)]_{t_{1}}) \\geq U_{k}+\\log([f_{D}(S_{q},m)]_{t_{k}})\\right\\}\\] \\[\\qquad\\cap\\left\\{U_{1}+\\log([f_{D}(S_{q},m)]_{t_{1}}) \\geq U_{k}+\\log([f_{D}(S_{q},m)]_{t_{k}})+2\\varepsilon^{*}\\right\\}\\Big{]}\\] \\[\\stackrel{{(a)}}{{=}}\\sum_{s_{q}}P[S_{q}=s_{q}]\\cdot P [\\cap_{k\\neq 1}\\{U_{1}+\\log([f_{D}(S_{q},m)]_{t_{1}})\\] \\[\\geq U_{k}+\\log([f_{D}(S_{q},m)]_{t_{k}})+2\\varepsilon^{*}\\}],\\]where (a) follows from the fact that \\[\\{U_{1}+\\log([f_{D}(S_{q},m)]_{t_{1}})\\geq U_{k}+\\log([f_{D}(S_{q},m) ]_{t_{k}})+2\\varepsilon^{*}\\}\\\\ \\subset\\{U_{1}+\\log([f_{D}(S_{q},m)]_{t_{1}})\\geq U_{k}+\\log([f_{D} (S_{q},m)]_{t_{k}})\\}\\,.\\] Now, note that, for \\(k\\in\\{2,\\ldots,|V|\\}\\), the variable \\(X_{k}\\equiv U_{1}-U_{k}\\sim\\text{Logistic}(0,1)\\) (for \\(k=1\\), define \\(X_{k}\\equiv 0\\)). Therefore, we can rewrite the bound for (i) as \\[P[R_{m}(\\mathbf{U},S_{q})=1,R_{m^{\\prime}}(\\mathbf{U},S_{q})=1]\\\\ \\geq\\sum_{s_{q}}P[S_{q}=s_{q}]\\cdot\\prod_{k\\neq 1}\\cdot P[\\{X_{k} \\geq\\log([f_{D}(S_{q},m)]_{t_{k}})-\\log([f_{D}(S_{q},m)]_{t_{1}})+2 \\varepsilon^{*}\\}]\\] and we can rewrite the bound for (ii) as \\[P[R_{m}(\\mathbf{U},S_{q})=1]P[R_{m^{\\prime}}(\\mathbf{U},S_{q})=1]\\leq\\\\ \\sum_{s_{q}}P[S_{q}=s_{q}]\\cdot\\left\\{\\prod_{k\\neq 1}P[\\{X_{k} \\geq\\log([f_{D}(S_{q},m)]_{t_{k}})-\\log([f_{D}(S_{q},m)]_{t_{k}})-2 \\varepsilon^{*}\\}]\\right\\}\\\\ \\times P[\\cap_{k\\neq 1}\\{X_{k}\\geq\\log([f_{D}(S_{q},m)]_{t_{k}})- \\log([f_{D}(S_{q},m)]_{t_{k}})\\}].\\] As a consequence, to prove that \\(P[R_{m}(\\mathbf{U},S_{q})=1,R_{m^{\\prime}}(\\mathbf{U},S_{q})=1]>P[R_{m}(\\mathbf{U},S_{q})= 1]P[R_{m^{\\prime}}(\\mathbf{U},S_{q})=1]\\), it suffices to show that \\[\\sum_{s_{q}}P[S_{q}=s_{q}]\\prod_{k\\neq 1}\\cdot P[\\{X_{k}\\geq\\log([f_{D}(S_ {q},m)]_{t_{k}})-\\log([f_{D}(S_{q},m)]_{t_{1}})+2\\varepsilon^{*}\\}]\\\\ >\\sum_{s_{q}}P[S_{q}=s_{q}]\\prod_{k\\neq 1}\\cdot P[\\{X_{k}\\geq\\log([f_{D }(S_{q},m)]_{t_{k}})-\\log([f_{D}(S_{q},m)]_{t_{1}})-2\\varepsilon^{*}\\}]\\\\ \\times P[\\cap_{k\\neq 1}\\{X_{k}\\geq\\log([f_{D}(S_{q},m)]_{t_{k}})- \\log([f_{D}(S_{q},m)]_{t_{1}})\\}] \\tag{16}\\] To do so, note that Eq. 16 holds trivially for \\(\\varepsilon^{*}=0\\) since \\[P[\\cap_{k\\neq 1}\\{X_{k}\\geq\\log([f_{D}(S_{q},m)]_{t_{k}})-\\log([f_{D}(S_{q},m) ]_{t_{1}})\\}]<1,\\] which is a fixed term independent of \\(m^{\\prime}\\). Since all terms in Eq. 16 are continuous in \\(\\varepsilon^{*}\\), there exists \\(\\varepsilon^{*}(m)>0\\), possibly dependent of \\(m\\) but independent of \\(m^{\\prime}\\), such that Eq. 16 holds if \\[\\sup_{s_{q}}\\left\\|\\log(f_{D}(s_{q},m))-\\log(f_{D}(s_{q},m^{\\prime}))\\right\\| _{\\infty}<\\varepsilon^{*}(m).\\] Since by assumption \\(D_{t}>0\\) for all \\(t\\in V\\), there exists \\(\\varepsilon(m)>0\\) in probability space such that Eq. 16 holds if \\[\\sup_{s_{q}}\\left\\|f_{D}(s_{q},m)-f_{D}(s_{q},m^{\\prime})\\right\\|_{\\infty}< \\varepsilon(m).\\] This concludes the proof."
    },
    {
      "title": "Proof Of Proposition 4",
      "text": "Under coupled autoregressive generation, if the LLM \\(m\\) samples the preferred token \\(t_{+}\\), then the LLM \\(m^{\\prime}\\) must also sample \\(t_{+}\\) because \\(t_{+}\\) is more likely under \\(m^{\\prime}\\) than under \\(m\\) and the sampling mechanism defined by \\(f_{T}\\) and \\(P_{U}\\) satisfies counterfactual stability. This implies that the win-rate achieved by \\(m\\) against \\(m^{\\prime}\\) is \\[\\mathbb{E}_{\\mathbf{U}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s_{q})>R_{m^{\\prime}}(\\mathbf{ U},s_{q})\\}]=P[f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{+},f_{T}(f_{D}(s_{q},m^{ \\prime}),\\mathbf{U})=t_{-}]=0 \\tag{17}\\]and that \\[P[f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{+},f_{T}(f_{D}(s_{q},m^{\\prime}),\\mathbf{U})=t_{+}]=P[ f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{+}]=p_{m}. \\tag{18}\\] Using the same reasoning, if the LLM \\(m^{\\prime}\\) samples the non-preferred token \\(t_{-}\\), then, \\(m\\) must also sample \\(t_{-}\\) because \\(t_{-}\\) is more likely under \\(m\\) than under \\(m^{\\prime}\\). This implies that \\[P[f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{-},f_{T}(f_{D}(s_{q},m^{\\prime}),\\mathbf{U})=t_{- }]=P[f_{T}(f_{D}(s_{q},m^{\\prime}),\\mathbf{U})=t_{-}]=1-p_{m^{\\prime}} \\tag{19}\\] Then, from Eq. 18 and Eq. 19, we can conclude that \\[\\mathbb{E}_{\\mathbf{U}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s_{q})=R_{m^{\\prime}}(\\mathbf{ U},s_{q})\\}]=p_{m}+(1-p_{m^{\\prime}}) \\tag{20}\\] Finally, from Eq. 17 and Eq. 20, we can conclude that the win-rate achieved by \\(m^{\\prime}\\) against \\(m\\) is \\[\\mathbb{E}_{\\mathbf{U}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s_{q})<R_{m^{ \\prime}}(\\mathbf{U},s_{q})\\}]\\] \\[=1-\\mathbb{E}_{\\mathbf{U}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s_{q})>R_{ m^{\\prime}}(\\mathbf{U},s_{q})\\}]-\\mathbb{E}_{\\mathbf{U}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{U},s_{q} )=R_{m^{\\prime}}(\\mathbf{U},s_{q})\\}]=p_{m^{\\prime}}-p_{m}.\\] Under independent autoregressive generation, the LLMs \\(m\\) and \\(m^{\\prime}\\) sample tokens independently from each other, _i.e._, \\(f_{T}(f_{D}(s_{q},m),\\mathbf{U})\\perp f_{T}(f_{D}(s_{q},m^{\\prime}),\\mathbf{U}^{\\prime})\\). Thus, we can factorize all joint probabilities when computing the win-rates and obtain \\[\\mathbb{E}_{\\mathbf{U},\\mathbf{U}^{\\prime}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{ U},s_{q})>R_{m^{\\prime}}(\\mathbf{U}^{\\prime},s_{q})\\}] =P[f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{+}]\\cdot P[f_{T}(f_{D}(s_{q},m^ {\\prime}),\\mathbf{U}^{\\prime})=t_{-}]\\] \\[=p_{m}\\cdot(1-p_{m^{\\prime}})\\] and \\[\\mathbb{E}_{\\mathbf{U},\\mathbf{U}^{\\prime}\\sim P_{U}}[\\mathbf{1}\\{R_{m}(\\mathbf{ U},s_{q})<R_{m^{\\prime}}(\\mathbf{U}^{\\prime},s_{q})\\}]=p_{m^{\\prime}}\\cdot(1-p_{m}).\\]"
    },
    {
      "title": "Proof Of Proposition 5",
      "text": "We follow the notations and technique of Proposition 3. Fix query \\(s_{q}\\) and consider first the case of independent autoregressive generation. Since each LLM can only assign a non-zero probability to single-token sequences, we have: \\[P[R_{m}(\\mathbf{U},s_{q})=R_{m^{\\prime}}(\\mathbf{U}^{\\prime},s_{q})] =\\sum_{k=1}^{|V|}P[f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{k}]P[f_{T}(f_{D }(s_{q},m^{\\prime}),\\mathbf{U})=t_{k}]\\] \\[<\\sum_{k=1}^{|V|}P[f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{k}],\\] In the case of coupled autoregressive generation, since \\[P\\left[\\{f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{k}\\}\\cap\\{f_{T}(f_{D}(s_{q},m),\\mathbf{U} )=t_{j}\\}\\right]=0,\\;i\\neq j,\\] we obtain: \\[P[R_{m}(\\mathbf{U},s_{q})=R_{m^{\\prime}}(\\mathbf{U},s_{q})]\\] \\[=P\\left[\\cup_{i}\\{f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{k},f_{T}(f_{D}( s_{q},m^{\\prime}),\\mathbf{U})=t_{k}\\}\\right]\\] \\[=\\sum_{k}P[\\{f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{k},f_{T}(f_{D}(s_{q},m^{\\prime}),\\mathbf{U})=t_{k}\\}]\\] \\[=\\sum_{k}P[f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{k}]P[f_{T}(f_{D}(s_{q}, m^{\\prime}),\\mathbf{U})=t_{k}|f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{k}].\\]We now follow [63] and expand the posterior Gumbels, \\(P[f_{T}(f_{D}(s_{q},m^{\\prime}),\\mathbf{U})=t_{k}|f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{k}]\\), as truncated Gumbel distributions. In particular, we leverage the fact that \\[\\max_{t\\in V}\\{U_{t}+\\log([f_{D}(s_{q},\\bullet)]_{t})\\}\\sim\\text{Gumbel}(0,1), \\tag{21}\\] and that a Gumbel distribution, with parameter \\(\\log(\\theta)\\), truncated at \\(b\\sim\\text{Gumbel}(0,1)\\) can be sampled as \\[-\\log(\\exp(-b)-\\log(\\eta)/\\theta),\\;\\eta\\sim U(0,1). \\tag{22}\\] Furthermore, by assumption, \\(D_{t_{k}}>0\\) for all \\(k\\in\\{1,\\ldots,|V|\\}\\), so that any bound on the absolute difference of log-probabilities \\(|\\log([f_{D}(s_{q},m)]_{t_{k}})-\\log([f_{D}(s_{q},m^{\\prime})]_{t_{k}})|\\) uniformly implies a bound on the difference of probabilities \\(|[f_{D}(s_{q},m)]_{t_{k}}-[f_{D}(s_{q},m^{\\prime})]_{t_{k}}|\\) and vice versa. Using the bound \\[|\\log([f_{D}(s_{q},m)]_{t_{k}})-\\log([f_{D}(s_{q},m^{\\prime})]_{t_{k}})|\\leq \\varepsilon^{*}\\] and the Gumbel properties in Eq. 21 and Eq. 22, we obtain: \\[P[R_{m}(\\mathbf{U},s_{q})=R_{m^{\\prime}}(\\mathbf{U},s_{q})]\\] \\[=\\sum_{k}P[f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{k}]\\] \\[\\qquad\\times P\\Bigg{[}\\bigcap_{k}\\Big{\\{}\\log([f_{D}(s_{1},m^{ \\prime})]_{t_{k}})-\\log([f_{D}(s_{1},m)]_{t_{k}})-\\log(-\\log(\\eta_{k}))\\] \\[\\qquad\\qquad\\qquad\\geq\\log([f_{D}(s_{1},m^{\\prime})]_{t_{j}})- \\log([f_{D}(s_{1},m)]_{t_{j}})-\\log(-\\log(\\eta_{k})-\\log(\\eta_{j})/[f_{D}(s_{1 },m^{\\prime})]_{t_{j}})\\Big{\\}}\\Bigg{]}\\] \\[\\geq\\sum_{k}P[f_{T}(f_{D}(s_{q},m),\\mathbf{U})=t_{k}]\\] \\[\\qquad\\times P\\left[\\cap_{k}\\{-\\log(-\\log(\\eta_{k}))\\geq-2 \\varepsilon^{*}-\\log(-\\log(\\eta_{k})-\\log(\\eta_{j})/[f_{D}(s_{1},m^{\\prime})] _{t_{j}})\\}\\right] \\tag{23}\\] where \\(\\eta_{k}\\sim\\text{U}(0,1)\\) are independently distributed uniform random variables. Now, note that the claim holds for \\(\\varepsilon^{*}=0\\) since, in that case, we have that \\[P\\left[\\bigcap_{k}\\{-\\log(-\\log(\\eta_{k}))\\geq-\\log(-\\log(\\eta_{k})-\\log(\\eta _{k})/[f_{D}(s_{1},m^{\\prime})]_{t_{k}})\\}\\right]=1,\\] using that \\(x\\mapsto-\\log(x)\\) is strictly decreasing. Since all terms in Eq. 23 are continuous in \\(\\varepsilon^{*}\\), there exists \\(\\varepsilon^{*}(m)>0\\), possibly dependent on \\(m\\) but independent of \\(m^{\\prime}\\), such that \\[P[R_{m}(\\mathbf{U},s_{q})=R_{m^{\\prime}}(\\mathbf{U},s_{q})]>P[R_{m}(\\mathbf{U},s_{q})=R_{m ^{\\prime}}(\\mathbf{U}^{\\prime},s_{q})] \\tag{24}\\] holds if \\[\\sup_{s_{q}}\\left\\|\\log(f_{D}(s_{q},m))-\\log(f_{D}(s_{q},m^{\\prime}))\\right\\| _{\\infty}<\\varepsilon^{*}(m).\\] Since by assumption \\(D_{t}>0\\) for all \\(t\\in V\\), there exists \\(\\varepsilon(m)>0\\) in probability space such that Eq. 24 holds if \\[\\sup_{s_{q}}\\left\\|f_{D}(s_{q},m)-f_{D}(s_{q},m^{\\prime})\\right\\|_{\\infty}< \\varepsilon(m).\\] This concludes the proof."
    },
    {
      "title": "Calculation Of Average Win-Rates In The Example Used In Sections 1 And 4",
      "text": "In this section, we provide detailed calculations of the win-rates for the example in Sections 1 and 4. Recall that in this example, we are given three LLMs \\(m_{1}\\), \\(m_{2}\\) and \\(m_{3}\\), and we need to rank them according to their ability to answer correctly two types of input prompts, \\(q\\) and \\(q^{\\prime}\\), picked uniformly at random. We assume that the true probability that each LLM answers correctly each type of input prompt is given by: \\[\\begin{array}{c c c}\\hline&m_{1}&m_{2}&m_{3}\\\\ \\hline q&p_{1}=0.4&p_{2}=0.48&p_{3}=0.5\\\\ q^{\\prime}&p_{1}^{\\prime}=1&p_{2}^{\\prime}=0.9&p_{3}^{\\prime}=0.89\\\\ \\hline\\end{array}\\] Using Proposition 4, the win-rates under independent autoregressive generation are given, for each LLM \\(m_{k}\\), by: \\[\\frac{1}{2}\\sum_{j\\neq k}\\mathbb{E}_{\\mathbf{U},\\mathbf{U}^{\\prime}\\sim P_{U},S_{q} \\sim P_{Q}}[\\mathbf{1}\\{R_{m_{k}}(\\mathbf{U},S_{q})>R_{m_{j}}(\\mathbf{U}^{\\prime},S_{ q})\\}]=\\frac{\\sum_{j\\neq k}p_{k}(1-p_{j})+\\sum_{j\\neq k}p_{k}^{\\prime}(1-p_{j}^{ \\prime})}{4}. \\tag{25}\\] Substituting the numerical values we obtain: \\[\\frac{1}{2}\\sum_{j\\neq 1}\\mathbb{E}_{\\mathbf{U},\\mathbf{U}^{\\prime}\\sim P_{U},S _{q}\\sim P_{Q}}[\\mathbf{1}\\{R_{m_{1}}(\\mathbf{U},S_{q})>R_{m_{j}}(\\mathbf{U}^{\\prime},S _{q})\\}]=0.1545, \\tag{26}\\] \\[\\frac{1}{2}\\sum_{j\\neq 2}\\mathbb{E}_{\\mathbf{U},\\mathbf{U}^{\\prime}\\sim P_{U}, S_{q}\\sim P_{Q}}[\\mathbf{1}\\{R_{m_{2}}(\\mathbf{U},S_{q})>R_{m_{j}}(\\mathbf{U}^{\\prime},S _{q})\\}]=0.15675,\\] \\[\\frac{1}{2}\\sum_{j\\neq 3}\\mathbb{E}_{\\mathbf{U},\\mathbf{U}^{\\prime}\\sim P_{U},S_{q}\\sim P_{Q}}[\\mathbf{1}\\{R_{m_{3}}(\\mathbf{U},S_{q})>R_{m_{j}}(\\mathbf{U}^{\\prime},S_{q})\\}]=0.16225\\] Similarly, using Proposition 4, the win-rates using coupled autoregressive generation can be written, for each LLM \\(m_{k}\\), as: \\[\\frac{1}{2}\\sum_{j\\neq k}\\mathbb{E}_{\\mathbf{U}\\sim P_{U},S_{q}\\sim P_{Q}}[ \\mathbf{1}\\{R_{m_{k}}(\\mathbf{U},S_{q})>R_{m_{j}}(\\mathbf{U},S_{q})\\}]=\\frac{\\sum_{j \\neq k}(p_{k}-p_{j})_{+}+\\sum_{j\\neq k}(p_{k}^{\\prime}-p_{j}^{\\prime})_{+}}{4}, \\tag{27}\\] where \\((\\bullet)_{+}=\\max(0,\\bullet)\\) denotes the positive part. Substituting the numerical values we obtain: \\[\\frac{1}{2}\\sum_{j\\neq 1}\\mathbb{E}_{\\mathbf{U}\\sim P_{U},S_{q}\\sim P_{Q} }[\\mathbf{1}\\{R_{m_{1}}(\\mathbf{U},S_{q})>R_{m_{j}}(\\mathbf{U},S_{q})\\}]=0.0525,\\] \\[\\frac{1}{2}\\sum_{j\\neq 2}\\mathbb{E}_{\\mathbf{U}\\sim P_{U},S_{q}\\sim P_{Q} }[\\mathbf{1}\\{R_{m_{2}}(\\mathbf{U},S_{q})>R_{m_{j}}(\\mathbf{U},S_{q})\\}]=0.0225,\\] \\[\\frac{1}{2}\\sum_{j\\neq 3}\\mathbb{E}_{\\mathbf{U}\\sim P_{U},S_{q}\\sim P_{Q} }[\\mathbf{1}\\{R_{m_{3}}(\\mathbf{U},S_{q})>R_{m_{j}}(\\mathbf{U},S_{q})\\}]=0.03.\\] [MISSING_PAGE_FAIL:24]"
    },
    {
      "title": "Appendix D Additional Experimental Results On The Mmlu Dataset",
      "text": "Figure 4: **Comparison between three pairs of LLMs on multiple-choice questions from the “college computer science” knowledge area of the MMLU dataset. Panels in column (a) show the kernel density estimate (KDE) of the covariance between the scores of the two LLMs on each question under coupled generation; the dashed lines correspond to average values. Panels in column (b) show the KDE of the variance of the difference between the scores of the LLMs on each question under coupled and independent generation; the highlighted points correspond to median values. Panels in column (c) show the absolute error in the estimation of the expected difference between the scores of the LLMs against the number of samples; for each point on the x-axis, we perform 1,000 sub-samplings and shaded areas correspond to 95% confidence intervals.**"
    },
    {
      "title": "6 College Chemistry",
      "text": "Figure 5: **Comparison between Llama-3.2-1B-Instruct and Llama-3.2-3B-Instruct on multiple-choice questions from four knowledge areas of the MMLU dataset. Panels in column (a) show the kernel density estimate (KDE) of the covariance between the scores of the two LLMs on each question under coupled generation; the dashed lines correspond to average values. Panels in column (b) show the KDE of the variance of the difference between the scores of the LLMs on each question under coupled and independent generation; the highlighted points correspond to median values. Panels in column (c) show the absolute error in the estimation of the expected difference between the scores of the LLMs against the number of samples; for each point on the x-axis, we perform 1,000 sub-samplings and shaded areas correspond to 95% confidence intervals. We observe qualitatively similar results for other knowledge areas.** [MISSING_PAGE_EMPTY:27]"
    }
  ]
}
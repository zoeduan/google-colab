{
  "title": "Measuring Social Norms of Large Language Models",
  "authors": [
    "Ye Yuan",
    "Kexin Tang",
    "Jianhao Shen",
    "Ming Zhang",
    "Chenguang Wang",
    "Pan Lu",
    "Swaroop Mishra",
    "Tony Xia",
    "Liang Qiu",
    "Kai- Wei Chang",
    "Song-Chun Zhu",
    "Oyvind Tafjord",
    "Peter Clark",
    "Long Ouyang",
    "Jeffrey Wu",
    "Xu Jiang",
    "Diogo Almeida",
    "Carroll Wainwright",
    "Pamela Mishkin",
    "Chong Zhang",
    "Colin Raffel",
    "Noam Shazeer",
    "Adam Roberts",
    "Katherine Lee",
    "Sharan Narang",
    "Michael Matena",
    "Yanqi Zhou",
    "Wei Li",
    "Peter J 2020 Liu",
    "Freda Shi",
    "Xinyun Chen",
    "Kanishka Misra",
    "Nathan Scales",
    "David Dohan",
    "Ed H Chi",
    "Nathanael Schärli",
    "Denny 2023 Zhou",
    "Large",
    "Aarohi Srivastava",
    "Abhinav Rastogi",
    "Abhishek Rao",
    "Abu Awal",
    "Md Shoeb",
    "Abubakar Abid",
    "Adam Fisch",
    "Adam R Brown",
    "Adam Santoro",
    "Aditya Gupta",
    "Rohan Taori",
    "Ishaan Gulrajani",
    "Tianyi Zhang",
    "Yann Dubois",
    "Xuechen Li",
    "Carlos Guestrin",
    "Percy Liang",
    "Tatsunori B Hashimoto",
    "Alpaca",
    "Hugo Touvron",
    "Thibaut Lavril",
    "Gautier Izacard",
    "Xavier Martinet",
    "Marie-Anne Lachaux",
    "Timothée Lacroix",
    "Baptiste Rozière",
    "Naman Goyal",
    "Eric Hambro",
    "Faisal Azhar",
    "Aurelien Rodriguez",
    "Armand Joulin"
  ],
  "abstract": "\n We present a new challenge to examine whether large language models understand social norms. In contrast to existing datasets, our dataset requires a fundamental understanding of social norms to solve. Our dataset features the largest set of social norm skills, consisting of 402 skills and 12, 383 questions covering a wide set of social norms ranging from opinions and arguments to culture and laws. We design our dataset according to the K-12 curriculum. This enables the direct comparison of the social understanding of large language models to humans, more specifically, elementary students. While prior work generates nearly random accuracy on our benchmark, recent large language models such as GPT3.5-Turbo and LLaMA2-Chat are able to improve the performance significantly, only slightly below human performance. We then propose a multi-agent framework based on large language models to improve the models' ability to understand social norms. This method further improves large language models to be on par with humans. Given the increasing adoption of large language models in real-world applications, our finding is particularly important and presents a unique direction for future improvements. \n",
  "references": [
    {
      "id": null,
      "title": "Measuring Social Norms of Large Language Models",
      "authors": [
        "Ye Yuan",
        "Kexin Tang",
        "Jianhao Shen",
        "Ming Zhang",
        "Chenguang Wang",
        "Pan Lu",
        "Swaroop Mishra",
        "Tony Xia",
        "Liang Qiu",
        "Kai- Wei Chang",
        "Song-Chun Zhu",
        "Oyvind Tafjord",
        "Peter Clark",
        "Long Ouyang",
        "Jeffrey Wu",
        "Xu Jiang",
        "Diogo Almeida",
        "Carroll Wainwright",
        "Pamela Mishkin",
        "Chong Zhang",
        "Colin Raffel",
        "Noam Shazeer",
        "Adam Roberts",
        "Katherine Lee",
        "Sharan Narang",
        "Michael Matena",
        "Yanqi Zhou",
        "Wei Li",
        "Peter J 2020 Liu",
        "Freda Shi",
        "Xinyun Chen",
        "Kanishka Misra",
        "Nathan Scales",
        "David Dohan",
        "Ed H Chi",
        "Nathanael Schärli",
        "Denny 2023 Zhou",
        "Large",
        "Aarohi Srivastava",
        "Abhinav Rastogi",
        "Abhishek Rao",
        "Abu Awal",
        "Md Shoeb",
        "Abubakar Abid",
        "Adam Fisch",
        "Adam R Brown",
        "Adam Santoro",
        "Aditya Gupta",
        "Rohan Taori",
        "Ishaan Gulrajani",
        "Tianyi Zhang",
        "Yann Dubois",
        "Xuechen Li",
        "Carlos Guestrin",
        "Percy Liang",
        "Tatsunori B Hashimoto",
        "Alpaca",
        "Hugo Touvron",
        "Thibaut Lavril",
        "Gautier Izacard",
        "Xavier Martinet",
        "Marie-Anne Lachaux",
        "Timothée Lacroix",
        "Baptiste Rozière",
        "Naman Goyal",
        "Eric Hambro",
        "Faisal Azhar",
        "Aurelien Rodriguez",
        "Armand Joulin"
      ],
      "year": "",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "",
      "authors": [
        "M Bozhidar",
        "Kate Bashkov",
        "Lara Mattison",
        "Hochstein"
      ],
      "year": "2021",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Language models are few-shot learners",
      "authors": [
        "Tom Brown",
        "Benjamin Mann",
        "Nick Ryder",
        "Melanie Subbiah"
      ],
      "year": "2020",
      "venue": "Advances in neural information processing systems",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "Ying Sheng, and others. 2023. Vicuna: An open-source chatbot impressing gpt-4",
      "authors": [
        "Lingjiao Chen",
        "Matei Zaharia",
        "James Zou",
        "; Wei-Lin",
        "Zhuohan Chiang",
        "Zi Li",
        "Lin"
      ],
      "year": "2023",
      "venue": "Ying Sheng, and others. 2023. Vicuna: An open-source chatbot impressing gpt-4",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Palm: Scaling language modeling with pathways",
      "authors": [
        "Aakanksha Chowdhery",
        "Sharan Narang",
        "Jacob Devlin",
        "Maarten Bosma"
      ],
      "year": "2023",
      "venue": "Journal of Machine Learning Research",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Agent instructs large language models to be general zeroshot reasoners",
      "authors": [
        "Nicholas Crispino",
        "Kyle Montgomery",
        "Fankun Zeng",
        "Dawn Song",
        "Chenguang Wang"
      ],
      "year": "2023",
      "venue": "Google Gemini Team. 2023. Gemini: A family of highly capable multimodal models",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "On calibration of modern neural networks",
      "authors": [
        "Chuan Guo",
        "Geoff Pleiss",
        "Yu Sun",
        "Kilian Q Weinberger"
      ],
      "year": "2017",
      "venue": "ICML",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "Dawn Song, and Jacob Steinhardt. 2021a. Measuring massive multitask language understanding",
      "authors": [
        "Dan Hendrycks",
        "Collin Burns",
        "Steven Basart",
        "Andy Zou",
        "Mantas Mazeika"
      ],
      "year": "",
      "venue": "ICLR",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "Eric Tang, Dawn Song, and Jacob Steinhardt. 2021b. Measuring mathematical problem solving with the math dataset",
      "authors": [
        "Dan Hendrycks",
        "Collin Burns",
        "Saurav Kadavath",
        "Akul Arora",
        "Steven Basart"
      ],
      "year": "",
      "venue": "Eric Tang, Dawn Song, and Jacob Steinhardt. 2021b. Measuring mathematical problem solving with the math dataset",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Long short-term memory",
      "authors": [
        "Sepp Hochreiter",
        "Jürgen Schmidhuber"
      ],
      "year": "1997",
      "venue": "Neural computation",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "How does the smartscore work?",
      "authors": [
        "Ixl"
      ],
      "year": "2014",
      "venue": "b. Understanding the ixl smartscore",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "Unifiedqa: Crossing format boundaries with a single QA system",
      "authors": [
        "Daniel Khashabi",
        "Sewon Min",
        "Tushar Khot",
        "Ashish Sabharwal",
        "Oyvind Tafjord",
        "Peter Clark",
        "Hannaneh Hajishirzi"
      ],
      "year": "2020",
      "venue": "Findings of EMNLP",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "The impact of ixl math and ixl ela on student achievement in grades pre-k to 12",
      "authors": [
        "Ixl Learning"
      ],
      "year": "2019",
      "venue": "The impact of ixl math and ixl ela on student achievement in grades pre-k to 12",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Camel: Communicative agents for\" mind\" exploration of large scale language model society",
      "authors": [
        "Guohao Li",
        "Hasan Abed",
        "Al Kader Hammoud",
        "Hani Itani",
        "Dmitrii Khizbullin",
        "Bernard Ghanem"
      ],
      "year": "2023",
      "venue": "Camel: Communicative agents for\" mind\" exploration of large scale language model society",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models",
      "authors": [
        "Hugo Touvron",
        "Louis Martin",
        "Kevin Stone",
        "Peter Albert",
        "Amjad Almahairi",
        "Yasmine Babaei",
        "Nikolay Bashlykov",
        "Soumya Batra",
        "Prajjwal Bhargava"
      ],
      "year": "",
      "venue": "Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "Chatlog: Recording and analyzing chatgpt across time",
      "authors": [
        "Shangqing Tu",
        "Chunyang Li",
        "Jifan Yu",
        "Xiaozhi Wang",
        "Lei Hou",
        "Juanzi Li"
      ],
      "year": "2023",
      "venue": "Chatlog: Recording and analyzing chatgpt across time",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "DeepStruct: Pretraining of language models for structure prediction",
      "authors": [
        "Chenguang Wang",
        "Xiao Liu",
        "Zui Chen",
        "Haoyun Hong",
        "Jie Tang",
        "Dawn Song"
      ],
      "year": "2022",
      "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
      "doi": "10.18653/v1/2022.findings-acl.67"
    },
    {
      "id": "b16",
      "title": "Language models are open knowledge graphs",
      "authors": [
        "Chenguang Wang",
        "Xiao Liu",
        "Dawn Song"
      ],
      "year": "2020",
      "venue": "Language models are open knowledge graphs",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "2023a. Dt-solver: Automated theorem proving with dynamic-tree sampling guided by proof-level value function",
      "authors": [
        "Haiming Wang",
        "Ye Yuan",
        "Zhengying Liu",
        "Jianhao Shen",
        "Yichun Yin",
        "Jing Xiong",
        "Enze Xie",
        "Han Shi",
        "Yujun Li",
        "Lin Li"
      ],
      "year": "",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "Tensor networks meet neural networks: A survey and future perspectives",
      "authors": [
        "Maolin Wang",
        "Yu Pan",
        "Zenglin Xu",
        "Xiangli Yang",
        "Guangxi Li",
        "Andrzej Cichocki"
      ],
      "year": "2023",
      "venue": "Tensor networks meet neural networks: A survey and future perspectives",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "Chain-of-thought prompting elicits reasoning in large language models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Dale Schuurmans",
        "Maarten Bosma",
        "Fei Xia",
        "Ed Chi",
        "V Quoc",
        "Denny Le",
        "Zhou"
      ],
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "Zecheng Tang, and Nan Duan. 2023a. Visual chatgpt: Talking, drawing and editing with visual foundation models",
      "authors": [
        "Chenfei Wu",
        "Shengming Yin",
        "Weizhen Qi",
        "Xiaodong Wang"
      ],
      "year": "",
      "venue": "Zecheng Tang, and Nan Duan. 2023a. Visual chatgpt: Talking, drawing and editing with visual foundation models",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework",
      "authors": [
        "Qingyun Wu",
        "Gagan Bansal",
        "Jieyu Zhang",
        "Yiran Wu",
        "Shaokun Zhang",
        "Erkang Zhu",
        "Beibin Li",
        "Li Jiang",
        "Xiaoyun Zhang",
        "Chi Wang"
      ],
      "year": "2023",
      "venue": "Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework",
      "doi": "10.48550/arXiv.2308.08155"
    },
    {
      "id": "b22",
      "title": "The rise and potential of large language model based agents: A survey",
      "authors": [
        "Zhiheng Xi",
        "Wenxiang Chen",
        "Xin Guo",
        "Wei He",
        "Yiwen Ding",
        "Boyang Hong",
        "Ming Zhang",
        "Junzhe Wang",
        "Senjie Jin",
        "Enyu Zhou"
      ],
      "year": "2023",
      "venue": "The rise and potential of large language model based agents: A survey",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "Dual queries with low rank approximation re-ranking for in-context learning",
      "authors": [
        "Jing Xiong",
        "Zixuan Li",
        "Chuanyang Zheng",
        "Zhijiang Guo",
        "Yichun Yin",
        "Enze Xie",
        "Zhicheng Yang",
        "Qingxing Cao",
        "Haiming Wang",
        "Xiongwei Han"
      ],
      "year": "",
      "venue": "Dual queries with low rank approximation re-ranking for in-context learning",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "Benchmarking formal mathematical proof reduction for generative language models",
      "authors": [
        "Jing Xiong",
        "Jianhao Shen",
        "Ye Yuan",
        "Haiming Wang",
        "Yichun Yin",
        "Zhengying Liu",
        "Lin Li",
        "Zhijiang Guo",
        "Qingxing Cao",
        "Yinya Huang"
      ],
      "year": "",
      "venue": "Benchmarking formal mathematical proof reduction for generative language models",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "React: Synergizing reasoning and acting in language models",
      "authors": [
        "Shunyu Yao",
        "Jeffrey Zhao",
        "Dian Yu",
        "Nan Du",
        "Izhak Shafran",
        "Karthik Narasimhan",
        "Yuan Cao"
      ],
      "year": "2022",
      "venue": "React: Synergizing reasoning and acting in language models",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Exchange-ofthought: Enhancing large language model capabilities through cross-model communication",
      "authors": [
        "Zhangyue Yin",
        "Qiushi Sun"
      ],
      "year": "2023",
      "venue": "Exchange-ofthought: Enhancing large language model capabilities through cross-model communication",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "Measuring Social Norms Of Large Language Models",
      "text": "Ye Yuan1,2,3, Kexin Tang1,2, Jianhao Shen1,2, Ming Zhang1,2,3, Chenguang Wang4 Corresponding authors.The code and dataset are available at [https://huggingface.co/datasets/socialnormdataset/social](https://huggingface.co/datasets/socialnormdataset/social). ability to understand social norms. Especially, post-training techniques such as reinforcement learning with human feedback (RLHF) (Ouyang et al., 2022) improve the performance over their base models significantly. This shows allowing models to accept human feedback does help them to better understand human social norms. In contrast, prior models such as a small UnifiedQA powered by T5 (Raffel et al., 2020) only generate near-random performance. Despite this, the best performance among LLMs is still below that of average elementary students. For instance, GPT3.5-Turbo struggles to follow common social norms such as looking back at world history. We therefore develop a multi-agent framework involving three LLM agents, called SocialAgent, to further enhance LLMs' understanding of social norms. Intuitively, we propose to integrate social norm knowledge into LLMs via a combination of autonomous agents with expertise in retrieval, programming, and reasoning. With SocialAgent, both LLMs reach the competitiveness with humans. For example, GPT3.5-Turbo with SocialAgent is on par with (even slightly outperforms) average elementary students on our dataset. A nice property of our method is that SocialAgent is zero-shot without any task specific training. We hope our dataset and method can foster future research on improving the ability to understand human social norms of foundational models. Figure 1: Summary of our dataset and results."
    },
    {
      "title": "2 The Social Benchmark",
      "text": ""
    },
    {
      "title": "Dataset",
      "text": "We introduce a new dataset named Social to examine the ability to understand human social norms. Social norms are social and shared among members of a group. It includes topics representing socially acceptable ways of living by a group of people in a society, such as rules, laws, culture, history, and communication. Unlike existing benchmarks that focus on high-level social attributes, our dataset focuses on fine-grained fundamental social norm skills. Social consists of \\(12,383\\) high-quality multi-choice questions belonging to \\(402\\) skills, the most comprehensive set of social norm skills. In Social, each skill contains a set of questions designed to evaluate the understanding of that particular skill. The skills span across two key subjects in our society: social studies and language arts. Understanding these skills is important to the wide adoption of LLMs. The overall dataset statistics are shown in Table 1. Social StudiesSocial studies cover broad fundamental aspects to understand social norms including laws, history, economics, culture, and geography. For the skills under this subject, we follow the design of U.S. National Education standards. We collect data from IXL1, one of the largest online education platforms focusing on the K-12 curriculum, which aligns with our design principle. Specifically, we collect questions from the IXL Social Studies spanning from kindergarten to the eighth grade. We also conduct data postprocessing such as question deduplication. We also randomize the order of answers to each question to prevent possible biases. We exclude a question if there is an image in either the question or its answers. Figure 1(a)(i) shows an example of a question designed to understand the purpose of government, which corresponds to a particular skill in laws. Footnote 1: [https://www.ixl.com](https://www.ixl.com) Language ArtsLanguage arts focus on the rules of using language, including opinions and arguments, book study, writing strategies, and other language skills. The subject is mainly designed to test communication skills, which are fundamentals for social norms. Similarly, we also follow the U.S. National Education standards implemented by IXL Language Arts. Similar data postprocessing with the social studies subset was done. This subset includes subtle language skills such as distinguishing facts from opinions, as shown in Figure 1(a)(ii). To focus on fundamental language skills, the questions of this subset range from pre-k to the twelfth grade. Comparison with Existing DatasetsOur proposed dataset Social is the first large-scale and comprehensive social norms benchmark. A comparison with other datasets is shown in Figure 1(a). Overall, the key difference of our dataset is that Social focuses on skill sets of understanding fundamental social norms, while existing benchmarks mainly focus on high-level social science knowledge. Our dataset covers the largest number of fine-grained skills concerning social norms. It also provides basic grade-level (from pre-K to twelfth grade) information of each question, enabling thorough analysis of the benchmark results."
    },
    {
      "title": "Analysis",
      "text": "To better understand the features of Social, we perform the following analysis focusing on its unique aspects including information about skills and grades. More analyses are presented in the appendix. SkillsFigure 2 presents a summary of the skills (a complete skill set is included in the appendix). Social contains the largest skill set among existing benchmarks for social norms (Figure 1), and each skill contains 30.8 questions on average. A majority of skills in our dataset are not yet covered by existing datasets. These skills are the basis of understanding human social norms. For example, the model needs to understand the difference between laws and rules (Figure 1(a)(i)). Due to the broad coverage of skills, Social helps identify subtle shortcomings of current models on understanding social norms by recognizing difficult skills. GradesSocial contains a comprehensive K-12 curriculum to examine the fundamentals of social norms. This helps obtain the grade-level performance of current models. Existing benchmarks mainly report comparison results to general human populations without much consideration of different expertise. Our dataset enables a more controlled \\begin{table} \\begin{tabular}{c c c c} \\hline \\hline **Subject** & **\\#Skills** & **\\#Questions** & **Average \\#A** \\\\ \\hline Social Studies & 170 & 2,315 & 3.4 \\\\ Language Arts & 232 & 10,068 & 2.4 \\\\ \\hline Total & 402 & 12,383 & 2.6 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 1: Social dataset statistics. comparison to millions of elementary student users from our data source. This aligns with our main focus, i.e., understanding fundamental and essential social norms. Figure 3 shows the total number of skills of each grade."
    },
    {
      "title": "Models",
      "text": "We benchmark state-of-the-art LLMs including GPT3.5-Turbo (Ouyang et al., 2022) and LLaMA2-Chat (Touvron et al., 2023) on Social. We evaluate the models under their zero-shot setups. Figure 4 shows a running example of zero-shot GPT3.5-Turbo. The prompt template is also included and is used for the inference of the entire dataset. LLaMA2-Chat adopts the same zero-shot setting. We also compare these recent LLMs to previous models such as UnifiedQA (Khashabi et al., 2020) under the zero-shot setting. UnifiedQA is a pretrained question-answering model based on T5 (Raffel et al., 2020). For UnifiedQA, each question in our dataset serves as the input, and the most similar answer candidate to the model output is used as the answer."
    },
    {
      "title": "Metrics And Human Performance",
      "text": "We evaluate the models' overall accuracy as well as their accuracy on each subject, each skill, and each grade. Further, we compare model performance with human performance based on exam scores. We specifically utilize the IXL SmartScore (Learning, 2019). Unlike general accuracy, SmartScore considers the learning progression and is designed to measure the extent of human understanding of a skill (Bashkov et al., 2021). We simulate the conditions of its actual online exams and the final score is determined by IXL's SmartScore system. According to IXL (IXL, 2014, 2014), a SmartScore exceeding \\(90.0\\) indicates excellent for understanding or mastering a skill. Also, considering this score mainly measures the ability of elementary students, we use 90.0 as the reference score of human performance. Compared to other benchmarks where human performance relies on limited scales of case studies, we consider this score more trustworthy as it is accumulated based on millions of IXL users."
    },
    {
      "title": "3 The Socialagent Approach",
      "text": "In this section, we present an approach to improve the LLMs' ability to understand social norms. Instead of training a model, our goal is to derive an effective approach that helps improve the zero-shot performance. Motivated by recent advancements in language agents (Li et al., 2023; Xi et al., 2023; Wu et al., 2023), we build a multi-agent framework (Figure 5) based on LLMs to fuse social norm relevant world knowledge, symbolic knowledge, and model knowledge to solve our Social. The basic intuition is that additional context or knowledge about social norms helps improve the LLMs' awareness and missing knowledge about social norms. SocialAgent consists of three LLM agents for this purpose. Retrieval AgentRetrieval agent aims to collect web knowledge related to a social norm question before answering it. This follows the similar intuition of the search action in agents such as Re Figure 4: Zero-shot setup of GPT3.5-Turbo. Figure 3: #Skills per grade. Figure 2: A summary of skills. Act Yao et al. (2022). Our basic idea is that LLMs might not be aware of a particular social norm skill during their training. Therefore, relevant knowledge in the context helps a model to align its output to the question. An LLM is asked to generate questions for a retrieval engine. We use Wikipedia search API as our engine. The output response of this agent is the search results. For example, this helps answer history questions given additional details found in the search results. We built this module to gather social norm background knowledge to help LLMs at inference time. Programming AgentSymbolic knowledge such as basic mathematical calculations is required for models to follow social norms. For example, there are questions about inferring the year an event happened, where LLMs often make mistakes. Retrieval is suboptimal for solving this type of question. We therefore propose to enable LLMs to make calls to symbolic APIs. To verify this idea, we use a basic calculator API in the SocialAgent. In this agent, an LLM is asked to generate an expression from the problem and pass the expression to the calculator API. The output response is the calculation result. Reasoning AgentRecent studies show chain of thought Wei et al. (2022) helps unlock reasoning abilities of LLMs. Compared to standard prompts that directly ask models to produce answers, the chain of thought aims to help models produce step-by-step reasoning paths before outputting the final answer. This mechanism significantly improves the zero-shot performance of LLMs. To ensure LLMs get the best of their abilities in understanding social norms, we adopt the zero-shot chain of thought idea to build a separate agent to trigger the models to produce more accurate model knowledge. Overall, the reasoning agent is asked to think step-by-step. More specifically, we use \"let's think step-by-step\" as the prompt along with the question to obtain the response including reasoning paths from an LLM (Figure 5). The overall pipeline is presented in Figure 5. The input is the question. Each above agent in SocialAgent takes the same input. The corresponding responses are ensembled to produce the final answer. Our ensembling procedure is as follows. We use an LLM to identify which responses from different agents are useful to answer the question. Compared to straightforward ensembling of all responses, our procedure helps guide models to ignore irrelevant context Shi et al. (2023), which lays the foundation for a better understanding of social norms. Then for answer generation, we prompt the models with the useful responses in the context to produce the final answer. Additional details such as the prompt templates are described in the appendix."
    },
    {
      "title": "4 Experiments",
      "text": "In this section, we show the evaluation results of SocialAgent on Social. We also provide results of recent LLMs including LLaMA2-Chat and GPT3.5-Turbo. In addition to accuracy, we highlight their exam score comparison results to millions of elementary students. Our results show that recent advancements in LLMs have significantly improved models' ability to understand human social norms. Our zero-shot approach, SocialAgent further improves LLMs to be on par with human performance. More details of our benchmark and \\begin{table} \\begin{tabular}{l c c c} \\hline \\hline Model & Social Studies & Language Arts & Avg. \\\\ \\hline Random & 32.2\\% & 44.7\\% & 38.4\\% \\\\ Unified\\(\\mathsf{QA}_{\\text{Simail}}\\) & 36.2\\% & 52.2\\% & 44.2\\% \\\\ Unified\\(\\mathsf{QA}_{\\text{Inner}}\\) & 49.0\\% & 60.0\\% & 54.5\\% \\\\ Unified\\(\\mathsf{QA}_{\\text{Large}}\\) & 67.5\\% & 67.4\\% & 67.5\\% \\\\ \\hline LLaMA2-70B-Chat & 90.4\\% & 78.0\\% & 84.2\\% \\\\ GPT3.5-Turbo & 91.9\\% & 86.9\\% & 89.4\\% \\\\ \\hline SocialAgent\\({}_{\\text{LLLALA2-70B-Chat}}\\) & 91.8\\% & 80.3\\% & 86.1\\% \\\\ SocialAgent\\({}_{\\text{CPTS1.5-Turbo}}\\) & 93.6\\% & 88.3\\% & 91.0\\% \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 2: Evaluation results (accuracy) on Social. Figure 5: The pipeline of our proposed SocialAgent method. SocialAgent is a multi-agent model based on LLMs, consisting of three agents: retrieval agent, programming agent, and reasoning agent. Each agent takes the problem as input and outputs its response. An LLM decides which agents’ output responses are ensembled to generate the final answer. additional results are included in the appendix."
    },
    {
      "title": "Main Results",
      "text": "To examine the social norm understanding, we evaluate models zero-shot on our datasets. The results are shown in Table 2. Notably, the recent LLMs such as LLaMA2-70B-Chat and GPT3.5-Turbo improve the performance of previous models by a large margin on average. We also see that GPT3.5-Turbo performs better than LLaMA2-70B-Chat. We observe similar increases in both social studies and language arts. The most improvements (24.4%) are brought by GPT3.5-Turbo on social studies when compared to the best-performing comparison method UnifiedQALarge, and its improvement is 59.7% over random accuracy. The main reason is that both LLaMA2-70B-Chat and GPT3.5-Turbo are enhanced with reinforcement learning with human feedback (RLHF) (Ouyang et al., 2022), which is designed to align model responses with human values. This is important to social norm understanding. This is clear from the performance comparison between LLaMA2-70B-Chat and LLaMA2-70B in Figure 6. LLaMA2-70B-Chat improves the performance over LLaMA2-70B by 38.6% on average, and the only notable difference is that LLaMA2-70B-Chat is equipped with the RLHF. This also adds explanations about having more improvements in social studies compared to those in language arts. RLHF mainly brings social perspectives without much emphasis on fundamental language phenomena. Importantly, SocialAgent consistently performs the best on both subjects (Table 2). With SocialAgent, both LLaMA2-70B-Chat and GPT3.5-Turbo improve their performance on our dataset. The best performance is achieved by SocialAgent\\({}_{\\mathrm{GPT3.5-Turbo}}\\). This shows that our proposed method is able to integrate important social norm knowledge into LLMs."
    },
    {
      "title": "Results Analysis",
      "text": "SkillsWe show the accuracy of comparison models and our method on the skill level in Figure 7. We show the results on an uncurated list of skills from both subjects. The complete results on the full skill set are in the appendix. We find similar trends with the overall results on corresponding subjects. Recent advancements in LLMs, in particular, RLHF, improve the performance significantly over the previous near random accuracy. With SocialAgent, both GPT3.5-Turbo and LLaMA2-70B-Chat improve their social norm understanding across different social norm skills. GPT3.5-Turbo outperforms LLaMA2-70B-Chat, and SocialAgent\\({}_{\\mathrm{GPT3.5-Turbo}}\\) obtains the best overall performance. While there are social norm skills such as \"purpose-of-government\" and \"reasons-for-opinion\" have been mastered by Figure 6: Model performance of LLaMA2. Figure 7: Results on sampled skills of each subject. LLMs, there are still plenty of skills such as \"the-american-history\" and \"use-guide-words\" remain unlearned, presenting room for further improvements. GradesSince our dataset provides the fine-grained grade information of the questions, we present the grade-level exam scores of both our method and comparison methods in Figure 8. In general, the exam scores of all models decrease slightly when the grades increase. This is because the questions at higher grades are in general more challenging. However, this trend is not obvious based on this human intuition. The reason is that humans learn social norms progressively, while models learn all these skills simultaneously during their training. Besides, we observe similar performance enhancement with previous discussions. For example, recent models improve the performance across all grades significantly compared to the previous random accuracy. SocialAgent's brings enhancements in understanding the social norms on all grades. Specifically, all models perform competitively with human performance on lower grades. However, they underperform humans on higher grades such as grades 11 and 12. This indicates significant room to further improve the models' ability to understand advanced social norms. Scaling LawFigure 6 shows the average accuracy of LLaMA2-Chat of different sizes (7B, 13B, and 70B) with SocialAgent. Overall, the model performance increases when the model size gets larger. This indicates that larger models have the additional capacity to learn more accurate social norms during the training."
    },
    {
      "title": "Ablation Study",
      "text": "To investigate the importance of each key component of SocialAgent we show the ablation results of LLaMA2-70B-Chat with SocialAgent on the social studies subset in Table 3. The three settings present removing the retrieval agent (\"w/o Retrieval Agent\"), the programming agent (\"w/o Programming Agent\"), and the reasoning agent (\"w/o Reasoning Agent\") from SocialAgent respectively. Overall, all components are important since the default SocialAgent\\({}_{\\mathrm{LLaMA2-70B-Chat}}\\) obtains the best result. The most significant decrease is brought by removing the reasoning agent. This means that the model has learned certain fundamentals of social norms during their training. So, a better way to prompt the model to obtain the most relevant knowledge is necessary. Moreover, both the retrieval agent and programming agent are essential to incorporate important social norm knowledge into the models."
    },
    {
      "title": "Comparison With Human",
      "text": "It is important to compare models' social norm understanding to that of humans. We compare the exam scores of both GPT3.5-Turbo and LLaMA2-70B-Chat and our methods with millions of elementary student users of the IXL platform. The results are shown in Figure 9. Overall, both models still underperform average elementary students in terms of understanding social norms. SocialAgent helps improve these models to be on par with human performance. For instance, SocialAgent\\({}_{\\mathrm{GPT3.5-Turbo}}\\) outperforms humans by an average of 0.8%. This result is significant although more advancements are needed to compete with human experts. Figure 8: Average grade-level exam scores. \\begin{table} \\begin{tabular}{l c} \\hline \\hline Model & Social Studies \\\\ \\hline SocialAgent\\({}_{\\mathrm{LLaMA2-70B-Chat}}\\) & 91.8\\% \\\\ w/o Retrieval Agent & 91.6\\% \\\\ w/o Programming Agent & 91.4\\% \\\\ w/o Reasoning Agent & 90.3\\% \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 3: Ablation results on LLaMA2-70B-Chat with the SocialAgent method. Figure 9: Compare exam scores of models and humans."
    },
    {
      "title": "Case Study",
      "text": "To better understand what are the models' strengths or weaknesses in understanding social norms, we show examples of best-performing GPT3.5-Turbo predictions with SocialAgent. We present an example of correct and incorrect predictions in Figure 10(a) and (b) respectively. Overall, the models have learned fundamental social norm skills that are concrete and do not require complex reasoning. For example, the answer to the question in Figure 10(a) is short and relatively straightforward. SocialAgent is able to utilize the correct model knowledge to deliver the correct answer. Otherwise, the models struggle. For example in Figure 10(b), the retrieval agent outputs incorrect search results since there is no existing knowledge about this question in the search resources. The other two agent components also do not provide useful context. Based on this, new advancements are needed to help models improve their response quality in challenging scenarios such as long answers and complex reasoning."
    },
    {
      "title": "5 Related Work",
      "text": "Large language models have demonstrated significant improvements in a variety of NLP tasks recently. LLMs have been introduced and used in real-world applications Brown et al. (2020); Wang et al. (2022); Ouyang et al. (2022); OpenAI (2023); Chowdhery et al. (2023); Touvron et al. (2023); Taori et al. (2023); Chiang et al. (2023); Pan et al. (2024); Wang et al. (2023). Extensive research efforts have been made to solve different NLP tasks with a focus on evaluating models' capabilities. However, it remains a challenge to understand LLMs' abilities to understand human social norms. There are existing datasets and benchmarks that aim to help understand the capabilities and limitations of LLMs Hendrycks et al. (2021); Ba et al. (2022); Liang et al. (2022); Srivastava et al. (2022); Shen et al. (2024); Liu et al. (2023); Xiong et al. (2023). MMLU Hendrycks et al. (2021) contains 57 tasks spanning broad topics such as maths, science, and history. Lu et al. (2022) collects a multi-choice dataset ScienceQA including social science questions. HELM Liang et al. (2022) is presented to evaluate many aspects of models such as accuracy and robustness on a wide collection of existing tasks such as question answering and toxicity detection. BIG-bench Srivastava et al. (2022) is a benchmark with more than 200 tasks. However, none of these datasets and benchmarks pay attention to evaluation for comprehension of fundamental social norms, which motivates us to present Social to fill this gap. There are attempts to connect LLMs with external knowledge, tools and models Yao et al. (2022); Schick et al. (2023); Topsakal and Akinci (2023); Liang et al. (2023); Wu et al. (2023); Xiong et al. (2023); Wang et al. (2020); Shen et al. (2022); Crispino et al. (2023). ReAct Yao et al. (2022) is a general paradigm which combines reasoning and acting with LLMs to solve NLP tasks. Schick et al. (2023) show that LMs can teach themselves to use external tools. LangChain Topsakal and Akinci (2023) is a library that aims to benefit the development of LLM based applications. Wu et al. (2023) propose a multi-agent framework to obtain the answer through the conversations among multiple LLM agents. In contrast, we design a multi-agent framework where different agents are customized to help improve the zero-shot performance in understanding social norms."
    },
    {
      "title": "6 Conclusion",
      "text": "We introduce a new benchmark for examining LLMs' understanding of social norms. Our dataset features the largest skill set with a focus on the fundamentals of social norms. We evaluated state-of-the-art LLMs including GPT3.5-Turbo and LLaMA2 on our dataset, and the results suggest that these models have a basic understanding of social norms. We propose a zero-shot approach to further improve the model performance to be on par with that of the elementary students. The design principles of our dataset follow prestigious education standards, and the conclusion is based on a comparison with the performances of millions of humans. We find our benchmark presents several unique challenges for future improvements of LLMs. Figure 10: SocialAgent\\(\\mathtt{gt3.5-Turbo}\\) example predictions. [MISSING_PAGE_FAIL:9] Chengwu Liu, Jianhao Shen, et al. 2023a. Fimo: A challenge formal dataset for automated theorem proving. _arXiv preprint arXiv:2309.04295_. * Liu et al. (2023) Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke, Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, et al. 2023b. Bolaa: Benchmarking and orchestrating llm-augmented autonomous agents. _arXiv preprint arXiv:2308.05960_. * Lu et al. (2022) Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. 2022. Learn to explain: Multimodal reasoning via thought chains for science question answering. In _NeurIPS_. * OpenAI (2023) OpenAI. 2023. Gpt-4 technical report. * Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. _Advances in neural information processing systems_, 35:27730-27744. * Pan et al. (2019) Yu Pan, Jing Xu, Maolin Wang, Jinmian Ye, Fei Wang, Kun Bai, and Zenglin Xu. 2019. Compressing recurrent neural networks with tensor ring for action recognition. In _AAAI_, pages 4683-4690. AAAI Press. * Pan et al. (2024) Yu Pan, Ye Yuan, Yichun Yin, Jiaxin Shi, Zenglin Xu, Ming Zhang, Lifeng Shang, Xin Jiang, and Qun Liu. 2024. Preparing lessons for progressive training on language models. _arXiv preprint arXiv:2401.09192_. * Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. _The Journal of Machine Learning Research_, 21(1):5485-5551. * Rumelhart et al. (1986) David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. 1986. Learning internal representations by error propagation, parallel distributed processing, explorations in the microstructure of cognition, ed. de rumelhart and j. mcctelland. vol. 1. 1986. _Biometrika_, 71:599-607. * Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. Toolformer: Language models can teach themselves to use tools. * Shen et al. (2022) Jianhao Shen, Chenguang Wang, Ye Yuan, et al. 2022. Palt: parameter-lite transfer of language models for knowledge graph completion. _arXiv preprint arXiv:2210.13715_. * Shen et al. (2024) Jianhao Shen, Ye Yuan, Srbuhi Mirzoyan, Ming Zhang, and Chenguang Wang. 2024. Measuring vision-language stem skills of neural models. _arXiv preprint arXiv:2402.17205_. * Shi et al. (2023) Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H Chi, Nathanael Scharli, and Deny Zhou. 2023. Large language models can be easily distracted by irrelevant context. In _International Conference on Machine Learning_, pages 31210-31227. PMLR. * Srivastava et al. (2022) Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abuwal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adria Garriga-Alonso, et al. 2022. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. _arXiv preprint arXiv:2206.04615_. * Taori et al. (2023) Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. 2023. Alpaca: A strong, replicable instruction-following model. _Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html_, 3(6):7. * Topsakal and Akinci (2023) Oguzhan Topsakal and Tahir Cetin Akinci. 2023. Creating large language model applications utilizing langchain: A primer on developing llm apps fast. _International Conference on Applied Engineering and Natural Sciences_, 1(1):1050-1056. * Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a. Llama: Open and efficient foundation language models. * Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajwal Bhargava, Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models. _arXiv preprint arXiv:2307.09288_. * Tu et al. (2023) Shangqing Tu, Chunyang Li, Jifan Yu, Xiaozhi Wang, Lei Hou, and Juanzi Li. 2023. Chatlog: Recording and analyzing chatgpt across time. _arXiv preprint arXiv:2304.14106_. * Wang et al. (2022) Chenguang Wang, Xiao Liu, Zui Chen, Haoyun Hong, Jie Tang, and Dawn Song. 2022. DeepStruct: Pre-training of language models for structure prediction. In _Findings of the Association for Computational Linguistics: ACL 2022_, pages 803-823, Dublin, Ireland. Association for Computational Linguistics. * Wang et al. (2020) Chenguang Wang, Xiao Liu, and Dawn Song. 2020. Language models are open knowledge graphs. _arXiv preprint arXiv:2010.11967_. * Wang et al. (2023) Haiming Wang, Ye Yuan, Zhengying Liu, Jianhao Shen, Yichun Yin, Jing Xiong, Enze Xie, Han Shi, Yujun Li, Lin Li, et al. 2023a. Dt-solver: Automated theorem proving with dynamic-tree sampling guided by proof-level value function. In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 12632-12646. Maolin Wang, Yu Pan, Zenglin Xu, Xiangli Yang, Guangxi Li, and Andrzej Cichocki. 2023b. Tensor networks meet neural networks: A survey and future perspectives. _arXiv preprint arXiv:2302.09019_. * Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. _Advances in Neural Information Processing Systems_, 35:24824-24837. * Wu et al. (2023a) Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. 2023a. Visual chatgpt: Talking, drawing and editing with visual foundation models. * Wu et al. (2023b) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023b. AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework. ArXiv:2308.08155 [cs]. * Xi et al. (2023) Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. 2023. The rise and potential of large language model based agents: A survey. _arXiv preprint arXiv:2309.07864_. * Xiong et al. (2023a) Jing Xiong, Zixuan Li, Chuanyang Zheng, Zhijiang Guo, Yichun Yin, Enze Xie, Zhicheng Yang, Qingxing Cao, Haiming Wang, Xiongwei Han, et al. 2023a. Dq-lore: Dual queries with low rank approximation re-ranking for in-context learning. _arXiv preprint arXiv:2310.02954_. * Xiong et al. (2023b) Jing Xiong, Jianhao Shen, Ye Yuan, Haiming Wang, Yichun Yin, Zhengying Liu, Lin Li, Zhijiang Guo, Qingxing Cao, Yinya Huang, et al. 2023b. Trigo: Benchmarking formal mathematical proof reduction for generative language models. _arXiv preprint arXiv:2310.10180_. * Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in language models. _arXiv preprint arXiv:2210.03629_. * Yin et al. (2023) Zhangyue Yin, Qiushi Sun, et al. 2023. Exchange-of-thought: Enhancing large language model capabilities through cross-model communication. More Details on Social In this section, we provide more details on Social, including dataset analysis, models, and dataset collection."
    },
    {
      "title": "Analysis",
      "text": "Questions and AnswersSocial contains multi-choice questions (Appendix D provides a question example for each skill). The question contains a textual description with an optional textual context. We further analyze the questions from the following aspects. (i) The number of answers. Social has averaging \\(2.6\\) answer options for each question. The distribution is presented in Figure 11. In practice, the more answer options one question has, the more difficult it is. (ii) Question type. We categorize questions based on the first three words of the question text as shown in Figure 12. Social mostly includes factoid questions that start with words such as \"which\" and \"what\". We also show the word cloud of our Social in Figure 13. We can see the most common words like \"sentence\" and \"complete\". This indicates that many questions are sentence-completion type. (iii) Question distribution. Figure 14 depicts the distribution of question lengths. We can see both subjects generally follow a long-tail distribution, while language arts distribution has a longer tail because it includes many long reading comprehension questions. Heuristically, longer questions are more difficult to solve. Figure 15 shows the number of questions in each grade. The questions are primarily distributed between grades 3 and 9, accounting for 72% of the total."
    },
    {
      "title": "Dataset Collection",
      "text": "We collect the Social Studies and Language Arts datasets from _IXL2_. We collect all the multi-choice questions which only contain texts. All questions have only one correct answer. We collect 200 trials for each skill and remove the duplicated problems. Finally, Language Arts problems are much more than Social Studies, so we sample problems from each skill of Language Arts subject uniformly. Footnote 2: [https://www.ixl.com/](https://www.ixl.com/)"
    },
    {
      "title": "Additional Related Work",
      "text": "There are existing agent frameworks, such as RecAct (Yao et al., 2022), Exchange-of-Thought (Yin et al., 2023), BOLAA (Liu et al., 2023), etc. Rect needs multiple turns of dialog, which often leads the models to forget the long dependency knowledge. Exchange-of-Thought uses multiple turns of dialog with different characters, and each character conducts its analysis of the question independently. Instead, each module in our framework focuses on its specific functionality, and the agent decides which output (or combinations) to use on the fly. BOLAA mainly enables LLM to do planning when solving problems. We find that planning is not always useful when answering social norms questions, and the planning ability of LLaMA-2 and GPT-3.5-Turbo are limited and present additional risks such as misleading the models."
    },
    {
      "title": "Appendix B More Details On Experiments",
      "text": ""
    },
    {
      "title": "Experimental Setup",
      "text": "In Social, we only provide the test set for the LLMs evaluation without training or fine-tuning. So traditional language models such as RNN or LSTM (Rumelhart et al., 1986; Hochreiter and Schmidhuber, 1997; Wang et al., 2023; Pan et al., 2019) are not evaluated. For GPT3.5, we use OpenAI GPT-3.5-Turbo API. Specifically, we use GPT-3.5-Turbo-0613. Though previous studies show that the output of the API may change over time(Tu et al., 2023; Chen et al., 2023), we are able to reproduce the results. While for LLaMA2, we use 4-bit quantization to save the memory. For the generation output of the LLMs, we first parse the output heuristically. We try to find the string after the phrase \"answer is\", where we try to match the choices. If this pre-parse fails, we use Leven Figure 11: #Answers distribution. shtein distance to get the final choice. The detailed prompts are shown in Figure 21."
    },
    {
      "title": "Detailed Experimental Analysis",
      "text": "Number of AnswersWe also analyze how model performance changes with the number of answers. We show the results in Figure 16. Surprisingly, the accuracy increases with the number of answers, which is contrary to the expectation that more choices lead to harder problems. CalibrationWe show the relationship between the confidence of LLaMA2-70B models and the corresponding accuracy in Figure 17. A reliable model should be calibrated, which means the output confidence should match the accuracy (Guo et al., 2017). We use the sum of the log probability of the predicted answers as the confidence and show the relationship between the confidence and the accuracy. We find that the zero-shot LLaMA2-70B-Chat is well-calibrated. However, the pre-trained LLaMA2-70B model without instruction tuning is not well-calibrated, which shows the importance of alignment fine-tuning. More Details on Exam ScoreWe show the Exam Score for each skill in Table 5 to 8. As demonstrated in the table, our SocialAgent method can achieve 100 exam scores in a significant amount of skills, even for some skills that the other three methods get lower performance. Question LengthsWe show how the question length affects model accuracy in Figure 18. Overall, we can find that the longer the question length, the harder the question, and the worse the performance. Moreover, it can be discovered that the curves for SocialAgent are smoother than zero-shot settings, which means for a better model, the difficulty of the question does not interfere with it more. Question TypeWe use the first word in the question to mark the types of problems, and list the Figure 12: Question type distribution. Figure 13: Word cloud of question texts in Social. Figure 15: #Questions per grade. accuracy on the top-10 number of question types in Figure 19. Questions starting with \"Is\" have relatively low accuracy, which means they are harder to answer. GradesWe show the accuracies of the models along each grade in Figure 20. We find that the higher the grade, the lower accuracy of the models. Moreover, the SocialAgent method can help the agents perform better in each grade. Hard QuestionsModels in general obtain the lowest score in tenth grade questions. This means that the higher the grade, the harder the questions are. Tenth grade questions are hardest for the models. Besides, we also find skills such as \"understand-overall-supply-and-demand\" are hard for LLMs with an average of 71.0% accuracy (much lower than the average accuracy). Data ContaminationThe source datasets (e.g., IXL) require registration to access their data and are designed for education purposes. So it is very unlikely that the data is part of the training data of the LLMs. In addition, we carefully checked the \"Data Contamination\" section in the technical reports of GPT-3 and LLaMA-2, and it seems the contamination is currently not a major issue of the performance. Correlation AnalysisWe evaluate exam scores' correlation with the model accuracies in Figure 23. A positive correlation can be found, and exam scores can capture the accuracy as an important factor. Figure 16: Results on questions with different numbers of answers. Figure 19: Results on different question types. Figure 17: LLaMA2 calibration results. The \\(x\\)-axis denotes the sum of the log probability of the predicted answers. Figure 20: Average grade-level accuracies. Figure 18: Results on questions with different lengths. [MISSING_PAGE_FAIL:15]"
    },
    {
      "title": "Appendix A",
      "text": "\\begin{table} \\begin{tabular}{|p{142.3pt}|p{142.3pt}|} \\hline SocialAgent Component & Inputs and Outputs \\\\ \\hline \\multirow{4}{*}{Problem} & Which is an example of a law? \\\\ & 00 You You should get a new birth/network city at months, \\\\ & 00 You may may get other share the speed limit. \\\\ & 00 You may get more than other person home director. \\\\ & 00 You should get more from rest and vegetables. \\\\ \\hline \\multirow{4}{*}{Retrieval Agent} & Input: Low \\\\ & **Output:** Page: Low \\\\ & Summary: Low is not yet of middle that are created and are embedded by myself or environmental institutions to regulate whether, with no precise definition a master of happening during. It has been virtually derived from a solution at the day of pilots. Some targeted has come to mind by a simple platform or a single legitimate, resulting in a timely, or inaccurate though different legalizations are completely or completely completely private, usually in common. In addition, these individuals may not simply binding the individuals, without any time totally binding the contents, including distribution between the day and the other. The content of these behaviors may be influenced by a combination, between other, and the profile could benefit. The two simple platforms, recommends, homology and activity at various ways and their access as a mediator of influencing human people. \\\\ & Legal system may become juveniles, with their diffuseness and/or incorporation in comparative law. \\\\ \\hline \\multirow{4}{*}{Programming Agent} & Input: *=*=* \\\\ & **Output:** NA \\\\ & **Unite:** Like \\\\ \\hline \\multirow{4}{*}{Reasoning Agent} & Output: To determine which of the given options is in example of a law, we need to understand the distribution of law. According to the information provided by the Wikipedia search, a law is not of public created and inflexible by social or governmental institutions to regulate whether. \\\\ & Let's analysis and option: \\\\ & 00 You should get new birth/network city its months. The statement is a recommendation or a public, but it does not represent a law. It does not represent a law or employment employment employment. \\\\ & 00 You may get another than the speed limit. The statement represents. \\\\ & 00 You may get more than other people, but it is not in inflexible by multiple firms and its enforcement agencies. \\\\ & 00 You may get more than other ones. The statement is a rule or reproduction, but it does not represent a law. It does not represent a law. It is not likely a recommendation or another than a law enforced by social or governmental institutions. \\\\ & 00 You should get more than just upstitute. Similarly to option. On this assumption is a recommendation or a choice, but it does not represent a law. It does not involve any enforcement by social or governmental institutions. \\\\ & 00 You may get more than other people. \\\\ \\hline Answer & Predicted Strips: (1) surprise \\\\ \\hline \\end{tabular} \\end{table} Table 4: Full example of Figure 21. Figure 23: The correlation graph of exam scores with model accuracies. \\begin{table} \\begin{tabular}{|c|c|c|c|c|c|} \\hline & Runbin & LALAL33-Chart & SocialAgent & \\(\\text{GP1-3-Ch}\\) & \\(\\text{GP2-3-Ch}\\) & \\(\\text{GP3-3-Ch}\\) & \\(\\text{GP4-3-Ch}\\) \\\\ \\hline \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\cline{2-7} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text{per}\\)} & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness & \\(\\text{per}\\)-bitness \\\\ \\hline \\multirow{2}{*}{\\(\\text [MISSING_PAGE_EMPTY:18] [MISSING_PAGE_FAIL:19] [MISSING_PAGE_EMPTY:20] [MISSING_PAGE_EMPTY:21] [MISSING_PAGE_FAIL:22] [MISSING_PAGE_FAIL:23] [MISSING_PAGE_FAIL:24] Subject: Social Studies Skill the-american-evolution-new-bright-tastes Description: In the 17600, smuggling was an important part of the colonial economy. What does smuggling meat? Choices: (a) defining goods from foreign merchants, (b) trading one good for another without the use of money, (c) shipping goods recently or illegally, (d) producing retail from minerals and rocks) Answer index: 2 Subject: Social Studies Skill: the-american-ing Description: What does such water on the American big stand fee? Choices: (a) a president, (b) a state, (c) a war, (d) a city] Answer index: 1 Subject: Social Studies Skill: weak-air-the-earth-to-war Description: What was World War I originally called? Choices: (a) the First First War, (b) the Great War, (c) the European Revolution, (d) European War I I] Answer index: 1 Answer index: 1 Subject: Social Studies Skill: the-ocrika-us-ball-team-of-opinion Description: Which sentence states a fact? Choices: (a) the Great Carnegus was served by the Colorado River, (b) The Great Carnegus in the new breathing place the United States.] Answer index: 0 Subject: Social Studies Skill: the-ocrika-us-balling Descriptions: Complete the sentence. The Empire State Building was built during a tough time in American history. That time was known as -- License: (a) the Colonial Period, (b) the Gold Rauh, (c) the Reconstruction Era, (d) the General Depression] Answer index: 3 Subject: Social Studies Skill: the-american-evolution-the-sethelling Description: Complete the sentence. A the First Continental Congress, the colonies agreed to -- goods imported from Great Britain. Choices: [a) stop buying, (b) hory morn, (c) duters, (d) tar] Answer index: 0 Subject: Social Studies Skill: what-a-the-uand-to-pence Descriptions: Complete the text. During the Paris Peace conference, one group of men was known as --. They represented the most powerful countries at the conference. Choices: (a) the Three Emergons' League, (b) the Axis Landers, (c) the Big Four, (d) the explained deepest 20000. Answer index: 2 Subject: Social Studies Skill: the-american-evolution-turing-the-old-of-the-war Descriptions: The Continental Army suffered many losses in the autumn of 1776. Thomsa Pain, a popular writer, was traveling with the army. In late December, he wrote an essay. Read the passage from Thomsa Prize's essay. These narrow the question above. These are the times that they try us's seals. The summer soldier and the sunlaine pursuit will, in this crisis, shrink from the service of their country; but he that stands by it now, deserves the love and thanks of man and woman. Which sentence best explains what he meant by these work? Choices: (a) He not believe the Americans were doing the right thing, (b) General Washington did not know how to lead an army, (c) The British soldiers were afraid of the Americans, (d) The Continental Army was struggling, but it was fighting for a good camel.] Answer index: 3 Subject: Social Studies Skill: the-ocrika-us-ball-team-of-the-art-to-war Skill: the-ocrika-us-ball-team-of-the-art-to-war Description: What was World War I originally called? Choices: (a) the First War, (b) the Great War, (c) the European Revolution, (d) European War I] Answer index: 1 Answer index: 2 Subject: Social Studies Skill: the-ocrika-us-ball-team-of-the-art-to-war Description: What was World War I originally called? Choices: (a) the First War, (c) the American-to-war Where I will Answer index: 1 Answer index: 1 Subject: Social Studies Skill: the-ocrika-us-ball-team-of-the-art-to-war Description: What were World War I originally called? Choices: (a) the First War, (b) the Great War, (c) the European Revolution, (d) European War I] Answer index: 1 Answer index: 2 Subject: Social Studies Skill: the-ocrika-us-ball-team-of-the-art-to-war Description: In July 1861, a Union army arrested south from Washington, D.C., into Virginia. In past was to voice Manass Junction, in important railroad center. This plan led the Great Battle of Bull Run, the first major battle of the war. Address: (a) The Great Battle of Bull Run, the first major battle of the war. Address: (b) the First War, (c) the American-to-war Complete the sentence. Subject: Social Studies Skill: the-ocrika-us-ball-team-of-the-art-to-war Description: What was World War I originally called? Choices: (a) the First War, (c) the American-to-war Where I will Answer index: 1 Subject: Social Studies Skill: the-ocrika-us-ball-team-of-the-art-to-war Description: What were World War I originally called? Choices: (a) the First War, (b) the Great War, (c) the European Revolution, (d) European War I] Answer index: 1 Answer index: 2 Subject: Social Studies Skill: the-ocrika-us-ball-team-of-the-art-to-war Description: What were World War I originally called? Choices: (a) the First War, (c) the European Revolution, (d) European War I] Answer index: 1 Answer index: 1 Subject: Social Studies Skill: the-ocrika-us-ball-team-of-the-art-to-war Description: Which sentence states a fact? Skill: the-ocrika-us-ball-team-of-the-art-to-war Description: In July 1861, a Union army arrested south from Washington, D.C., into Virginia. In past was to voice Manass Junction, in important railroad center. This plan led the Great Battle of Bull Run, the first major battle of the war. Address: (b) the First War, (c) the American-to-war Complete the sentence. Complete the sentence. Complete the sentence. Complete the sentence. Complete the sentence. Complete the sentence. Complete: the sentence. Complete: the sentence. Complete: the (a) the Colonial Period, (b) the Gold Rauh, (c) the Reconstruction Era, (d) the General Depression] Answer index: 3 Answer index: 0 Subject: Social Studies Skill: the-ocrika-us-ball-team-of-the-art-to-war Description: While was World War I. One side was called the -- and the other was called the -- Complete: (a) Axis powers -- Allied powers, (b) Allied powers -- Central powers -- Axis powers -- Axis powers, (d) Allied powers -- Triple Extract) Answer index: 1 Answer index: 1 Subject: Social Studies Skill: what-a-the-out-to-pence Skill: the-ocrika-us-of-likely Descriptions: Complete the text. Deming: The State of Liberty was finished in 1886. However, the building's goal had been to finish in 1876, Why was 1876 important? Deming: The state of Liberty was finished in 1886. This was 1876 important? Deming: The state of Liberty was finished in 1886. However, the building's goal had been to finish in 1876, Why was 1876 important? Deming: The state of Liberty was finished in 1876, Why was 1876 important? Deming: The state of Liberty was finished in 1876, Why was 1876 important? Deming: The state of Liberty was finished in 1886. However, the building's goal had been to finish in 1876, Why was 1876 important? [MISSING_PAGE_EMPTY:26] [MISSING_PAGE_FAIL:27] [MISSING_PAGE_FAIL:28] Subject: Social Studies Skill: ancient-clina Description: For people in ancient Chinese communities, flooding around the Yellow and Vignere Rivers was a commiting problem. Bar floods had both positive and negative effects for people in ancient China. Which of the following was a positive effect of flooding? Choices: [A] Brooklyn tall may annush who lived near the river. (b) After a river flooded, fertile soil was left on the land. (c) Many crops were destroyed by the floods. (d) Floods destroyed homes located near the river.] Answer index: 1 Subject: Social Studies Subject: Social Studies Subject: social Studies Subject: origin-of-lam Description: Muslim believe there is only one goal. They call this goal Alah, which means \"Golf\" in Arabic. The following passage describes a Muslim belief about how Akhis revealed, or communicated, messages to his followers. Read the passage. Then answer the question below. We believe in Alah and [the message that] was revealed to us and what was revealed to Abraham... and the techoseling which Alah grew to Moses and Jeans and to other people. ... All Iman is 34 in _Zararlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: ancient-cryber-the-old kingdom Description: Complete the text. Before Upper and Lower Egypt became one kingdom, they were divided into names, or... Each name was controlled by a nommer, or... Each name was controlled by a nommer, or... Choose: [a] Louisiana, (b) farms, (c) churches, (d) teams] Answer index: 0 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: original-of-lam Skill: origins-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to Abraham... and the techoseling which Alah grew to Moses and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: origin-of-lam Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to Abraham... and the techoseling which Alah grew to Moses and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (c) Alah is the same gold the Jews and Christiins wonhip., (d) Alah is the same gold the Jews and Christiins wonhip., (e) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: origin-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to Abraham... and the techoseling which Alah grew to Moses and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: original-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to Abraham... and the techoseling which Alah grew to Moses and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (c) Alah is the same gold the Jews and Christiins wonhip., (d) Alah is the same gold the Jews and Christiins wonhip., (e) Alah sent messages to Abraham, but not to other people.] Answer index: 0 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: original-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to Abraham... and the techoseling which Alah grew to Moses and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: original-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to Abraham... and the techoseling which Alah grew to Moses and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (c) Alah is the same gold the Jews and Christiins wonhip., (d) Alah is the same gold the Jews and Christiins wonhip., (e) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: original-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to Abraham... and the techoseling which Alah grew to Moses and Jeans and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: origin-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to a Arabian... and the techoseling which Alah grew to Moses and Jeans and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 0 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: original-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to a Arabian... and the techoseling which Alah grew to Moses and Jeans and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Answer index: 2 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: original-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to a Arabian... and the techoseling which Alah grew to Moses and Jeans and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Answer index: 2 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: original-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to a Arabian... and the techoseling which Alah grew to Moses and Jeans and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Answer index: 2 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: origin-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to a Arabian... and the techoseling which Alah grew to Moses and Jeans and Jeans and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Answer index: 2 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: social Studies Subject: origin-of-clina Definition: For people in the Alah and [the message that] was revealed to us and what was revealed to a Arabian... and the techoseling which Alah grew to Moses and Jeans and Jeans and to other people. ... All Iman is 34 in _Zarlo_ Hobas Anisri, translates, Towards Understanding the Qu'in'in's, Volume 1. Copyright 1998 by The Islamic Foundation. Based on this passage, which statement de most Muslim believe is true? Choices: [a] Alah is more powerful than the gold Jews and Christiins wonhip., (b) Alah is the same gold the Jews and Christiins wonhip., (c) Alah is the same gold the Jews and Christiins wonhip., (c) Alah sent messages to Abraham, but not to other people.] Answer index: 1 Answer index: 2 Subject: Social Studies Subject: Social Studies Subject: Social Studies Subject: social [MISSING_PAGE_FAIL:30] Subject: Social Studies Skill: adversary-in-the-acuth Descripting: For more than 300 years, people were enclosed in Africa and then brought to North and South America, where they were sold. But in the early 1800s, this changed. In 1807, Great Britain made it illegal to buy and sell emander people across the Atlantic Ocean using British ships. The United States did not ban latency, but it did ban importing any new enthered people into the country. So, by 1860, most emander people in the United States. Subject: Social Studies Shill: randomization Description: Enquiar Franklin played an important part in which conflict? Choieves: (a) World Warf L (b) the Civil War, (c) the American Revolution, (d) the War of 1812) Answer index: 2 Answer index: 0 Subject: Social Studies Shill: data-to-bus-matters Skill: pale-incidents Description: When bus in die des Manutos celebrated? Choieves: (a) April 15, 0 (b) October 27, (c) November 1 and 2, (d) the last Monday in May] Answer index: 2 Subject: Social Studies Shill: static-ball Description: When was Harriet Thubman born? Choieves: (a) the 1490s, (b) the 1610s, (c) the 1820s, (d) the 1910s] Answer index: 2 Subject: Social Studies Shill: Social Studies Shill: humanza Description: When does Kuramza celebrate? Descripting: What does Kuramza celebrate? Causes: (a) the birthday of Dr. Martin Luther King, Jr., (b) the signing of the Declaration of Independence, (c) the history and culture of African American people, (d) the day that sheury emfool? Answer index: 2 Subject: Social Studies Shill: full-passes Description: Use this paragraph to answer the question below. Shill Gates gave up in a family that laid to have contracts. When they played tennis or went Chieves: [a) by listening on the letter gimeth, (b) by priming your dratlied in a perfect circle, (c) by estimating your dratlied longer than anyone else's, (d) by knocking over everyone else's Growing up, Bill Gates was always competitive. That meant he... Chieves: [a) was always well behaved, (b) hated sports, (c) ited in the best] Answer index: 2 Subject: Social Studies Shill: privacy-protocent Shill: cash-bakmanh Description: Both Hathamh is the beginning of a ten-day religious period. The period ends with black holiday? Choieves: [a) Hunakakak, (b) Passover, (c) Yvon Kijver, (d) Purin] Answer index: 2 Subject: Social Studies Definition: Although most merchants traded in shorter sections of the Silk Road, some merchants occasionally traveled to new regions. These merchants could learn about different parts of the Silk Road from neighborhoods. The passage below comes from a quickbook for merchants written in the first century CF. Scholar this it was written by an Egyptian merchant who traveled in the Rest and Indian Ocean. Read the passage from the quickbook. Then follow the instructions below. Now the whole country of India has very many rivers, and very great echo and flow with the ticks... entrance and departure of weeks it very dangerous to these who are inexperienced of who come to this market towards for the first time. Since: Peirplus of the Red Sea This guidebook: helped merchants learn... It could also help them --- Choieves: [a) show the geography of a new place... mezel dangerous areas, (b) to build brains... I learn how to swim, (c) to speak new languages... find where markers were Located] Answer index: 0 Subject: Social Studies Shill: the-chochois Description: One of the most vivid descriptions of life about a shive ship comes from a book written by Donald Bajian (ob-ob-ob-ah-hev-Mir-no). In the following passage, Gainomic describes his experiences on a shive beyond her the American. Read the passage. Then complex the sentence below. I was soon put down under the clocks, and there I received such a solution in my north as I had never experimented in my life.... I became so sick and so low that I was not able to eat. But soon, to my girl, but for the white eminer offered the [ooz], and, on my refacing to (c) African... I get about great shaved, (d) European... and other, while other thought are served. I would have jumped over the shide, but I could not, and, besides, the crew used to watch us very closely... I feel we should keep into the water. ... List we should in case we would Complete the sentence. Equaino published his book in 1789 in Great Britain. Most of his readers were while Europeons. Equaino then likely were lost his book to personalize... people to... Chinese: [a) British... end the share table, (b) Native American... again the slave trade, (c) African... right against shaved, (d) European... purchase more emlaved people] Answer index: 0 \\begin{table} \\begin{tabular}{|p{142.3pt}|p{142.3pt}|} \\hline Subject: Social Studies & Support: Social Studies \\\\ Skill: randomm & Skill: randomm \\\\ Description: Complete the sentence. & Description: Complete the sentence. \\\\ Choice: [a) World Warf L (b) The Civil War, (c) the American Revolution, (d) the War of 1812] & Choice: [a) How to be 1800s, this changed. \\\\ Amwer index: 2 & Amwer index: 0 \\\\ \\hline Subject: Social Studies & Subject: Social Studies \\\\ Skill: data-to-bus-matters & Skill: pale-incidents \\\\ Description: When bus in die des Manutos celebrated? & Description: Why do we look up to Jackie Robinson? \\\\ Choices: [a) April 15, (b) October 27, (c) November 1 and 2, (d) the last Monday in May] & Choices: [a) How was heavy, (b) He was brene, (c) He was popular, (d) He was famsy.] \\\\ Amwer index: 2 & Amwer index: 1 \\\\ \\hline Subject: Social Studies & Subject: Social Studies \\\\ Skill: starting-ball & Descripting: Complete the sentence. \\\\ Description: When was Harriet Thubman born? & Sitting Bull was an important... leader in the 1800s. \\\\ Choices: [a) the 1490s, (b) He 1610s, (c) the 1820s, (d) the 1910s] & Choice: [a) Japanese American, (b) Native American, (c) German American, (d) Mexican American] \\\\ Answer index: 2 & Amwer index: 1 \\\\ \\hline Subject: Social Studies & Subject: Social Studies \\\\ Skill: humanza & Skill: bimodal-mashill \\\\ Description: What does Kuramza celebrate? & Description: Through Marshall was a Supreme Court junctice for 24 years. What do Supreme Court junctice for 24 years. What do Supreme Court junctice for 24 years. \\\\ Choices: [a) the birthday of Dr. Martin Luther King, Jr., (b) the signing of the Declaration of Independence, (c) the history and culture of African American people, (d) the day that slinery emfool? & Choice: [a) They runish criminals, (b) They make theireure tactics with other countries.] \\\\ Answer index: 2 & Amwer index: 2 \\\\ \\hline Subject: Social Studies & Subject: Social Studies \\\\ Skill: full-passes & Description: The unking paragraph to answer the question below. \\\\ Skill: humanza & Ball Gates gave up in a family that laid to have contracts. When they played tennis or went Definition: [a) by listening on the letter gimeth, (b) by priming your dratlied in a perfect circle, (c) by estimating your dratlied longer than anyone else’s, (d) by knocking over everyone else’s drajekels & Committee the sentences. \\\\ Answer index: 0 & Growing up, Bill Gates was always competitive. That meant he... Choices: [a) was always well behaved, (b) hated sports, (c) ited in the best] Answer index: 2 & Amwer index: 2 \\\\ \\hline Subject: Social Studies & Subject: Social Studies \\\\ Skill: privacy-protocent & Skill: non-bakmanh \\\\ Description: Which is an example of a law? & Description: Both Hathamh is the beginning of a ten-day religious period. The period ends with black holiday? \\\\ Choices: [a) It would not be a factory in Pennsylvania, (b) He helped both ships in Benton, (c) He helped more eown from Tennessee to Virginia, (d) He worked in a bank in New York City.] & Amwer index: 2 \\\\ \\hline Subject: Social Studies & Subject: Social Studies \\\\ Discripting: Although most merchants traded in shorter sections of the Silk Road, some merchants occasionally traveled to new regions. These merchants could learn about different parts of the Silk Road from neighborhoods. The passage below comes from a quickbook for merchants written in the first century CF. Scholar this it was written by an Egyptian merchant who traveled in the Rest and Indian Ocean. \\\\ Descripting: When Davy Credit was 12 years old, his family needed help making money. & Read the passage from the quickbook. Then follow the instructions below. Now the whole country of India has very many rivers, and very great echo and flow with the ticks... entrance and departure of weeks it very dangerous to these who are inexperienced or who come to this market towards for the first time. \\\\ Answer index: 2 & Source: Peirplus of the Red Sea \\\\ This guidebook: helped merchants learn... It could also help them... Choieves: [a) show the geography of a new place... mezel dangerous areas, (b) to build books... I learn how to swim, (c) to speak new languages... find where markers were Answer index: 0 \\\\ \\hline Subject: Social Studies & Subject: Social Studies \\\\ Skill: the-choistions & Description: One of the most vivid descriptions of life about a shive ship comes from a book written by Donald Bajian (ob-ob-ob-ah-hev-Mir-no). In the following passage, Game describes his experiences on a shive beyond her the American. Read the passage. Then complex the sentence below. \\\\ I was soon put down under the clocks, and there I received such a solution in my north as I had never experimented in my life.... I became so sick and so low that I was not able to eat. \\\\ Answer index: 0 & But soon, to my girl, but for the white eminer offered the [ooz], and, on my refacing to (c) African... right against shaved, (d) European... and other, while other thought are reserved.... I would have jumped over the shide, but I could not, and, besides, the crew used to watch us very closely... I feel we should keep into the water.. [MISSING_PAGE_FAIL:32] [MISSING_PAGE_EMPTY:33] [MISSING_PAGE_FAIL:34] Support: Social Studies Sail: individualistic-in-the-global-age Descriptors: Industrializationizationization towards dramatic changes to Americans' daily lives. Read a random scholar's description of those changes. Then answer the question please. Within a few decades, when American homes became networked.... handful of relying on calls and [their] carried in their home, then then he can have was connected to the identity network the provided media logic... Instead of relying on... outcomes and enough, each home was gradually connected to two more markets, we plugging a supply of clean running water and the other taking waste out into assess. However of the risk after 1800 and of the working-cline after 1910 were increasingly applied with actual heating. Robbert I. Gorlich, The Rise and Fill of American Growth, Princeton University Press, 2016. What is the main idea of the paper? Cites: [A] As the U.S. Unsymmetrical, fewer homes lack deductively and central heating., [b] Industrialization gene may Americans much more comfortable lives., [c] Electric lighting and seven meals home stories and more dangerous. [d] Extension because very modern, but negligible projects' homes did not change.] Answer: 1: [b] Support: Social Studies Sail: new-optimal-choosing-founding-and-government Descriptors: Members of a religious group called the Purtains founded the Massachusetts By Colony. Unlike the Pligening, the Purtains did not want to leave the Church of England Inward, they wanted to change the Church of England Descriptors: what is the main idea of the paper? The first governor of the Massachusetts Bclay CA campus on a Purtains named John Wattenberg The penotype below comes from a North Wartengege one in the Purtains on other wagge In two England. Read the penotype. The answer the question below. For we mean consider that we shall see all to any organ that. The eyes of all people are open we set that if we had finished all the work on this work. [...] could make us to withdraw this project help from us, we shall be made a story and a by through the world. Table 24: Question examples for each skill (part 11). [MISSING_PAGE_FAIL:36] [MISSING_PAGE_EMPTY:37] [MISSING_PAGE_FAIL:38] [MISSING_PAGE_EMPTY:39] [MISSING_PAGE_FAIL:40] [MISSING_PAGE_FAIL:41] \\begin{table} \\begin{tabular}{|p{142.3pt}|p{142.3pt}|} \\hline Subject: Language Arts & Subject: Language Arts \\\\ Salit: audio-based-to-use-like-de-others & Similar: the-aware-with-the-context-simplike-used-to-1-2-3 \\\\ Description: Which would us not like the other? & Description: Complete the sentence. [a]he (b) (a) (b) (a) (b) (a) (b) \\\\ Ansner index 3 & Ansner index 3 \\\\ \\hline Subject: Language Arts & Subject: Language APIs \\\\ Salit: complete-aware-with-the-context-simplike-used-to-4-5-6-7 & Similar: the-aware-control-multi-level \\\\ Description: Complete the sentence. & Description: Soker the model would then host complex the sentence. \\\\ I use a had day. - current to lock. & The coach. - In that dial. - the team if it were's to have in the season. \\\\ Choice: [a]int (b) (a) (b) (a) & Ansner index 0 \\\\ Ansner Index 2 & Ansner index 0 \\\\ \\hline Subject: Language Arts & Subject: Language-Arts \\\\ Salit: use-the-order-strict-sub-cases & Similar: the-aware-with-the-context-simplike-used-to-1-2-3 \\\\ Description: Which would us not like the other? & Description: Complete the sentence. [a]he (b) (a) (b) (a) (b) \\\\ Ansner index 3 & Ansner index 3 \\\\ \\hline Subject: Language APIs & Subject: Language APIs \\\\ Salit: complete-aware-with-the-context-simplike-used-to-4-5-6-7 & Similar: the-aware-control-multi-level \\\\ Description: Complete the sentence. & Description: Soker the model would then host complex the sentence. \\\\ I use a had day. - current to lock. & The coach. - In that dial. - the team if it were's to have in the season. \\\\ Choice: [a]int (b) (a) (b) (a) & Ansner index 0 \\\\ Ansner Index 0 & Ansner index 0 \\\\ \\hline Subject: Language Arts & Subject: Language APIs \\\\ Salit: use-the-order-strict-sub-cases & Similar: the-aware-with-the-context-simplike-used-to-1-2-3 \\\\ Description: Which would us not like the other? & Description: Complete the sentence. [a]he (b) (a) (b) (a) (b) \\\\ Ansner Index 3 & Ansner index 3 \\\\ \\hline Subject: Language APIs & Subject: Language APIs \\\\ Salit: use-the-aware-with-the-context-simplike-used-to-4-5-6-7 & Similar: the-aware-control-multi-level \\\\ Description: Complete the sentence. & Description: Soker the model would then host complex the sentence. \\\\ I use a had day. - current to lock. & The coach. - In that dial. - the team if it were's to have in the season. \\\\ Choice: [a]int (b) (a) (b) (a) & Ansner index 0 \\\\ Ansner Index 0 & Ansner index 0 \\\\ \\hline Subject: Language APIs & Subject: Language APIs \\\\ Salit: use-the-order-strict-sub-cases & Similar: the-aware-with-the-context-simplike-used-to-1-2-3 \\\\ Description: Outside the sentence. & Description: Complete the sentence. [a]he (b) (a) (b) (a) (b) (a) \\\\ Ansner Index 1 & Ansner index 1 \\\\ \\hline Subject: Language APIs & Subject: Language APIs \\\\ Salit: use-the-aware-with-the-context-simplike-used-to-4-5-6-7 & Similar: the-aware-control-multi-level \\\\ Description: Complete the sentence. & Description: Soker the model would then host complex the sentence. \\\\ I use a had day. - current to lock. & The coach. - In dial. - the team if it were's to have in the season. \\\\ Choice: [a]int (b) (a) (b) (a) (a) (b) (a) (b) (a) (b) (a) (b) (a) (b) (a) (b) (a) (b) (a) (b) (a) (b) (a) (b) (b) (a) [MISSING_PAGE_FAIL:43] [MISSING_PAGE_EMPTY:44] [MISSING_PAGE_EMPTY:45] [MISSING_PAGE_FAIL:46] [MISSING_PAGE_EMPTY:47] Subject: Language Aits Still: use-context-as-to-the-meaning-of-foreign-expressions Description: What is the meaning of the foreign expression in bullet 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight hundred sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] occasionally, [b] a group, (c) unexpectedly, (b) finally? Answer index: 1 Subject: Language Aits Still: use-context-as-to-the-meaning-of-foreign-expressions Description: What is the meaning of the foreign expression in bullet 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-as-to-the-meaning-of-foreign-expressions Description: What is the meaning of the foreign expression in bullet 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-as-to-the-meaning-of-foreign-expressions Description: What is the meaning of the foreign expression in bullet 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-as-to-the-meaning-of-foreign-expressions Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-as-to-the-meaning-of-foreign-expressions Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-as-to-the-meaning-of-foreign-expressions 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-as-to-the-meaning-of-foreign-expressions 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned \"#nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned #nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned #nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned #nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned #nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which thousands dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-foreign-expressions 10 2014, giant maths warned #nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-for-the-meaning-of-meaning-of-foreign-expressions 10 2014, giant maths warned #nause\" in parts of Southeast Asia. More than eight handized sigmaps were reported in Singapore, which dispersed a soccer match at Doral Malame Salim in Malaysia. Chinese: [a] a la name, (b) canner do the ischemic Answer index: 0 Subject: Language Aits Still: use-context-as-to-the-meaning-of-meaning-of-meaning-of-meaning-of-meaning-of-meaning-meaning-of-meaning-meaning-of-meaning-meaning-of-meaning-meaning-of-meaning-meaning-of-meaning-meaning-of-meaning-meaning-of-meaning-meaning-of-meaning-meaning-meaning-of-meaning-meaning-meaning-of-meaning-meaning-meaning-of-meaning-meaning-meaning-meaning-meaning-of- [MISSING_PAGE_FAIL:49] Subject: Language Arts Skill: analyse-passages-from-a-long-walk-to-aware part-2 Description: Read the following passage from \"A Long Walk to Water\". In this excerpt, Salvin has just arrived in Rochester, New York, and is meeting his host family. There they were, sampling and saving in the airport tabley-has new family: Chris, the father, Louise, the mother, and four children. Such would have stripes, just as he had before. He first his shoulders relax a little on seeing their cager smiles. From Linda Sue Park, A Long Walk to Water. Copyright 2010 by Linda Sue Park How Side Salk for legal motion in this new family? Choices [(a) He feels measure of how to fit into his new family, but he is excited to get to know them, (b) His tension and nerves begin to subade, but he still feels a little overwhelmed. (c) He is thought for their generosity, but he wants to remain emotionally guizel.] Answer index: 1 Subject: Language Arts Skill: analyse-passages-from-a-single-to-screening-inputtable-oxymon-paradax Descriptions: Which figure of speech is used in this text? Latures asked here if they could adapt a cafe, and her mother resplied, \"I's **\"definite maybe\",\" so Laurent didn't want to get her hopes up. Choices [(a) explaining, (b) arguments] Answer index: 1 \\begin{tabular}{l} Subject: Language-of-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular} \\begin{tabular}{l} Subject: Language-to-speech \\\\ \\end{tabular}"
    }
  ]
}
{
  "title": "A Survey on LLM-based News Recommender Systems",
  "authors": [
    "Rongyao Wang",
    "Veronica Liesaputra",
    "Staff, IEEE Zhiyi Huang"
  ],
  "abstract": "\n News recommender systems play a critical role in mitigating the information overload problem. In recent years, due to the successful applications of large language model technologies, researchers have utilized Discriminative Large Language Models (DLLMs) or Generative Large Language Models (GLLMs) to improve the performance of news recommender systems. Although several recent surveys review significant challenges for deep learning-based news recommender systems, such as fairness, privacypreserving, and responsibility, there is a lack of a systematic survey on Large Language Model (LLM)-based news recommender systems. In order to review different core methodologies and explore potential issues systematically, we categorize DLLM-based and GLLM-based news recommender systems under the umbrella of LLM-based news recommender systems. In this survey, we first overview the development of deep learning-based news recommender systems. Then, we review LLM-based news recommender systems based on three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. Next, we examine the challenges from various perspectives, including datasets, benchmarking tools, and methodologies. Furthermore, we conduct extensive experiments to analyze how large language model technologies affect the performance of different news recommender systems. Finally, we comprehensively explore the future directions for LLMbased news recommendations in the era of LLMs. \n",
  "references": [
    {
      "id": null,
      "title": "A Survey on LLM-based News Recommender Systems",
      "authors": [
        "Rongyao Wang",
        "Veronica Liesaputra",
        "Zhiyi Huang"
      ],
      "year": "2015",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "NPA: Neural news recommendation with personalized attention",
      "authors": [
        "C Wu",
        "F Wu",
        "M An",
        "J Huang",
        "Y Huang",
        "X Xie"
      ],
      "year": "2019",
      "venue": "KDD",
      "doi": ""
    },
    {
      "id": "b1",
      "title": "Drn: A deep reinforcement learning framework for news recommendation",
      "authors": [
        "G Zheng",
        "F Zhang",
        "Z Zheng",
        "Y Xiang",
        "N J Yuan",
        "X Xie",
        "Z Li"
      ],
      "year": "2018",
      "venue": "Proceedings of the 2018 world wide web conference",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "Personalized news recommendation: Methods and challenges",
      "authors": [
        "C Wu",
        "F Wu",
        "Y Huang",
        "X Xie"
      ],
      "year": "2023",
      "venue": "ACM Transactions on Information Systems",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "DKN: Deep knowledge-aware network for news recommendation",
      "authors": [
        "H Wang",
        "F Zhang",
        "X Xie",
        "M Guo"
      ],
      "year": "2018",
      "venue": "DKN: Deep knowledge-aware network for news recommendation",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Fine-grained interest matching for neural news recommendation",
      "authors": [
        "H Wang",
        "F Wu",
        "Z Liu",
        "X Xie"
      ],
      "year": "2020",
      "venue": "ACL",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "Neural news recommendation with topic-aware news representation",
      "authors": [
        "C Wu",
        "F Wu",
        "M An",
        "Y Huang",
        "X Xie"
      ],
      "year": "2019",
      "venue": "ACL",
      "doi": ""
    },
    {
      "id": "b6",
      "title": "Neural news recommendation with long-and short-term user representations",
      "authors": [
        "M An",
        "F Wu",
        "C Wu",
        "K Zhang",
        "Z Liu",
        "X Xie"
      ],
      "year": "2019",
      "venue": "ACL",
      "doi": ""
    },
    {
      "id": "b7",
      "title": "News recommendation via multi-interest news sequence modelling",
      "authors": [
        "R Wang",
        "S Wang",
        "W Lu",
        "X Peng"
      ],
      "year": "2022",
      "venue": "ICASSP",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "Graph neural news recommendation with long-term and short-term interest modeling",
      "authors": [
        "L Hu",
        "C Li",
        "C Shi",
        "C Yang",
        "C Shao"
      ],
      "year": "2020",
      "venue": "Information Processing & Management",
      "doi": ""
    },
    {
      "id": "b9",
      "title": "Neural news recommendation with collaborative news encoding and structural user encoding",
      "authors": [
        "Z Mao",
        "X Zeng",
        "K.-F Wong"
      ],
      "year": "2021",
      "venue": "EMNLP",
      "doi": ""
    },
    {
      "id": "b10",
      "title": "Graph neural news recommendation with user existing and potential interest modeling",
      "authors": [
        "Z Qiu",
        "Y Hu",
        "X Wu"
      ],
      "year": "2022",
      "venue": "ACM Transactions on Knowledge Discovery from Data",
      "doi": ""
    },
    {
      "id": "b11",
      "title": "Intention-aware user modeling for personalized news recommendation",
      "authors": [
        "R Wang",
        "S Wang",
        "W Lu",
        "X Peng",
        "W Zhang",
        "C Zheng",
        "X Qiao"
      ],
      "year": "2023",
      "venue": "International Conference on Database Systems for Advanced Applications",
      "doi": ""
    },
    {
      "id": "b12",
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A N Gomez",
        "I Kaiser",
        "Polosukhin"
      ],
      "year": "2017",
      "venue": "Attention is all you need",
      "doi": ""
    },
    {
      "id": "b13",
      "title": "Fastformer: Additive attention can be all you need",
      "authors": [
        "C Wu",
        "F Wu",
        "T Qi",
        "Y Huang",
        "X Xie"
      ],
      "year": "2021",
      "venue": "Fastformer: Additive attention can be all you need",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "Empowering news recommendation with pre-trained language models",
      "authors": [
        "C Wu",
        "F Wu",
        "T Qi",
        "Y Huang"
      ],
      "year": "2021",
      "venue": "SIGIR",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "Multimodal recommender systems: A survey",
      "authors": [
        "Q Liu",
        "J Hu",
        "Y Xiao",
        "X Zhao",
        "J Gao",
        "W Wang",
        "Q Li",
        "J Tang"
      ],
      "year": "2024",
      "venue": "ACM Comput. Surv",
      "doi": "10.1145/3695461"
    },
    {
      "id": "b16",
      "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M.-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Transformers: State-of-the-art natural language processing",
      "authors": [
        "T Wolf",
        "L Debut",
        "V Sanh",
        "J Chaumond",
        "C Delangue",
        "A Moi",
        "P Cistac",
        "T Rault",
        "R Louf",
        "M Funtowicz"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations",
      "doi": ""
    },
    {
      "id": "b18",
      "title": "A survey on large language models for recommendation",
      "authors": [
        "L Wu",
        "Z Zheng",
        "Z Qiu",
        "H Wang",
        "H Gu",
        "T Shen",
        "C Qin",
        "C Zhu",
        "H Zhu",
        "Q Liu"
      ],
      "year": "2024",
      "venue": "World Wide Web",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "Roberta: A robustly optimized bert pretraining approach",
      "authors": [
        "Y Liu",
        "M Ott",
        "N Goyal",
        "J Du",
        "M Joshi",
        "D Chen",
        "O Levy",
        "M Lewis",
        "L Zettlemoyer",
        "V Stoyanov"
      ],
      "year": "2019",
      "venue": "Roberta: A robustly optimized bert pretraining approach",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
      "authors": [
        "M Lewis"
      ],
      "year": "2019",
      "venue": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "Mtrec: Multi-task learning over bert for news recommendation",
      "authors": [
        "Q Bi",
        "J Li",
        "L Shang",
        "X Jiang",
        "Q Liu",
        "H Yang"
      ],
      "year": "2022",
      "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
      "doi": ""
    },
    {
      "id": "b22",
      "title": "MINER: Multi-interest matching network for news recommendation",
      "authors": [
        "J Li",
        "J Zhu",
        "Q Bi",
        "G Cai",
        "L Shang",
        "Z Dong",
        "X Jiang",
        "Q Liu"
      ],
      "year": "2022",
      "venue": "ACL",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "Unitrec: A unified text-to-text transformer and joint contrastive learning framework for text-based recommendation",
      "authors": [
        "Z Mao",
        "H Wang",
        "Y Du",
        "K.-F Wong"
      ],
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
      "doi": ""
    },
    {
      "id": "b24",
      "title": "Amm: Attentive multi-field matching for news recommendation",
      "authors": [
        "Q Zhang",
        "Q Jia",
        "C Wang",
        "J Li",
        "Z Wang",
        "X He"
      ],
      "year": "2021",
      "venue": "Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval",
      "doi": ""
    },
    {
      "id": "b25",
      "title": "Newsbert: Distilling pre-trained language model for intelligent news application",
      "authors": [
        "C Wu",
        "F Wu",
        "Y Yu",
        "T Qi",
        "Y Huang",
        "Q Liu"
      ],
      "year": "2021",
      "venue": "Newsbert: Distilling pre-trained language model for intelligent news application",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "Unbert: User-news matching bert for news recommendation",
      "authors": [
        "Q Zhang",
        "J Li",
        "Q Jia",
        "C Wang",
        "J Zhu",
        "Z Wang",
        "X He"
      ],
      "year": "2021",
      "venue": "IJCAI",
      "doi": ""
    },
    {
      "id": "b27",
      "title": "Generative news recommendation",
      "authors": [
        "S Gao",
        "J Fang",
        "Q Tu",
        "Z Yao",
        "Z Chen",
        "P Ren",
        "Z Ren"
      ],
      "year": "2024",
      "venue": "Proceedings of the ACM on Web Conference 2024",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Rewriting bias: Mitigating media bias in news recommender systems through automated rewriting",
      "authors": [
        "Q Ruan",
        "J Xu",
        "S Leavy",
        "B Mac Namee",
        "R Dong"
      ],
      "year": "2024",
      "venue": "Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",
      "doi": ""
    },
    {
      "id": "b29",
      "title": "Lkpnr: Large language models and knowledge graph for personalized news recommendation framework",
      "authors": [
        "H Chen",
        "R Xie",
        "X Cui",
        "Z Yan",
        "X Wang",
        "Z Xuan",
        "K Zhang"
      ],
      "year": "2024",
      "venue": "Computers, Materials & Continua",
      "doi": ""
    },
    {
      "id": "b30",
      "title": "A survey of personalized news recommendation",
      "authors": [
        "X Meng",
        "H Huo",
        "X Zhang",
        "W Wang",
        "J Zhu"
      ],
      "year": "2023",
      "venue": "Data Science and Engineering",
      "doi": ""
    },
    {
      "id": "b31",
      "title": "A survey on knowledgeaware news recommender systems",
      "authors": [
        "A Iana",
        "M Alam",
        "H Paulheim"
      ],
      "year": "2024",
      "venue": "A survey on knowledgeaware news recommender systems",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "Dan: Deep attention neural network for news recommendation",
      "authors": [
        "Q Zhu",
        "X Zhou",
        "Z Song",
        "J Tan",
        "L Guo"
      ],
      "year": "2019",
      "venue": "Proceedings of the AAAI conference on artificial intelligence",
      "doi": ""
    },
    {
      "id": "b33",
      "title": "Wg4rec: Modeling textual content with word graph for news recommendation",
      "authors": [
        "S Shi",
        "W Ma",
        "Z Wang",
        "M Zhang",
        "K Fang",
        "J Xu",
        "Y Liu",
        "S Ma"
      ],
      "year": "2021",
      "venue": "Proceedings of the 30th ACM International Conference on Information & Knowledge Management",
      "doi": ""
    },
    {
      "id": "b34",
      "title": "Hram: A hybrid recurrent attention machine for news recommendation",
      "authors": [
        "D Khattar",
        "V Kumar",
        "V Varma",
        "M Gupta"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th ACM international conference on information and knowledge management",
      "doi": ""
    },
    {
      "id": "b35",
      "title": "Trnews: Heterogeneous user-interest transfer learning for news recommendation",
      "authors": [
        "G Hu",
        "Q Yang"
      ],
      "year": "2021",
      "venue": "Proceedings of the 16th Conference of the European Chapter",
      "doi": ""
    },
    {
      "id": "b36",
      "title": "Embedding-based news recommendation for millions of users",
      "authors": [
        "S Okura",
        "Y Tagami",
        "S Ono",
        "A Tajima"
      ],
      "year": "2017",
      "venue": "KDD",
      "doi": ""
    },
    {
      "id": "b37",
      "title": "Time-aware attentive neural network for news recommendation with long-and shortterm user representation",
      "authors": [
        "Y Pang",
        "Y Zhang",
        "J Tong",
        "Z Wei"
      ],
      "year": "2020",
      "venue": "Knowledge Science, Engineering and Management: 13th International Conference",
      "doi": ""
    },
    {
      "id": "b38",
      "title": "News recommendation with topic-enriched knowledge graphs",
      "authors": [
        "D Lee",
        "B Oh",
        "S Seo",
        "K.-H Lee"
      ],
      "year": "2020",
      "venue": "Proceedings of the 29th ACM international conference on information & knowledge management",
      "doi": ""
    },
    {
      "id": "b39",
      "title": "Weave&rec: A word embedding based 3-d convolutional network for news recommendation",
      "authors": [
        "D Khattar",
        "V Kumar",
        "V Varma",
        "M Gupta"
      ],
      "year": "2018",
      "venue": "Proceedings of the 27th ACM international conference on information and knowledge management",
      "doi": ""
    },
    {
      "id": "b40",
      "title": "Deep neural networks for news recommendations",
      "authors": [
        "K Park",
        "J Lee",
        "J Choi"
      ],
      "year": "2017",
      "venue": "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management",
      "doi": ""
    },
    {
      "id": "b41",
      "title": "Chameleon: a deep learning meta-architecture for news recommender systems",
      "authors": [
        "G De Souza Pereira Moreira"
      ],
      "year": "2018",
      "venue": "Proceedings of the 12th ACM Conference on Recommender Systems",
      "doi": ""
    },
    {
      "id": "b42",
      "title": "Neural news recommendation with multi-head self-attention",
      "authors": [
        "C Wu",
        "F Wu",
        "S Ge",
        "T Qi",
        "Y Huang",
        "X Xie"
      ],
      "year": "2019",
      "venue": "EMNLP",
      "doi": ""
    },
    {
      "id": "b43",
      "title": "Dynamic attention-integrated neural network for session-based news recommendation",
      "authors": [
        "L Zhang",
        "P Liu",
        "J A Gulla"
      ],
      "year": "2019",
      "venue": "Dynamic attention-integrated neural network for session-based news recommendation",
      "doi": ""
    },
    {
      "id": "b44",
      "title": "Dynamic news recommendation with hierarchical attention network",
      "authors": [
        "H Zhang",
        "X Chen",
        "S Ma"
      ],
      "year": "2019",
      "venue": "2019 IEEE International Conference on Data Mining (ICDM)",
      "doi": ""
    },
    {
      "id": "b45",
      "title": "Si-news: Integrating social information for news recommendation with attention-based graph convolutional network",
      "authors": [
        "P Zhu",
        "D Cheng",
        "S Luo",
        "F Yang",
        "Y Luo",
        "W Qian",
        "A Zhou"
      ],
      "year": "2022",
      "venue": "Neurocomputing",
      "doi": ""
    },
    {
      "id": "b46",
      "title": "Graph enhanced representation learning for news recommendation",
      "authors": [
        "S Ge",
        "C Wu",
        "F Wu",
        "T Qi",
        "Huang"
      ],
      "year": "",
      "venue": "Graph enhanced representation learning for news recommendation",
      "doi": ""
    },
    {
      "id": "b47",
      "title": "Joint knowledge pruning and recurrent graph convolution for news recommendation",
      "authors": [
        "Y Tian",
        "Y Yang",
        "X Ren",
        "P Wang",
        "F Wu",
        "Q Wang",
        "C Li"
      ],
      "year": "2021",
      "venue": "Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval",
      "doi": ""
    },
    {
      "id": "b48",
      "title": "Reinforced anchor knowledge graph generation for news recommendation reasoning",
      "authors": [
        "D Liu",
        "J Lian",
        "Z Liu",
        "X Wang",
        "G Sun",
        "X Xie"
      ],
      "year": "2021",
      "venue": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining",
      "doi": ""
    },
    {
      "id": "b49",
      "title": "Kred: Knowledge-aware document representation for news recommendations",
      "authors": [
        "D Liu",
        "J Lian",
        "S Wang",
        "Y Qiao",
        "J.-H Chen",
        "G Sun",
        "X Xie"
      ],
      "year": "2020",
      "venue": "Proceedings of the 14th ACM conference on recommender systems",
      "doi": ""
    },
    {
      "id": "b50",
      "title": "Knowledge-guided article embedding refinement for session-based news recommendation",
      "authors": [
        "H.-S Sheu",
        "Z Chu",
        "D Qi",
        "S Li"
      ],
      "year": "2021",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "doi": ""
    },
    {
      "id": "b51",
      "title": "Neural news recommendation with attentive multi-view learning",
      "authors": [
        "C Wu",
        "F Wu",
        "M An",
        "J Huang",
        "Y Huang"
      ],
      "year": "2019",
      "venue": "IJCAI",
      "doi": ""
    },
    {
      "id": "b52",
      "title": "Aspect-driven user preference and news representation learning for news recommendation",
      "authors": [
        "W Lu",
        "R Wang",
        "S Wang",
        "X Peng",
        "H Wu",
        "Q Zhang"
      ],
      "year": "2022",
      "venue": "IEEE Transactions on Intelligent Transportation Systems",
      "doi": ""
    },
    {
      "id": "b53",
      "title": "Hi-fi ark: Deep user representation via high-fidelity archive network",
      "authors": [
        "Z Liu",
        "Y Xing",
        "F Wu",
        "M An",
        "X Xie"
      ],
      "year": "2019",
      "venue": "IJCAI",
      "doi": ""
    },
    {
      "id": "b54",
      "title": "Neural news recommendation with heterogeneous user behavior",
      "authors": [
        "C Wu",
        "F Wu",
        "M An",
        "T Qi",
        "J Huang",
        "Y Huang",
        "X Xie"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing",
      "doi": ""
    },
    {
      "id": "b55",
      "title": "Towards better representation learning for personalized news recommendation: A multi-channel deep fusion approach",
      "authors": [
        "J Lian",
        "F Zhang",
        "X Xie",
        "G Sun"
      ],
      "year": "2018",
      "venue": "IJCAI",
      "doi": ""
    },
    {
      "id": "b56",
      "title": "HieRec: Hierarchical user interest modeling for personalized news recommendation",
      "authors": [
        "T Qi",
        "F Wu",
        "C Wu",
        "P Yang",
        "Y Yu",
        "X Xie",
        "Y Huang"
      ],
      "year": "2021",
      "venue": "ACL",
      "doi": ""
    },
    {
      "id": "b57",
      "title": "Pp-rec: News recommendation with personalized user interest and time-aware news popularity",
      "authors": [
        "T Qi",
        "F Wu",
        "C Wu",
        "Y Huang"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
      "doi": ""
    },
    {
      "id": "b58",
      "title": "News recommendation with candidate-aware user modeling",
      "authors": [],
      "year": "2022",
      "venue": "SIGIR",
      "doi": ""
    },
    {
      "id": "b59",
      "title": "Popularity-enhanced news recommendation with multi-view interest representation",
      "authors": [
        "J Wang",
        "Y Chen",
        "Z Wang",
        "W Zhao"
      ],
      "year": "2021",
      "venue": "CIKM",
      "doi": ""
    },
    {
      "id": "b60",
      "title": "Intention nets: Psychology-inspired user choice behavior modeling for next-basket prediction",
      "authors": [
        "S Wang",
        "L Hu",
        "Y Wang",
        "Q Z Sheng",
        "M Orgun",
        "L Cao"
      ],
      "year": "2020",
      "venue": "AAAI",
      "doi": ""
    },
    {
      "id": "b61",
      "title": "Sentirec: Sentiment diversity-aware neural news recommendation",
      "authors": [
        "C Wu",
        "F Wu",
        "T Qi",
        "Y Huang"
      ],
      "year": "2020",
      "venue": "Proceedings of the 1st conference of the Asia-Pacific chapter of the association for computational linguistics and the 10th international joint conference on natural language processing",
      "doi": ""
    },
    {
      "id": "b62",
      "title": "Removing ais sentiment manipulation of personalized news delivery",
      "authors": [
        "C Wu",
        "F Wu",
        "T Qi",
        "W.-Q Zhang",
        "X Xie",
        "Y Huang"
      ],
      "year": "2022",
      "venue": "Humanities and Social Sciences Communications",
      "doi": ""
    },
    {
      "id": "b63",
      "title": "Fairness-aware news recommendation with decomposed adversarial learning",
      "authors": [
        "C Wu",
        "F Wu",
        "X Wang",
        "Y Huang",
        "X Xie"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI conference on artificial intelligence",
      "doi": ""
    },
    {
      "id": "b64",
      "title": "A hierarchical and disentangling interest learning framework for unbiased and true news recommendation",
      "authors": [
        "S Wang",
        "W Wang",
        "X Zhang",
        "Y Wang",
        "H Liu",
        "F Chen"
      ],
      "year": "2024",
      "venue": "Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining",
      "doi": ""
    },
    {
      "id": "b65",
      "title": "Privacypreserving news recommendation model learning",
      "authors": [
        "T Qi",
        "F Wu",
        "C Wu",
        "Y Huang",
        "X Xie"
      ],
      "year": "2020",
      "venue": "Privacypreserving news recommendation model learning",
      "doi": ""
    },
    {
      "id": "b66",
      "title": "Efficientfedrec: Efficient federated learning framework for privacypreserving news recommendation",
      "authors": [
        "J Yi",
        "F Wu",
        "C Wu",
        "R Liu",
        "G Sun",
        "X Xie"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
      "doi": ""
    },
    {
      "id": "b67",
      "title": "User modeling with click preference and reading satisfaction for news recommendation",
      "authors": [
        "C Wu",
        "F Wu",
        "T Qi",
        "Y Huang"
      ],
      "year": "2020",
      "venue": "IJCAI",
      "doi": ""
    },
    {
      "id": "b68",
      "title": "Personal or general? a hybrid strategy with multi-factors for news recommendation",
      "authors": [
        "Z Huang",
        "B Jin",
        "H Zhao",
        "Q Liu",
        "D Lian",
        "B Tengfei",
        "E Chen"
      ],
      "year": "2023",
      "venue": "ACM Transactions on Information Systems",
      "doi": ""
    },
    {
      "id": "b69",
      "title": "Train once, use flexibly: A modular framework for multi-aspect neural news recommendation",
      "authors": [
        "A Iana",
        "G Glavaš",
        "H Paulheim"
      ],
      "year": "2023",
      "venue": "Train once, use flexibly: A modular framework for multi-aspect neural news recommendation",
      "doi": ""
    },
    {
      "id": "b70",
      "title": "Newsreclib: A pytorch-lightning library for neural news recommendation",
      "authors": [],
      "year": "2023",
      "venue": "Newsreclib: A pytorch-lightning library for neural news recommendation",
      "doi": ""
    },
    {
      "id": "b71",
      "title": "News recommendation with category description by a large language model",
      "authors": [
        "Y Yada",
        "H Yamana"
      ],
      "year": "2024",
      "venue": "News recommendation with category description by a large language model",
      "doi": ""
    },
    {
      "id": "b72",
      "title": "Once: Boosting content-based recommendation with both open-and closedsource large language models",
      "authors": [
        "Q Liu",
        "N Chen",
        "T Sakai",
        "X.-M Wu"
      ],
      "year": "2024",
      "venue": "Proceedings of the 17th ACM International Conference on Web Search and Data Mining",
      "doi": ""
    },
    {
      "id": "b73",
      "title": "Modeling user viewing flow using large language models for article recommendation",
      "authors": [
        "Z Liu",
        "Z Chen",
        "M Zhang",
        "S Duan",
        "H Wen",
        "L Li",
        "N Li",
        "Y Gu",
        "G Yu"
      ],
      "year": "2024",
      "venue": "Companion Proceedings of the ACM on Web Conference 2024",
      "doi": ""
    },
    {
      "id": "b74",
      "title": "Tiny-newsrec: Effective and efficient plm-based news recommendation",
      "authors": [
        "Y Yu",
        "F Wu",
        "C Wu",
        "J Yi",
        "Q Liu"
      ],
      "year": "2022",
      "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
      "doi": ""
    },
    {
      "id": "b75",
      "title": "Training large-scale news recommenders with pretrained language models in the loop",
      "authors": [
        "S Xiao",
        "Z Liu",
        "Y Shao",
        "T Di",
        "B Middha",
        "F Wu",
        "X Xie"
      ],
      "year": "2022",
      "venue": "Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining",
      "doi": ""
    },
    {
      "id": "b76",
      "title": "Recprompt: A prompt tuning framework for news recommendation using large language models",
      "authors": [
        "D Liu",
        "B Yang",
        "H Du",
        "D Greene",
        "A Lawlor",
        "R Dong",
        "I Li"
      ],
      "year": "2023",
      "venue": "Recprompt: A prompt tuning framework for news recommendation using large language models",
      "doi": ""
    },
    {
      "id": "b77",
      "title": "Cherryrec: Enhancing news recommendation quality via llm-driven framework",
      "authors": [
        "S Wang",
        "L Wang",
        "Y Bu",
        "T Huang"
      ],
      "year": "2024",
      "venue": "Cherryrec: Enhancing news recommendation quality via llm-driven framework",
      "doi": ""
    },
    {
      "id": "b78",
      "title": "Streamingrec: a framework for benchmarking stream-based news recommenders",
      "authors": [
        "M Jugovac",
        "D Jannach",
        "M Karimi"
      ],
      "year": "2018",
      "venue": "Proceedings of the 12th ACM conference on recommender systems",
      "doi": ""
    },
    {
      "id": "b79",
      "title": "Accurate news recommendation coalescing personal and global temporal preferences",
      "authors": [
        "B Koo",
        "H Jeon",
        "U Kang"
      ],
      "year": "2020",
      "venue": "Advances in Knowledge Discovery and Data Mining: 24th Pacific-Asia Conference, PAKDD 2020",
      "doi": ""
    },
    {
      "id": "b80",
      "title": "Dynamic hierarchical attention network for news recommendation",
      "authors": [
        "Q Zhao",
        "X Chen",
        "H Zhang",
        "X Li"
      ],
      "year": "2024",
      "venue": "Expert Systems with Applications",
      "doi": ""
    },
    {
      "id": "b81",
      "title": "Fair multistakeholder news recommender system with hypergraph ranking",
      "authors": [
        "A Gharahighehi",
        "C Vens",
        "K Pliakos"
      ],
      "year": "2021",
      "venue": "Information Processing & Management",
      "doi": ""
    },
    {
      "id": "b82",
      "title": "Lancer: A lifetimeaware news recommender system",
      "authors": [
        "H.-K Bae",
        "J Ahn",
        "D Lee",
        "S.-W Kim"
      ],
      "year": "2023",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": ""
    },
    {
      "id": "b83",
      "title": "News session-based recommendations using deep neural networks",
      "authors": [
        "G De Souza Pereira Moreira",
        "F Ferreira",
        "A M Da Cunha"
      ],
      "year": "2018",
      "venue": "Proceedings of the 3rd workshop on deep learning for recommender systems",
      "doi": ""
    },
    {
      "id": "b84",
      "title": "The plista dataset",
      "authors": [
        "B Kille",
        "F Hopfgartner",
        "T Brodt",
        "T Heintz"
      ],
      "year": "2013",
      "venue": "Proceedings of the 2013 international news recommender systems workshop and challenge",
      "doi": ""
    },
    {
      "id": "b85",
      "title": "The adressa dataset for news recommendation",
      "authors": [
        "J A Gulla",
        "L Zhang",
        "P Liu",
        "Ö Özgöbek",
        "X Su"
      ],
      "year": "2017",
      "venue": "Proceedings of the international conference on web intelligence",
      "doi": ""
    },
    {
      "id": "b86",
      "title": "MIND: A large-scale dataset for news recommendation",
      "authors": [
        "F Wu",
        "Y Qiao",
        "J.-H Chen",
        "T Wu",
        "Chuhan Qi",
        "J Lian",
        "D Liu",
        "X Xie",
        "J Gao",
        "W Wu"
      ],
      "year": "2020",
      "venue": "ACL",
      "doi": ""
    },
    {
      "id": "b87",
      "title": "Npr: a news portal recommendations dataset",
      "authors": [
        "J P Lucas",
        "J F G Da Silva",
        "L F De Figueiredo"
      ],
      "year": "2023",
      "venue": "NORMalize@ RecSys",
      "doi": ""
    },
    {
      "id": "b88",
      "title": "Mind your language: A multilingual dataset for cross-lingual news recommendation",
      "authors": [
        "A Iana",
        "G Glavaš",
        "H Paulheim"
      ],
      "year": "2024",
      "venue": "Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "doi": ""
    },
    {
      "id": "b89",
      "title": "Eb-nerd a large-scale dataset for news recommendation",
      "authors": [
        "J Kruse",
        "K Lindskow",
        "S Kalloori",
        "M Polignano",
        "C Pomo",
        "A Srivastava",
        "A Uppal",
        "M R Andersen",
        "J Frellsen"
      ],
      "year": "2024",
      "venue": "Proceedings of the Recommender Systems Challenge",
      "doi": ""
    },
    {
      "id": "b90",
      "title": "Mm-rec: Visiolinguistic model empowered multimodal news recommendation",
      "authors": [
        "C Wu",
        "F Wu",
        "T Qi",
        "C Zhang",
        "Y Huang",
        "T Xu"
      ],
      "year": "2022",
      "venue": "Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval",
      "doi": ""
    },
    {
      "id": "b91",
      "title": "Legommenders: A comprehensive content-based recommendation library with llm support",
      "authors": [
        "Q Liu",
        "L Fan",
        "X.-M Wu"
      ],
      "year": "2024",
      "venue": "Legommenders: A comprehensive content-based recommendation library with llm support",
      "doi": ""
    },
    {
      "id": "b92",
      "title": "Microsoft recommenders: tools to accelerate developing recommender systems",
      "authors": [
        "S Graham",
        "J.-K Min",
        "T Wu"
      ],
      "year": "2019",
      "venue": "Proceedings of the 13th ACM Conference on Recommender Systems",
      "doi": ""
    },
    {
      "id": "b93",
      "title": "Recbole: Towards a unified, comprehensive and efficient framework for recommendation algorithms",
      "authors": [
        "W X Zhao",
        "S Mu",
        "Y Hou",
        "Z Lin",
        "Y Chen",
        "X Pan",
        "K Li",
        "Y Lu",
        "H Wang",
        "C Tian",
        "Y Min",
        "Z Feng",
        "X Fan",
        "X Chen",
        "P Wang",
        "W Ji",
        "Y Li",
        "X Wang",
        "J Wen"
      ],
      "year": "2021",
      "venue": "CIKM",
      "doi": ""
    },
    {
      "id": "b94",
      "title": "Spar: Personalized content-based recommendation via long engagement attention",
      "authors": [
        "C Zhang",
        "Y Sun",
        "J Chen",
        "J Lei",
        "M Abdul-Mageed",
        "S Wang",
        "R Jin",
        "S Park",
        "N Yao",
        "B Long"
      ],
      "year": "2024",
      "venue": "Spar: Personalized content-based recommendation via long engagement attention",
      "doi": ""
    },
    {
      "id": "b95",
      "title": "Benchmarking news recommendation in the era of green ai",
      "authors": [
        "Q Liu",
        "J Zhu",
        "Q Dai",
        "X.-M Wu"
      ],
      "year": "2024",
      "venue": "Companion Proceedings of the ACM on Web Conference 2024",
      "doi": ""
    },
    {
      "id": "b96",
      "title": "Discrete semantic tokenization for deep ctr prediction",
      "authors": [
        "Q Liu",
        "H Hu",
        "J Wu",
        "J Zhu",
        "M.-Y Kan",
        "X.-M Wu"
      ],
      "year": "2024",
      "venue": "Companion Proceedings of the ACM on Web Conference 2024",
      "doi": ""
    },
    {
      "id": "b97",
      "title": "Halogen: Fantastic llm hallucinations and where to find them",
      "authors": [
        "A Ravichander",
        "S Ghela",
        "D Wadden",
        "Y Choi"
      ],
      "year": "2025",
      "venue": "Halogen: Fantastic llm hallucinations and where to find them",
      "doi": ""
    },
    {
      "id": "b98",
      "title": "Enhancing llm's ability to generate more repository-aware unit tests through precise contextual information injection",
      "authors": [
        "X Yin",
        "C Ni",
        "X Li",
        "L Chen",
        "G Ma",
        "X Yang"
      ],
      "year": "2025",
      "venue": "Enhancing llm's ability to generate more repository-aware unit tests through precise contextual information injection",
      "doi": ""
    },
    {
      "id": "b99",
      "title": "Prompt learning for news recommendation",
      "authors": [
        "Z Zhang",
        "B Wang"
      ],
      "year": "2023",
      "venue": "Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "doi": ""
    },
    {
      "id": "b100",
      "title": "Prompt-based generative news recommendation (pgnr): Accuracy and controllability",
      "authors": [
        "X Li",
        "Y Zhang",
        "E C Malthouse"
      ],
      "year": "2024",
      "venue": "European Conference on Information Retrieval",
      "doi": ""
    },
    {
      "id": "b101",
      "title": "Multi-agent collaboration framework for recommender systems",
      "authors": [
        "Z Wang",
        "Y Yu",
        "W Zheng",
        "W Ma",
        "M Zhang"
      ],
      "year": "2024",
      "venue": "Multi-agent collaboration framework for recommender systems",
      "doi": ""
    },
    {
      "id": "b102",
      "title": "When large language model based agent meets user behavior analysis: A novel user simulation paradigm",
      "authors": [
        "L Wang",
        "J Zhang",
        "H Yang",
        "Z Chen",
        "J Tang",
        "Z Zhang",
        "X Chen",
        "Y Lin",
        "R Song",
        "W X Zhao"
      ],
      "year": "2023",
      "venue": "When large language model based agent meets user behavior analysis: A novel user simulation paradigm",
      "doi": ""
    },
    {
      "id": "b103",
      "title": "An efficient recommendation generation using relevant jaccard similarity",
      "authors": [
        "S Bag",
        "S K Kumar",
        "M K Tiwari"
      ],
      "year": "2019",
      "venue": "Information Sciences",
      "doi": ""
    }
  ],
  "sections": [
    {
      "title": "A Survey On Llm-Based News Recommender Systems",
      "text": "Rongyao Wang, Veronica Liesaputra, Zhiyi Huang This paper was produced by the IEEE Publication Technology Group. They are in Piscataway, NJ.Manuscript received April 19, 2021; revised August 16, 2021."
    },
    {
      "title": "Abstract",
      "text": "News recommender systems play a critical role in mitigating the information overload problem. In recent years, due to the successful applications of large language model technologies, researchers have utilized Discriminative Large Language Models (DLLMs) or Generative Large Language Models (GLLMs) to improve the performance of news recommender systems. Although several recent surveys review significant challenges for deep learning-based news recommender systems, such as fairness, privacy-preserving, and responsibility, there is a lack of a systematic survey on Large Language Model (LLM)-based news recommender systems. In order to review different core methodologies and explore potential issues systematically, we categorize DLLM-based and GLLM-based news recommender systems under the umbrella of LLM-based news recommender systems. In this survey, we first overview the development of deep learning-based news recommender systems. Then, we review LLM-based news recommender systems based on three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. Next, we examine the challenges from various perspectives, including datasets, benchmarking tools, and methodologies. Furthermore, we conduct extensive experiments to analyze how large language model technologies affect the performance of different news recommender systems. Finally, we comprehensively explore the future directions for LLM-based news recommendations in the era of LLMs. News Recommender System, Discriminative Large Language Models, Generative Large Language Models."
    },
    {
      "title": "I Introduction",
      "text": "Large amount of news is generated in the era of Internet. It is difficult for users to find news that they are interested in from online news applications such as Google News, Bing News, and Toutiao. In these applications, news recommender systems are employed to help users alleviate this information overload as well as to improve users' reading experience [1, 2]. In recent years, increasing attention to news recommendation has led to a growing number of publications on news recommender systems as shown in Figure 1. With the growth of deep-learning techniques in Natural Language Processing (NLP), various deep-learning methods are utilized in the news recommender systems and achieve state-of-the-art performances [3]. Most news recommender systems are built on deep neural network frameworks, such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Graph Neural Networks (GNNs), due to their superior abilities at representing and learning textual information. CNNs are leveraged to extract local textual features from news contents [4, 5, 6], such as fine-grained news features, and knowledge-based news features. RNNs are utilized to capture users' diverse preferences based on their behavior sequences [7, 8], for example, long- and short-term user interest and multiple user interest. Furthermore, GNNs are commonly employed to model structural news-user representations [9, 10, 11, 12] such as structural intent-aware user representation. Although these neural networks can improve the performance of the news recommender systems, many researchers have found that these general deep-learning methods tend to reach their limitations at learning more complex information [13, 14, 15, 16] such as deep news-user relationship and multi-modal representation. With the advancement of Transformers [17, 18, 19] in NLP, researchers utilize DLLMs, such as BERT [17], RoBERTa [20] and BART [21], as news encoders to capture the potential semantic information in news content [22, 23, 15, 24], or apply DLLMs' special training Fig. 1: The tendency of news recommendation papers published between 2015 and 2024, based on Google Scholar data. strategy to model news-user semantic relationship for news recommendation [25, 26, 27]. These DLLM-based methods achieve better performance than deep neural networks (_e.g._, CNNs, RNNs, GNNs). However, DLLM-based news recommender systems are constrained by their limited pre-trained knowledge, which makes it challenging to leverage them effectively for addressing cold-start problem and modeling accurate news and users' representations [17, 20, 26]. Recent GLLMs (_e.g._, GPT-4 1, LLaMA 2, PaLM 3) have a substantially larger number of parameters and are pre-trained on significantly higher amount of data, which makes it more powerful at semantic understanding and generation. Recently, there are rapid growth in GLLM-based news recommender systems, and some can achieve state-of-the-art performance [28, 29, 30] because it can alleviate the cold-start problem by generating relevant information, and use its strong reasoning and learning abilities to explore accurate news features and model users' interests. However, GLLM-based news recommender systems typically require significant training time and resources. Footnote 1: [https://openai.com/index/gpt-4/](https://openai.com/index/gpt-4/) Footnote 2: [https://www.llama.com/](https://www.llama.com/) Footnote 3: [https://ai.google/discover/palm2](https://ai.google/discover/palm2) Many comprehensive survey studies summarize and review various methodologies of news recommender systems. For instance, Wu et al. [3] reviewed different challenges, technologies, and future directions of deep learning based personalized news recommender systems. While Meng et al. [31] reviewed various significant parts of personalized news recommender system such as data collection, news recommendation model, and personalized news display. They focused on discussing different news recommendation methods based on graph structure learning. Iana et al. [32] categorized knowledge-aware news recommendation into three parts: neural methods, non-neural entity-centric methods, and non-neural path-based methods. Specifically, they review different methodologies of news recommender systems which utilize external knowledge to enhance performance. However, currently, there is a gap in a systematic survey on LLM-based news recommender systems with extensive experiments. In this paper, we summarize and review various LLM-based (including DLLM and GLLM) news recommendation approaches based on three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. Text-oriented modeling is defined as a set of foremost text-based encoding methods that use DLLMs and GLLMs for news recommendation. Then, we review methods that focus on building user profiles as user-oriented modeling for news recommendation. The prediction-oriented modeling represents methods relevant to prediction, _i.e._, optimizing predicting function based on users and news. Moreover, we examine the challenges from various perspectives, including datasets, benchmarking tools, and methodologies. We have also conducted comprehensive benchmark experiments to thoroughly compare and review the existing systems' performance, advantages, disadvantages, and limitations. The performance of each news recommender system is measured in terms of classification metrics, ranking metrics, diversity metrics, and personalization metrics. Finally, we review future directions on new recommendation in the era of LLMs to support future news recommendation research. Our main contributions are as follows: * As far as we know, this is the first systematic survey of news recommender systems by conducting extensive experiments in the era of LLMs. * We propose a unified research framework that reviews different LLM-based news recommendation models based on three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. * Through objective experiments, we evaluate various LLM-based news recommender systems from different angles using a variety of metrics, _i.e._, classification metrics, ranking metrics, diversity metrics, and personalization metrics. This paper is organized as follows: Section II discusses different deep learning-based news recommendation methodologies. While, Section III reviews LLM-based news recommendation methods from three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. Section IV explores the challenges of LLM-based news recommender systems. Section V details our benchmark experiments' designs and results of various LLM-based news recommendation methodologies. Section VI explores future directions for LLM-based news recommender systems. Finally, in Section VII, we conclude our systematic survey and significant findings."
    },
    {
      "title": "Ii Overview Of Deep Learning-Based News Recommender Systems",
      "text": "Before the era of large language models, deep-learning methods (_e.g._, CNNs, RNNs, GNNs) were commonly used to design news recommender systems [33, 34, 35, 36, 37, 38, 39]. Research works in each period have demonstrated consistent patterns across different deep-learning technology development stages. Based on our knowledge and previous works [3, 15, 32], we can conclude a general uniform news recommendation framework as shown in Figure 2, which consists of three main components: news encoder, user encoder and click predictor. Specifically,the news encoder is devised to construct accurate news representations and support user interest modeling. The user encoder is designed to explore users' preferences and build users' representations based on accurate news representations. The click predictor is proposed to calculate matching scores between candidate news representations and users' representations. In this section, we categorize different research works into two types based on the characteristics of news recommendation as follows: news-oriented modeling and user-oriented modeling. To clearly illustrate our observations, an overview of deep learning-based news recommendation methodologies is presented in Table I."
    },
    {
      "title": "_News-Oriented Modeling_",
      "text": "Initially, most researchers focus on applying basic deep-learning methods to construct news embeddings. To be specific, CNNs are among the earliest deep-learning methods applied in news recommender systems. For example, Wang et al. [4] managed to design CNN-based news encoders with a knowledge graph. Khattar et al. [40] utilized 3D-CNNs to encode news representations. Moreover, attention mechanism (_e.g._, additive attention, multi-head self-attention) is employed to model accurate news representation [33, 43] as well as capture textual content representations [1]. In particular, Gabriel et al. [42] proposed a deep learning-based news recommendation architecture that applied deep neural networks (DNNs) and RNNs to encode content representations. Wu et al. [6] designed a topic-aware news encoder to build news representations with news categories. To construct comprehensive news representations, other researchers focus on devising effective news encoders to encode informative news features. To capture sufficient textual information in news content, Wu et al. [52] proposed a multi-view news encoder that can encode all informative news features such as title, category, and abstract. Lian et al. [56] proposed applying multi-layer fully connected networks and attention mechanisms to design a deep fusion model for news representation learning. The aforementioned models encode basic news features (_e.g._, title, category, abstract) with different deep-learning methods. Due to the limitations of deep-learning methods during this period, most researchers are interested in exploring different deep-learning methodologies to improve the accuracy of news recommender systems."
    },
    {
      "title": "_User-Oriented Modeling_",
      "text": "With the growth of deep learning-based news recommender systems, user representation learning has gained increasing attention from researchers. For example, Liu et al. [54] utilized self-attention networks to encode deep user representations. Aiming to capture users' long- and short-term representations, An et al. [7] proposed to employ RNNs (_e.g._, gated recurrent unit networks) to model users' consistent and temporal preferences. Ge et al. [47] employed GNNs (_e.g._, graph attention networks) and modified transformer networks to model users' high-order relatedness. Although these representation learning methods are proposed to encode news and users' features in order to generate accurate embedding representations for news recommendation, they are only at the mid-exploration stage of deep learning-based news recommender systems. During the rapid development stage of deep-learning methods ranging from 2020 to 2023, researchers have observed that deep-learning methods not only explore more accurate textual features but also model real-world user profiles (_e.g._, interest, intention, behaviour). Aiming to build accurate users' interests and obtain more effective recommendation performance, most works utilize different sufficient deep-learning methods to devise their innovative user interest models [5, 57, 11, 58, 60]. They all aim to extract diverse user interests from historical records and achieve state-of-the-art performance in their experiments. By leveraging effective and accessible deep learning methods, we can obtain accurate representations of user interests as expected. For instance, applying RNNs could help our model capture long sequential features [8], while GNNs could assist in modeling structural interest representations and high-order relationships between news and users [10]. Moreover, user intention is a critical concept in news recommendation, originating from the field of psychology [61]. In order to Fig. 2: A general uniform news recommendation framework model users' intentions from sequential history records, Wang et al. [12] devised a GNN-based framework to extract intentions with a knowledge graph. In addition to modeling user representations, other aspects of the user experience (_e.g._, privacy, fairness, sentiment) should also be taken into account in news recommender systems. In terms of privacy, Yi et al. [67] proposed using federated learning to protect users' privacy while reducing computation and communication costs. For fairness, Wu et al. [64] first employed decomposed adversarial learning to learn bias-free representations in the news recommender system. Furthermore, Wu et al. [62] devised to model sentiment-aware news representations with a sentiment prediction task. The aforementioned research directions have become prominent research topics in the field of news recommender systems in recent years."
    },
    {
      "title": "Iii Llm-Based News Recommendation Methodology",
      "text": "In this section, we review how LLM-based methods are used to construct the three main components of a news recommendation system: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling."
    },
    {
      "title": "_News-Oriented Modeling_",
      "text": "Initially, most researchers utilize various DLLMs to encode the textual news content. Specifically, Wu et al. [15] first proposed the use of BERT to enhance the natural language understanding capabilities of news recommender systems. Their core contribution is replacing the conventional news encoder module consisting of CNNs, RNNs and GNNs with a module composed of DLLMs and attention mechanisms. Huang et al. [69] introduced a multi-factor fusion model to address the impact of specific news events (_i.e._, breaking news). To enable multi-aspect customization for news recommendation, such as incorporating news features like sentiment and categories, Iana et al. [70] proposed a novel framework that leverages DLLMs and contrastive learning to model both content- and aspect-based news representations. These methods commonly leverage BERT-based models to enhance the comprehension of textual information for news recommendation. As demonstrated in these studies [71, 15], BERT-based models have enhanced news recommender systems, achieving approximately a 3% improvement in performance compared to deep learning-based methods. The application of GLLMs in news recommender systems is distinct from the approach used in DLLM-based news recommender systems. At the inception of GLLMs, most researchers favored incorporating additional critical information generated by GLLMs into news recommender systems. For example, Gao et al. [28] proposed a novel generative news recommendation framework that constructs news narratives (_e.g._, personalized multi-news narratives) using GLLMs, with a newly proposed training method to enhance recommendation accuracy. Similarly, Yada et al. [72] applied GLLMs (_i.e._, GPT-4) to generate category descriptions in the news recommender system. Chen et al. [30] effectively leveraged GLLMs to construct rich semantic news representations and utilize Wikidata KG to tackle the long-tail problem in news recommender systems. Liu et al. [73] proposed a novel framework to apply large language model technologies (_e.g._, GPT-4, LLaMA) to learn contextual information with effective prompts and fine-tuning methods on the \\begin{table} \\begin{tabular}{p{113.8pt} p{113.8pt} p{113.8pt}} \\hline \\hline **Type** & **Methodology** & **Model** \\\\ \\hline \\multirow{8}{*}{News-oriented modeling} & Convolutional Neural Network (CNN) & Weave\\&Rec [40], DNN4NR [41] \\\\ & Recurrent Neural Network (RNN) & GRU [37], CHAMELEON [42], HRAM [35] \\\\ & Attention Mechanism & NRMs [43], DAN [33], DAIN [44], NPA [1], DNA [45] \\\\ & Graph Neural Network (GNN) & SI-News [46], GERL [47] \\\\ & Knowledge Graph (KG) & DKN [4], TEKGR [39], KOPRA [48], AnchorKG [49], KRED [50], CAGE [51] \\\\ & Reinforcement Learning & DRN [2] \\\\ & News Representation Learning & TANR [6], NAML [52], WG4Rec [34], ANRS [53] \\\\ \\hline \\multirow{8}{*}{User-oriented modeling} & User Representation Learning & LSTUR [7], HiFi-Ark [54], NRHUB [55], CNE-SUE [10], DFM [56], TANN [38], GNewsRec [9], HiRec [57], PP-Rec [58], CAUM [59] \\\\ & Interest Modeling & MINS [8], MINER [23], FIM [5], PENR [60], GREP [11], THnews [36] \\\\ & Intention Modeling & IPNR [61] \\\\ & Sentiment Modeling & SentRec [62], SentiDebias [63] \\\\ & Fairness Modeling & FairRec [64], HDInt [65] \\\\ & Privacy-preserving Modeling & CenNewsRec [66], FedRec [67] \\\\ & Satisfaction Modeling & CPRS [68] \\\\ \\hline \\hline \\end{tabular} \\end{table} TABLE I: Overview of deep learning-based news recommender systems in recent years. We categorize the research based on their methodologies. news recommendation dataset (_e.g._, MIND). In order to alleviate the problem of media bias, Ruan et al. [29] proposed leveraging GLLMs to rewrite news headlines for users in news recommender systems. The researchers effectively leverage the powerful generative capabilities of GLLMs to achieve approximately a 10% improvement in the performance of news recommendation."
    },
    {
      "title": "_User-Oriented Modeling_",
      "text": "Modeling users' preferences lies at the heart of news recommender systems. An advanced modeling method could enhance news recommendation models to understand users' needs and recommend relevant articles that meet their preferences. The applications of LLMs in news recommender systems not only improve the ability to understand textual information but also enable the creation of accurate user profiles by leveraging contextual features. For instance, Zhang et al. [27] designed a user-news matching framework with BERT, whose core idea is matching clicked and candidate news with multi-grained representations (_i.e._, word-level representations, news-level representations) in a BERT architecture. During the same period, the attentive multi-field matching framework is proposed by Zhang et al. [25]. Although their methodology is similar to that of [27], the matching objects and granularity differ (_i.e._, news titles, abstracts, and bodies are used in this matching process). Similarly, Li et al. [23] proposed a multi-interest matching framework that applies a poly attention scheme to extract multiple interests with BERT-based news encoders. To effectively model users' immediate and long-term preferences, Liu et al. [74] utilized attention mechanisms and GLLMs to address these challenges, using clicked news articles as the basis. As far as we observed, GLLM-based user models are less than DLLM-based user models. Therefore, a significant gap exists in modeling user preferences using GLLMs."
    },
    {
      "title": "_Prediction-Oriented Modeling_",
      "text": "The prediction-oriented modeling consists of a combination of training strategies and prediction methods. Specifically, NewsBERT [26] is a novel DLLM-based news recommendation framework that simultaneously learns valuable insights from both teacher and student models through the distillation of BERT. Yu et al. [75] first proposed a self-supervised domain-specific post-training approach into a DLLM-based news recommendation framework with a novel two-stage knowledge distillation methodology. Moreover, Xiao et al. [76] proposed an innovative training framework SpeedyFeed to reduce the time and resource costs associated with training DLLM-based news recommender systems. To enhance the performance of news recommendation tasks, Bi et al. [22] designed a multi-task framework that improves effectiveness by incorporating multi-field features, including news recommendation, news classification, and named entity recognition (NER). Furthermore, Liu et al. [77] proposed a prompt-based news recommendation framework that demonstrates the effectiveness of a GLLM-based prompt strategy by leveraging an iterative bootstrapping process. Wang et al. [78] proposed a GLLM-based news recommendation model that utilizes a GLLM to filter out low-value news and recommend high-value news to users, using a newly designed metric called CherryRec. These methods provide great strategies to assist us train and optimize LLM-based news recommender systems. However, research on GLLM-based news recommender systems is still in the early stages and presents researchers with more opportunities and challenges to overcome."
    },
    {
      "title": "Iv Challenges",
      "text": "In this section, we discuss our observations on the challenges of LLM-based news recommender systems, focusing on datasets, tools, and methodologies."
    },
    {
      "title": "_Challenges Of Datasets_",
      "text": "There are some publicly available news recommendation datasets such as Globo [84], Plista [85], Adressa [86], MIND [87], NPR [88], xMIND [89], and EB-NeRD [90]. We summarize their characteristics in Table II. Specifically, Plista offers a large collection of news texts and user behaviors gathered from 13 German news portals. Globo only includes word embeddings of the news texts, without additional textual features, which significantly limits the available information. Because textual information is essential in constructing news and user representations. As we can observe, Adressa and MIND are two of popular news recommendation datasets, which include informative news and user features. NPR is an enhanced news dataset by Globo, offering more comprehensive news content and detailed user behavior data, which consists of metadata information about news articles, recommendation impressions and user consumption history. xMIND is a multilingual news recommendation dataset built on MIND, which includes 14 linguistically and geographically diverse languages. EB-NeRD is collected from the information of Ekstra Bladet, which consists of 37 million impression logs, 251 million interactions and news metadata. Despite the availability of some resources, public news recommendation datasets face significant challenges as follows: 1. Quantity: The available public news datasets are insufficient to meet the rapid growth of news recommender systems. As we can see in Table II,MIND dataset is the most popular dataset on which most researchers prefer to conduct experiments. However, the MIND dataset has nearly reached its limitation in some works [15, 26]. We are in the zone of model overfitting to this dataset. So we need more datasets to really evaluate the generalizability of the model. It is essential to release some new news datasets to enable researchers to conveniently design and conduct experiments across different datasets. 2. Information: MIND dataset contains the most informative features (_e.g._, title, abstract, category, entity) compared with others. However, this alone is insufficient to significantly enhance news recommender systems. This is because additional information (_e.g._, publisher, location, reading time, etc) is required to model more accurate user representations. Incorporating users' reading time per news article could improve the accuracy of modeling their preferences [68]. Including publisher information could contribute to building fairness-aware news recommender systems [19]. Additionally, utilizing images within news articles could enable researchers to develop multi-modal news recommender systems, which can empower news representation learning [91]. As a result, the development of news recommender systems is constrained by available news datasets. Moreover, an LLM trained solely on English is unlikely to perform well on Norwegian or other language datasets without additional training."
    },
    {
      "title": "_Challenges Of Benchmarking Tools_",
      "text": "Smart and user-friendly benchmarking tools enable researchers to conduct studies more easily. In recent years, several benchmarking tools have been released to support the development of news recommender systems. We collect and review important benchmarking tools related to news recommendation illustrated in Table III, including Microsoft Recommenders [93], RecBole [94], News-Recommendation, NewsRecLib [71], and Legommender [92]."
    },
    {
      "title": "Iv-B1 Microsoft Recommenders",
      "text": "Microsoft Recommenders 11 is published by Microsoft Recommenders team providing several examples and practices for building recommender systems. This benchmarking tool contains five essential news recommendation models including NRMS [43], NPA [1], NAML [52], LSTUR [7] \\begin{table} \\begin{tabular}{c c c c c c c c} \\hline \\hline Released Year & Dataset & \\# News & \\# User & \\# Behavior & Textual Feature & Language & Reference \\\\ \\hline 2013 & Plista 4 & 70,353 & / & 1,095,323 & title, body, category & German & Jugovac et al. [79] \\\\ \\hline 2018 & Globo 5 & 46,000 & 314,000 & 3,00,000 & word embeddings & Portuguese & Gabriel et al. [42] \\\\ & & & & & of texts & & \\\\ \\hline 2018 & Adressa 6 & 48,486 & 3,083,438 & 27,223,576 & title, body, category, entity & Norwegian & Dan et al. [33], Hu et al. [9], Sheu et al. [51], Koo et al. [80], zhao et al. [81], Gharahigheh et al. [82], Bae et al. [83], Huang et al. [69], Yi et al. [67], Lee et al. [39] \\\\ \\hline 2020 & MIND 7 & 161,013 & 1,000,000 & 24,155,470 & title, abstract, category, entity & English & Wang et al. [4], Wu et al. [16, 14, 15, 26, 43, 52, 62, 64], An et al. [7], Wang et al. [5], Qi et al. [57, 59], Qiu et al. [11], Li et al. [23], Mao et al. [10], Xu et al. [24], Wang et al. [8], Zhang et al. [25, 27], Gao et al. [28], Yi et al. [67], Ge et al. [47], Liu et al. [54], Wang et al. [60], Lu et al. [53], Bi et al. [22] \\\\ \\hline 2023 & NPR 8 & 148,099 & 1,162,802 & 1,402,576 & title, content, topic & Portuguese & - \\\\ \\hline 2024 & xMIND 9 & 130,379 & 1,000,000 & 24,155,470 & title, abstract & Multi-languages & - \\\\ \\hline 2024 & EB-NeRD 10 & 125,541 & 1,103,602 & 37,966,985 & title, abstract, body, category, entities, URL, sentiment, topic & Danish & - \\\\ \\hline \\hline \\end{tabular} \\end{table} TABLE II: Comparisons of different news recommendation datasets [MISSING_PAGE_FAIL:7] [6], CAUM [59], CenNewsRec [66], MINS [8], etc) and news datasets (_e.g._, MIND, Adressa, xMIND), which enables researchers to quickly reproduce news recommendation methods and conduct experiments among different datasets. Although this benchmarking tool categorizes news recommender systems into two classes: deep learning-based news recommendation and fairness-aware news recommendation, the models provided are insufficient to support future research due to the lack of multi-modal news recommender systems, GLLM-based news recommender. systems, etc. Several future directions require attention, including debiased news recommender systems, LLM-based news recommender systems, multi-modal news recommender systems, and privacy-preserving news recommender systems."
    },
    {
      "title": "Iii-B5 Legommender",
      "text": "Legommender is a content-based recommendation benchmarking tool released by personal researchers, which aims to support LLM-based recommender systems. This benchmarking tool contains four news recommendation models such as NAML [52], NRMS [43], LSTUR [7], and PLMNR [15]. They devised this tool to serve their research such as ONCE [73], SPAR [95], GreenRec [96] and UIST [97]. Legommender guides researchers on effectively applying LLMs to news recommendations including DLLM- and GLLM-based frameworks. However, it is not sufficient to support a wide range of news recommendation models with LLMs. Furthermore, additional news recommendation datasets are expected to better serve LLM-based news recommender systems."
    },
    {
      "title": "_Challenges Of Methodologies_",
      "text": "LLM-based news recommender systems face several challenges in the era of LLMs. We will review these various challenges from three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling."
    },
    {
      "title": "Iii-C1 News-Oriented Modeling",
      "text": "News representation modeling is critical for accurate news recommendation, strongly related to NLP technologies such as word embedding [37] and LLMs. LLM-based news recommender systems utilize LLMs as news encoders to learn informative news representations, and their superior performance has been validated in numerous studies [71, 15, 73]. Although language models offer promising advantages for news representations, challenges still need to be addressed. First of all, the information generated by GLLMs is not always credible (_i.e._, GLLMs may exhibit hallucinations.) [98]. Therefore, it is essential to develop more reliable methodologies to validate the accuracy of generated representations. Second, processing large volumes of textual information with LLMs consumes significant time and resources [99]. Third, LLM-based news recommender systems are unable to process long documents due to their limited context window, which restricts their ability to construct comprehensive news representations. Furthermore, modeling multiple languages poses a significant challenge for LLM-based news recommender systems, as not all LLMs are equipped to handle multiple languages effectively. In summary, more effective and efficient LLM-based news encoders are needed to better leverage LLMs for constructing informative news representations."
    },
    {
      "title": "Iii-C2 User-Oriented Modeling",
      "text": "User-oriented modeling plays a critical role in news recommender systems. As far as we know, most researchers prefer to model user and news representations simultaneously using DLLMs [23, 25, 26, 27, 69, 70, 75]. As a result, there is limited research focused on building special user representations independently such as multiple interests modeling, intention modeling, and sentiment modeling [8, 12, 62]. In the real world, user behaviors are complex and dynamic. Current user representation models cannot describe complex and dynamic user behaviors. For example, users' interests might be influenced by breaking news along with time. It is essential to carefully analyze and understand users' interests based on their behaviors. Although DLLMs enhance news representations as well as user representations, it is not sufficient to fully understand real complex users' behaviors. On the other hand, limited research has focused on modeling user representations using GLLMs [28, 30]. They propose generating additional information such as narratives by GLLMs and then aggregating it with the original features of news articles. However, these published studies ignore exploring deep and various user behaviours based on GLLM-enhanced context. For example, user behaviours when reading online newspapers may be influenced by their purpose and preferences. Therefore, efficiently building complex and dynamic user representations using GLLMs remains a significant challenge for news recommendation."
    },
    {
      "title": "Iii-C3 Prediction-Oriented Modeling",
      "text": "Prediction-oriented modeling is related to training strategies and prediction including different training frameworks, evaluation methods, and ranking methodologies. It is more and more pivotal for news recommender systems in the period of LLMs. Due to the high time and resource consumption of DLLMs and GLLMs, LLM-based news recommender systems require optimization during training and prompting. First of all, LLM-based news recommender systems often apply one-tower architecture to match candidate news and user interests [25, 27]. These ranking methods can accurately explore the relatedness between candidate news and user interests with multi-grained features. However, these methods are unsuitable for low-latency or low-resource scenarios due to their high inference time and resource requirements[19]. Moreover, training open-source GLLMs, such as LLaMA, for use in news recommendation requires significant time and expensive hardware to support these experiments. Efficient and effective training frameworks and ranking methods are required to accelerate prediction without high time and resource consumption. Second, current LLM-based methods lack accountability for their generated results. Many researchers have already utilized LLMs to replace traditional prediction frameworks such as the two-tower model as shown in Figure 2[100]-[103]. However, the generated results by GLLMs are not credible. Therefore, how to evaluate the accuracy of the generated information is a significant challenge. Moreover, new metrics are required to support LLM-based news recommender systems in order to verify their robustness, reliability, and performance."
    },
    {
      "title": "V Experiments",
      "text": "In this section, we introduce experimental settings such as datasets, metrics, and news recommendation models that we used in our experiments. Further, we conduct extensive experiments in order to answer the following questions: **Q1**: How is the performance of LLM-based news recommendation models compared with deep learning-based news recommendation models in terms of classification and ranking? **Q2**: Do LLM-based news recommendation models outperform deep learning-based news recommendation models in terms of diversity and personalization? **Q3**: Do LLMs improve the performance of news recommendation sharply compared with the original deep learning-based news recommendation models? **Q4**: How do GLLM-based news recommendation models perform compared with DLLM-based news recommendation models?"
    },
    {
      "title": "_Datasets_",
      "text": "For our experiments, we will utilize the two most commonly used datasets in our experiments: MIND [87] and Adressa [86]."
    },
    {
      "title": "V-A1 Mind",
      "text": "MIND was released by Microsoft in 2020 [87] and constructed based on anonymous user logs obtained from Microsoft News platform. There are two versions: MIND-small and MIND-large. MIND-small contains 65,238 news metadata and 347,727 logs generated by 94,057 users. MIND-large consists of 24,155,470 logs of 1,000,000 users and 161,013 pieces of news. Each piece of news contains titles, abstracts, categories, and entities In terms of users, MIND provides their IDs and clicked logs including news clicks and impressions."
    },
    {
      "title": "V-A2 Adressa",
      "text": "Adressa was published by Norwegian University of Science and Technology, which contains a collection of news articles and sessions from Adressa'sisen news platform [86]. There are two sub-datasets: one-week and ten-week. The one-week Adressa dataset is comprised of 11,207 articles and 2,286,835 session logs of 561,733 users. The 10-week Adressa dataset is composed of 48,486 articles and 27,223,576 session logs of 3,083,438 users. Each news article consists of titles, categories, bodies, and entities. Each session log includes various information about the user such as IDs, regions, time, browser, and city. Due to the limitation of training time and resources, we use the MIND-small and one-week Adressa dataset to conduct our experiments."
    },
    {
      "title": "_Evaluation Metrics_",
      "text": "Several evaluation metrics are utilized to verify the performance of news recommender systems in terms of ranking, classification, diversity, and personalization. In this section, we present the metrics employed in our experiments."
    },
    {
      "title": "V-B1 Classification Metrics",
      "text": "News recommendation can be considered as a classification task. Hence, several classification metrics can be used. Area Under Curve (AUC) score is commonly used in the evaluation of news recommendations. A high AUC score indicates that the news recommendation model has a stronger ability to distinguish between negative and positive samples, enabling it to recommend relevant news to users effectively. The score is calculated as follows: \\[\\text{AUC}=\\frac{1}{|P|\\times|N|}\\sum_{p\\in P}\\sum_{n\\in N}I(s(p)>s(n)), \\tag{1}\\] where \\(P\\) is positive samples, \\(N\\) is negative samples, \\(p\\) is one of positive samples, \\(n\\) is one of negative samples, \\(s(p)\\) is the predicting score of positive samples, \\(s(n)\\) is the predicting score of negative samples. \\(I(s(p)>s(n))\\) indicates that if \\(s(p)>s(n)\\), the result is 1; otherwise, it is 0, computed as follows: \\[I(s(p)>s(n))=\\begin{cases}1,&\\text{if }s(p)>s(n)\\\\ 0,&\\text{otherwise}\\end{cases}. \\tag{2}\\] Additionally, there are other popular metrics used in the evaluation of news recommender systems such as Precision, Recall, and Hit Rate (HR), which are computed as follows: \\[\\text{Precision}=\\frac{TP}{TP+FP}, \\tag{3}\\] \\[\\text{Recall}=\\frac{TP}{TP+FN}, \\tag{4}\\] \\[\\text{HR}@k=\\frac{1}{|U|}\\sum_{u\\in U}\\mathbb{I}(R_{u}\\cap\\hat{R}_{u}(k)\\neq \\emptyset), \\tag{5}\\]where \\(TP\\) indicates true positive samples, \\(FP\\) means false positive samples, \\(FN\\) indicates false negative samples, \\(R_{u}\\) is the collection of interested items for user \\(u\\), \\(\\hat{R}_{u}(k)\\) is a top-\\(k\\) list of interested items for user \\(u\\), \\(\\mathbb{I}\\) is exponential function, if true, return 1; otherwise, return 0. In summary, AUC is widely utilized to evaluate the models' ability to recognize positive and negative samples. Precision measures the accuracy of correctly predicting positive samples. Recall is widely used to verify the ability to distinguish all positive samples. Hit rate is proposed to evaluate whether the recommended news list contains the user's interested news."
    },
    {
      "title": "Iv-B2 Ranking Metrics",
      "text": "News recommendation can be considered as a ranking task. Therefore, there are several ranking metrics used in the evaluation of news recommender systems. Apart from AUC, which is also a ranking metric, Mean Reciprocal Rank (MRR) and Normalized Discounted Cumulative Gain (nDCG). Specifically, MRR is utilized to evaluate whether interested news appears in the top positions of the recommended news list. nDCG measures whether the most relevant news appears in the top positions of the recommended news list, which focuses on the ranking quality and relevance of recommended results. MRR and nDCG\\(@k\\) are formulated as follows: \\[\\text{MRR}=\\frac{1}{|Q|}\\sum_{i=1}^{|Q|}\\frac{1}{\\text{Rank}_{i}}, \\tag{6}\\] \\[\\text{nDCG}@k=\\frac{\\sum_{i=1}^{k}\\frac{\\text{rel}_{i}}{\\log_{2}(i+1)}}{\\sum_ {i=1}^{k}\\frac{\\text{rel}_{i}^{\\mathbb{I}}}{\\log_{2}(i+1)}}, \\tag{7}\\] where \\(Q\\) is the set of queries, \\(|Q|\\) is the total number of queries, \\(\\text{Rank}_{i}\\) is the rank position of the first relevant to the \\(i\\)-th query. \\(\\text{rel}_{i}\\) is the relevance score of the \\(i\\)-th result, \\(\\text{rel}_{i}^{*}\\) is relevance score under ideal ranking."
    },
    {
      "title": "Iv-B3 Diversity Metrics",
      "text": "In order to measure the diversity of news recommendations, Iana et al. [70] proposed aspect-based diversity metrics as follows: \\[D_{A_{p}}@k=-\\sum_{j\\in A_{p}}\\frac{p\\left(j\\right)\\log p\\left(j\\right)}{ \\log\\left(|A_{p}|\\right)}, \\tag{8}\\] where \\(A_{p}\\) is the collection of aspects, \\(|A_{p}|\\) is the number of aspects."
    },
    {
      "title": "Iv-B4 Personalization Metrics",
      "text": "The Jaccard similarity [104] is used to evaluate the personalization of news recommendations, which is computed as follows: \\[PS_{A_{p}}@k=\\frac{\\sum_{j=1}^{|A_{p}|}\\min\\left(\\mathcal{R}_{j},\\mathcal{H} _{j}\\right)}{\\sum_{j=1}^{|A_{p}|}\\max\\left(\\mathcal{R}_{j},\\mathcal{H}_{j} \\right)}, \\tag{9}\\] where \\(\\mathcal{H}\\) is the user history, \\(\\mathcal{R}\\) is the recommendation list, \\(\\mathcal{H}_{j}\\) and \\(\\mathcal{R}_{j}\\) are the probability of a piece of news with class \\(j\\). In our experiments, we denote \\(categ\\_div\\) as the topical category-based diversity and \\(sent\\_div\\) as sentiment-based diversity. Moreover, we consider \\(categ\\_pers\\) as the topical category-based personalization and \\(sent\\_pers\\) as sentiment-based personalization. In our experiments, we compute top 5 and 10 scores in terms of nDCG, Hit, Recall, Precision, diversity, and personalization."
    },
    {
      "title": "_Baselines_",
      "text": "In order to evaluate the performance of LLM-based news recommendation models, we conduct extensive experiments on various methodologies which are classified into three groups: deep learning-based news recommendation models, DLLM-based news recommendation models, and GLLM-based news recommendation."
    },
    {
      "title": "Iv-C1 Deep Learning-Based News Recommendation Models",
      "text": "* NPA [1], a personalized news recommendation model, which applies users' IDs to improve the performance of news recommendation with CNNs and attention mechanisms. * TANR [6], a topic-aware news recommendation model, which promotes news recommendations with a topic classification task using CNNs and attention mechanisms. * NAML [52], a deep learning-based news recommendation model with multi-viewing learning, which builds news representations from various news features such as titles, abstracts, and categories using CNNs and attention mechanisms. * LSTUR [7], a deep learning-based news recommendation model, which employs RNNs to learn long- and short-term user representations. * NRMS [43], a deep learning-based news recommendation model, which utilizes multi-head self-attention mechanisms to capture complex news and users' features. * CenNewsRec [66], a privacy-preserving news recommendation model, which applies federated learning to jointly train accurate news recommender systems on users' devices and servers. * CAUM [59], a candidate-aware news recommendation model, which learns candidate-aware user representations using self-attention mechanisms and CNNs in order to accurately match users' interests. * MINS [8], a deep learning-based news recommendation model, which can learn multi-interest user representations through a multi-channel network consisting of RNNs and self-attention mechanisms. * SentiDebias [63], a deep learning-based news recommendation model, which employs decomposed adversarial learning to achieve fairness-aware news recommendation in terms of different sentiments. * SentiRec [62], a diversity-aware news recommendation model, which applies Transformers to model sentiment-aware news and user representations, jointly training with a sentiment prediction task."
    },
    {
      "title": "Iv-C2 Dllm-Based News Recommendation Models",
      "text": "* MINER [23], a DLLM-based news recommendation model, which proposes a poly attention scheme to learn multi-interest user representations over BERT. * MANNeR [70], a DLLM-based news recommendation model, which proposes a modular framework to learn aspect-specific representations over BERT. * LSTUR-DLLM, TANR-DLLM, NRMS-DLLM, and NAML-DLLM are DLLM-empowered news recommendation models, in which the original news encoders are modified to incorporate DLLMs, inspired by previous works [15, 71]."
    },
    {
      "title": "Iv-C3 Gllm-Based News Recommendation Models",
      "text": "* LKPNR [30], a generative news recommendation framework, which integrates a knowledge graph and GLLMs into deep learning-based news recommendation models. * ONCE [73], a hybrid content-based recommendation framework, which leverages both open- and closed-source GLLMs to enhance the performance of content-based recommender systems including news recommender systems."
    },
    {
      "title": "_Experimental Setup_",
      "text": "We use similar configurations with NewsRecLib [71] in terms of deep learning-based news recommendation models and DLLM-based news recommendation models. Besides, we employ official codes to reproduce GLLM-based news recommendation models (_e.g._, ONCE20, LKPNR21) on the MIND dataset. Specifically, we only reproduce DIRE (Discriminative Recommendation Framework)-NAML to conduct our main experiments in Table IV. Each model is trained and tested five times. For the sake of fairness and impartiality of the results, we calculate their average and standard deviation as shown in Table IV, Table VI and Table V. Footnote 20: [https://github.com/Jyonn/ONCE](https://github.com/Jyonn/ONCE) Footnote 21: [https://github.com/Xuan-ZW/LKPNR](https://github.com/Xuan-ZW/LKPNR)"
    },
    {
      "title": "_Performance Evaluation_",
      "text": "Iv-E1 Reply to Q1: LLM-based news recommendation models vs. deep learning-based news recommendation models w.r.t. classification and ranking As we can see in Table IV, the classification metrics including AUC and Recall reflect the performance of positive and negative classification in news recommender systems. For experiments on the MIND dataset, the LLM-based news recommendation model MANNeR achieves the best performance in terms of the main metric AUC, improving 22 by approximately 13% compared to the deep learning-based news recommendation model TANR. Moreover, LKPNR significantly outperforms the best deep learning-based news recommendation model NAML in terms of Recall metrics, achieving an average 7% improvement. These improvements prove the effectiveness of LLM-based news recommendation models in terms of classification and ranking capability on the MIND dataset. However, results on the Adressa dataset exhibit conflicting phenomena. Notably, deep learning-based news recommendation models such as CAUM and LSTUR markedly outperform all LLM-based news recommendation models. This happens to be because it isn't effective for LLM-based news recommendation models to encode multilingual information such as Norwegian on the Adressa dataset. Footnote 22: The improvement is over the suboptimal performing baseline methods. To more intuitively evaluate the accuracy of news recommendation models, we enrich our experiments using Hit Rate and Precision. Figure 3 demonstrates the results in terms of Hit Rate and Precision on the MIND dataset. MANNeR achieves the best performance _w.r.t._ Hit Rate on the MIND dataset. This superiority can be attributed to the effectiveness of a novel aspect-based framework with LLM-based methodologies which can learn aspect-specific representations for news recommendation. In addition, MANNeR obviously outperforms other news recommendation models in terms of Precision as shown in Figure 4. This emphasizes the superiority of LLM-based news recommendation models in terms of Hit Rate and Precision on the MIND dataset. However, the results illustrate different tendencies on the Adressa dataset. To be specific, LSTUR and CAUM stand out as two of deep learning-based news recommendation models as indicated by Hit@\\(k\\). This is likely due to the fact that LLM-based news recommendation models cannot effectively encode multilingual news features, leading to decreased performance on the Adressa dataset. In contrast, LLM-based news recommendation models, such as LSTUR-DLLM and NAML-DLLM, exhibit better precision compared to deep learning-based news recommendation models. This superiority can be attributed to the fact that LLM-based news recommendation models can model informative news representations, which is effective in deriving higher precision. In summary, LLM-based news recommendation models have demonstrated great potential, while deep learning methods still have their advantages. Iv-E2 Reply to Q2: LLM-based news recommendation models vs. deep learning-based news recommendation models w.r.t. diversity and personalization Table V presents results of diversity and personalization on the MIND dataset. Notably, LLM-based news recommendation models like MINER and NRMS-DLLM outperform deep learning-based news recommendation models in \\begin{table} \\begin{tabular}{c|c|c c c c c c} \\hline \\hline \\multirow{2}{*}{Dataset} & \\multirow{2}{*}{Model} & \\multicolumn{6}{c}{Metric} \\\\ \\cline{3-8} & & AUC & MRR & NDCG@5 & NDCG@10 & Recall@5 & Recall@10 \\\\ \\hline \\hline & NPA & 57.12\\(\\pm\\)0.0035 & 30.61\\(\\pm\\)0.0046 & 28.68\\(\\pm\\)0.0036 & 34.89\\(\\pm\\)0.0031 & 41.95\\(\\pm\\)0.0043 & 59.98\\(\\pm\\)0.0022 \\\\ & LSTUR & 56.31\\(\\pm\\)0.017 & 33.09\\(\\pm\\)0.0057 & 31.31\\(\\pm\\)0.0068 & 37.61\\(\\pm\\)0.0068 & 45.37\\(\\pm\\)0.0055 & 63.5\\(\\pm\\)0.0044 \\\\ & TANR & 60.83\\(\\pm\\)0.0066 & 32.88\\(\\pm\\)0.0037 & 30.93\\(\\pm\\)0.0045 & 37.19\\(\\pm\\)0.0034 & 44.71\\(\\pm\\)0.007 & 62.51\\(\\pm\\)0.0047 \\\\ & NRMS & 55.63\\(\\pm\\)0.0229 & 28.63\\(\\pm\\)0.0158 & 26.78\\(\\pm\\)0.014 & 33.3\\(\\pm\\)0.0133 & 40.38\\(\\pm\\)0.0135 & 59.17\\(\\pm\\)0.0125 \\\\ & NAML & 50.17\\(\\pm\\)0.0004 & 34.55\\(\\pm\\)0.0066 & 32.69\\(\\pm\\)0.0055 & 38.93\\(\\pm\\)0.0048 & 46.73\\(\\pm\\)0.0048 & 64.59\\(\\pm\\)0.0023 \\\\ & CenNewsRec & 53.85\\(\\pm\\)0.015 & 26.6\\(\\pm\\)0.0105 & 24.98\\(\\pm\\)0.0105 & 31.67\\(\\pm\\)0.0092 & 39.05\\(\\pm\\)0.0123 & 58.35\\(\\pm\\)0.0078 \\\\ & CAUM & 60.63\\(\\pm\\)0.0111 & 34.15\\(\\pm\\)0.0091 & 32.23\\(\\pm\\)0.0084 & 38.69\\(\\pm\\)0.0076 & 44.75\\(\\pm\\)0.0331 & 63.36\\(\\pm\\)0.0294 \\\\ MIND & MINS & 58.78\\(\\pm\\)0.0161 & 33.76\\(\\pm\\)0.0036 & 31.87\\(\\pm\\)0.0034 & 38.29\\(\\pm\\)0.0033 & 46.0\\(\\pm\\)0.0066 & 64.39\\(\\pm\\)0.0054 \\\\ & SentiDebias & 54.82\\(\\pm\\)0.0204 & 25.6\\(\\pm\\)0.0142 & 23.3\\(\\pm\\)0.0133 & 30.12\\(\\pm\\)0.0129 & 35.59\\(\\pm\\)0.0127 & 55.32\\(\\pm\\)0.0105 \\\\ & SentiRec & 52.87\\(\\pm\\)0.0085 & 29.44\\(\\pm\\)0.0188 & 27.18\\(\\pm\\)0.0175 & 33.62\\(\\pm\\)0.0167 & 40.25\\(\\pm\\)0.0178 & 58.83\\(\\pm\\)0.0159 \\\\ & LSTUR-DLLM & 50\\(\\pm\\)0 & 30.15\\(\\pm\\)0.0079 & 28.56\\(\\pm\\)0.0077 & 34.92\\(\\pm\\)0.0077 & 42.02\\(\\pm\\)0.0112 & 60.27\\(\\pm\\)0.0111 \\\\ & TANR-DLLM & 49.95\\(\\pm\\)0.0013 & 25.32\\(\\pm\\)0.0143 & 22.81\\(\\pm\\)0.0148 & 29.17\\(\\pm\\)0.0152 & 34.16\\(\\pm\\)0.0222 & 52.61\\(\\pm\\)0.0229 \\\\ & NRMS-DLLM & 50\\(\\pm\\)0 & 20.77\\(\\pm\\)0.0228 & 18.37\\(\\pm\\)0.0231 & 24.83\\(\\pm\\)0.0218 & 28.71\\(\\pm\\)0.0327 & 47.63\\(\\pm\\)0.0273 \\\\ & NAML-DLLM & 52.59\\(\\pm\\)0.0189 & 30.13\\(\\pm\\)0.0128 & 28.42\\(\\pm\\)0.0123 & 34.95\\(\\pm\\)0.012 & 41.89\\(\\pm\\)0.0147 & 60.61\\(\\pm\\)0.0146 \\\\ & MINER & 51.08\\(\\pm\\)0.0062 & 24.9\\(\\pm\\)0.0039 & 22.6\\(\\pm\\)0.0062 & 28.85\\(\\pm\\)0.0054 & 34.44\\(\\pm\\)0.0083 & 52.58\\(\\pm\\)0.0053 \\\\ & MANNeR & **68.44\\(\\pm\\)0.0088** & **37.3\\(\\pm\\)0.017** & **35.67\\(\\pm\\)0.0163** & **41.79\\(\\pm\\)0.0142** & 49.96\\(\\pm\\)0.0134 & 67.4\\(\\pm\\)0.0069 \\\\ & LKPNR & 67.32\\(\\pm\\)0.0004 & 31.99\\(\\pm\\)0.0003 & 35.46\\(\\pm\\)0.0005 & 41.77\\(\\pm\\)0.0002 & **50.27\\(\\pm\\)0.001** & **68.21\\(\\pm\\)0.0004** \\\\ & ONCE & 65.06\\(\\pm\\)0.0031 & 32.76\\(\\pm\\)0.0046 & 34.00\\(\\pm\\)0.0054 & 40.17\\(\\pm\\)0.0049 & 48.37\\(\\pm\\)0.0054 & 65.9\\(\\pm\\)0.0046 \\\\ \\hline & NPA & 52.72\\(\\pm\\)0.0366 & 32.94\\(\\pm\\)0.0223 & 32.51\\(\\pm\\)0.0303 & 38.77\\(\\pm\\)0.0387 & 45.93\\(\\pm\\)0.0539 & 65.43\\(\\pm\\)0.0879 \\\\ & LSTUR & 68.37\\(\\pm\\)0.0104 & **36.85\\(\\pm\\)0.0194** & **37.68\\(\\pm\\)0.029** & **44.85\\(\\pm\\)0.0241** & **54.23\\(\\pm\\)0.0462** & 76.39\\(\\pm\\)0.0439 \\\\ & TANR & 50.22\\(\\pm\\)0.0028 & 33.99\\(\\pm\\)0.0222 & 33.71\\(\\pm\\)0.0323 & 41.5\\(\\pm\\)0.0256 & 48.4\\(\\pm\\)0.0492 & 72.65\\(\\pm\\)0.0278 \\\\ & NRMS & 64.54\\(\\pm\\)0.0259 & 30.35\\(\\pm\\)0.0207 & 28.63\\(\\pm\\)0.0285 & 38.85\\(\\pm\\)0.0342 & 42.09\\(\\pm\\)0.0444 & 73.78\\(\\pm\\)0.0897 \\\\ & NAML & 50\\(\\pm\\)0 & 35.52\\(\\pm\\)0.016 & 35.15\\(\\pm\\)0.0227 & 42.42\\(\\pm\\)0.0213 & 48.99\\(\\pm\\)0.0378 & 71.71\\(\\pm\\)0.0499 \\\\ & CenNewsRec & 64.77\\(\\pm\\)0.0295 & 29.63\\(\\pm\\)0.021 & 26.97\\(\\pm\\)0.0305 & 36.74\\(\\pm\\)0.0347 & 38.04\\(\\pm\\)0.0533 & 68.62\\(\\pm\\)0.0773 \\\\ & CAUM & **72.33\\(\\pm\\)0.0475** & 35.68\\(\\pm\\)0.0327 & 36.04\\(\\pm\\)0.0443 & 44.42\\(\\pm\\)0.0473 & 52.48\\(\\pm\\)0.0723 & **78.5\\(\\pm\\)0.0778** \\\\ & MINS & 68.68\\(\\pm\\)0.0486 & 33.49\\(\\pm\\)0.039 & 32.13\\(\\pm\\)0.0514 & 40.84\\(\\pm\\)0.0489 & 45terms of diversity, achieving an average 7% improvement over SentiRec. Table VI indicates that LLM-based news recommendation models outperform deep learning-based news recommendation models on the Adressa dataset, with improvements up to 6%. These results verify the superiority of LLM-based news recommendation models in enhancing the diversity and personalization of news recommendations. However, deep learning-based news recommendation model like LSTUR exhibits better personalization on the MIND dataset, as indicated by \\(categ\\_pers@k\\). In contrast, deep learning-based news recommendation models, such as SentiRec and MINS, present a better diversity of news recommendations on the Adressa dataset, as illustrated in Table VI. In summary, the experimental results on the two datasets are complex, and LLM-based news recommendation models do not necessarily outperform deep learning-based methods, while deep learning-based methods still benefit news recommendation systems in terms of diversity and personalization."
    },
    {
      "title": "V-B3 Reply To Q3: Dllm-Empowered News Recommendation Models Vs. Original News Recommendation Models",
      "text": "There are four DLLM-empowered news recommendation models such as LSTUR-DLLM, TANR-DLLM, NRMS-DLLM, and NAML-DLLM in Table IV. We can observe that DLLM-empowered news recommendation models do not perform superior to the original models on both datasets. This may be because DLLMs are not effectively trained on a small-scale dataset. It is worth noting that a previous study [15] has demonstrated significant improvements in DLLM-empowered news recommendation models over original models on a large-scale dataset. In addition, we make an interesting observation: DLLM-empowered news recommendation models show apparent improvements in Precision on the Adressa dataset as illustrated in Figure 4. We assume that DLLM-empowered news recommendation models, such as NAML-DLLM and LSTUR-DLLM, can better capture semantic information from news titles due to the Adressa dataset's emphasis on shallow semantic features, such as titles and keywords. In addition, we analyze the performance in terms of diversity and personalization as shown in Table V and Table VI. We find that most results of DLLM-based news recommendation models illustrate suboptimal performance. In contrast, NRMS-DLLM achieves the best performance in terms of \\(categ\\_div@k\\) on the MIND dataset, while NAML-DLLM demonstrates significant improvements in terms of \\(categ\\_pers@k\\). In summary, the improvements of DLLM-empowered news recommendation models are limited by specific factors, such as dataset scale, while deep learning-based news recommendation models continue to offer benefits for news recommendation."
    },
    {
      "title": "V-B4 Reply To Q4: Dllm-Based News Recommendation Models Vs. Gllm-Based News Recommendation Models",
      "text": "As shown in Table IV, LKPNR exhibits lower performance than MANNeR but still achieves competitive results compared with other baselines. It is evident that using GLLM-based approaches is not necessarily effective compared with DLLM-based news recommendation models. Due to the limitation of time and computing resources, we haven't conducted additional experiments on other datasets and metrics. In the future, we will enrich our experiments and explore more GLLM-based news recommendation models in terms of different metrics."
    },
    {
      "title": "Vi Future Directions",
      "text": "LLM-based news recommendation has already achieved state-of-the-art performance over the past time. However, there are some challenges to be Fig. 3: The Hit Rate on the MIND and Adressa dataset. \\begin{table} \\begin{tabular}{c|c c c c c c c c} \\hline \\hline \\multirow{2}{*}{Model} & \\multicolumn{8}{c}{Metric} \\\\ \\cline{2-10} & categ\\_div@5 & categ\\_div@10 & categ\\_pers@5 & categ\\_pers@10 & sent\\_div@5 & sent\\_div@10 & sent\\_pers@5 & sent\\_pers@10 \\\\ \\hline NPA & 37.05\\(\\pm\\)0.0075 & 51.09\\(\\pm\\)0.0073 & 16.96\\(\\pm\\)0.0019 & 22.69\\(\\pm\\)0.0019 & 56.67\\(\\pm\\)0.017 & 67.33\\(\\pm\\)0.0083 & 25.56\\(\\pm\\)0.0017 & 34.7\\(\\pm\\)0.0024 \\\\ LSTUR & 29.91\\(\\pm\\)0.0089 & 43.45\\(\\pm\\)0.009 & **20.28\\(\\pm\\)0.0056** & **25.69\\(\\pm\\)0.0043** & 56.28\\(\\pm\\)0.0179 & 66.13\\(\\pm\\)0.0087 & 26.25\\(\\pm\\)0.0024 & 35.11\\(\\pm\\)0.0021 \\\\ TANR & 35.08\\(\\pm\\)0.006 & 49.13\\(\\pm\\)0.0041 & 18.83\\(\\pm\\)0.0025 & 24.2\\(\\pm\\)0.0022 & 58.19\\(\\pm\\)0.0051 & 67.21\\(\\pm\\)0.0019 & 26.11\\(\\pm\\)0.0018 & 35.05\\(\\pm\\)0.0023 \\\\ NRMS & 36.57\\(\\pm\\)0.0093 & 50.97\\(\\pm\\)0.0051 & 15.15\\(\\pm\\)0.0061 & 21.34\\(\\pm\\)0.0071 & 59.44\\(\\pm\\)0.0158 & 67.2\\(\\pm\\)0.0062 & 26.07\\(\\pm\\)0.0019 & 34.97\\(\\pm\\)0.0008 \\\\ NAML & 32.74\\(\\pm\\)0.0046 & 47.4\\(\\pm\\)0.0046 & 20.06\\(\\pm\\)0.0027 & 25.09\\(\\pm\\)0.0026 & 56.93\\(\\pm\\)0.0066 & 66.77\\(\\pm\\)0.0041 & 25.92\\(\\pm\\)0.003 & 34.99\\(\\pm\\)0.0023 \\\\ CenNewsRec & 36.24\\(\\pm\\)0.008 & 51.04\\(\\pm\\)0.0034 & 14.74\\(\\pm\\)0.003 & 20.73\\(\\pm\\)0.0021 & 59.07\\(\\pm\\)0.0227 & 67.02\\(\\pm\\)0.0085 & 25.92\\(\\pm\\)0.005 & 35.0\\(\\pm\\)0.002 \\\\ CAUM & 33.67\\(\\pm\\)0.0073 & 47.17\\(\\pm\\)0.0026 & 19.28\\(\\pm\\)0.0032 & 25.21\\(\\pm\\)0.0033 & 57.78\\(\\pm\\)0.0125 & 66.56\\(\\pm\\)0.0077 & 26.21\\(\\pm\\)0.0022 & 35.2\\(\\pm\\)0.0011 \\\\ MINS & 32.79\\(\\pm\\)0.0036 & 46.56\\(\\pm\\)0.0055 & 19.37\\(\\pm\\)0.0065 & 24.99\\(\\pm\\)0.0055 & 56.96\\(\\pm\\)0.0111 & 66.11\\(\\pm\\)0.0075 & 26.22\\(\\pm\\)0.0025 & **35.16\\(\\pm\\)0.002** \\\\ SentiDebias & 41.11\\(\\pm\\)0.0082 & 53.58\\(\\pm\\)0.0059 & 14.69\\(\\pm\\)0.0059 & 20.97\\(\\pm\\)0.004 & 57.21\\(\\pm\\)0.0295 & 66.77\\(\\pm\\)0.016 & 26.29\\(\\pm\\)0.0053 & 35.01\\(\\pm\\)0.0034 \\\\ SentiRec & 37.49\\(\\pm\\)0.0237 & 52.02\\(\\pm\\)0.0146 & 15.08\\(\\pm\\)0.0079 & 21.16\\(\\pm\\)0.0074 & **60.68\\(\\pm\\)0.015** & 68.46\\(\\pm\\)0.0074 & 25.31\\(\\pm\\)0.0041 & 34.6\\(\\pm\\)0.0036 \\\\ LSTUR-DLLM & 24.68\\(\\pm\\)0.0232 & 38.19\\(\\pm\\)0.0174 & 18.88\\(\\pm\\)0.0074 & 24.06\\(\\pm\\)0.0064 & 58.23\\(\\pm\\)0.0298 & 66.97\\(\\pm\\)0.017 & 25.72\\(\\pm\\)0.0025 & 34.53\\(\\pm\\)0.0021 \\\\ TANR-DLLM & 40.17\\(\\pm\\)0.0177 & 52.09\\(\\pm\\)0.0167 & 14.03\\(\\pm\\)0.0135 & 19.7\\(\\pm\\)0.0165 & 56.46\\(\\pm\\)0.0231 & 66.03\\(\\pm\\)0.0161 & 25.13\\(\\pm\\)0.01 & 33.79\\(\\pm\\)0.010 \\\\ NRMS-DLLM & **44.03\\(\\pm\\)0.0092** & **54.99\\(\\pm\\)0.0042** & 14.49\\(\\pm\\)0.0042 & 20.62\\(\\pm\\)0.0037 & 59.44\\(\\pm\\)0.0158 & 67.2\\(\\pm\\)0.0062 & 26.07\\(\\pm\\)0.0019 & 34.97\\(\\pm\\)0.0008 \\\\ NAML-DLLM & 25.87\\(\\pm\\)0.0268 & 39.38\\(\\pm\\)0.022 & **20.46\\(\\pm\\)0.0079** & 25.07\\(\\pm\\)0.0078 & 57.28\\(\\pm\\)0.0149 & 66.48\\(\\pm\\)0.0084 & 26.09\\(\\pm\\)0.0039 & 34.89\\(\\pm\\)0.0038 \\\\ MINER & 42.94\\(\\pm\\)0.0017 & 54.75\\(\\pm\\)0.0011 & 15.11\\(\\pm\\)0.0025 & 21.24\\(\\pm\\)0.0024 & 60.58\\(\\pm\\)0.0022 & **68.71\\(\\pm\\)0.001** & 25.4\\(\\pm\\)0.0018 & 34.29\\(\\pm\\)0.0017 \\\\ MANNeR & 33.95\\(\\pm\\)0.0147 & 48.06\\(\\pm\\)0.01 & 19.4\\(\\pm\\)0.0048 & 24.63\\(\\pm\\)0.0047 & 51.09\\(\\pm\\)0.0276 & 63.99\\(\\pm\\)0.0168 & **26.32\\(\\pm\\)0.0018** & 35.1\\(\\pm\\)0.0005 \\\\ \\hline \\hline \\end{tabular} \\end{table} TABLE V: Comparison of different news recommendation models in terms of personalization and diversity on MIND. Through analyzing these results, we can have a conclusion that LLM-based approaches enhance the performance of news recommendation models in terms of diversity and personalization. The reported values represent the mean and standard deviation derived from five distinct experimental runs. Bold indicates the best experimental results. Underline means the second-best experimental results. Fig. 4: The Precision on the MIND and Adressa dataset. [MISSING_PAGE_FAIL:15] to explore accurate and overall user interests. This is because users' preferences are complex and dynamic in the real-world scenario. There are three future directions to improve deep user modeling for LLM-based news recommendation. Firstly, a unified user modeling framework is required in LLM-based news recommender systems. Most research has explored various types of user preferences such as long- and short-term user interests [7], intentions [12], and multiple interests [8]. However, there is no unified user modeling framework that supports the representation of various user preferences. Second, LLM-based news recommender systems are required to understand dynamic user preferences. This is because user preferences commonly evolve over time. For example, breaking news can quickly shift users' interests during that period."
    },
    {
      "title": "Vi-B4 Effective Prediction Method",
      "text": "Prediction is a crucial component of news recommender systems, as it determines the outputs of the entire system. It is common for most research [1, 6, 8, 23, 53, 54, 57] to apply MLP and dot-product calculating results in news recommender systems. As far as we are concerned, two future directions are discussed as follows. Firstly, prediction with contrastive learning enables to enhance performance of news recommender systems. This is because contrastive learning excels at maximizing similarity between positive samples while minimizing similarity between negative samples. Second, prediction with casual inference promotes the interpretability and robustness of news recommender systems. Due to the black-box nature of deep learning-based methods, the outputs of news recommender systems lack explainability. Therefore, improving the explainability of predictions has become a crucial direction for future research."
    },
    {
      "title": "Vi-B5 Efficient Training Strategy",
      "text": "LLM-based news recommender systems require a large training time to obtain the best performance. Hence, it is necessary to develop efficient training methods reducing time and resource consumption. There are two future directions to promote training methods. First of all, training with knowledge distillation is required in LLM-based news recommender systems. This is because knowledge distillation helps extract essential information, thereby reducing time and resource consumption. Second, training with meta-learning can achieve better performance using less data. Meanwhile, applying meta-learning could help alleviate the cold-start problem in news recommender systems."
    },
    {
      "title": "Vi-B6 Trustworthy Llm-Based News Recommender System",
      "text": "Building trustworthy news recommender systems is a crucial future direction, encompassing aspects such as modeling fairness, reducing bias, improving explainability, and ensuring privacy preservation in news recommender systems. It is essential to develop trustworthy news recommender systems due to the incredible outputs of large language models and deep learning-based methods. Additionally, trustworthy news recommender systems enable to enhance users' experience. For example, most users prefer to know reasons why systems recommend interesting news articles to them. Providing explainability can enhance trust in news recommender systems."
    },
    {
      "title": "Vi-B7 Social-Driven Llm-Based News Recommender System",
      "text": "Social-driven news recommender systems can be developed by implementing LLMs. This is because LLMs can explore related content on the Internet and then learn users' preferences based on real-world relations. For example, if Tom, who likes the NBA, is shown as Jerry's friend on Facebook, we can infer that Jerry may also like the NBA based on their related online activities. Therefore, leveraging social relationships on the Internet can help systems extract users' latent preferences and build more accurate user profiles."
    },
    {
      "title": "Vii Conclusion",
      "text": "News recommendation is a crucial technology that benefits both individuals and society. A large amount of previous research demonstrates the superiority of deep learning-based news recommender systems compared to statistical machine learning-based methods. With the advancement of large language model technology, news recommendation faces great opportunities and challenges. In order to assist researchers in studying better this field and guide new researchers in the correct direction, we systematically and comprehensively review LLM-based news recommender systems including methodologies, challenges, and future directions. Moreover, we propose a unified research framework to review different research. Notably, it is the first survey to conduct extensive experiments in terms of deep-learning- and LLM-based news recommendation models. Through this survey, we not only illustrate the superiority of LLM-based news recommender systems but also present the effectiveness of deep learning-based news recommender systems. In the future, we will evaluate the diversity and personalization of LLM-based news recommendation models and review more LLM-based news recommendation models."
    },
    {
      "title": "Acknowledgments",
      "text": "This should be a simple paragraph before the References to thank those individuals and institutions who have supported your work on this article."
    },
    {
      "title": "References",
      "text": "* [1] C. Wu, F. Wu, M. An, J. Huang, Y. Huang, and X. Xie, \"NPA: Neural news recommendation with personalized attention,\" in _KDD_, 2019, pp. 2576-2584. * [2] G. Zheng, F. Zhang, Z. Zheng, Y. Xiang, N. J. Yuan, X. Xie, and Z. Li, \"Drn: A deep reinforcement learning framework for news recommendation,\" in _Proceedings of the 2018 world wide web conference_, 2018, pp. 167-176. * [3] C. Wu, F. Wu, Y. Huang, and X. Xie, \"Personalized news recommendation: Methods and challenges,\" _ACM Transactions on Information Systems_, vol. 41, no. 1, pp. 1-50, 2023. * [4] H. Wang, F. Zhang, X. Xie, and M. Guo, \"DKN: Deep knowledge-aware network for news recommendation,\" in _WWW_, 2018, pp. 1835-1844. * [5] H. Wang, F. Wu, Z. Liu, and X. Xie, \"Fine-grained interest matching for neural news recommendation,\" in _ACL_, 2020, pp. 836-845. * [6] C. Wu, F. Wu, M. An, Y. Huang, and X. Xie, \"Neural news recommendation with topic-aware news representation,\" in _ACL_, 2019, pp. 1154-1159. * [7] M. An, F. Wu, C. Wu, K. Zhang, Z. Liu, and X. Xie, \"Neural news recommendation with long-and short-term user representations,\" in _ACL_, 2019, pp. 336-345. * [8] R. Wang, S. Wang, W. Lu, and X. Peng, \"News recommendation via multi-interest news sequence modelling,\" in _ICASSP_, 2022, pp. 7942-7946. * [9] L. Hu, C. Li, C. Shi, C. Yang, and C. Shao, \"Graph neural news recommendation with long-term and short-term interest modeling,\" _Information Processing & Management_, vol. 57, no. 2, p. 102142, 2020. * [10] Z. Mao, X. Zeng, and K.-F. Wong, \"Neural news recommendation with collaborative news encoding and structural user encoding,\" in _EMNLP_, 2021, pp. 46-55. * [11] Z. Qiu, Y. Hu, and X. Wu, \"Graph neural news recommendation with user existing and potential interest modeling,\" _ACM Transactions on Knowledge Discovery from Data_, vol. 16, no. 5, pp. 1-17, 2022. * [12] R. Wang, S. Wang, W. Lu, X. Peng, W. Zhang, C. Zheng, and X. Qiao, \"Intention-aware user modeling for personalized news recommendation,\" in _International Conference on Database Systems for Advanced Applications_. Springer, 2023, pp. 179-194. * [13] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,. Kaiser, and I. Polosukhin, \"Attention is all you need,\" in _NeurIPS_, 2017, pp. 6000-6010. * [14] C. Wu, F. Wu, T. Qi, Y. Huang, and X. Xie, \"Fastformer: Additive attention can be all you need,\" _arXiv preprint arXiv:2108.09084_, 2021. * [15] C. Wu, F. Wu, T. Qi, and Y. Huang, \"Empowering news recommendation with pre-trained language models,\" in _SIGIR_, 2021, pp. 1652-1656. * [16] Q. Liu, J. Hu, Y. Xiao, X. Zhao, J. Gao, W. Wang, Q. Li, and J. Tang, \"Multimodal recommender systems: A survey,\" _ACM Comput. Surv._, vol. 57, no. 2, Oct. 2024. [Online]. Available: [https://doi.org/10.1145/3695461](https://doi.org/10.1145/3695461) * [17] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, \"Bert: Pre-training of deep bidirectional transformers for language understanding,\" in _Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)_, 2019, pp. 4171-4186. * [18] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Csistac, T. Rault, R. Louf, M. Funtowicz _et al._, \"Transformers: State-of-the-art natural language processing,\" in _Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations_, 2020, pp. 38-45. * [19] L. Wu, Z. Zheng, Z. Qiu, H. Wang, H. Gu, T. Shen, C. Qin, C. Zhu, H. Zhu, Q. Liu _et al._, \"A survey on large language models for recommendation,\" _World Wide Web_, vol. 27, no. 5, p. 60, 2024. * [20] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, \"Roberta: A robustly optimized bert pretraining approach,\" _arXiv preprint arXiv:1907.11692_, 2019. * [21] M. Lewis, \"Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension,\" _arXiv preprint arXiv:1910.13461_, 2019. * [22] Q. Bi, J. Li, L. Shang, X. Jiang, Q. Liu, and H. Yang, \"Mrtec: Multi-task learning over bert for news recommendation,\" in _Findings of the Association for Computational Linguistics: ACL 2022_, 2022, pp. 2663-2669. * [23] J. Li, J. Zhu, Q. Bi, G. Cai, L. Shang, Z. Dong, X. Jiang, and Q. Liu, \"MINER: Multi-interest matching network for news recommendation,\" in _ACL_, 2022, pp. 343-352. * [24] Z. Mao, H. Wang, Y. Du, and K.-F. Wong, \"Unitrec: A unified text-to-text transformer and joint contrastive learning framework for text-based recommendation,\" in _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)_, 2023, pp. 1160-1170. * [25] Q. Zhang, Q. Jia, C. Wang, J. Li, Z. Wang, and X. He, \"Amm: Attentive multi-field matching for news recommendation,\" in _Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval_, 2021, pp. 1588-1592. * [26] C. Wu, F. Wu, Y. Yu, T. Qi, Y. Huang, and Q. Liu, \"News-bert: Distilling pre-trained language model for intelligent news application,\" _arXiv preprint arXiv:2102.04887_, 2021. * [27] Q. Zhang, J. Li, Q. Jia, C. Wang, J. Zhu, Z. Wang, and X. He, \"UhpcNet: User-news matching bert for news recommendation.\" in _IJCAI_, vol. 21, 2021, pp. 3356-3362. * [28] S. Gao, J. Fang, Q. Tu, Z. Yao, Z. Chen, P. Ren, and Z. Ren, \"Generative news recommendation,\" in _Proceedings of the ACM on Web Conference 2024_, 2024, pp. 3444-3453. * [29] Q. Ruan, J. Xu, S. Leavy, B. Mac Name, and R. Dong, \"Rewriting bias: Mitigating media bias in news recommender systems through automated rewriting,\" in _Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization_, 2024, pp. 67-77. * [30] H. Chen, R. Xie, X. Cui, Z. Yan, X. Wang, Z. Xuan, and K. Zhang, \"Lkpnr: Large language models and knowledge graph for personalized news recommendation framework.\" _Computers, Materials & Continua_, vol. 79, no. 3, 2024. * [31] X. Meng, H. Huo, X. Zhang, W. Wang, and J. Zhu, \"A survey of personalized news recommendation,\" _Data Science and Engineering_, vol. 8, no. 4, pp. 396-416, 2023. * [32] A. Iana, M. Alam, and H. Paulheim, \"A survey on knowledge-aware news recommender systems,\" _Semantic Web_, no. Preprint, pp. 1-62, 2024. * [33] Q. Zhu, X. Zhou, Z. Song, J. Tan, and L. Guo, \"Dan: Deep attention neural network for news recommendation,\" in _Proceedings of the AAAI conference on artificial intelligence_, vol. 33, no. 01, 2019, pp. 5973-5980. * [34] S. Shi, W. Ma, Z. Wang, M. Zhang, K. Fang, J. Xu, Y. Liu, and S. Ma, \"Wg4rec: Modeling textual content with word graph for news recommendation,\" in _Proceedings of the 30th ACM International Conference on Information & Knowledge Management_, 2021, pp. 1651-1660. * [35] D. Khattar, V. Kumar, V. Varma, and M. Gupta, \"Hram: A hybrid recurrent attention machine for news recommendation,\" in _Proceedings of the 27th ACM international conference on information and knowledge management_, 2018, pp. 1619-1622. * [36] G. Hu and Q. Yang, \"Trees: Heterogeneous user-interest transfer learning for news recommendation,\" in _Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume_, 2021, pp. 734-744. * [37] S. Okura, Y. Tagami, S. Ono, and A. Tajima, \"Embedding-based news recommendation for millions of users,\" in _KDD_, 2017, pp. 1933-1942. * [38] Y. Pang, Y. Zhang, J. Tong, and Z. Wei, \"Time-aware attentive neural network for news recommendation with long-and short-term user representation,\" in _Knowledge Science, Engineering and Management: 13th International Conference, KSEM 2020, Hangzhou, China, August 28-30, 2020, Proceedings, Part II 13_. Springer, 2020, pp. 76-87. * [39] D. Lee, B. Oh, S. Seo, and K.-H. Lee, \"News recommendation with topic-enriched knowledge graphs,\" in _Proceedings of the 29th ACM international conference on information & knowledge management_, 2020, pp. 695-704. * [40] D. Khattar, V. Kumar, V. Varma, and M. Gupta, \"Weave&rec: A word embedding based 3-d convolutional network for news recommendation,\" in _Proceedings of the 27th ACM international conference on information and knowledge management_, 2018, pp. 1855-1858. * [41] K. Park, J. Lee, and J. Choi, \"Deep neural networks for news recommendations,\" in _Proceedings of the 2017 ACM on Conference on Information and Knowledge Management_, 2017, pp. 2255-2258. * [42] G. de Souza Pereira Moreira, \"Chameleon: a deep learning meta-architecture for news recommender systems,\" in _Proceedings of the 12th ACM Conference on Recommender Systems_, 2018, pp. 578-583. * [43] C. Wu, F. Wu, S. Ge, T. Qi, Y. Huang, and X. Xie, \"Neural news recommendation with multi-head self-attention,\" in _EMNLP_, 2019, pp. 6390-6395. * [44] L. Zhang, P. Liu, and J. A. Gulla, \"Dynamic attention-integrated neural network for session-based news recommendation,\" _Machine Learning_, vol. 108, pp. 1851-1875, 2019. * [45] H. Zhang, X. Chen, and S. Ma, \"Dynamic news recommendation with hierarchical attention network,\" in _2019 IEEE International Conference on Data Mining (ICDM)_. IEEE, 2019, pp. 1456-1461. * [46] P. Zhu, D. Cheng, S. Luo, F. Yang, Y. Luo, W. Qian, and A. Zhou, \"Si-news: Integrating social information for news recommendation with attention-based graph convolutional network,\" _Neurocomputing_, vol. 494, pp. 33-42, 2022. * [47] S. Ge, C. Wu, F. Wu, T. Qi, and Y. Huang, \"Graph enhanced representation learning for news recommendation,\" in _Proceedings of the web conference 2020_, 2020, pp. 2863-2869. * [48] Y. Tian, Y. Yang, X. Ren, P. Wang, F. Wu, Q. Wang, and C. Li, \"Joint knowledge pruning and recurrent graph convolution for news recommendation,\" in _Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval_, 2021, pp. 51-60. * [49] D. Liu, J. Lian, Z. Liu, X. Wang, G. Sun, and X. Xie, \"Reinforced anchor knowledge graph generation for news recommendation reasoning,\" in _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_, 2021, pp. 1055-1065. * [50] D. Liu, J. Lian, S. Wang, Y. Qiao, J.-H. Chen, G. Sun, and X. Xie, \"Kred: Knowledge-aware document representation for news recommendations,\" in _Proceedings of the 14th ACM conference on recommender systems_, 2020, pp. 200-209. * [51] H.-S. Shen, Z. Chu, D. Qi, and S. Li, \"Knowledge-guided article embedding refinement for session-based news recommendation,\" _IEEE Transactions on Neural Networks and Learning Systems_, vol. 33, no. 12, pp. 7921-7927, 2021. * [52] C. Wu, F. Wu, M. An, J. Huang, and Y. Huang, \"Neural news recommendation with attentive multi-view learning,\" in _IJCAI_, 2019, pp. 3863-3869. * [53] W. Lu, R. Wang, S. Wang, X. Peng, H. Wu, and Q. Zhang, \"Aspect-driven user preference and news representation learning for news recommendation,\" _IEEE Transactions on Intelligent Transportation Systems_, vol. 23, no. 12, pp. 25 297-25 307, 2022. * [54] Z. Liu, Y. Xing, F. Wu, M. An, and X. Xie, \"Hi-fi ark: Deep user representation via high-fidelity archive network.\" in _IJCAI_, 2019, pp. 3059-3065. * [55] C. Wu, F. Wu, M. An, T. Qi, J. Huang, Y. Huang, and X. Xie, \"Neural news recommendation with heterogeneous user behavior,\" in _Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCSLP)_, 2019, pp. 4874-4883. * [56] J. Lian, F. Zhang, X. Xie, and G. Sun, \"Towards better representation learning for personalized news recommendation: A multi-channel deep fusion approach,\" in _IJCAI_, 2018, pp. 3805-3811. * [57] T. Qi, F. Wu, C. Wu, P. Yang, Y. Yu, X. Xie, and Y. Huang, \"HieRec: Hierarchical user interest modeling for personalized news recommendation,\" in _ACL_, 2021, pp. 5446-5456. * [58] T. Qi, F. Wu, C. Wu, and Y. Huang, \"Pp-rec: News recommendation with personalized user interest and time-aware news popularity,\" in _Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)_, 2021, pp. 5457-5467. * [59] ----, \"News recommendation with candidate-aware user modeling,\" in _SIGIR_, 2022, p. 1917-1921. * [60] J. Wang, Y. Chen, Z. Wang, and W. Zhao, \"Popularity-enhanced news recommendation with multi-view interest representation,\" in _CIKM_, 2021, pp. 1949-1958. * [61] S. Wang, L. Hu, Y. Wang, Q. Z. Sheng, M. Orgun, and L. Cao, \"Intention nets: Psychology-inspired user choice behavior modeling for next-basket prediction,\" in _AAAI_, 2020, pp. 6259-6266. * [62] C. Wu, F. Wu, T. Qi, and Y. Huang, \"Sentirec: Sentiment diversity-aware neural news recommendation,\" in _Proceedings of the 1st conference of the Asia-Pacific Chapter of the association for computational linguistics and the 10th international joint conference on natural language processing_, 2020, pp. 44-53. * [63] C. Wu, F. Wu, T. Qi, W.-Q. Zhang, X. Xie, and Y. Huang, \"Removing as sentiment manipulation of personalized news delivery,\" _Huanities and Social Sciences Communications_, vol. 9, no. 1, pp. 1-9, 2022. * [64] C. Wu, F. Wu, X. Wang, Y. Huang, and X. Xie, \"Fairness-aware news recommendation with decomposed adversarial learning,\" in _Proceedings of the AAAI conference on artificial intelligence_, vol. 35, no. 5, 2021, pp. 4462-4469. * [65] S. Wang, W. Wang, X. Zhang, Y. Wang, H. Liu, and F. Chen, \"A hierarchical and disentangling interest learning framework for unbiased and true news recommendation,\" in _Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, 2024, pp. 3200-3211. * [66] T. Qi, F. Wu, C. Wu, Y. Huang, and X. Xie, \"Privacy-preserving news recommendation model learning,\" _arXiv preprint arXiv:2003.09592_, 2020. * [67] J. Yi, F. Wu, C. Wu, R. Liu, G. Sun, and X. Xie, \"Efficient-fedrec: Efficient federated learning framework for privacy-preserving news recommendation,\" in _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, 2021, pp. 2814-2824. * [68] C. Wu, F. Wu, T. Qi, and Y. Huang, \"User modeling with click preference and reading satisfaction for news recommendation.\" in _IJCAI_, 2020, pp. 3023-3029. * [69] Z. Huang, B. Jin, H. Zhao, Q. Liu, D. Lian, B. Tengfei, and E. Chen, \"Personal or general? a hybrid strategy with multi-factors for news recommendation,\" _ACM Transactions on Information Systems_, vol. 41, no. 2, pp. 1-29, 2023. * [70] A. Iana, G. Glavas, and H. Paulheim, \"Train once, use flexibly: A modular framework for multi-aspect neural news recommendation,\" _arXiv preprint arXiv:2307.16089_, 2023. * [71] ----, \"Newsreclib: A pytorch-lighting library for neural news recommendation,\" _arXiv preprint arXiv:2310.01146_, 2023. * [72] Y. Yada and H. Yamana, \"News recommendation with category description by a large language model,\" _arXiv preprint arXiv:2405.13007_, 2024. * [73] Q. Liu, N. Chen, T. Sakai, and X.-M. Wu, \"Once: Boosting content-based recommendation with both open-and closed-source large language models,\" in _Proceedings of the 17th ACM International Conference on Web Search and Data Mining_, 2024, pp. 452-461. * [74] Z. Liu, Z. Chen, M. Zhang, S. Duan, H. Wen, L. Li, N. Li, Y. Gu, and G. Yu, \"Modeling user viewing flow using large language models for article recommendation,\" in _Companion Proceedings of the ACM on Web Conference 2024_, 2024, pp. 83-92. * [75] Y. Yu, F. Wu, C. Wu, J. Yi, and Q. Liu, \"Tiny-newsrec: Effective and efficient plm-based news recommendation,\" in _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, 2022, pp. 5478-5489. * [76] S. Xiao, Z. Liu, Y. Shao, T. Di, B. Middha, F. Wu, and X. Xie, \"Training large-scale news recommenders with pretrained language models in the loop,\" in _Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, 2022, pp. 4215-4225. * [77] D. Liu, B. Yang, H. Du, D. Greene, A. Lawlor, R. Dong, and I. Li, \"Recprompt: A prompt tuning framework for news recommendation using large language models,\" _arXiv preprint arXiv:2312.10463_, 2023. * [78] S. Wang, L. Wang, Y. Bu, and T. Huang, \"Cherryrec: Enhancing news recommendation quality via llm-driven framework,\" _arXiv preprint arXiv:2406.12243_, 2024. * [79] M. Jugowicz, D. Jannach, and M. Karimi, \"Streamingrec: a framework for benchmarking stream-based news recommenders,\" in _Proceedings of the 12th ACM conference on recommender systems_, 2018, pp. 269-273. * [80] B. Koo, H. Jeon, and U. Kang, \"Accurate news recommendation coalescing personal and global temporal preferences,\" in _Advances in Knowledge Discovery and Data Mining: 24th Pacific-Asia Conference, PAKDD 2020, Singapore, May 11-14, 2020, Proceedings, Part I 24_. Springer, 2020, pp. 78-90. * [81] Q. Zhao, X. Chen, H. Zhang, and X. Li, \"Dynamic hierarchical attention network for news recommendation,\" _Expert Systems with Applications_, vol. 255, p. 124667, 2024. * [82] A. Gharahighchi, C. Vens, and K. Pliakos, \"Fair multi-stakeholder news recommender system with hypergraph ranking,\" _Information Processing & Management_, vol. 58, no. 5, p. 102663, 2021. * [83] H.-K. Bae, J. Ahn, D. Lee, and S.-W. Kim, \"Lancer: A lifetime-aware news recommender system,\" in _Proceedings of the AAAI Conference on Artificial Intelligence_, vol. 37, no. 4, 2023, pp. 4141-4148. * [84] G. de Souza Pereira Moreira, F. Ferreira, and A. M. Da Cunha, \"News session-based recommendations using deep neural networks,\" in _Proceedings of the 3rd workshop on deep learning for recommender systems_, 2018, pp. 15-23. * [85] B. Kille, F. Hopfgartner, T. Brodt, and T. Heintz, \"The plista dataset,\" in _Proceedings of the 2013 international news recommender systems workshop and challenge_, 2013, pp. 16-23. * [86] J. A. Gulla, L. Zhang, P. Liu, O. Ozgobek, and X. Su, \"The adressa dataset for news recommendation,\" in _Proceedings of the international conference on web intelligence_, 2017, pp. 1042-1048. * [87] F. Wu, Y. Qiao, J.-H. Chen, T. Wu, Chuhan Qi, J. Lian, D. Liu, X. Xie, J. Gao, and W. Wu, \"MIDN: A large-scale dataset for news recommendation,\" in _ACL_, 2020, pp. 3597-3606. * [88] J. P. Lucas, J. F. G. da Silva, and L. F. de Figueiredo, \"Npr: a news portal recommendations dataset.\" in _NORMalize@ RecSys_, 2023. * [89] A. Iana, G. Glavas, and H. Paulheim, \"Mind your language: A multilingual dataset for cross-lingual news recommendation,\" in _Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval_, 2024, pp. 553-563. * [90] J. Kruse, K. Lindskow, S. Kalloori, M. Polignano, C. Pomo, A. Srivastava, A. Uppal, M. R. Andersen, and J. Frellsen, \"Eb-nerd a large-scale dataset for news recommendation,\" in _Proceedings of the Recommender Systems Challenge 2024_, 2024, pp. 1-11. * [91] C. Wu, F. Wu, T. Qi, C. Zhang, Y. Huang, and T. Xu, \"Mm-rec: Visiolinguistic model empowered multimodal news recommendation,\" in _Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval_, 2022, pp. 2560-2564. * [92] Q. Liu, L. Fan, and X.-M. Wu, \"Legcommenders: A comprehensive content-based recommendation library with llm support,\" _arXiv preprint arXiv:2412.15973_, 2024. * [93] S. Graham, J.-K. Min, and T. Wu, \"Microsoft recommenders: tools to accelerate developing recommender systems,\" in _Proceedings of the 13th ACM Conference on Recommender Systems_, 2019, pp. 542-543. * [94] W. X. Zhao, S. Mu, Y. Hou, Z. Lin, Y. Chen, X. Pan, K. Li, Y. Lu, H. Wang, C. Tian, Y. Min, Z. Feng, X. Fan, X. Chen, P. Wang, W. Ji, Y. Li, X. Wang, and J. Wen, \"Recbole: Towards a unified, comprehensive and efficient framework for recommendation algorithms,\" in _CIKM_. ACM, 2021, pp. 4653-4664. * [95] C. Zhang, Y. Sun, J. Chen, J. Lei, M. Abdul-Mageed, S. Wang, R. Jin, S. Park, N. Yao, and B. Long, \"Spar: Personalized content-based recommendation via long engagement attention,\" _arXiv preprint arXiv:2402.10555_, 2024. * [96] Q. Liu, J. Zhu, Q. Dai, and X.-M. Wu, \"Benchmarking news recommendation in the era of era i,\" in _Companion Proceedings of the ACM on Web Conference 2024_, 2024, pp. 971-974. * [97] Q. Liu, H. Hu, J. Wu, J. Zhu, M.-Y. Kan, and X.-M. Wu, \"Discrete semantic tokenization for deep ctr prediction,\" in _Companion Proceedings of the ACM on Web Conference 2024_, 2024, pp. 919-922. * [98] A. Ravichander, S. Ghela, D. Wadden, and Y. Choi, \"Halogen: Fantastic llm hallucinations and where to find them,\" _arXiv preprint arXiv:2501.08292_, 2025. * [99] X. Yin, C. Ni, X. Li, L. Chen, G. Ma, and X. Yang, \"Enhancing llm's ability to generate more repository-aware unit tests through precise contextual information injection,\" _arXiv preprint arXiv:2501.07425_, 2025. * [100] Z. Zhang and B. Wang, \"Prompt learning for news recommendation,\" in _Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval_, 2023, pp. 227-237. * [101] X. Li, Y. Zhang, and E. C. Malthouse, \"Prompt-based generative news recommendation (pgnr): Accuracy and controllability,\" in _European Conference on Information Retrieval_. Springer, 2024, pp. 66-79. * [102] Z. Wang, Y. Yu, W. Zheng, W. Ma, and M. Zhang, \"Multi-agent collaboration framework for recommender systems,\" _arXiv preprint arXiv:2402.15253_, 2024. * [103] L. Wang, J. Zhang, H. Yang, Z. Chen, J. Tang, Z. Zhang, X. Chen, Y. Lin, R. Song, W. X. Zhao _et al._, \"When large language model based agent meets user behavior analysis: A novel user simulation paradigm,\" _arXiv preprint arXiv:2306.02552_, 2023. * [104] S. Bag, S. K. Kumar, and M. K. Tiwari, \"An efficient recommendation generation using relevant jaccard similarity,\" _Information Sciences_, vol. 483, pp. 53-64, 2019."
    }
  ]
}
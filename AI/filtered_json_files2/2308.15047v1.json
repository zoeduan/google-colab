{
  "title": "Large language models converge toward human-like concept organization",
  "authors": [
    "Jonathan Gabel Christiansen",
    "Mathias Lykke Gammelgaard",
    "Anders Søgaard"
  ],
  "abstract": "\n Large language models show human-like performance in knowledge extraction, reasoning and dialogue, but it remains controversial whether this performance is best explained by memorization and pattern matching, or whether it reflects human-like inferential semantics and world knowledge. Knowledge bases such as WikiData provide large-scale, high-quality representations of inferential semantics and world knowledge. We show that large language models learn to organize concepts in ways that are strikingly similar to how concepts are organized in such knowledge bases. Knowledge bases model collective, institutional knowledge, and large language models seem to induce such knowledge from raw text. We show that bigger and better models exhibit more human-like concept organization, across four families of language models and three knowledge graph embeddings. * Equal contributions 2 One famous example of this view is an article by Emily Bender and colleagues  [1] , who argue that these models are simply stochastic parrots that 'haphazardly stitch together sequences of linguistic forms' without any true understanding of the world or context. Preprint. Under review. \n",
  "references": [
    {
      "id": null,
      "title": "Large language models converge toward human-like concept organization",
      "authors": [
        "Jonathan Gabel Christiansen",
        "Mathias Lykke Gammelgaard",
        "Anders Søgaard"
      ],
      "year": "2023",
      "venue": "",
      "doi": ""
    },
    {
      "id": "b0",
      "title": "Association for Computer Machinery -ACM",
      "authors": [
        "Emily M Bender",
        "Timnit Gebru",
        "Angelina Mcmillan-Major",
        "Shmargaret Shmitchell"
      ],
      "year": "2021",
      "venue": "Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency",
      "doi": "10.1145/3442188.3445922"
    },
    {
      "id": "b1",
      "title": "Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. Pythia: A suite for analyzing large language models across training and scaling",
      "authors": [
        "Stella Biderman",
        "Hailey Schoelkopf",
        "Quentin Anthony",
        "Herbie Bradley",
        "O' Kyle",
        "Eric Brien",
        "Mohammad Hallahan",
        "Shivanshu Aflah Khan",
        "Purohit",
        "Edward Usvsn Sai Prashanth",
        "Raff"
      ],
      "year": "2023",
      "venue": "Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. Pythia: A suite for analyzing large language models across training and scaling",
      "doi": ""
    },
    {
      "id": "b2",
      "title": "Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit",
      "authors": [
        "Steven Bird",
        "Ewan Klein",
        "Edward Loper"
      ],
      "year": "2009",
      "venue": "Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit",
      "doi": ""
    },
    {
      "id": "b3",
      "title": "Translating embeddings for modeling multi-relational data",
      "authors": [
        "Antoine Bordes",
        "Nicolas Usunier",
        "Alberto Garcia-Durán",
        "Jason Weston",
        "Oksana Yakhnenko"
      ],
      "year": "2013",
      "venue": "Proceedings of the 26th International Conference on Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b4",
      "title": "Language models are few-shot learners",
      "authors": [
        "Tom Brown",
        "Benjamin Mann",
        "Nick Ryder",
        "Melanie Subbiah",
        "Jared D Kaplan",
        "Prafulla Dhariwal",
        "Arvind Neelakantan",
        "Pranav Shyam",
        "Girish Sastry",
        "Amanda Askell",
        "Sandhini Agarwal",
        "Ariel Herbert-Voss",
        "Gretchen Krueger",
        "Tom Henighan",
        "Rewon Child",
        "Aditya Ramesh",
        "Daniel Ziegler",
        "Jeffrey Wu",
        "Clemens Winter",
        "Chris Hesse",
        "Mark Chen",
        "Eric Sigler",
        "Mateusz Litwin",
        "Scott Gray",
        "Benjamin Chess",
        "Jack Clark",
        "Christopher Berner",
        "Sam Mccandlish",
        "Alec Radford",
        "Ilya Sutskever",
        "Dario Amodei"
      ],
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b5",
      "title": "A toolbox for representational similarity analysis",
      "authors": [
        "C Nili H Wingfield",
        "Walther A Su",
        "L Marslen-Wilson",
        "W Kriegeskorte",
        "N"
      ],
      "year": "2014",
      "venue": "PLoS Comput Biol",
      "doi": "10.1371/journal.pcbi.1003553"
    },
    {
      "id": "b6",
      "title": "Brains and algorithms partially converge in natural language processing",
      "authors": [
        "Charlotte Caucheteux",
        "Jean-Rémi King"
      ],
      "year": "2022",
      "venue": "Communications Biology",
      "doi": "10.1038/s42003-022-03036-1"
    },
    {
      "id": "b7",
      "title": "Could a machine think?",
      "authors": [
        "Paul M Churchland",
        "Patricia S Churchland"
      ],
      "year": "1990",
      "venue": "Scientific American",
      "doi": ""
    },
    {
      "id": "b8",
      "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019",
      "doi": "10.18653/v1/n19-1423"
    },
    {
      "id": "b9",
      "title": "Rotate king to get queen: Word relationships as orthogonal transformations in embedding space",
      "authors": [
        "Kawin Ethayarajh"
      ],
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "doi": "10.18653/v1/D19-1354"
    },
    {
      "id": "b10",
      "title": "Retrofitting word vectors to semantic lexicons",
      "authors": [
        "Manaal Faruqui",
        "Jesse Dodge",
        "Sujay Kumar Jauhar",
        "Chris Dyer",
        "Eduard Hovy",
        "Noah A Smith"
      ],
      "year": "2015",
      "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "doi": "10.3115/v1/N15-1184"
    },
    {
      "id": "b11",
      "title": "Analogy training multilingual encoders",
      "authors": [
        "Nicolas Garneau",
        "Mareike Hartmann",
        "Anders Sandholm",
        "Sebastian Ruder",
        "Ivan Vulić",
        "Anders Søgaard"
      ],
      "year": "2021",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "doi": "10.1609/aaai.v35i14.17524"
    },
    {
      "id": "b12",
      "title": "Representational similarity analysis -connecting the branches of systems neuroscience",
      "authors": [
        "Nikolaus Kriegeskorte",
        "Marieke Mur",
        "Peter Bandettini"
      ],
      "year": "2008",
      "venue": "Frontiers in Systems Neuroscience",
      "doi": "10.3389/neuro.06.004.2008"
    },
    {
      "id": "b13",
      "title": "Pytorch-biggraph: A large scale graph embedding system",
      "authors": [
        "Adam Lerer",
        "Ledell Wu",
        "Jiajun Shen",
        "Timothee Lacroix",
        "Luca Wehrstedt",
        "Abhijit Bose",
        "Alex Peysakhovich"
      ],
      "year": "2019",
      "venue": "Proceedings of Machine Learning and Systems",
      "doi": ""
    },
    {
      "id": "b14",
      "title": "Implications of the convergence of language and vision model geometries",
      "authors": [
        "Jiaang Li",
        "Yova Kementchedjhieva",
        "Anders Søgaard"
      ],
      "year": "2023",
      "venue": "Implications of the convergence of language and vision model geometries",
      "doi": ""
    },
    {
      "id": "b15",
      "title": "The debate over understanding in ai's large language models",
      "authors": [
        "Melanie Mitchell",
        "David C Krakauer"
      ],
      "year": "2023",
      "venue": "Proceedings of the National Academy of Sciences",
      "doi": "10.1073/pnas.2215907120"
    },
    {
      "id": "b16",
      "title": "Understanding linearity of crosslingual word embedding mappings",
      "authors": [
        "Xutan Peng",
        "Mark Stevenson",
        "Chenghua Lin",
        "Chen Li"
      ],
      "year": "2022",
      "venue": "Transactions on Machine Learning Research",
      "doi": ""
    },
    {
      "id": "b17",
      "title": "Toward a universal decoder of linguistic meaning from brain activation",
      "authors": [
        "Francisco Pereira",
        "Bin Lou",
        "Brianna Pritchett",
        "Samuel Ritter",
        "Samuel J Gershman",
        "Nancy G Kanwisher",
        "Matthew M Botvinick",
        "Evelina Fedorenko"
      ],
      "year": "2018",
      "venue": "Nature Communications",
      "doi": "10.1038/s41467-018-03068-4"
    },
    {
      "id": "b18",
      "title": "Meaning without reference in large language models",
      "authors": [
        "Steven Piantadosi",
        "Felix Hill"
      ],
      "year": "2022",
      "venue": "NeurIPS 2022 Workshop on Neuro Causal and Symbolic AI (nCSI)",
      "doi": ""
    },
    {
      "id": "b19",
      "title": "Language Models are Unsupervised Multitask Learners",
      "authors": [
        "Alec Radford",
        "Jeff Wu",
        "Rewon Child",
        "D Luan",
        "Dario Amodei",
        "Ilya Sutskever"
      ],
      "year": "2019",
      "venue": "Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/ 9405cc0",
      "doi": ""
    },
    {
      "id": "b20",
      "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "authors": [
        "Colin Raffel",
        "Noam Shazeer",
        "Adam Roberts",
        "Katherine Lee",
        "Sharan Narang",
        "Michael Matena",
        "Yanqi Zhou",
        "Wei Li",
        "Peter J Liu"
      ],
      "year": "2020",
      "venue": "Journal of Machine Learning Research",
      "doi": ""
    },
    {
      "id": "b21",
      "title": "The singleton fallacy: Why current critiques of language models miss the point",
      "authors": [
        "Magnus Sahlgren",
        "Fredrik Carlsson"
      ],
      "year": "2021",
      "venue": "Frontiers in Artificial Intelligence",
      "doi": "10.3389/frai.2021.682578"
    },
    {
      "id": "b22",
      "title": "A generalized solution of the orthogonal procrustes problem",
      "authors": [
        "Peter Schönemann"
      ],
      "year": "1966",
      "venue": "Psychometrika",
      "doi": ""
    },
    {
      "id": "b23",
      "title": "How stable is knowledge base knowledge?",
      "authors": [
        "Suhas Shrinivasan",
        "Simon Razniewski"
      ],
      "year": "2022",
      "venue": "How stable is knowledge base knowledge?",
      "doi": "10.48550/arXiv.2211.00989"
    },
    {
      "id": "b24",
      "title": "Cross-Lingual Word Embeddings. Synthesis Lectures on Human Language Technologies",
      "authors": [
        "Anders Søgaard",
        "Ivan Vulić",
        "Sebastian Ruder",
        "Manaal Faruqui"
      ],
      "year": "2019",
      "venue": "Cross-Lingual Word Embeddings. Synthesis Lectures on Human Language Technologies",
      "doi": "10.2200/S00920ED2V01Y201904HLT042"
    },
    {
      "id": "b25",
      "title": "Complex embeddings for simple link prediction",
      "authors": [
        "Théo Trouillon",
        "Johannes Welbl",
        "Sebastian Riedel",
        "Eric Gaussier",
        "Guillaume Bouchard"
      ],
      "year": "2016",
      "venue": "Proceedings of The 33rd International Conference on Machine Learning",
      "doi": ""
    },
    {
      "id": "b26",
      "title": "BERT is to NLP what AlexNet is to CV: Can pre-trained language models identify analogies?",
      "authors": [
        "Asahi Ushio",
        "Luis Espinosa Anke",
        "Steven Schockaert",
        "Jose Camacho-Collados"
      ],
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
      "doi": "10.18653/v1/2021.acl-long.280"
    },
    {
      "id": "b27",
      "title": "Attention is all you need",
      "authors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan N Gomez",
        "Ł Ukasz Kaiser",
        "Illia Polosukhin"
      ],
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "doi": ""
    },
    {
      "id": "b28",
      "title": "Are all good word vector spaces isomorphic?",
      "authors": [
        "Ivan Vulić",
        "Sebastian Ruder",
        "Anders Søgaard"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "doi": "10.18653/v1/2020.emnlp-main.257"
    },
    {
      "id": "b29",
      "title": "KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation",
      "authors": [
        "Xiaozhi Wang",
        "Tianyu Gao",
        "Zhaocheng Zhu",
        "Zhengyan Zhang",
        "Zhiyuan Liu",
        "Juanzi Li",
        "Jian Tang"
      ],
      "year": "2021",
      "venue": "Transactions of the Association for Computational Linguistics",
      "doi": "10.1162/tacl_a_00360"
    },
    {
      "id": "b30",
      "title": "Transformers: State-of-the-art natural language processing",
      "authors": [
        "Thomas Wolf",
        "Lysandre Debut",
        "Victor Sanh",
        "Julien Chaumond",
        "Clement Delangue",
        "Anthony Moi",
        "Pierric Cistac",
        "Tim Rault",
        "Remi Louf",
        "Morgan Funtowicz",
        "Joe Davison",
        "Sam Shleifer",
        "Clara Patrick Von Platen",
        "Yacine Ma",
        "Julien Jernite",
        "Canwen Plu",
        "Teven Xu",
        "Sylvain Le Scao",
        "Mariama Gugger",
        "Quentin Drame",
        "Alexander Lhoest",
        "Rush"
      ],
      "year": "2020",
      "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
      "doi": "10.18653/v1/2020.emnlp-demos.6"
    },
    {
      "id": "b31",
      "title": "Jaket: Joint pretraining of knowledge graph and language understanding",
      "authors": [
        "Donghan Yu",
        "Chenguang Zhu",
        "Yiming Yang",
        "Michael Zeng"
      ],
      "year": "",
      "venue": "AAAI 2022, February 2022",
      "doi": ""
    },
    {
      "id": "b32",
      "title": "Opt: Open pre-trained transformer language models",
      "authors": [
        "Susan Zhang",
        "Stephen Roller",
        "Naman Goyal",
        "Mikel Artetxe",
        "Moya Chen",
        "Shuohui Chen",
        "Christopher Dewan",
        "Mona Diab",
        "Xian Li",
        "Xi Victoria Lin"
      ],
      "year": "",
      "venue": "Opt: Open pre-trained transformer language models",
      "doi": ""
    },
    {
      "id": "b33",
      "title": "GraphVite: A high-performance CPU-GPU hybrid system for node embedding",
      "authors": [
        "Zhaocheng Zhu",
        "Shizhen Xu",
        "Jian Tang",
        "Meng Qu"
      ],
      "year": "2019",
      "venue": "The World Wide Web Conference",
      "doi": "10.1145/3308558.3313508"
    }
  ],
  "sections": [
    {
      "title": "Large Language Models Converge Toward Human-Like Concept Organization",
      "text": "Jonathan Gabel Christiansen Equal contributions Mathias Lykke Gammelaard Department of Computer Science University of Copenhagen Corresponding author: soegaard@di.ku.dk Anders Sogaard Department of Computer Science University of Copenhagen Corresponding author: soegaard@di.ku.dk"
    },
    {
      "title": "Abstract",
      "text": "Large language models show human-like performance in knowledge extraction, reasoning and dialogue, but it remains controversial whether this performance is best explained by memorization and pattern matching, or whether it reflects human-like inferential semantics and world knowledge. Knowledge bases such as WikiData provide large-scale, high-quality representations of inferential semantics and world knowledge. We show that large language models learn to organize concepts in ways that are strikingly similar to how concepts are organized in such knowledge bases. Knowledge bases model collective, institutional knowledge, and large language models seem to induce such knowledge from raw text. We show that bigger and better models exhibit more human-like concept organization, across four families of language models and three knowledge graph embeddings."
    },
    {
      "title": "1 Introduction",
      "text": "The artificial intelligence community is split on the question of whether \"some generative model [i.e., language model] trained only on text, given enough data and computational resources, could understand natural language in some non-trivial sense.\" Half of the community (51%) - according to a recent survey [16] - are willing to attribute non-trivial understanding to large language models (LLMs). The other half of the community (49%) argue that the illusion of understanding is the result of an Eliza effect.2 The research question, as formulated by Mitchell and Krakauer [16], is: Footnote 2: One famous example of this view is an article by Emily Bender and colleagues [1], who argue that these models are simply _stochastic parrots_ that ‘habhazardly stitch together sequences of linguistic forms’ without any true understanding of the world or context. \"do these systems (or will their near-term successors) actually, even in the absence of physical experience, create something like the rich concept-based mental models that are central to human understanding, and, if so, does scaling these models create even better concepts?\" We present a series of experiments designed to answer this question directly. Our findings suggest (very strongly) that the models (representations) induced by larger and better LLMs become more and more human-like."
    },
    {
      "title": "Contributions",
      "text": "We present a series of experiments with four families of LLMs (21 models), as well as three knowledge graph embedding algorithms. Using three different methods, we compare the vector spaces of the LLMs to the vector spaces induced by the graph embedding algorithms. (This amounts to a total of 220 experiments.) We find that the vector spaces of LLMs within each family become increasingly structurally similar to those of knowledge graph embeddings. This shows that LLMs partially converge on human-like concept organization, facilitating inferential semantics [19].3 The sample efficiency of this convergence seem to depend on a number of factors, including polysemy and semantic category. Our findings have important implications. They vindicate the conjecture in [19] that LLMs exhibit inferential semantics, settling the research question presented in [16], cited above. This means that LLMs partially converge toward human-like concept representations and, thus, come to partially 'understand language', in a non-trivial sense. We speculate that the human-like conceptual organization is also what facilitates out-of-distribution inferences in LLMs. Footnote 3: We use ‘converge’ in the sense of Caucheteux and King [7]."
    },
    {
      "title": "2 Experiments",
      "text": ""
    },
    {
      "title": "Language Models",
      "text": "We evaluate the vector spaces induced by four well-known families of language models, conducting experiments with a total of 20 different transformer-based models, as well as a baseline static word vector space. The four families are OPT [33], GPT-2 [20], and Pythia [2] (non-deduplicated version at model checkpoint step 143000) and BERT [9].4 We also evaluated the vector space of GPT-3 [5], i.e., _text-embedding-ada-002_.5 Transformer-based LLMs use multiple layers of self-attention [28] and can model complex interactions across large context windows. Both left and right context can be considered. GPT, OPT and Pythia are decoder-only autoregressive LLMs, however, and thus only consider left context, i.e., the words preceding the next token. BERT is an encoder-only non-autoregressive LLM and considers both left and right context of the masked token to be predicted. Transformers are in general considered state-of-the-art for most NLP tasks [31]. For each of the language model families, we consider variants with increasing size in terms of the number of model parameters. See Table 1 for a model overview. Footnote 4: We also evaluated the TS [21] LM series. T5 is trained with a multi-task objective, leading to mixed results. Footnote 5: [https://platform.openai.com/docs/guides/embeddings/what-are-embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)"
    },
    {
      "title": "Knowledge Graph Embeddings",
      "text": "We experiment with three graph embedding algorithms and the vector spaces induced by running these on large-scale knowledge bases. Figure 1: A simplified sketch of our experimental protocol. A vocabulary of 20K words is encoded using a language model and the corresponding entities are fetched from a pre-trained graph embedding system. The resulting vector spaces are then aligned. After alignment we evaluate retrieval performance in the target vector space. If retrieval performance is perfect, the spaces are (nearest neighbor graph) isomorphic."
    },
    {
      "title": "2.2.1 Biggraph",
      "text": "The first vector space is that of the so-called _BigGraph_ embeddings [14]. BigGraph is trained on an input knowledge graph, i.e. a list of edges, identified by its' source and target entities and a relation type. The network output is a feature vector or embedding for every entity in the graph. An inherent quality of this method is that adjacent entities are placed close to each other in the vector space. The particular embeddings used in this work are obtained by pre-training on WikiData, a well-known knowledge base6. Knowledge bases like Wikidata provide a structured representation of the real-world [24] and encode implicit world knowledge. The BigGraph embeddings contain all entities from the _\"truthy\"_ Wikidata dump (2019-03-06) and thus includes URLs, dates etc; which are not (directly) included in language model vocabularies. To ensure comparability between the vector spaces, we limit ourselves to _single word_ BigGraph entities. From these single word entities we pick \\(20,000\\) common English words.7 Footnote 6: [https://nexubiggraph.readthedocs.io/en/latest/pretrained_embeddings.html](https://nexubiggraph.readthedocs.io/en/latest/pretrained_embeddings.html) Footnote 7: [https://github.com/tnc20hours/google-10000-engils/blob/master/2k.txt](https://github.com/tnc20hours/google-10000-engils/blob/master/2k.txt)"
    },
    {
      "title": "2.2.2 Graphvite",
      "text": "Our second and third knowledge base-derived vector spaces were both obtained by the GraphVite graph embedding algorithm [34]. We use the following pre-trained models; _TransE_[4] and _CompLex_[26], both of which are pre-trained on WikiData5m [30]. We use the same entities presented in SS2.2.1."
    },
    {
      "title": "Graph Isomophism",
      "text": "An isomorphism from \\(G_{1}=(V_{1},E_{1})\\) to \\(G_{2}=(V_{2},E_{2})\\) is a bijection \\(f:V_{1}\\to V_{2}\\) such that any pair of nodes \\(a\\) and \\(b\\) are joined by an edge iff \\(f(a)\\) and \\(f(b)\\) are joined by an edge. Near-isomorphism of graphs refers to the situation where two graphs are not exactly isomorphic but exhibit strong structural similarity. Note that if the nearest neighbor graphs of two embedding spaces are isomorphic, there exists a vector space mapping with precision@1 of 1.0; see SS2.7 for details on how to compute precision@1. We will evaluate to what extent (the \\(k\\)-nearest neighbor graphs of the) LLM vector spaces are isomorphic to the knowledge graph embeddings, by computing representational similarity analysis scores, as well as by evaluating the precision@\\(k\\) of linear projections."
    },
    {
      "title": "Linear Projections",
      "text": "We present two distinct methods of mapping (or projecting) the vector space of an LLM to the vector space of BigGraph (BG) and GraphVite (GV). Let \\(\\mathbf{M}_{\\text{LM}}\\in\\mathbf{R}^{V\\times d_{\\text{ref}}}\\) be a matrix of word embeddings and \\(\\mathbf{M}_{\\text{REF}}\\in\\mathbf{R}^{V\\times d_{\\text{ref}}}\\) a matrix of knowledge graph node embeddings, where \\(V\\) denotes the size of the vocabulary, \\(d_{\\text{e}}\\) the dimensionality of the word embeddings for a given language model and \\(d_{\\text{ref}}\\) refers to dimensionality of the knowledge graph embeddings, with \\(d_{\\text{ref}}=200\\) for BG and \\(d_{\\text{ref}}=512\\) for GV. Our first approach is to use generalized Procrustes analysis [23] to align \\(\\mathbf{M}_{\\text{LM}}\\) with \\(\\mathbf{M}_{\\text{REF}}\\). Since this method enforces \\(d_{e}=d_{\\text{ref}}\\), we use PCA to reduce the dimensionality of \\(\\mathbf{M}_{\\text{LM}}\\) to the desired size. The aim of Procrustes analysis is thus to find a transformation matrix \\(\\mathbf{\\Omega}\\) that minimizes the sum of squared distance between each pair of word embeddings in \\(\\mathbf{M}_{\\text{LM}}\\) with \\(\\mathbf{M}_{\\text{REF}}\\). This is achieved by \\begin{table} \\begin{tabular}{l l l l l l l l} \\hline **LM** & **Params** & **LM** & **Params** & **LM** & **Params** & **LM** & **Params** \\\\ \\hline OPT-12SM & 125M & GPT-2 small & 117M & Pythia-70M & 70M & BERT-7mv & 4.4M \\\\ OPT-250M & 350M & GPT-2 medium & 345M & Pythia-160M & 160M & BERT-7mN & 11.3M \\\\ OPT-13B & 1.3B & GPT-2 large & 774M & Pythia-410M & 410M & BERT-SMALL & 29.1M \\\\ OPT-2.7B & 2.7B & GPT-2xl & 1.5B & Pythia-11B & 1B & BERT-MEDIUM & 41.7M \\\\ OPT-6.7B & 6.7B & GPT-3 Ada-002 & 175B & Pythia-2.8B & 2.8B & BERT-BASE & 110.1M \\\\ & & & Pythia–6.9B & 6.9B & & \\\\ \\hline \\end{tabular} \\end{table} Table 1: 21 transformer-based language models used in this experiment. solving the following problem: \\[\\min_{\\mathbf{\\Omega}=s\\mathbf{\\Lambda}}||\\mathbf{\\Omega}\\mathbf{M}_{\\text{LM}}- \\mathbf{M}_{\\text{BF}}||_{F}^{2}\\] \\[s\\in\\mathbf{R}^{+},~{}\\mathbf{A}\\in\\mathbf{R}^{d_{e}\\times d_{e}} \\text{ s.t. }\\mathbf{A}^{\\mathbf{T}}\\mathbf{A}=\\mathbf{I}\\] Where \\(F\\) denotes the Frobenius norm and we have that \\(\\mathbf{\\Omega}\\) can be computed using singular value decomposition. In practice, we compute \\(\\mathbf{\\Omega}\\) using a subset of the full vocabulary; \\(V_{\\text{train}}\\). Secondly, we propose utilizing \\(d_{\\text{ref}}\\) ridge regression models \\(f_{i}\\) for \\(i=1,2,..,d_{\\text{ref}}\\), with one predictor for each dimension of the reference vector space. Each predictor \\(f_{i}\\) is trained on a subset of the full vocabulary \\(V_{\\text{train}}\\) and learns a function \\(f_{i}:\\mathbf{R}^{d_{e}}\\rightarrow\\left\\{\\mathbf{R}\\right\\}_{j}\\), for \\(j=1,2,..,d_{\\text{ref}}\\), where \\(j\\) indicates the \\(j\\)'th dimension of the reference vector space. The ridge regression models are re-trained for each language model as \\(d_{e}\\) varies across these. Once trained, the models can be used to project the remaining vocabulary \\(V_{\\text{test}}\\). The methodology of using a separate ridge regression model for each dimension of the reference/target vector space has previously been used to decode linguistic meaning from brain activation [18]."
    },
    {
      "title": "Representational Similarity Analysis",
      "text": "To further gauge the similarity of the vector spaces induced by LLMs and knowledge graph embeddings, we present experiments using Representational Similarity Analysis (RSA) [6]. For a given language model we consider the matrix \\(\\mathbf{M}_{\\text{LM}}\\) of word embeddings alongside the corresponding matrix \\(\\mathbf{M}_{\\text{REF}}\\). We compute the representational dissimilarity matrices (RDMs); i.e. for each word embedding in each of the matrices we compute the euclidean distance to all other word embeddings within that respective matrix, thus generating two \\(V\\times V\\) RDMs. Once the RDMs has been computed (denote them \\(r_{1}\\) and \\(r_{2}\\)), they are then compared used cosine similarity: \\[\\text{cos}(r_{1},r_{2})=\\frac{r_{1}^{T}r_{2}}{\\sqrt{r_{1}^{T}r_{1}r_{2}^{2}r_ {2}}}\\] A cosine similarity close to 1.0 will indicate \\(\\mathbf{M}_{\\text{LM}}\\) more closely resembles \\(\\mathbf{M}_{\\text{BF}}\\). Note that we flatten the RDMs in practice, to get a single value as a final metric. Representational similarity analysis is a well-known method within neuroscience, see for instance [13]."
    },
    {
      "title": "Analogies",
      "text": "Finally, we carry out experiments using the WiQueen analogy dataset [12]. The dataset consists of quadruples <\\(w_{1},w_{2},w_{3},w_{4}\\)> of analogies, e.g. <_Hefei,Anhui,Guiyang,Guizhou>_ which corresponds to the analogy _\"Hefei is to Anhui, as Guiyang is to Guizhou.\"_. We encode the individual words from the analogies using each of the language models, thus obtaining a new quadruple <\\(e_{1},e_{2},e_{3},e_{4}\\)> of word embeddings for each analogy and language model. We then proceed to _\"solve\"_ the analogy mathematically by computing \\(e_{1}-e_{2}+e_{3}=e_{\\text{new}}\\)[10]. Finally, we compare \\(e_{\\text{new}}\\) to \\(e_{4}\\), by checking if \\(e_{\\text{new}}\\) and \\(e_{4}\\) are nearest neighbors in the WiQueen vector space. Note how for an LLM vector space to solve the analogy task (completely) is equivalent to being (nearest neighbor graph) isomorphic to the underlying knowledge base [17]."
    },
    {
      "title": "Evaluation",
      "text": "For the experiments in which we induce a linear mapping \\(\\mathbf{\\Omega}\\) and \\(f(\\mathbf{M}_{\\text{LM}})\\) between the vector spaces of LLMs and BigGraph/GraphVite, we evaluate how close \\(\\mathbf{M}_{\\text{LM}}\\mathbf{\\Omega}\\) and \\(f(\\mathbf{M}_{\\text{LM}})\\) is to \\(\\mathbf{M}_{\\text{REF}}\\) using precision@\\(k\\) as our performance metric.8 That is, for each word \\(w\\) in \\(V_{\\text{test}}\\), we perform k-nearest neighbors of the corresponding word embedding contained within the projection of \\(\\mathbf{M}_{\\text{LM}}\\) in the reference vector space. If \\(w\\) is found among the k-nearest neighbors in the reference vector space, we say that the precision at \\(k\\) (p@k) is 100%. The final precision is then scored as an average over all words in \\(V_{\\text{test}}\\). Note that for all values of \\(k\\) this will either be a _\"hit\"_ or a _\"miss\"_ as there is only one relevant item to retrieve. The full vocabulary \\(V\\) contains 20,000 words and is split into \\(V_{\\text{train}}\\) and \\(V_{\\text{test}}\\) at 80%/20% respectively, which makes a random retrieval baseline \\(\\texttt{P@1}=\\frac{1}{4000}\\). In practice, our linear projections are found to be significantly more precise, which in turn reflects the growing resemblance between the vector spaces of increasingly larger language models and the vector spaces of the knowledge graph embeddings induced by the BigGraph/GraphVite graph embedding algorithms. Note that for the experiment involving analogies, we do not use a reference vector space, but instead evaluate the retrieval directly using the WiQueen data set. For the representational similarity analysis, we simply use the cosine similarity between the RDM of each language model and the RDM of BigGraph/GraphVite as the performance metric."
    },
    {
      "title": "3 Results",
      "text": ""
    },
    {
      "title": "Procrustes Analysis",
      "text": "We report alignment precision (p@k) for \\(k\\in\\{1,10,20,50\\}\\), with our main results depicted in Figure 2. The plots show the convergence results, i.e. the relationship between language model size and alignment precision. For all four model families, we see a consistent trend, where larger language models lead to better alignments with the reference vector spaces. Overall, GPT appears to have the most pronounced convergence properties. Note that the different graph embeddings heavily influence the precision, but that the _trend_ is similar across graph embedding systems. For our best performing model GPT-3 (ada-002) projected onto the vector space of GraphVite (TransE) using Procrustes analysis, we observe a P@50 beyond 60%, which in turn means that more than 6/10 words are mapped to a relatively small neighborhood of 50 words out of a total of 4000 words in \\(V_{\\text{test}}\\). This, in our view, constitutes strong evidence that LLMs learn human-like concept organizations. Figure 2: Plot labels: \\(k=1\\), \\(k=10\\), \\(k=20\\), \\(k=50\\). Projection onto the vector space of BigGraph (1st row), ComplEx (2nd row) and TransE (3rd row) using **generalized Procrustes analysis** and retrieval performance p@k at \\(k=\\{1,10,20,50\\}\\) for 4 language model families. We see results up to p@50\\(\\sim\\)0.7, and strong, positive convergence (almost) across the board."
    },
    {
      "title": "Ridge Regression",
      "text": "As a secondary projection method we train \\(d_{\\text{ref}}\\) ridge regression predictors, i.e. one for each dimension of the reference vector space. These predictors are then used to project the remaining vocabulary of word embeddings \\(V_{\\text{test}}\\) for a given language model to the reference vector space. After this, retrieval can be conducted. The retrieval performance for \\(k=\\{1,10,20,50\\}\\) and all four model families can be found in figure 3. The results share some characteristics with those presented in SS3.1, but in some cases performance drops for the families' largest models (e.g. OPT-6.7B and Ada-002), presumably because of poor signal-to-noise ratios in the extra dimensions, which, in Procrustes Analysis, are removed through principal component analysis."
    },
    {
      "title": "Analogies",
      "text": "Figure 4 shows the results of the four series of language models on the WiQueen data set. Again, we observe a consistent upward trend for all four model families. Note that this experiment more closely resembles a real-world task for a language model, as analogies play a central role in human commonsense reasoning [27]. The trends shown in figure 4 are in tune with those presented in SS3.1-3.2 and thus expands the evidence to support our arguments to more realistic use cases of language models."
    },
    {
      "title": "Representational Similarity Analysis",
      "text": "The results of the representational similarity analysis for all four language model families can be found in the supplementary material. The partial convergence results are similar to those obtained with linear projection. Figure 3: Plot labels: \\(k=1\\), \\(k=10\\), \\(k=20\\), \\(k=50\\). Projection onto the vector space of BigGraph (1st row), ComplEx (2nd row) and TransE (3rd row) using **ridge regression** and retrieval performance **p@k** at \\(k=\\{1,10,20,50\\}\\) for 4 language model families. We see strong, positive convergence, except for the GPT-3 results. [MISSING_PAGE_FAIL:7] performance. Specifically that anthroponyms has a relatively low max slope coefficient, suggesting slow convergence properties while the language model size grows. In addition to this, we observe that the _places_ (i.e. world cities) has a substantially higher positive rate, than other categories considered, which indicates that large language models might have better internal representations of some concepts compared to others."
    },
    {
      "title": "Analogies",
      "text": "Usho et al. (2017) investigated how well LLMs such as GPT are able to solve analogies. They obtained the best results using GPT. This aligns well with our finding that GPT-{2,3} has solid convergence properties and obtained the overall best results; see Figure 4."
    },
    {
      "title": "5 Discussion",
      "text": "We have seen that language models converge on human-like concept organizations. How surprising is this? Given the contentious debate around whether large language models 'understand' (Sundundur et al., 2016), including whether they induce models of knowledge, our result is important. Large language models do not only learn to use patterns in context, but as a result, they induce compressed models of knowledge. In retrospect, it is also clear, however, that some results, e.g., the near-isomorphism of word vector spaces across languages (Kang et al., 2017) or the near-isomorphism with representations from computer vision (Kang et al., 2018), already pointed in this direction. Language models for different languages likely learn similar concept geometries, because they induce models of (our knowledge of) the world. Language and computer vision models, in a similar way, share one reference, namely, the world we live in, and what we know about it. \\begin{table} \\begin{tabular}{l l l l l l l l} \\hline \\hline \\multicolumn{2}{l}{**Polysemy**} & \\multicolumn{6}{c}{**Semantic category**} \\\\ \\hline **Variable** & **\\% positive** & **Max coeff.** & **SD** & **Variable** & **\\% positive** & **Max coeff.** & **SD** \\\\ \\hline 1 & 0.812 & 0.172 & 0.038 & Common & 0.938 & 0.151 & 0.029 \\\\ 2-3 & 0.792 & 0.145 & 0.032 & Places & 1.0 & 0.105 & 0.020 \\\\ 4+ & 0.771 & 0.129 & 0.028 & Names & 0.917 & 0.061 & 0.013 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 2: The effect of polysemy and word classes on the convergence trend. _Common_ refer to common english words (i.e. those presented in §2.2.1). \\begin{table} \\begin{tabular}{l l l l l l l l l} \\hline \\hline \\multirow{2}{*}{**Models**} & \\multirow{2}{*}{**Polysemy**} & \\multicolumn{2}{c}{**BigGraph**} & \\multicolumn{2}{c}{**TrankF**} & \\multicolumn{2}{c}{**CompEx**} & \\multicolumn{2}{c}{**Semantic**} & \\multicolumn{2}{c}{**BigGraph**} & \\multicolumn{2}{c}{**TrankF**} \\\\ & & **P@50** & **P@50** & **P@50** & **category** & **P@50** & **P@50** & **P@50** \\\\ \\hline \\multirow{3}{*}{OPT-6.7b} & 1 & **0.595** & **0.748** & **0.590** & Common & 0.203 & **0.529** & **0.444** \\\\ & 2-3 & 0.490 & 0.680 & 0.483 & Places & **0.299** & 0.382 & 0.325 \\\\ & 4+ & 0.385 & 0.610 & 0.435 & Names & 0.210 & 0.264 & 0.222 \\\\ \\hline \\multirow{3}{*}{ADA-002} & 1 & **0.610** & **0.813** & **0.618** & Common & 0.276 & **0.651** & **0.478** \\\\ & 2-3 & 0.520 & 0.760 & 0.528 & Places & **0.373** & 0.465 & 0.367 \\\\ & 4+ & 0.423 & 0.675 & 0.450 & Names & 0.285 & 0.329 & 0.250 \\\\ \\hline \\multirow{3}{*}{Pythia-6.9b} & 1 & **0.495** & **0.538** & **0.478** & Common & 0.126 & **0.235** & **0.228** \\\\ & 2-3 & 0.373 & 0.488 & 0.410 & Places & **0.190** & 0.204 & 0.188 \\\\ & 4+ & 0.323 & 0.348 & 0.310 & Names & 0.145 & 0.150 & 0.139 \\\\ \\hline \\multirow{3}{*}{BERT-BASE} & 1 & **0.533** & **0.785** & **0.578** & Common & 0.239 & **0.508** & **0.393** \\\\ & 2-3 & 0.425 & 0.688 & 0.505 & Places & **0.350** & 0.359 & 0.322 \\\\ & 4+ & 0.320 & 0.538 & 0.448 & Names & 0.259 & 0.228 & 0.198 \\\\ \\hline \\hline \\end{tabular} \\end{table} Table 3: Effect of polysemy and semantic category on the largest model from each model family. Procrustes is used as the projection method. Note that a low level of lexical ambiguity leads to better performance and that the best performing semantic category varies across the reference vector spaces."
    },
    {
      "title": "Practical Implications",
      "text": "There has already been considerable work on grounding language models in knowledge bases. This work often has focused on algorithms for joint language and graph embedding [32]. Our work suggests that similar results can be obtained with'retro-fitting' [11], i.e., fine-tuning the language models to improve existing similarities. See, for example, the approach taken by [12]. Our results also suggest, however, that in the limit, perhaps grounding in knowledge bases will become redundant. The systematicity of human-like conceptual organization in language models seemingly facilitates out-of-distribution capacities, e.g., enabling analogical inference."
    },
    {
      "title": "Philosophical Implications",
      "text": "Our results clearly show that language models induce inferential semantics [22; 19]. This, we believe, settles the debate about the capacities of large language models [16]. Our results also, however, question the divide between syntax and semantics [8]. Semantics, in a way, seems to fall out of syntax. Clearly, our results have no bearing on intentionality (the aboutness of mental tokens), but they do suggest one way syntactic tokens acquire semantics."
    },
    {
      "title": "6 Limitations",
      "text": "We have experimented with three families of autoregressive language models and one non-autoregressive family. We have compared the word vector spaces induced by such models with three vector spaces induced by graph embedding algorithms over large knowledge bases. All our experiments have been limited to English. This, of course, is a major limitation. Language characteristics may effect the quality of word vector spaces, and morpho-syntactic properties may influence how corpora and knowledge bases align. Finally, while we do error analysis over polysemy and semantic categories, we acknowledge that the set of variables that covary with performance, is probably much larger."
    },
    {
      "title": "7 Conclusion",
      "text": "This paper weighs in on the debate around understanding in large language models and show how large language models converge toward human-like concept organization, building implicit models of the world (as we know it). Over 220 experiments, we show how language models converge toward human-like concept organization, with particularly strong similarities in how monosemous and common words are encoded. Our observations have important practical and philosophical implications, providing a possible explanation for the out-of-distribution capacities of large language models and settling the above debate."
    },
    {
      "title": "8 Computational Requirements",
      "text": "A Google Colab Pro+ subscription or similar (\\(\\geq 52\\)GB RAM) is required in order to reproduce our experiments. We used an NVIDIA V100 and A100 Tensor Core GPU, provided by Google Colab."
    },
    {
      "title": "9 Acknowledgement",
      "text": ""
    },
    {
      "title": "References",
      "text": "* ACM. doi: 10.1145/3442188.3445922. URL [https://dl.acm.org/doi/10.1145/3442188.3445922](https://dl.acm.org/doi/10.1145/3442188.3445922). * Biderman et al. [2021] Stella Biderman, Hailey Schoelkopf, Quentin Anthony, Herbie Bradley, Kyle O'Brien, Eric Hallahan, Mohammad Afah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff,Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. Pythia: A suite for analyzing large language models across training and scaling, 2023. * Bird et al. [2009] Steven Bird, Ewan Klein, and Edward Loper. _Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit_. O'Reilly, Beijing, 2009. ISBN 978-0-596-51649-9. doi: [http://my.safaribooksonline.com/9780596516499](http://my.safaribooksonline.com/9780596516499). URL [http://www.nltk.org/book](http://www.nltk.org/book). * Volume 2_, NIPS'13, page 2787-2795, Red Hook, NY, USA, 2013. Curran Associates Inc. * Brown et al. [2020] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alex Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, _Advances in Neural Information Processing Systems_, volume 33, pages 1877-1901. Curran Associates, Inc., 2020. URL [https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf). * Wingfield et al. [2014] Nili H Wingfield C, Walther A, Su L, Marslen-Wilson W, and Kriegeskorte N. A toolbox for representational similarity analysis. _PLoS Comput Biol._, 13(4):e1005508, 2014. doi: 10.1371/journal.pcbi.1003553. URL [https://EconPapers.repec.org/RePEc:spr:psycho:v:31:y:1966:i:1:p:1-10](https://EconPapers.repec.org/RePEc:spr:psycho:v:31:y:1966:i:1:p:1-10). * Caucheteux and King [2022] Charlotte Caucheteux and Jean-Remi King. Brains and algorithms partially converge in natural language processing. _Communications Biology_, 5:134, 02 2022. doi: 10.1038/s42003-022-03036-1. * Churchland and Churchland [1990] Paul M. Churchland and Patricia S. Churchland. Could a machine think? _Scientific American_, 262 1:32-7, 1990. * Devlin et al. [2019] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, _Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)_, pages 4171-4186. Association for Computational Linguistics, 2019. doi: 10.18653/v1/n19-1423. URL [https://doi.org/10.18653/v1/n19-1423](https://doi.org/10.18653/v1/n19-1423). * Ethayarajh [2019] Kawin Ethayarajh. Rotate king to get queen: Word relationships as orthogonal transformations in embedding space. In _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)_, pages 3503-3508, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1354. URL [https://aclanthology.org/D19-1354](https://aclanthology.org/D19-1354). * Faruqui et al. [2015] Manaal Faruqui, Jesse Dodge, Sujay Kumar Jauhar, Chris Dyer, Eduard Hovy, and Noah A. Smith. Retrofitting word vectors to semantic lexicons. In _Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_, pages 1606-1615, Denver, Colorado, May-June 2015. Association for Computational Linguistics. doi: 10.3115/v1/N15-1184. URL [https://aclanthology.org/N15-1184](https://aclanthology.org/N15-1184). * Garneau et al. [2021] Nicolas Garneau, Mareike Hartmann, Anders Sandholm, Sebastian Ruder, Ivan Vulic, and Anders Sogaard. Analogy training multilingual encoders. _Proceedings of the AAAI Conference on Artificial Intelligence_, 35(14):12884-12892, May 2021. doi: 10.1609/aaai.v35i14.17524. URL [https://ojs.aaai.org/index.php/AAAI/article/view/17524](https://ojs.aaai.org/index.php/AAAI/article/view/17524). - connecting the branches of systems neuroscience. _Frontiers in Systems Neuroscience_, 2, 2008. ISSN 1662-5137. doi: 10.3389/neuro.06.004.2008. URL [https://www.frontiersin.org/articles/10.3389/neuro.06.004.2008](https://www.frontiersin.org/articles/10.3389/neuro.06.004.2008). * Lerer et al. [2019] Adam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt, Abhijit Bose, and Alex Peysakhovich. Pytorch-biggraph: A large scale graph embedding system. In A. Talwalkar, V. Smith, and M. Zaharia, editors, _Proceedings of Machine Learning and Systems_, volume 1, pages 120-131, 2019. URL [https://proceedings.mlsys.org/paper_files/paper/2019/file/e2c420d928d4bf8ceOff2ec19b371514-Paper.pdf](https://proceedings.mlsys.org/paper_files/paper/2019/file/e2c420d928d4bf8ceOff2ec19b371514-Paper.pdf). * Li et al. [2023] Jiaang Li, Yova Kementchedjhieva, and Anders Sogaard. Implications of the convergence of language and vision model geometries, 2023. * Mitchell and Krakauer [2023] Melanie Mitchell and David C. Krakauer. The debate over understanding in ai's large language models. _Proceedings of the National Academy of Sciences_, 120(13):e2215907120, 2023. doi: 10.1073/pnas.2215907120. URL [https://www.pnas.org/doi/abs/10.1073/pnas.2215907120](https://www.pnas.org/doi/abs/10.1073/pnas.2215907120). * Peng et al. [2022] Xutan Peng, Mark Stevenson, Chenghua Lin, and Chen Li. Understanding linearity of cross-lingual word embedding mappings. _Transactions on Machine Learning Research_, 2022. ISSN 2835-8856. URL [https://openreview.net/forum?id=8HuyXvbvqX](https://openreview.net/forum?id=8HuyXvbvqX). * Pereira et al. [2018] Francisco Pereira, Bin Lou, Brianna Pritchett, Samuel Ritter, Samuel J. Gershman, Nancy G. Kanwisher, Matthew M. Botvinick, and Evelina Fedorenko. Toward a universal decoder of linguistic meaning from brain activation. _Nature Communications_, 9, 03 2018. doi: 10.1038/s41467-018-03068-4. URL [https://www.nature.com/articles/s41467-018-03068-4](https://www.nature.com/articles/s41467-018-03068-4). * Piantadosi and Hill [2022] Steven Piantadosi and Felix Hill. Meaning without reference in large language models. In _NeurIPS 2022 Workshop on Neuro Causal and Symbolic AI (nCSI)_, 2022. URL [https://openreview.net/forum?id=nRxJEWzmFM](https://openreview.net/forum?id=nRxJEWzmFM). * Radford et al. [2019] Alec Radford, Jeff Wu, Rewon Child, D. Luan, Dario Amodei, and Ilya Sutskever. Language Models are Unsupervised Multitask Learners. 2019. URL [https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe](https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe). * Raffel et al. [2020] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. _Journal of Machine Learning Research_, 21(140):1-67, 2020. URL [http://jmlr.org/papers/v21/20-074.html](http://jmlr.org/papers/v21/20-074.html). * Sahlgren and Carlsson [2021] Magnus Sahlgren and Fredrik Carlsson. The singleton fallacy: Why current critiques of language models miss the point. _Frontiers in Artificial Intelligence_, 4, 2021. ISSN 2624-8212. doi: 10.3389/frai.2021.682578. URL [https://www.frontiersin.org/articles/10.3389/frai.2021.682578](https://www.frontiersin.org/articles/10.3389/frai.2021.682578). * Schonemann [1966] Peter Schonemann. A generalized solution of the orthogonal procrustes problem. _Psychometrika_, 31(1):1-10, 1966. URL [https://EconPapers.repec.org/RePEc:spr:psycho:v:31:y:1966:i:1:p:1-10](https://EconPapers.repec.org/RePEc:spr:psycho:v:31:y:1966:i:1:p:1-10). * Shrinivasan and Razniewski [2022] Suhas Shrinivasan and Simon Razniewski. How stable is knowledge base knowledge? _CoRR_, abs/2211.00989, 2022. doi: 10.48550/arXiv.2211.00989. URL [https://doi.org/10.48550/arXiv.2211.00989](https://doi.org/10.48550/arXiv.2211.00989). * Sogaard et al. [2019] Anders Sogaard, Ivan Vulic, Sebastian Ruder, and Manaal Faruqui. _Cross-Lingual Word Embeddings_. Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers, United States, 2 edition, 2019. doi: 10.2200/S00920ED2V01Y201904HLT042. * Trouillon et al. [2016] Theo Trouillon, Johannes Welbl, Sebastian Riedel, Eric Gaussier, and Guillaume Bouchard. Complex embeddings for simple link prediction. In Maria Florina Balcan and Kilian Q. Weinberger, editors, _Proceedings of The 33rd International Conference on Machine Learning_, volume 48 of _Proceedings of Machine Learning Research_, pages 2071-2080, New York, New York, USA, 20-22 Jun 2016. PMLR. URL [https://proceedings.mlr.press/v48/trouillon16.html](https://proceedings.mlr.press/v48/trouillon16.html). * Ushio et al. [2021] Asahi Ushio, Luis Espinosa Anke, Steven Schockaert, and Jose Camacho-Collados. BERT is to NLP what AlexNet is to CV: Can pre-trained language models identify analogies? In _Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)_, pages 3609-3624, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.280. URL [https://aclanthology.org/2021.acl-long.280](https://aclanthology.org/2021.acl-long.280). * Vaswani et al. [2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, L ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 30. Curran Associates, Inc., 2017. URL [https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf). * Vulic et al. [2020] Ivan Vulic, Sebastian Ruder, and Anders Sogaard. Are all good word vector spaces isomorphic? In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)_, pages 3178-3192, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.257. URL [https://aclanthology.org/2020.emnlp-main.257](https://aclanthology.org/2020.emnlp-main.257). * Wang et al. [2021] Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan Zhang, Zhiyuan Liu, Juanzi Li, and Jian Tang. KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation. _Transactions of the Association for Computational Linguistics_, 9:176-194, 03 2021. ISSN 2307-387X. doi: 10.1162/tacl_a_00360. URL [https://doi.org/10.1162/tacl_a_00360](https://doi.org/10.1162/tacl_a_00360). * Wolf et al. [2020] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. Transformers: State-of-the-art natural language processing. In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations_, pages 38-45, Online, October 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-demos.6. URL [https://aclanthology.org/2020.emnlp-demos.6](https://aclanthology.org/2020.emnlp-demos.6). * Yu et al. [2022] Donghan Yu, Chenguang Zhu, Yiming Yang, and Michael Zeng. Jaket: Joint pre-training of knowledge graph and language understanding. In _AAAI 2022_, February 2022. URL [https://www.microsoft.com/en-us/research/publication/jaket-joint-pre-training-of-knowledge-graph-and-language-understanding/](https://www.microsoft.com/en-us/research/publication/jaket-joint-pre-training-of-knowledge-graph-and-language-understanding/). * Zhang et al. [2022] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open pre-trained transformer language models. _arXiv preprint arXiv:2205.01068_, 5 2022. URL [https://arxiv.org/abs/2205.01068](https://arxiv.org/abs/2205.01068). * Zhu et al. [2019] Zhaocheng Zhu, Shizhen Xu, Jian Tang, and Meng Qu. GraphVite: A high-performance CPU-GPU hybrid system for node embedding. In _The World Wide Web Conference_. ACM, may 2019. doi: 10.1145/3308558.3313508. URL [https://doi.org/10.1145.2F3308558.3313508](https://doi.org/10.1145.2F3308558.3313508)."
    }
  ]
}